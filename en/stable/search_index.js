var documenterSearchIndex = {"docs": [

{
    "location": "#",
    "page": "Home",
    "title": "Home",
    "category": "page",
    "text": ""
},

{
    "location": "#Julia-Documentation-1",
    "page": "Home",
    "title": "Julia Documentation",
    "category": "section",
    "text": ""
},

{
    "location": "#Manual-1",
    "page": "Home",
    "title": "Manual",
    "category": "section",
    "text": "Introduction\nGetting Started\nVariables\nIntegers and Floating-Point Numbers\nMathematical Operations and Elementary Functions\nComplex and Rational Numbers\nStrings\nFunctions\nControl Flow\nScope of Variables\nTypes\nMethods\nConstructors\nConversion and Promotion\nInterfaces\nModules\nDocumentation\nMetaprogramming\nMulti-dimensional Arrays\nLinear Algebra\nNetworking and Streams\nParallel Computing\nDate and DateTime\nRunning External Programs\nCalling C and Fortran Code\nHandling Operating System Variation\nEnvironment Variables\nInteracting With Julia\nEmbedding Julia\nPackages\nProfiling\nStack Traces\nPerformance Tips\nWorkflow Tips\nStyle Guide\nFrequently Asked Questions\nNoteworthy Differences from other Languages\nUnicode Input"
},

{
    "location": "#Standard-Library-1",
    "page": "Home",
    "title": "Standard Library",
    "category": "section",
    "text": "Essentials\nCollections and Data Structures\nMathematics\nNumbers\nStrings\nArrays\nTasks and Parallel Computing\nLinear Algebra\nConstants\nFilesystem\nI/O and Network\nPunctuation\nSorting and Related Functions\nPackage Manager Functions\nDates and Time\nIteration utilities\nUnit Testing\nC Interface\nC Standard Library\nDynamic Linker\nProfiling\nStackTraces\nSIMD Support"
},

{
    "location": "#Developer-Documentation-1",
    "page": "Home",
    "title": "Developer Documentation",
    "category": "section",
    "text": "Reflection and introspection\nDocumentation of Julia\'s Internals\nInitialization of the Julia runtime\nJulia ASTs\nMore about types\nMemory layout of Julia Objects\nEval of Julia code\nCalling Conventions\nHigh-level Overview of the Native-Code Generation Process\nJulia Functions\nBase.Cartesian\nTalking to the compiler (the :meta mechanism)\nSubArrays\nSystem Image Building\nWorking with LLVM\nprintf() and stdio in the Julia runtime\nBounds checking\nProper maintenance and care of multi-threading locks\nArrays with custom indices\nBase.LibGit2\nModule loading\nDeveloping/debugging Julia\'s C code\nReporting and analyzing crashes (segfaults)\ngdb debugging tips\nUsing Valgrind with Julia\nSanitizer support"
},

{
    "location": "manual/introduction/#",
    "page": "Introduction",
    "title": "Introduction",
    "category": "page",
    "text": ""
},

{
    "location": "manual/introduction/#man-introduction-1",
    "page": "Introduction",
    "title": "Introduction",
    "category": "section",
    "text": "Scientific computing has traditionally required the highest performance, yet domain experts have largely moved to slower dynamic languages for daily work. We believe there are many good reasons to prefer dynamic languages for these applications, and we do not expect their use to diminish. Fortunately, modern language design and compiler techniques make it possible to mostly eliminate the performance trade-off and provide a single environment productive enough for prototyping and efficient enough for deploying performance-intensive applications. The Julia programming language fills this role: it is a flexible dynamic language, appropriate for scientific and numerical computing, with performance comparable to traditional statically-typed languages.Because Julia\'s compiler is different from the interpreters used for languages like Python or R, you may find that Julia\'s performance is unintuitive at first. If you find that something is slow, we highly recommend reading through the Performance Tips section before trying anything else. Once you understand how Julia works, it\'s easy to write code that\'s nearly as fast as C.Julia features optional typing, multiple dispatch, and good performance, achieved using type inference and just-in-time (JIT) compilation, implemented using LLVM. It is multi-paradigm, combining features of imperative, functional, and object-oriented programming. Julia provides ease and expressiveness for high-level numerical computing, in the same way as languages such as R, MATLAB, and Python, but also supports general programming. To achieve this, Julia builds upon the lineage of mathematical programming languages, but also borrows much from popular dynamic languages, including Lisp, Perl, Python, Lua, and Ruby.The most significant departures of Julia from typical dynamic languages are:The core language imposes very little; the standard library is written in Julia itself, including primitive operations like integer arithmetic\nA rich language of types for constructing and describing objects, that can also optionally be used to make type declarations\nThe ability to define function behavior across many combinations of argument types via multiple dispatch\nAutomatic generation of efficient, specialized code for different argument types\nGood performance, approaching that of statically-compiled languages like CAlthough one sometimes speaks of dynamic languages as being \"typeless\", they are definitely not: every object, whether primitive or user-defined, has a type. The lack of type declarations in most dynamic languages, however, means that one cannot instruct the compiler about the types of values, and often cannot explicitly talk about types at all. In static languages, on the other hand, while one can – and usually must – annotate types for the compiler, types exist only at compile time and cannot be manipulated or expressed at run time. In Julia, types are themselves run-time objects, and can also be used to convey information to the compiler.While the casual programmer need not explicitly use types or multiple dispatch, they are the core unifying features of Julia: functions are defined on different combinations of argument types, and applied by dispatching to the most specific matching definition. This model is a good fit for mathematical programming, where it is unnatural for the first argument to \"own\" an operation as in traditional object-oriented dispatch. Operators are just functions with special notation – to extend addition to new user-defined data types, you define new methods for the + function. Existing code then seamlessly applies to the new data types.Partly because of run-time type inference (augmented by optional type annotations), and partly because of a strong focus on performance from the inception of the project, Julia\'s computational efficiency exceeds that of other dynamic languages, and even rivals that of statically-compiled languages. For large scale numerical problems, speed always has been, continues to be, and probably always will be crucial: the amount of data being processed has easily kept pace with Moore\'s Law over the past decades.Julia aims to create an unprecedented combination of ease-of-use, power, and efficiency in a single language. In addition to the above, some advantages of Julia over comparable systems include:Free and open source (MIT licensed)\nUser-defined types are as fast and compact as built-ins\nNo need to vectorize code for performance; devectorized code is fast\nDesigned for parallelism and distributed computation\nLightweight \"green\" threading (coroutines)\nUnobtrusive yet powerful type system\nElegant and extensible conversions and promotions for numeric and other types\nEfficient support for Unicode, including but not limited to UTF-8\nCall C functions directly (no wrappers or special APIs needed)\nPowerful shell-like capabilities for managing other processes\nLisp-like macros and other metaprogramming facilities"
},

{
    "location": "manual/getting-started/#",
    "page": "Getting Started",
    "title": "Getting Started",
    "category": "page",
    "text": ""
},

{
    "location": "manual/getting-started/#Getting-Started-1",
    "page": "Getting Started",
    "title": "Getting Started",
    "category": "section",
    "text": "Julia installation is straightforward, whether using precompiled binaries or compiling from source. Download and install Julia by following the instructions at https://julialang.org/downloads/.The easiest way to learn and experiment with Julia is by starting an interactive session (also known as a read-eval-print loop or \"repl\") by double-clicking the Julia executable or running julia from the command line:$ julia\n               _\n   _       _ _(_)_     |  A fresh approach to technical computing\n  (_)     | (_) (_)    |  Documentation: https://docs.julialang.org\n   _ _   _| |_  __ _   |  Type \"?help\" for help.\n  | | | | | | |/ _` |  |\n  | | |_| | | | (_| |  |  Version 0.5.0-dev+2440 (2016-02-01 02:22 UTC)\n _/ |\\__\'_|_|_|\\__\'_|  |  Commit 2bb94d6 (11 days old master)\n|__/                   |  x86_64-apple-darwin13.1.0\n\njulia> 1 + 2\n3\n\njulia> ans\n3To exit the interactive session, type ^D – the control key together with the d key or type quit(). When run in interactive mode, julia displays a banner and prompts the user for input. Once the user has entered a complete expression, such as 1 + 2, and hits enter, the interactive session evaluates the expression and shows its value. If an expression is entered into an interactive session with a trailing semicolon, its value is not shown. The variable ans is bound to the value of the last evaluated expression whether it is shown or not. The ans variable is only bound in interactive sessions, not when Julia code is run in other ways.To evaluate expressions written in a source file file.jl, write include(\"file.jl\").To run code in a file non-interactively, you can give it as the first argument to the julia command:$ julia script.jl arg1 arg2...As the example implies, the following command-line arguments to julia are taken as command-line arguments to the program script.jl, passed in the global constant ARGS. The name of the script itself is passed in as the global PROGRAM_FILE. Note that ARGS is also set when script code is given using the -e option on the command line (see the julia help output below) but PROGRAM_FILE will be empty. For example, to just print the arguments given to a script, you could do this:$ julia -e \'println(PROGRAM_FILE); for x in ARGS; println(x); end\' foo bar\n\nfoo\nbarOr you could put that code into a script and run it:$ echo \'println(PROGRAM_FILE); for x in ARGS; println(x); end\' > script.jl\n$ julia script.jl foo bar\nscript.jl\nfoo\nbarThe -- delimiter can be used to separate command-line args to the scriptfile from args to Julia:$ julia --color=yes -O -- foo.jl arg1 arg2..Julia can be started in parallel mode with either the -p or the --machinefile options. -p n will launch an additional n worker processes, while --machinefile file will launch a worker for each line in file file. The machines defined in file must be accessible via a passwordless ssh login, with Julia installed at the same location as the current host. Each machine definition takes the form [count*][user@]host[:port] [bind_addr[:port]] . user defaults to current user, port to the standard ssh port. count is the number of workers to spawn on the node, and defaults to 1. The optional bind-to bind_addr[:port] specifies the ip-address and port that other workers should use to connect to this worker.If you have code that you want executed whenever Julia is run, you can put it in ~/.juliarc.jl:$ echo \'println(\"Greetings! 你好! 안녕하세요?\")\' > ~/.juliarc.jl\n$ julia\nGreetings! 你好! 안녕하세요?\n\n...There are various ways to run Julia code and provide options, similar to those available for the perl and ruby programs:julia [switches] -- [programfile] [args...]\n -v, --version             Display version information\n -h, --help                Print this message\n\n -J, --sysimage <file>     Start up with the given system image file\n --precompiled={yes|no}    Use precompiled code from system image if available\n --compilecache={yes|no}   Enable/disable incremental precompilation of modules\n -H, --home <dir>          Set location of `julia` executable\n --startup-file={yes|no}   Load ~/.juliarc.jl\n --handle-signals={yes|no} Enable or disable Julia\'s default signal handlers\n\n -e, --eval <expr>         Evaluate <expr>\n -E, --print <expr>        Evaluate and show <expr>\n -L, --load <file>         Load <file> immediately on all processors\n\n -p, --procs {N|auto}      Integer value N launches N additional local worker processes\n                           \"auto\" launches as many workers as the number of local cores\n --machinefile <file>      Run processes on hosts listed in <file>\n\n -i                        Interactive mode; REPL runs and isinteractive() is true\n -q, --quiet               Quiet startup (no banner)\n --color={yes|no}          Enable or disable color text\n --history-file={yes|no}   Load or save history\n\n --compile={yes|no|all|min}Enable or disable JIT compiler, or request exhaustive compilation\n -C, --cpu-target <target> Limit usage of cpu features up to <target>\n -O, --optimize={0,1,2,3}  Set the optimization level (default is 2 if unspecified or 3 if specified as -O)\n -g, -g <level>            Enable / Set the level of debug info generation (default is 1 if unspecified or 2 if specified as -g)\n --inline={yes|no}         Control whether inlining is permitted (overrides functions declared as @inline)\n --check-bounds={yes|no}   Emit bounds checks always or never (ignoring declarations)\n --math-mode={ieee,fast}   Disallow or enable unsafe floating point optimizations (overrides @fastmath declaration)\n\n --depwarn={yes|no|error}  Enable or disable syntax and method deprecation warnings (\"error\" turns warnings into errors)\n\n --output-o name           Generate an object file (including system image data)\n --output-ji name          Generate a system image data file (.ji)\n --output-bc name          Generate LLVM bitcode (.bc)\n --output-incremental=no   Generate an incremental output file (rather than complete)\n\n --code-coverage={none|user|all}, --code-coverage\n                           Count executions of source lines (omitting setting is equivalent to \"user\")\n --track-allocation={none|user|all}, --track-allocation\n                           Count bytes allocated by each source line"
},

{
    "location": "manual/getting-started/#Resources-1",
    "page": "Getting Started",
    "title": "Resources",
    "category": "section",
    "text": "In addition to this manual, there are various other resources that may help new users get started with Julia:Julia and IJulia cheatsheet\nLearn Julia in a few minutes\nLearn Julia the Hard Way\nJulia by Example\nHands-on Julia\nTutorial for Homer Reid\'s numerical analysis class\nAn introductory presentation\nVideos from the Julia tutorial at MIT\nYouTube videos from the JuliaCons"
},

{
    "location": "manual/variables/#",
    "page": "Variables",
    "title": "Variables",
    "category": "page",
    "text": ""
},

{
    "location": "manual/variables/#Variables-1",
    "page": "Variables",
    "title": "Variables",
    "category": "section",
    "text": "A variable, in Julia, is a name associated (or bound) to a value. It\'s useful when you want to store a value (that you obtained after some math, for example) for later use. For example:# Assign the value 10 to the variable x\njulia> x = 10\n10\n\n# Doing math with x\'s value\njulia> x + 1\n11\n\n# Reassign x\'s value\njulia> x = 1 + 1\n2\n\n# You can assign values of other types, like strings of text\njulia> x = \"Hello World!\"\n\"Hello World!\"Julia provides an extremely flexible system for naming variables. Variable names are case-sensitive, and have no semantic meaning (that is, the language will not treat variables differently based on their names).julia> x = 1.0\n1.0\n\njulia> y = -3\n-3\n\njulia> Z = \"My string\"\n\"My string\"\n\njulia> customary_phrase = \"Hello world!\"\n\"Hello world!\"\n\njulia> UniversalDeclarationOfHumanRightsStart = \"人人生而自由，在尊严和权利上一律平等。\"\n\"人人生而自由，在尊严和权利上一律平等。\"Unicode names (in UTF-8 encoding) are allowed:julia> δ = 0.00001\n1.0e-5\n\njulia> 안녕하세요 = \"Hello\"\n\"Hello\"In the Julia REPL and several other Julia editing environments, you can type many Unicode math symbols by typing the backslashed LaTeX symbol name followed by tab. For example, the variable name δ can be entered by typing \\delta-tab, or even α̂₂ by \\alpha-tab-\\hat- tab-\\_2-tab. (If you find a symbol somewhere, e.g. in someone else\'s code, that you don\'t know how to type, the REPL help will tell you: just type ? and then paste the symbol.)Julia will even let you redefine built-in constants and functions if needed:julia> pi\nπ = 3.1415926535897...\n\njulia> pi = 3\nWARNING: imported binding for pi overwritten in module Main\n3\n\njulia> pi\n3\n\njulia> sqrt(100)\n10.0\n\njulia> sqrt = 4\nWARNING: imported binding for sqrt overwritten in module Main\n4However, this is obviously not recommended to avoid potential confusion."
},

{
    "location": "manual/variables/#Allowed-Variable-Names-1",
    "page": "Variables",
    "title": "Allowed Variable Names",
    "category": "section",
    "text": "Variable names must begin with a letter (A-Z or a-z), underscore, or a subset of Unicode code points greater than 00A0; in particular, Unicode character categories Lu/Ll/Lt/Lm/Lo/Nl (letters), Sc/So (currency and other symbols), and a few other letter-like characters (e.g. a subset of the Sm math symbols) are allowed. Subsequent characters may also include ! and digits (0-9 and other characters in categories Nd/No), as well as other Unicode code points: diacritics and other modifying marks (categories Mn/Mc/Me/Sk), some punctuation connectors (category Pc), primes, and a few other characters.Operators like + are also valid identifiers, but are parsed specially. In some contexts, operators can be used just like variables; for example (+) refers to the addition function, and (+) = f will reassign it. Most of the Unicode infix operators (in category Sm), such as ⊕, are parsed as infix operators and are available for user-defined methods (e.g. you can use const ⊗ = kron to define ⊗ as an infix Kronecker product).The only explicitly disallowed names for variables are the names of built-in statements:julia> else = false\nERROR: syntax: unexpected \"else\"\n\njulia> try = \"No\"\nERROR: syntax: unexpected \"=\"Some Unicode characters are considered to be equivalent in identifiers. Different ways of entering Unicode combining characters (e.g., accents) are treated as equivalent (specifically, Julia identifiers are NFC-normalized). The Unicode characters ɛ (U+025B: Latin small letter open e) and µ (U+00B5: micro sign) are treated as equivalent to the corresponding Greek letters, because the former are easily accessible via some input methods."
},

{
    "location": "manual/variables/#Stylistic-Conventions-1",
    "page": "Variables",
    "title": "Stylistic Conventions",
    "category": "section",
    "text": "While Julia imposes few restrictions on valid names, it has become useful to adopt the following conventions:Names of variables are in lower case.\nWord separation can be indicated by underscores (\'_\'), but use of underscores is discouraged unless the name would be hard to read otherwise.\nNames of Types and Modules begin with a capital letter and word separation is shown with upper camel case instead of underscores.\nNames of functions and macros are in lower case, without underscores.\nFunctions that write to their arguments have names that end in !. These are sometimes called \"mutating\" or \"in-place\" functions because they are intended to produce changes in their arguments after the function is called, not just return a value.For more information about stylistic conventions, see the Style Guide."
},

{
    "location": "manual/integers-and-floating-point-numbers/#",
    "page": "Integers and Floating-Point Numbers",
    "title": "Integers and Floating-Point Numbers",
    "category": "page",
    "text": ""
},

{
    "location": "manual/integers-and-floating-point-numbers/#Integers-and-Floating-Point-Numbers-1",
    "page": "Integers and Floating-Point Numbers",
    "title": "Integers and Floating-Point Numbers",
    "category": "section",
    "text": "Integers and floating-point values are the basic building blocks of arithmetic and computation. Built-in representations of such values are called numeric primitives, while representations of integers and floating-point numbers as immediate values in code are known as numeric literals. For example, 1 is an integer literal, while 1.0 is a floating-point literal; their binary in-memory representations as objects are numeric primitives.Julia provides a broad range of primitive numeric types, and a full complement of arithmetic and bitwise operators as well as standard mathematical functions are defined over them. These map directly onto numeric types and operations that are natively supported on modern computers, thus allowing Julia to take full advantage of computational resources. Additionally, Julia provides software support for Arbitrary Precision Arithmetic, which can handle operations on numeric values that cannot be represented effectively in native hardware representations, but at the cost of relatively slower performance.The following are Julia\'s primitive numeric types:Integer types:Type Signed? Number of bits Smallest value Largest value\nInt8 ✓ 8 -2^7 2^7 - 1\nUInt8   8 0 2^8 - 1\nInt16 ✓ 16 -2^15 2^15 - 1\nUInt16   16 0 2^16 - 1\nInt32 ✓ 32 -2^31 2^31 - 1\nUInt32   32 0 2^32 - 1\nInt64 ✓ 64 -2^63 2^63 - 1\nUInt64   64 0 2^64 - 1\nInt128 ✓ 128 -2^127 2^127 - 1\nUInt128   128 0 2^128 - 1\nBool N/A 8 false (0) true (1)Floating-point types:Type Precision Number of bits\nFloat16 half 16\nFloat32 single 32\nFloat64 double 64Additionally, full support for Complex and Rational Numbers is built on top of these primitive numeric types. All numeric types interoperate naturally without explicit casting, thanks to a flexible, user-extensible type promotion system."
},

{
    "location": "manual/integers-and-floating-point-numbers/#Integers-1",
    "page": "Integers and Floating-Point Numbers",
    "title": "Integers",
    "category": "section",
    "text": "Literal integers are represented in the standard manner:julia> 1\n1\n\njulia> 1234\n1234The default type for an integer literal depends on whether the target system has a 32-bit architecture or a 64-bit architecture:# 32-bit system:\njulia> typeof(1)\nInt32\n\n# 64-bit system:\njulia> typeof(1)\nInt64The Julia internal variable Sys.WORD_SIZE indicates whether the target system is 32-bit or 64-bit:# 32-bit system:\njulia> Sys.WORD_SIZE\n32\n\n# 64-bit system:\njulia> Sys.WORD_SIZE\n64Julia also defines the types Int and UInt, which are aliases for the system\'s signed and unsigned native integer types respectively:# 32-bit system:\njulia> Int\nInt32\njulia> UInt\nUInt32\n\n# 64-bit system:\njulia> Int\nInt64\njulia> UInt\nUInt64Larger integer literals that cannot be represented using only 32 bits but can be represented in 64 bits always create 64-bit integers, regardless of the system type:# 32-bit or 64-bit system:\njulia> typeof(3000000000)\nInt64Unsigned integers are input and output using the 0x prefix and hexadecimal (base 16) digits 0-9a-f (the capitalized digits A-F also work for input). The size of the unsigned value is determined by the number of hex digits used:julia> 0x1\n0x01\n\njulia> typeof(ans)\nUInt8\n\njulia> 0x123\n0x0123\n\njulia> typeof(ans)\nUInt16\n\njulia> 0x1234567\n0x01234567\n\njulia> typeof(ans)\nUInt32\n\njulia> 0x123456789abcdef\n0x0123456789abcdef\n\njulia> typeof(ans)\nUInt64This behavior is based on the observation that when one uses unsigned hex literals for integer values, one typically is using them to represent a fixed numeric byte sequence, rather than just an integer value.Recall that the variable ans is set to the value of the last expression evaluated in an interactive session. This does not occur when Julia code is run in other ways.Binary and octal literals are also supported:julia> 0b10\n0x02\n\njulia> typeof(ans)\nUInt8\n\njulia> 0o10\n0x08\n\njulia> typeof(ans)\nUInt8The minimum and maximum representable values of primitive numeric types such as integers are given by the typemin() and typemax() functions:julia> (typemin(Int32), typemax(Int32))\n(-2147483648, 2147483647)\n\njulia> for T in [Int8,Int16,Int32,Int64,Int128,UInt8,UInt16,UInt32,UInt64,UInt128]\n           println(\"$(lpad(T,7)): [$(typemin(T)),$(typemax(T))]\")\n       end\n   Int8: [-128,127]\n  Int16: [-32768,32767]\n  Int32: [-2147483648,2147483647]\n  Int64: [-9223372036854775808,9223372036854775807]\n Int128: [-170141183460469231731687303715884105728,170141183460469231731687303715884105727]\n  UInt8: [0,255]\n UInt16: [0,65535]\n UInt32: [0,4294967295]\n UInt64: [0,18446744073709551615]\nUInt128: [0,340282366920938463463374607431768211455]The values returned by typemin() and typemax() are always of the given argument type. (The above expression uses several features we have yet to introduce, including for loops, Strings, and Interpolation, but should be easy enough to understand for users with some existing programming experience.)"
},

{
    "location": "manual/integers-and-floating-point-numbers/#Overflow-behavior-1",
    "page": "Integers and Floating-Point Numbers",
    "title": "Overflow behavior",
    "category": "section",
    "text": "In Julia, exceeding the maximum representable value of a given type results in a wraparound behavior:julia> x = typemax(Int64)\n9223372036854775807\n\njulia> x + 1\n-9223372036854775808\n\njulia> x + 1 == typemin(Int64)\ntrueThus, arithmetic with Julia integers is actually a form of modular arithmetic. This reflects the characteristics of the underlying arithmetic of integers as implemented on modern computers. In applications where overflow is possible, explicit checking for wraparound produced by overflow is essential; otherwise, the BigInt type in Arbitrary Precision Arithmetic is recommended instead."
},

{
    "location": "manual/integers-and-floating-point-numbers/#Division-errors-1",
    "page": "Integers and Floating-Point Numbers",
    "title": "Division errors",
    "category": "section",
    "text": "Integer division (the div function) has two exceptional cases: dividing by zero, and dividing the lowest negative number (typemin()) by -1. Both of these cases throw a DivideError. The remainder and modulus functions (rem and mod) throw a DivideError when their second argument is zero."
},

{
    "location": "manual/integers-and-floating-point-numbers/#Floating-Point-Numbers-1",
    "page": "Integers and Floating-Point Numbers",
    "title": "Floating-Point Numbers",
    "category": "section",
    "text": "Literal floating-point numbers are represented in the standard formats:julia> 1.0\n1.0\n\njulia> 1.\n1.0\n\njulia> 0.5\n0.5\n\njulia> .5\n0.5\n\njulia> -1.23\n-1.23\n\njulia> 1e10\n1.0e10\n\njulia> 2.5e-4\n0.00025The above results are all Float64 values. Literal Float32 values can be entered by writing an f in place of e:julia> 0.5f0\n0.5f0\n\njulia> typeof(ans)\nFloat32\n\njulia> 2.5f-4\n0.00025f0Values can be converted to Float32 easily:julia> Float32(-1.5)\n-1.5f0\n\njulia> typeof(ans)\nFloat32Hexadecimal floating-point literals are also valid, but only as Float64 values:julia> 0x1p0\n1.0\n\njulia> 0x1.8p3\n12.0\n\njulia> 0x.4p-1\n0.125\n\njulia> typeof(ans)\nFloat64Half-precision floating-point numbers are also supported (Float16), but they are implemented in software and use Float32 for calculations.julia> sizeof(Float16(4.))\n2\n\njulia> 2*Float16(4.)\nFloat16(8.0)The underscore _ can be used as digit separator:julia> 10_000, 0.000_000_005, 0xdead_beef, 0b1011_0010\n(10000, 5.0e-9, 0xdeadbeef, 0xb2)"
},

{
    "location": "manual/integers-and-floating-point-numbers/#Floating-point-zero-1",
    "page": "Integers and Floating-Point Numbers",
    "title": "Floating-point zero",
    "category": "section",
    "text": "Floating-point numbers have two zeros, positive zero and negative zero. They are equal to each other but have different binary representations, as can be seen using the bits function: :julia> 0.0 == -0.0\ntrue\n\njulia> bits(0.0)\n\"0000000000000000000000000000000000000000000000000000000000000000\"\n\njulia> bits(-0.0)\n\"1000000000000000000000000000000000000000000000000000000000000000\""
},

{
    "location": "manual/integers-and-floating-point-numbers/#Special-floating-point-values-1",
    "page": "Integers and Floating-Point Numbers",
    "title": "Special floating-point values",
    "category": "section",
    "text": "There are three specified standard floating-point values that do not correspond to any point on the real number line:Float16 Float32 Float64 Name Description\nInf16 Inf32 Inf positive infinity a value greater than all finite floating-point values\n-Inf16 -Inf32 -Inf negative infinity a value less than all finite floating-point values\nNaN16 NaN32 NaN not a number a value not == to any floating-point value (including itself)For further discussion of how these non-finite floating-point values are ordered with respect to each other and other floats, see Numeric Comparisons. By the IEEE 754 standard, these floating-point values are the results of certain arithmetic operations:julia> 1/Inf\n0.0\n\njulia> 1/0\nInf\n\njulia> -5/0\n-Inf\n\njulia> 0.000001/0\nInf\n\njulia> 0/0\nNaN\n\njulia> 500 + Inf\nInf\n\njulia> 500 - Inf\n-Inf\n\njulia> Inf + Inf\nInf\n\njulia> Inf - Inf\nNaN\n\njulia> Inf * Inf\nInf\n\njulia> Inf / Inf\nNaN\n\njulia> 0 * Inf\nNaNThe typemin() and typemax() functions also apply to floating-point types:julia> (typemin(Float16),typemax(Float16))\n(-Inf16, Inf16)\n\njulia> (typemin(Float32),typemax(Float32))\n(-Inf32, Inf32)\n\njulia> (typemin(Float64),typemax(Float64))\n(-Inf, Inf)"
},

{
    "location": "manual/integers-and-floating-point-numbers/#Machine-epsilon-1",
    "page": "Integers and Floating-Point Numbers",
    "title": "Machine epsilon",
    "category": "section",
    "text": "Most real numbers cannot be represented exactly with floating-point numbers, and so for many purposes it is important to know the distance between two adjacent representable floating-point numbers, which is often known as machine epsilon.Julia provides eps(), which gives the distance between 1.0 and the next larger representable floating-point value:julia> eps(Float32)\n1.1920929f-7\n\njulia> eps(Float64)\n2.220446049250313e-16\n\njulia> eps() # same as eps(Float64)\n2.220446049250313e-16These values are 2.0^-23 and 2.0^-52 as Float32 and Float64 values, respectively. The eps() function can also take a floating-point value as an argument, and gives the absolute difference between that value and the next representable floating point value. That is, eps(x) yields a value of the same type as x such that x + eps(x) is the next representable floating-point value larger than x:julia> eps(1.0)\n2.220446049250313e-16\n\njulia> eps(1000.)\n1.1368683772161603e-13\n\njulia> eps(1e-27)\n1.793662034335766e-43\n\njulia> eps(0.0)\n5.0e-324The distance between two adjacent representable floating-point numbers is not constant, but is smaller for smaller values and larger for larger values. In other words, the representable floating-point numbers are densest in the real number line near zero, and grow sparser exponentially as one moves farther away from zero. By definition, eps(1.0) is the same as eps(Float64) since 1.0 is a 64-bit floating-point value.Julia also provides the nextfloat() and prevfloat() functions which return the next largest or smallest representable floating-point number to the argument respectively:julia> x = 1.25f0\n1.25f0\n\njulia> nextfloat(x)\n1.2500001f0\n\njulia> prevfloat(x)\n1.2499999f0\n\njulia> bits(prevfloat(x))\n\"00111111100111111111111111111111\"\n\njulia> bits(x)\n\"00111111101000000000000000000000\"\n\njulia> bits(nextfloat(x))\n\"00111111101000000000000000000001\"This example highlights the general principle that the adjacent representable floating-point numbers also have adjacent binary integer representations."
},

{
    "location": "manual/integers-and-floating-point-numbers/#Rounding-modes-1",
    "page": "Integers and Floating-Point Numbers",
    "title": "Rounding modes",
    "category": "section",
    "text": "If a number doesn\'t have an exact floating-point representation, it must be rounded to an appropriate representable value, however, if wanted, the manner in which this rounding is done can be changed according to the rounding modes presented in the IEEE 754 standard.julia> x = 1.1; y = 0.1;\n\njulia> x + y\n1.2000000000000002\n\njulia> setrounding(Float64,RoundDown) do\n           x + y\n       end\n1.2The default mode used is always RoundNearest, which rounds to the nearest representable value, with ties rounded towards the nearest value with an even least significant bit.warning: Warning\nRounding is generally only correct for basic arithmetic functions (+(), -(), *(), /() and sqrt()) and type conversion operations. Many other functions assume the default RoundNearest mode is set, and can give erroneous results when operating under other rounding modes."
},

{
    "location": "manual/integers-and-floating-point-numbers/#Background-and-References-1",
    "page": "Integers and Floating-Point Numbers",
    "title": "Background and References",
    "category": "section",
    "text": "Floating-point arithmetic entails many subtleties which can be surprising to users who are unfamiliar with the low-level implementation details. However, these subtleties are described in detail in most books on scientific computation, and also in the following references:The definitive guide to floating point arithmetic is the IEEE 754-2008 Standard; however, it is not available for free online.\nFor a brief but lucid presentation of how floating-point numbers are represented, see John D. Cook\'s article on the subject as well as his introduction to some of the issues arising from how this representation differs in behavior from the idealized abstraction of real numbers.\nAlso recommended is Bruce Dawson\'s series of blog posts on floating-point numbers.\nFor an excellent, in-depth discussion of floating-point numbers and issues of numerical accuracy encountered when computing with them, see David Goldberg\'s paper What Every Computer Scientist Should Know About Floating-Point Arithmetic.\nFor even more extensive documentation of the history of, rationale for, and issues with floating-point numbers, as well as discussion of many other topics in numerical computing, see the collected writings of William Kahan, commonly known as the \"Father of Floating-Point\". Of particular interest may be An Interview with the Old Man of Floating-Point."
},

{
    "location": "manual/integers-and-floating-point-numbers/#Arbitrary-Precision-Arithmetic-1",
    "page": "Integers and Floating-Point Numbers",
    "title": "Arbitrary Precision Arithmetic",
    "category": "section",
    "text": "To allow computations with arbitrary-precision integers and floating point numbers, Julia wraps the GNU Multiple Precision Arithmetic Library (GMP) and the GNU MPFR Library, respectively. The BigInt and BigFloat types are available in Julia for arbitrary precision integer and floating point numbers respectively.Constructors exist to create these types from primitive numerical types, and parse() can be used to construct them from AbstractStrings.  Once created, they participate in arithmetic with all other numeric types thanks to Julia\'s type promotion and conversion mechanism:julia> BigInt(typemax(Int64)) + 1\n9223372036854775808\n\njulia> parse(BigInt, \"123456789012345678901234567890\") + 1\n123456789012345678901234567891\n\njulia> parse(BigFloat, \"1.23456789012345678901\")\n1.234567890123456789010000000000000000000000000000000000000000000000000000000004\n\njulia> BigFloat(2.0^66) / 3\n2.459565876494606882133333333333333333333333333333333333333333333333333333333344e+19\n\njulia> factorial(BigInt(40))\n815915283247897734345611269596115894272000000000However, type promotion between the primitive types above and BigInt/BigFloat is not automatic and must be explicitly stated.julia> x = typemin(Int64)\n-9223372036854775808\n\njulia> x = x - 1\n9223372036854775807\n\njulia> typeof(x)\nInt64\n\njulia> y = BigInt(typemin(Int64))\n-9223372036854775808\n\njulia> y = y - 1\n-9223372036854775809\n\njulia> typeof(y)\nBigIntThe default precision (in number of bits of the significand) and rounding mode of BigFloat operations can be changed globally by calling setprecision() and setrounding(), and all further calculations will take these changes in account.  Alternatively, the precision or the rounding can be changed only within the execution of a particular block of code by using the same functions with a do block:julia> setrounding(BigFloat, RoundUp) do\n           BigFloat(1) + parse(BigFloat, \"0.1\")\n       end\n1.100000000000000000000000000000000000000000000000000000000000000000000000000003\n\njulia> setrounding(BigFloat, RoundDown) do\n           BigFloat(1) + parse(BigFloat, \"0.1\")\n       end\n1.099999999999999999999999999999999999999999999999999999999999999999999999999986\n\njulia> setprecision(40) do\n           BigFloat(1) + parse(BigFloat, \"0.1\")\n       end\n1.1000000000004"
},

{
    "location": "manual/integers-and-floating-point-numbers/#man-numeric-literal-coefficients-1",
    "page": "Integers and Floating-Point Numbers",
    "title": "Numeric Literal Coefficients",
    "category": "section",
    "text": "To make common numeric formulas and expressions clearer, Julia allows variables to be immediately preceded by a numeric literal, implying multiplication. This makes writing polynomial expressions much cleaner:julia> x = 3\n3\n\njulia> 2x^2 - 3x + 1\n10\n\njulia> 1.5x^2 - .5x + 1\n13.0It also makes writing exponential functions more elegant:julia> 2^2x\n64The precedence of numeric literal coefficients is the same as that of unary operators such as negation. So 2^3x is parsed as 2^(3x), and 2x^3 is parsed as 2*(x^3).Numeric literals also work as coefficients to parenthesized expressions:julia> 2(x-1)^2 - 3(x-1) + 1\n3note: Note\nThe precedence of numeric literal coefficients used for implicit multiplication is higher than other binary operators such as multiplication (*), and division (/, \\, and //).  This means, for example, that 1 / 2im equals -0.5im and 6 // 2(2 + 1) equals 1 // 1.Additionally, parenthesized expressions can be used as coefficients to variables, implying multiplication of the expression by the variable:julia> (x-1)x\n6Neither juxtaposition of two parenthesized expressions, nor placing a variable before a parenthesized expression, however, can be used to imply multiplication:julia> (x-1)(x+1)\nERROR: MethodError: objects of type Int64 are not callable\n\njulia> x(x+1)\nERROR: MethodError: objects of type Int64 are not callableBoth expressions are interpreted as function application: any expression that is not a numeric literal, when immediately followed by a parenthetical, is interpreted as a function applied to the values in parentheses (see Functions for more about functions). Thus, in both of these cases, an error occurs since the left-hand value is not a function.The above syntactic enhancements significantly reduce the visual noise incurred when writing common mathematical formulae. Note that no whitespace may come between a numeric literal coefficient and the identifier or parenthesized expression which it multiplies."
},

{
    "location": "manual/integers-and-floating-point-numbers/#Syntax-Conflicts-1",
    "page": "Integers and Floating-Point Numbers",
    "title": "Syntax Conflicts",
    "category": "section",
    "text": "Juxtaposed literal coefficient syntax may conflict with two numeric literal syntaxes: hexadecimal integer literals and engineering notation for floating-point literals. Here are some situations where syntactic conflicts arise:The hexadecimal integer literal expression 0xff could be interpreted as the numeric literal 0 multiplied by the variable xff.\nThe floating-point literal expression 1e10 could be interpreted as the numeric literal 1 multiplied by the variable e10, and similarly with the equivalent E form.In both cases, we resolve the ambiguity in favor of interpretation as a numeric literals:Expressions starting with 0x are always hexadecimal literals.\nExpressions starting with a numeric literal followed by e or E are always floating-point literals."
},

{
    "location": "manual/integers-and-floating-point-numbers/#Literal-zero-and-one-1",
    "page": "Integers and Floating-Point Numbers",
    "title": "Literal zero and one",
    "category": "section",
    "text": "Julia provides functions which return literal 0 and 1 corresponding to a specified type or the type of a given variable.Function Description\nzero(x) Literal zero of type x or type of variable x\none(x) Literal one of type x or type of variable xThese functions are useful in Numeric Comparisons to avoid overhead from unnecessary type conversion.Examples:julia> zero(Float32)\n0.0f0\n\njulia> zero(1.0)\n0.0\n\njulia> one(Int32)\n1\n\njulia> one(BigFloat)\n1.000000000000000000000000000000000000000000000000000000000000000000000000000000"
},

{
    "location": "manual/mathematical-operations/#",
    "page": "Mathematical Operations and Elementary Functions",
    "title": "Mathematical Operations and Elementary Functions",
    "category": "page",
    "text": ""
},

{
    "location": "manual/mathematical-operations/#Mathematical-Operations-and-Elementary-Functions-1",
    "page": "Mathematical Operations and Elementary Functions",
    "title": "Mathematical Operations and Elementary Functions",
    "category": "section",
    "text": "Julia provides a complete collection of basic arithmetic and bitwise operators across all of its numeric primitive types, as well as providing portable, efficient implementations of a comprehensive collection of standard mathematical functions."
},

{
    "location": "manual/mathematical-operations/#Arithmetic-Operators-1",
    "page": "Mathematical Operations and Elementary Functions",
    "title": "Arithmetic Operators",
    "category": "section",
    "text": "The following arithmetic operators are supported on all primitive numeric types:Expression Name Description\n+x unary plus the identity operation\n-x unary minus maps values to their additive inverses\nx + y binary plus performs addition\nx - y binary minus performs subtraction\nx * y times performs multiplication\nx / y divide performs division\nx \\ y inverse divide equivalent to y / x\nx ^ y power raises x to the yth power\nx % y remainder equivalent to rem(x,y)as well as the negation on Bool types:Expression Name Description\n!x negation changes true to false and vice versaJulia\'s promotion system makes arithmetic operations on mixtures of argument types \"just work\" naturally and automatically. See Conversion and Promotion for details of the promotion system.Here are some simple examples using arithmetic operators:julia> 1 + 2 + 3\n6\n\njulia> 1 - 2\n-1\n\njulia> 3*2/12\n0.5(By convention, we tend to space operators more tightly if they get applied before other nearby operators. For instance, we would generally write -x + 2 to reflect that first x gets negated, and then 2 is added to that result.)"
},

{
    "location": "manual/mathematical-operations/#Bitwise-Operators-1",
    "page": "Mathematical Operations and Elementary Functions",
    "title": "Bitwise Operators",
    "category": "section",
    "text": "The following bitwise operators are supported on all primitive integer types:Expression Name\n~x bitwise not\nx & y bitwise and\nx | y bitwise or\nx ⊻ y bitwise xor (exclusive or)\nx >>> y logical shift right\nx >> y arithmetic shift right\nx << y logical/arithmetic shift leftHere are some examples with bitwise operators:julia> ~123\n-124\n\njulia> 123 & 234\n106\n\njulia> 123 | 234\n251\n\njulia> 123 ⊻ 234\n145\n\njulia> xor(123, 234)\n145\n\njulia> ~UInt32(123)\n0xffffff84\n\njulia> ~UInt8(123)\n0x84"
},

{
    "location": "manual/mathematical-operations/#Updating-operators-1",
    "page": "Mathematical Operations and Elementary Functions",
    "title": "Updating operators",
    "category": "section",
    "text": "Every binary arithmetic and bitwise operator also has an updating version that assigns the result of the operation back into its left operand. The updating version of the binary operator is formed by placing a = immediately after the operator. For example, writing x += 3 is equivalent to writing x = x + 3:julia> x = 1\n1\n\njulia> x += 3\n4\n\njulia> x\n4The updating versions of all the binary arithmetic and bitwise operators are:+=  -=  *=  /=  \\=  ÷=  %=  ^=  &=  |=  ⊻=  >>>=  >>=  <<=note: Note\nAn updating operator rebinds the variable on the left-hand side. As a result, the type of the variable may change.julia> x = 0x01; typeof(x)\nUInt8\n\njulia> x *= 2 # Same as x = x * 2\n2\n\njulia> typeof(x)\nInt64"
},

{
    "location": "manual/mathematical-operations/#man-dot-operators-1",
    "page": "Mathematical Operations and Elementary Functions",
    "title": "Vectorized \"dot\" operators",
    "category": "section",
    "text": "For every binary operation like ^, there is a corresponding \"dot\" operation .^ that is automatically defined to perform ^ element-by-element on arrays. For example, [1,2,3] ^ 3 is not defined, since there is no standard mathematical meaning to \"cubing\" an array, but [1,2,3] .^ 3 is defined as computing the elementwise (or \"vectorized\") result [1^3, 2^3, 3^3].  Similarly for unary operators like ! or √, there is a corresponding .√ that applies the operator elementwise.julia> [1,2,3] .^ 3\n3-element Array{Int64,1}:\n  1\n  8\n 27More specifically, a .^ b is parsed as the \"dot\" call (^).(a,b), which performs a broadcast operation: it can combine arrays and scalars, arrays of the same size (performing the operation elementwise), and even arrays of different shapes (e.g. combining row and column vectors to produce a matrix). Moreover, like all vectorized \"dot calls,\" these \"dot operators\" are fusing. For example, if you compute 2 .* A.^2 .+ sin.(A) (or equivalently @. 2A^2 + sin(A), using the @. macro) for an array A, it performs a single loop over A, computing 2a^2 + sin(a) for each element of A. In particular, nested dot calls like f.(g.(x)) are fused, and \"adjacent\" binary operators like x .+ 3 .* x.^2 are equivalent to nested dot calls (+).(x, (*).(3, (^).(x, 2))).Furthermore, \"dotted\" updating operators like a .+= b (or @. a += b) are parsed as a .= a .+ b, where .= is a fused in-place assignment operation (see the dot syntax documentation).Note the dot syntax is also applicable to user-defined operators. For example, if you define ⊗(A,B) = kron(A,B) to give a convenient infix syntax A ⊗ B for Kronecker products (kron), then [A,B] .⊗ [C,D] will compute [A⊗C, B⊗D] with no additional coding."
},

{
    "location": "manual/mathematical-operations/#Numeric-Comparisons-1",
    "page": "Mathematical Operations and Elementary Functions",
    "title": "Numeric Comparisons",
    "category": "section",
    "text": "Standard comparison operations are defined for all the primitive numeric types:Operator Name\n== equality\n!=, ≠ inequality\n< less than\n<=, ≤ less than or equal to\n> greater than\n>=, ≥ greater than or equal toHere are some simple examples:julia> 1 == 1\ntrue\n\njulia> 1 == 2\nfalse\n\njulia> 1 != 2\ntrue\n\njulia> 1 == 1.0\ntrue\n\njulia> 1 < 2\ntrue\n\njulia> 1.0 > 3\nfalse\n\njulia> 1 >= 1.0\ntrue\n\njulia> -1 <= 1\ntrue\n\njulia> -1 <= -1\ntrue\n\njulia> -1 <= -2\nfalse\n\njulia> 3 < -0.5\nfalseIntegers are compared in the standard manner – by comparison of bits. Floating-point numbers are compared according to the IEEE 754 standard:Finite numbers are ordered in the usual manner.\nPositive zero is equal but not greater than negative zero.\nInf is equal to itself and greater than everything else except NaN.\n-Inf is equal to itself and less then everything else except NaN.\nNaN is not equal to, not less than, and not greater than anything, including itself.The last point is potentially surprising and thus worth noting:julia> NaN == NaN\nfalse\n\njulia> NaN != NaN\ntrue\n\njulia> NaN < NaN\nfalse\n\njulia> NaN > NaN\nfalseand can cause especial headaches with Arrays:julia> [1 NaN] == [1 NaN]\nfalseJulia provides additional functions to test numbers for special values, which can be useful in situations like hash key comparisons:Function Tests if\nisequal(x, y) x and y are identical\nisfinite(x) x is a finite number\nisinf(x) x is infinite\nisnan(x) x is not a numberisequal() considers NaNs equal to each other:julia> isequal(NaN, NaN)\ntrue\n\njulia> isequal([1 NaN], [1 NaN])\ntrue\n\njulia> isequal(NaN, NaN32)\ntrueisequal() can also be used to distinguish signed zeros:julia> -0.0 == 0.0\ntrue\n\njulia> isequal(-0.0, 0.0)\nfalseMixed-type comparisons between signed integers, unsigned integers, and floats can be tricky. A great deal of care has been taken to ensure that Julia does them correctly.For other types, isequal() defaults to calling ==(), so if you want to define equality for your own types then you only need to add a ==() method.  If you define your own equality function, you should probably define a corresponding hash() method to ensure that isequal(x,y) implies hash(x) == hash(y)."
},

{
    "location": "manual/mathematical-operations/#Chaining-comparisons-1",
    "page": "Mathematical Operations and Elementary Functions",
    "title": "Chaining comparisons",
    "category": "section",
    "text": "Unlike most languages, with the notable exception of Python, comparisons can be arbitrarily chained:julia> 1 < 2 <= 2 < 3 == 3 > 2 >= 1 == 1 < 3 != 5\ntrueChaining comparisons is often quite convenient in numerical code. Chained comparisons use the && operator for scalar comparisons, and the & operator for elementwise comparisons, which allows them to work on arrays. For example, 0 .< A .< 1 gives a boolean array whose entries are true where the corresponding elements of A are between 0 and 1.Note the evaluation behavior of chained comparisons:julia> v(x) = (println(x); x)\nv (generic function with 1 method)\n\njulia> v(1) < v(2) <= v(3)\n2\n1\n3\ntrue\n\njulia> v(1) > v(2) <= v(3)\n2\n1\nfalseThe middle expression is only evaluated once, rather than twice as it would be if the expression were written as v(1) < v(2) && v(2) <= v(3). However, the order of evaluations in a chained comparison is undefined. It is strongly recommended not to use expressions with side effects (such as printing) in chained comparisons. If side effects are required, the short-circuit && operator should be used explicitly (see Short-Circuit Evaluation)."
},

{
    "location": "manual/mathematical-operations/#Elementary-Functions-1",
    "page": "Mathematical Operations and Elementary Functions",
    "title": "Elementary Functions",
    "category": "section",
    "text": "Julia provides a comprehensive collection of mathematical functions and operators. These mathematical operations are defined over as broad a class of numerical values as permit sensible definitions, including integers, floating-point numbers, rationals, and complex numbers, wherever such definitions make sense.Moreover, these functions (like any Julia function) can be applied in \"vectorized\" fashion to arrays and other collections with the dot syntax f.(A), e.g. sin.(A) will compute the sine of each element of an array A."
},

{
    "location": "manual/mathematical-operations/#Operator-Precedence-1",
    "page": "Mathematical Operations and Elementary Functions",
    "title": "Operator Precedence",
    "category": "section",
    "text": "Julia applies the following order of operations, from highest precedence to lowest:Category Operators\nSyntax . followed by ::\nExponentiation ^\nFractions //\nMultiplication * / % & \\\nBitshifts << >> >>>\nAddition + - | ⊻\nSyntax : .. followed by |>\nComparisons > < >= <= == === != !== <:\nControl flow && followed by || followed by ?\nAssignments = += -= *= /= //= \\= ^= ÷= %= |= &= ⊻= <<= >>= >>>=For a complete list of every Julia operator\'s precedence, see the top of this file: src/julia-parser.scmYou can also find the numerical precedence for any given operator via the built-in function Base.operator_precedence, where higher numbers take precedence:julia> Base.operator_precedence(:+), Base.operator_precedence(:*), Base.operator_precedence(:.)\n(9, 11, 15)\n\njulia> Base.operator_precedence(:+=), Base.operator_precedence(:(=))  # (Note the necessary parens on `:(=)`)\n(1, 1)"
},

{
    "location": "manual/mathematical-operations/#Numerical-Conversions-1",
    "page": "Mathematical Operations and Elementary Functions",
    "title": "Numerical Conversions",
    "category": "section",
    "text": "Julia supports three forms of numerical conversion, which differ in their handling of inexact conversions.The notation T(x) or convert(T,x) converts x to a value of type T.\nIf T is a floating-point type, the result is the nearest representable value, which could be positive or negative infinity.\nIf T is an integer type, an InexactError is raised if x is not representable by T.\nx % T converts an integer x to a value of integer type T congruent to x modulo 2^n, where n is the number of bits in T. In other words, the binary representation is truncated to fit.\nThe Rounding functions take a type T as an optional argument. For example, round(Int,x) is a shorthand for Int(round(x)).The following examples show the different forms.julia> Int8(127)\n127\n\njulia> Int8(128)\nERROR: InexactError()\nStacktrace:\n [1] Int8(::Int64) at ./sysimg.jl:77\n\njulia> Int8(127.0)\n127\n\njulia> Int8(3.14)\nERROR: InexactError()\nStacktrace:\n [1] convert(::Type{Int8}, ::Float64) at ./float.jl:658\n [2] Int8(::Float64) at ./sysimg.jl:77\n\njulia> Int8(128.0)\nERROR: InexactError()\nStacktrace:\n [1] convert(::Type{Int8}, ::Float64) at ./float.jl:658\n [2] Int8(::Float64) at ./sysimg.jl:77\n\njulia> 127 % Int8\n127\n\njulia> 128 % Int8\n-128\n\njulia> round(Int8,127.4)\n127\n\njulia> round(Int8,127.6)\nERROR: InexactError()\nStacktrace:\n [1] trunc(::Type{Int8}, ::Float64) at ./float.jl:651\n [2] round(::Type{Int8}, ::Float64) at ./float.jl:337See Conversion and Promotion for how to define your own conversions and promotions."
},

{
    "location": "manual/mathematical-operations/#Rounding-functions-1",
    "page": "Mathematical Operations and Elementary Functions",
    "title": "Rounding functions",
    "category": "section",
    "text": "Function Description Return type\nround(x) round x to the nearest integer typeof(x)\nround(T, x) round x to the nearest integer T\nfloor(x) round x towards -Inf typeof(x)\nfloor(T, x) round x towards -Inf T\nceil(x) round x towards +Inf typeof(x)\nceil(T, x) round x towards +Inf T\ntrunc(x) round x towards zero typeof(x)\ntrunc(T, x) round x towards zero T"
},

{
    "location": "manual/mathematical-operations/#Division-functions-1",
    "page": "Mathematical Operations and Elementary Functions",
    "title": "Division functions",
    "category": "section",
    "text": "Function Description\ndiv(x,y) truncated division; quotient rounded towards zero\nfld(x,y) floored division; quotient rounded towards -Inf\ncld(x,y) ceiling division; quotient rounded towards +Inf\nrem(x,y) remainder; satisfies x == div(x,y)*y + rem(x,y); sign matches x\nmod(x,y) modulus; satisfies x == fld(x,y)*y + mod(x,y); sign matches y\nmod1(x,y) mod() with offset 1; returns r∈(0,y] for y>0 or r∈[y,0) for y<0, where mod(r, y) == mod(x, y)\nmod2pi(x) modulus with respect to 2pi;  0 <= mod2pi(x)    < 2pi\ndivrem(x,y) returns (div(x,y),rem(x,y))\nfldmod(x,y) returns (fld(x,y),mod(x,y))\ngcd(x,y...) greatest positive common divisor of x, y,...\nlcm(x,y...) least positive common multiple of x, y,..."
},

{
    "location": "manual/mathematical-operations/#Sign-and-absolute-value-functions-1",
    "page": "Mathematical Operations and Elementary Functions",
    "title": "Sign and absolute value functions",
    "category": "section",
    "text": "Function Description\nabs(x) a positive value with the magnitude of x\nabs2(x) the squared magnitude of x\nsign(x) indicates the sign of x, returning -1, 0, or +1\nsignbit(x) indicates whether the sign bit is on (true) or off (false)\ncopysign(x,y) a value with the magnitude of x and the sign of y\nflipsign(x,y) a value with the magnitude of x and the sign of x*y"
},

{
    "location": "manual/mathematical-operations/#Powers,-logs-and-roots-1",
    "page": "Mathematical Operations and Elementary Functions",
    "title": "Powers, logs and roots",
    "category": "section",
    "text": "Function Description\nsqrt(x), √x square root of x\ncbrt(x), ∛x cube root of x\nhypot(x,y) hypotenuse of right-angled triangle with other sides of length x and y\nexp(x) natural exponential function at x\nexpm1(x) accurate exp(x)-1 for x near zero\nldexp(x,n) x*2^n computed efficiently for integer values of n\nlog(x) natural logarithm of x\nlog(b,x) base b logarithm of x\nlog2(x) base 2 logarithm of x\nlog10(x) base 10 logarithm of x\nlog1p(x) accurate log(1+x) for x near zero\nexponent(x) binary exponent of x\nsignificand(x) binary significand (a.k.a. mantissa) of a floating-point number xFor an overview of why functions like hypot(), expm1(), and log1p() are necessary and useful, see John D. Cook\'s excellent pair of blog posts on the subject: expm1, log1p, erfc, and hypot."
},

{
    "location": "manual/mathematical-operations/#Trigonometric-and-hyperbolic-functions-1",
    "page": "Mathematical Operations and Elementary Functions",
    "title": "Trigonometric and hyperbolic functions",
    "category": "section",
    "text": "All the standard trigonometric and hyperbolic functions are also defined:sin    cos    tan    cot    sec    csc\nsinh   cosh   tanh   coth   sech   csch\nasin   acos   atan   acot   asec   acsc\nasinh  acosh  atanh  acoth  asech  acsch\nsinc   cosc   atan2These are all single-argument functions, with the exception of atan2, which gives the angle in radians between the x-axis and the point specified by its arguments, interpreted as x and y coordinates.Additionally, sinpi(x) and cospi(x) are provided for more accurate computations of sin(pi*x) and cos(pi*x) respectively.In order to compute trigonometric functions with degrees instead of radians, suffix the function with d. For example, sind(x) computes the sine of x where x is specified in degrees. The complete list of trigonometric functions with degree variants is:sind   cosd   tand   cotd   secd   cscd\nasind  acosd  atand  acotd  asecd  acscd"
},

{
    "location": "manual/mathematical-operations/#Special-functions-1",
    "page": "Mathematical Operations and Elementary Functions",
    "title": "Special functions",
    "category": "section",
    "text": "Function Description\ngamma(x) gamma function at x\nlgamma(x) accurate log(gamma(x)) for large x\nlfact(x) accurate log(factorial(x)) for large x; same as lgamma(x+1) for x > 1, zero otherwise\nbeta(x,y) beta function at x,y\nlbeta(x,y) accurate log(beta(x,y)) for large x or y"
},

{
    "location": "manual/complex-and-rational-numbers/#",
    "page": "Complex and Rational Numbers",
    "title": "Complex and Rational Numbers",
    "category": "page",
    "text": ""
},

{
    "location": "manual/complex-and-rational-numbers/#Complex-and-Rational-Numbers-1",
    "page": "Complex and Rational Numbers",
    "title": "Complex and Rational Numbers",
    "category": "section",
    "text": "Julia ships with predefined types representing both complex and rational numbers, and supports all standard Mathematical Operations and Elementary Functions on them. Conversion and Promotion are defined so that operations on any combination of predefined numeric types, whether primitive or composite, behave as expected."
},

{
    "location": "manual/complex-and-rational-numbers/#Complex-Numbers-1",
    "page": "Complex and Rational Numbers",
    "title": "Complex Numbers",
    "category": "section",
    "text": "The global constant im is bound to the complex number i, representing the principal square root of -1. It was deemed harmful to co-opt the name i for a global constant, since it is such a popular index variable name. Since Julia allows numeric literals to be juxtaposed with identifiers as coefficients, this binding suffices to provide convenient syntax for complex numbers, similar to the traditional mathematical notation:julia> 1 + 2im\n1 + 2imYou can perform all the standard arithmetic operations with complex numbers:julia> (1 + 2im)*(2 - 3im)\n8 + 1im\n\njulia> (1 + 2im)/(1 - 2im)\n-0.6 + 0.8im\n\njulia> (1 + 2im) + (1 - 2im)\n2 + 0im\n\njulia> (-3 + 2im) - (5 - 1im)\n-8 + 3im\n\njulia> (-1 + 2im)^2\n-3 - 4im\n\njulia> (-1 + 2im)^2.5\n2.7296244647840084 - 6.960664459571898im\n\njulia> (-1 + 2im)^(1 + 1im)\n-0.27910381075826657 + 0.08708053414102428im\n\njulia> 3(2 - 5im)\n6 - 15im\n\njulia> 3(2 - 5im)^2\n-63 - 60im\n\njulia> 3(2 - 5im)^-1.0\n0.20689655172413796 + 0.5172413793103449imThe promotion mechanism ensures that combinations of operands of different types just work:julia> 2(1 - 1im)\n2 - 2im\n\njulia> (2 + 3im) - 1\n1 + 3im\n\njulia> (1 + 2im) + 0.5\n1.5 + 2.0im\n\njulia> (2 + 3im) - 0.5im\n2.0 + 2.5im\n\njulia> 0.75(1 + 2im)\n0.75 + 1.5im\n\njulia> (2 + 3im) / 2\n1.0 + 1.5im\n\njulia> (1 - 3im) / (2 + 2im)\n-0.5 - 1.0im\n\njulia> 2im^2\n-2 + 0im\n\njulia> 1 + 3/4im\n1.0 - 0.75imNote that 3/4im == 3/(4*im) == -(3/4*im), since a literal coefficient binds more tightly than division.Standard functions to manipulate complex values are provided:julia> z = 1 + 2im\n1 + 2im\n\njulia> real(1 + 2im) # real part of z\n1\n\njulia> imag(1 + 2im) # imaginary part of z\n2\n\njulia> conj(1 + 2im) # complex conjugate of z\n1 - 2im\n\njulia> abs(1 + 2im) # absolute value of z\n2.23606797749979\n\njulia> abs2(1 + 2im) # squared absolute value\n5\n\njulia> angle(1 + 2im) # phase angle in radians\n1.1071487177940904As usual, the absolute value (abs()) of a complex number is its distance from zero. abs2() gives the square of the absolute value, and is of particular use for complex numbers where it avoids taking a square root. angle() returns the phase angle in radians (also known as the argument or arg function). The full gamut of other Elementary Functions is also defined for complex numbers:julia> sqrt(1im)\n0.7071067811865476 + 0.7071067811865475im\n\njulia> sqrt(1 + 2im)\n1.272019649514069 + 0.7861513777574233im\n\njulia> cos(1 + 2im)\n2.0327230070196656 - 3.0518977991518im\n\njulia> exp(1 + 2im)\n-1.1312043837568135 + 2.4717266720048188im\n\njulia> sinh(1 + 2im)\n-0.4890562590412937 + 1.4031192506220405imNote that mathematical functions typically return real values when applied to real numbers and complex values when applied to complex numbers. For example, sqrt() behaves differently when applied to -1 versus -1 + 0im even though -1 == -1 + 0im:julia> sqrt(-1)\nERROR: DomainError:\nsqrt will only return a complex result if called with a complex argument. Try sqrt(complex(x)).\nStacktrace:\n [1] sqrt(::Int64) at ./math.jl:434\n\njulia> sqrt(-1 + 0im)\n0.0 + 1.0imThe literal numeric coefficient notation does not work when constructing a complex number from variables. Instead, the multiplication must be explicitly written out:julia> a = 1; b = 2; a + b*im\n1 + 2imHowever, this is not recommended; Use the complex() function instead to construct a complex value directly from its real and imaginary parts:julia> a = 1; b = 2; complex(a, b)\n1 + 2imThis construction avoids the multiplication and addition operations.Inf and NaN propagate through complex numbers in the real and imaginary parts of a complex number as described in the Special floating-point values section:julia> 1 + Inf*im\n1.0 + Inf*im\n\njulia> 1 + NaN*im\n1.0 + NaN*im"
},

{
    "location": "manual/complex-and-rational-numbers/#Rational-Numbers-1",
    "page": "Complex and Rational Numbers",
    "title": "Rational Numbers",
    "category": "section",
    "text": "Julia has a rational number type to represent exact ratios of integers. Rationals are constructed using the // operator:julia> 2//3\n2//3If the numerator and denominator of a rational have common factors, they are reduced to lowest terms such that the denominator is non-negative:julia> 6//9\n2//3\n\njulia> -4//8\n-1//2\n\njulia> 5//-15\n-1//3\n\njulia> -4//-12\n1//3This normalized form for a ratio of integers is unique, so equality of rational values can be tested by checking for equality of the numerator and denominator. The standardized numerator and denominator of a rational value can be extracted using the numerator() and denominator() functions:julia> numerator(2//3)\n2\n\njulia> denominator(2//3)\n3Direct comparison of the numerator and denominator is generally not necessary, since the standard arithmetic and comparison operations are defined for rational values:julia> 2//3 == 6//9\ntrue\n\njulia> 2//3 == 9//27\nfalse\n\njulia> 3//7 < 1//2\ntrue\n\njulia> 3//4 > 2//3\ntrue\n\njulia> 2//4 + 1//6\n2//3\n\njulia> 5//12 - 1//4\n1//6\n\njulia> 5//8 * 3//12\n5//32\n\njulia> 6//5 / 10//7\n21//25Rationals can be easily converted to floating-point numbers:julia> float(3//4)\n0.75Conversion from rational to floating-point respects the following identity for any integral values of a and b, with the exception of the case a == 0 and b == 0:julia> a = 1; b = 2;\n\njulia> isequal(float(a//b), a/b)\ntrueConstructing infinite rational values is acceptable:julia> 5//0\n1//0\n\njulia> -3//0\n-1//0\n\njulia> typeof(ans)\nRational{Int64}Trying to construct a NaN rational value, however, is not:julia> 0//0\nERROR: ArgumentError: invalid rational: zero(Int64)//zero(Int64)\nStacktrace:\n [1] Rational{Int64}(::Int64, ::Int64) at ./rational.jl:13\n [2] //(::Int64, ::Int64) at ./rational.jl:40As usual, the promotion system makes interactions with other numeric types effortless:julia> 3//5 + 1\n8//5\n\njulia> 3//5 - 0.5\n0.09999999999999998\n\njulia> 2//7 * (1 + 2im)\n2//7 + 4//7*im\n\njulia> 2//7 * (1.5 + 2im)\n0.42857142857142855 + 0.5714285714285714im\n\njulia> 3//2 / (1 + 2im)\n3//10 - 3//5*im\n\njulia> 1//2 + 2im\n1//2 + 2//1*im\n\njulia> 1 + 2//3im\n1//1 - 2//3*im\n\njulia> 0.5 == 1//2\ntrue\n\njulia> 0.33 == 1//3\nfalse\n\njulia> 0.33 < 1//3\ntrue\n\njulia> 1//3 - 0.33\n0.0033333333333332993"
},

{
    "location": "manual/strings/#",
    "page": "Strings",
    "title": "Strings",
    "category": "page",
    "text": ""
},

{
    "location": "manual/strings/#man-strings-1",
    "page": "Strings",
    "title": "Strings",
    "category": "section",
    "text": "Strings are finite sequences of characters. Of course, the real trouble comes when one asks what a character is. The characters that English speakers are familiar with are the letters A, B, C, etc., together with numerals and common punctuation symbols. These characters are standardized together with a mapping to integer values between 0 and 127 by the ASCII standard. There are, of course, many other characters used in non-English languages, including variants of the ASCII characters with accents and other modifications, related scripts such as Cyrillic and Greek, and scripts completely unrelated to ASCII and English, including Arabic, Chinese, Hebrew, Hindi, Japanese, and Korean. The Unicode standard tackles the complexities of what exactly a character is, and is generally accepted as the definitive standard addressing this problem. Depending on your needs, you can either ignore these complexities entirely and just pretend that only ASCII characters exist, or you can write code that can handle any of the characters or encodings that one may encounter when handling non-ASCII text. Julia makes dealing with plain ASCII text simple and efficient, and handling Unicode is as simple and efficient as possible. In particular, you can write C-style string code to process ASCII strings, and they will work as expected, both in terms of performance and semantics. If such code encounters non-ASCII text, it will gracefully fail with a clear error message, rather than silently introducing corrupt results. When this happens, modifying the code to handle non-ASCII data is straightforward.There are a few noteworthy high-level features about Julia\'s strings:The built-in concrete type used for strings (and string literals) in Julia is String. This supports the full range of Unicode characters via the UTF-8 encoding. (A transcode() function is provided to convert to/from other Unicode encodings.)\nAll string types are subtypes of the abstract type AbstractString, and external packages define additional AbstractString subtypes (e.g. for other encodings).  If you define a function expecting a string argument, you should declare the type as AbstractString in order to accept any string type.\nLike C and Java, but unlike most dynamic languages, Julia has a first-class type representing a single character, called Char. This is just a special kind of 32-bit primitive type whose numeric value represents a Unicode code point.\nAs in Java, strings are immutable: the value of an AbstractString object cannot be changed. To construct a different string value, you construct a new string from parts of other strings.\nConceptually, a string is a partial function from indices to characters: for some index values, no character value is returned, and instead an exception is thrown. This allows for efficient indexing into strings by the byte index of an encoded representation rather than by a character index, which cannot be implemented both efficiently and simply for variable-width encodings of Unicode strings."
},

{
    "location": "manual/strings/#man-characters-1",
    "page": "Strings",
    "title": "Characters",
    "category": "section",
    "text": "A Char value represents a single character: it is just a 32-bit primitive type with a special literal representation and appropriate arithmetic behaviors, whose numeric value is interpreted as a Unicode code point. Here is how Char values are input and shown:julia> \'x\'\n\'x\': ASCII/Unicode U+0078 (category Ll: Letter, lowercase)\n\njulia> typeof(ans)\nCharYou can convert a Char to its integer value, i.e. code point, easily:julia> Int(\'x\')\n120\n\njulia> typeof(ans)\nInt64On 32-bit architectures, typeof(ans) will be Int32. You can convert an integer value back to a Char just as easily:julia> Char(120)\n\'x\': ASCII/Unicode U+0078 (category Ll: Letter, lowercase)Not all integer values are valid Unicode code points, but for performance, the Char() conversion does not check that every character value is valid. If you want to check that each converted value is a valid code point, use the isvalid() function:julia> Char(0x110000)\n\'\\U110000\': Unicode U+110000 (category Cn: Other, not assigned)\n\njulia> isvalid(Char, 0x110000)\nfalseAs of this writing, the valid Unicode code points are U+00 through U+d7ff and U+e000 through U+10ffff. These have not all been assigned intelligible meanings yet, nor are they necessarily interpretable by applications, but all of these values are considered to be valid Unicode characters.You can input any Unicode character in single quotes using \\u followed by up to four hexadecimal digits or \\U followed by up to eight hexadecimal digits (the longest valid value only requires six):julia> \'\\u0\'\n\'\\0\': ASCII/Unicode U+0000 (category Cc: Other, control)\n\njulia> \'\\u78\'\n\'x\': ASCII/Unicode U+0078 (category Ll: Letter, lowercase)\n\njulia> \'\\u2200\'\n\'∀\': Unicode U+2200 (category Sm: Symbol, math)\n\njulia> \'\\U10ffff\'\n\'\\U10ffff\': Unicode U+10ffff (category Cn: Other, not assigned)Julia uses your system\'s locale and language settings to determine which characters can be printed as-is and which must be output using the generic, escaped \\u or \\U input forms. In addition to these Unicode escape forms, all of C\'s traditional escaped input forms can also be used:julia> Int(\'\\0\')\n0\n\njulia> Int(\'\\t\')\n9\n\njulia> Int(\'\\n\')\n10\n\njulia> Int(\'\\e\')\n27\n\njulia> Int(\'\\x7f\')\n127\n\njulia> Int(\'\\177\')\n127\n\njulia> Int(\'\\xff\')\n255You can do comparisons and a limited amount of arithmetic with Char values:julia> \'A\' < \'a\'\ntrue\n\njulia> \'A\' <= \'a\' <= \'Z\'\nfalse\n\njulia> \'A\' <= \'X\' <= \'Z\'\ntrue\n\njulia> \'x\' - \'a\'\n23\n\njulia> \'A\' + 1\n\'B\': ASCII/Unicode U+0042 (category Lu: Letter, uppercase)"
},

{
    "location": "manual/strings/#String-Basics-1",
    "page": "Strings",
    "title": "String Basics",
    "category": "section",
    "text": "String literals are delimited by double quotes or triple double quotes:julia> str = \"Hello, world.\\n\"\n\"Hello, world.\\n\"\n\njulia> \"\"\"Contains \"quote\" characters\"\"\"\n\"Contains \\\"quote\\\" characters\"If you want to extract a character from a string, you index into it:julia> str[1]\n\'H\': ASCII/Unicode U+0048 (category Lu: Letter, uppercase)\n\njulia> str[6]\n\',\': ASCII/Unicode U+002c (category Po: Punctuation, other)\n\njulia> str[end]\n\'\\n\': ASCII/Unicode U+000a (category Cc: Other, control)All indexing in Julia is 1-based: the first element of any integer-indexed object is found at index 1. (As we will see below, this does not necessarily mean that the last element is found at index n, where n is the length of the string.)In any indexing expression, the keyword end can be used as a shorthand for the last index (computed by endof(str)). You can perform arithmetic and other operations with end, just like a normal value:julia> str[end-1]\n\'.\': ASCII/Unicode U+002e (category Po: Punctuation, other)\n\njulia> str[end÷2]\n\' \': ASCII/Unicode U+0020 (category Zs: Separator, space)Using an index less than 1 or greater than end raises an error:julia> str[0]\nERROR: BoundsError: attempt to access \"Hello, world.\\n\"\n  at index [0]\n[...]\n\njulia> str[end+1]\nERROR: BoundsError: attempt to access \"Hello, world.\\n\"\n  at index [15]\n[...]You can also extract a substring using range indexing:julia> str[4:9]\n\"lo, wo\"Notice that the expressions str[k] and str[k:k] do not give the same result:julia> str[6]\n\',\': ASCII/Unicode U+002c (category Po: Punctuation, other)\n\njulia> str[6:6]\n\",\"The former is a single character value of type Char, while the latter is a string value that happens to contain only a single character. In Julia these are very different things."
},

{
    "location": "manual/strings/#Unicode-and-UTF-8-1",
    "page": "Strings",
    "title": "Unicode and UTF-8",
    "category": "section",
    "text": "Julia fully supports Unicode characters and strings. As discussed above, in character literals, Unicode code points can be represented using Unicode \\u and \\U escape sequences, as well as all the standard C escape sequences. These can likewise be used to write string literals:julia> s = \"\\u2200 x \\u2203 y\"\n\"∀ x ∃ y\"Whether these Unicode characters are displayed as escapes or shown as special characters depends on your terminal\'s locale settings and its support for Unicode. String literals are encoded using the UTF-8 encoding. UTF-8 is a variable-width encoding, meaning that not all characters are encoded in the same number of bytes. In UTF-8, ASCII characters – i.e. those with code points less than 0x80 (128) – are encoded as they are in ASCII, using a single byte, while code points 0x80 and above are encoded using multiple bytes – up to four per character. This means that not every byte index into a UTF-8 string is necessarily a valid index for a character. If you index into a string at such an invalid byte index, an error is thrown:julia> s[1]\n\'∀\': Unicode U+2200 (category Sm: Symbol, math)\n\njulia> s[2]\nERROR: UnicodeError: invalid character index\n[...]\n\njulia> s[3]\nERROR: UnicodeError: invalid character index\n[...]\n\njulia> s[4]\n\' \': ASCII/Unicode U+0020 (category Zs: Separator, space)In this case, the character ∀ is a three-byte character, so the indices 2 and 3 are invalid and the next character\'s index is 4; this next valid index can be computed by nextind(s,1), and the next index after that by nextind(s,4) and so on.Because of variable-length encodings, the number of characters in a string (given by length(s)) is not always the same as the last index. If you iterate through the indices 1 through endof(s) and index into s, the sequence of characters returned when errors aren\'t thrown is the sequence of characters comprising the string s. Thus we have the identity that length(s) <= endof(s), since each character in a string must have its own index. The following is an inefficient and verbose way to iterate through the characters of s:julia> for i = 1:endof(s)\n           try\n               println(s[i])\n           catch\n               # ignore the index error\n           end\n       end\n∀\n\nx\n\n∃\n\nyThe blank lines actually have spaces on them. Fortunately, the above awkward idiom is unnecessary for iterating through the characters in a string, since you can just use the string as an iterable object, no exception handling required:julia> for c in s\n           println(c)\n       end\n∀\n\nx\n\n∃\n\nyJulia uses the UTF-8 encoding by default, and support for new encodings can be added by packages. For example, the LegacyStrings.jl package implements UTF16String and UTF32String types. Additional discussion of other encodings and how to implement support for them is beyond the scope of this document for the time being. For further discussion of UTF-8 encoding issues, see the section below on byte array literals. The transcode() function is provided to convert data between the various UTF-xx encodings, primarily for working with external data and libraries."
},

{
    "location": "manual/strings/#Concatenation-1",
    "page": "Strings",
    "title": "Concatenation",
    "category": "section",
    "text": "One of the most common and useful string operations is concatenation:julia> greet = \"Hello\"\n\"Hello\"\n\njulia> whom = \"world\"\n\"world\"\n\njulia> string(greet, \", \", whom, \".\\n\")\n\"Hello, world.\\n\"Julia also provides * for string concatenation:julia> greet * \", \" * whom * \".\\n\"\n\"Hello, world.\\n\"While * may seem like a surprising choice to users of languages that provide + for string concatenation, this use of * has precedent in mathematics, particularly in abstract algebra.In mathematics, + usually denotes a commutative operation, where the order of the operands does not matter. An example of this is matrix addition, where A + B == B + A for any matrices A and B that have the same shape. In contrast, * typically denotes a noncommutative operation, where the order of the operands does matter. An example of this is matrix multiplication, where in general A * B != B * A. As with matrix multiplication, string concatenation is noncommutative: greet * whom != whom * greet. As such, * is a more natural choice for an infix string concatenation operator, consistent with common mathematical use.More precisely, the set of all finite-length strings S together with the string concatenation operator * forms a free monoid (S, *). The identity element of this set is the empty string, \"\". Whenever a free monoid is not commutative, the operation is typically represented as \\cdot, *, or a similar symbol, rather than +, which as stated usually implies commutativity."
},

{
    "location": "manual/strings/#string-interpolation-1",
    "page": "Strings",
    "title": "Interpolation",
    "category": "section",
    "text": "Constructing strings using concatenation can become a bit cumbersome, however. To reduce the need for these verbose calls to string() or repeated multiplications, Julia allows interpolation into string literals using $, as in Perl:julia> \"$greet, $whom.\\n\"\n\"Hello, world.\\n\"This is more readable and convenient and equivalent to the above string concatenation – the system rewrites this apparent single string literal into a concatenation of string literals with variables.The shortest complete expression after the $ is taken as the expression whose value is to be interpolated into the string. Thus, you can interpolate any expression into a string using parentheses:julia> \"1 + 2 = $(1 + 2)\"\n\"1 + 2 = 3\"Both concatenation and string interpolation call string() to convert objects into string form. Most non-AbstractString objects are converted to strings closely corresponding to how they are entered as literal expressions:julia> v = [1,2,3]\n3-element Array{Int64,1}:\n 1\n 2\n 3\n\njulia> \"v: $v\"\n\"v: [1, 2, 3]\"string() is the identity for AbstractString and Char values, so these are interpolated into strings as themselves, unquoted and unescaped:julia> c = \'x\'\n\'x\': ASCII/Unicode U+0078 (category Ll: Letter, lowercase)\n\njulia> \"hi, $c\"\n\"hi, x\"To include a literal $ in a string literal, escape it with a backslash:julia> print(\"I have \\$100 in my account.\\n\")\nI have $100 in my account."
},

{
    "location": "manual/strings/#Triple-Quoted-String-Literals-1",
    "page": "Strings",
    "title": "Triple-Quoted String Literals",
    "category": "section",
    "text": "When strings are created using triple-quotes (\"\"\"...\"\"\") they have some special behavior that can be useful for creating longer blocks of text. First, if the opening \"\"\" is followed by a newline, the newline is stripped from the resulting string.\"\"\"hello\"\"\"is equivalent to\"\"\"\nhello\"\"\"but\"\"\"\n\nhello\"\"\"will contain a literal newline at the beginning. Trailing whitespace is left unaltered. They can contain \" symbols without escaping. Triple-quoted strings are also dedented to the level of the least-indented line. This is useful for defining strings within code that is indented. For example:julia> str = \"\"\"\n           Hello,\n           world.\n         \"\"\"\n\"  Hello,\\n  world.\\n\"In this case the final (empty) line before the closing \"\"\" sets the indentation level.Note that line breaks in literal strings, whether single- or triple-quoted, result in a newline (LF) character \\n in the string, even if your editor uses a carriage return \\r (CR) or CRLF combination to end lines. To include a CR in a string, use an explicit escape \\r; for example, you can enter the literal string \"a CRLF line ending\\r\\n\"."
},

{
    "location": "manual/strings/#Common-Operations-1",
    "page": "Strings",
    "title": "Common Operations",
    "category": "section",
    "text": "You can lexicographically compare strings using the standard comparison operators:julia> \"abracadabra\" < \"xylophone\"\ntrue\n\njulia> \"abracadabra\" == \"xylophone\"\nfalse\n\njulia> \"Hello, world.\" != \"Goodbye, world.\"\ntrue\n\njulia> \"1 + 2 = 3\" == \"1 + 2 = $(1 + 2)\"\ntrueYou can search for the index of a particular character using the search() function:julia> search(\"xylophone\", \'x\')\n1\n\njulia> search(\"xylophone\", \'p\')\n5\n\njulia> search(\"xylophone\", \'z\')\n0You can start the search for a character at a given offset by providing a third argument:julia> search(\"xylophone\", \'o\')\n4\n\njulia> search(\"xylophone\", \'o\', 5)\n7\n\njulia> search(\"xylophone\", \'o\', 8)\n0You can use the contains() function to check if a substring is contained in a string:julia> contains(\"Hello, world.\", \"world\")\ntrue\n\njulia> contains(\"Xylophon\", \"o\")\ntrue\n\njulia> contains(\"Xylophon\", \"a\")\nfalse\n\njulia> contains(\"Xylophon\", \'o\')\nERROR: MethodError: no method matching contains(::String, ::Char)\nClosest candidates are:\n  contains(!Matched::Function, ::Any, !Matched::Any) at reduce.jl:664\n  contains(::AbstractString, !Matched::AbstractString) at strings/search.jl:378The last error is because \'o\' is a character literal, and contains() is a generic function that looks for subsequences. To look for an element in a sequence, you must use in() instead.Two other handy string functions are repeat() and join():julia> repeat(\".:Z:.\", 10)\n\".:Z:..:Z:..:Z:..:Z:..:Z:..:Z:..:Z:..:Z:..:Z:..:Z:.\"\n\njulia> join([\"apples\", \"bananas\", \"pineapples\"], \", \", \" and \")\n\"apples, bananas and pineapples\"Some other useful functions include:endof(str) gives the maximal (byte) index that can be used to index into str.\nlength(str) the number of characters in str.\ni = start(str) gives the first valid index at which a character can be found in str (typically 1).\nc, j = next(str,i) returns next character at or after the index i and the next valid character index following that. With start() and endof(), can be used to iterate through the characters in str.\nind2chr(str,i) gives the number of characters in str up to and including any at index i.\nchr2ind(str,j) gives the index at which the jth character in str occurs."
},

{
    "location": "manual/strings/#non-standard-string-literals-1",
    "page": "Strings",
    "title": "Non-Standard String Literals",
    "category": "section",
    "text": "There are situations when you want to construct a string or use string semantics, but the behavior of the standard string construct is not quite what is needed. For these kinds of situations, Julia provides non-standard string literals. A non-standard string literal looks like a regular double-quoted string literal, but is immediately prefixed by an identifier, and doesn\'t behave quite like a normal string literal.  Regular expressions, byte array literals and version number literals, as described below, are some examples of non-standard string literals. Other examples are given in the Metaprogramming section."
},

{
    "location": "manual/strings/#Regular-Expressions-1",
    "page": "Strings",
    "title": "Regular Expressions",
    "category": "section",
    "text": "Julia has Perl-compatible regular expressions (regexes), as provided by the PCRE library. Regular expressions are related to strings in two ways: the obvious connection is that regular expressions are used to find regular patterns in strings; the other connection is that regular expressions are themselves input as strings, which are parsed into a state machine that can be used to efficiently search for patterns in strings. In Julia, regular expressions are input using non-standard string literals prefixed with various identifiers beginning with r. The most basic regular expression literal without any options turned on just uses r\"...\":julia> r\"^\\s*(?:#|$)\"\nr\"^\\s*(?:#|$)\"\n\njulia> typeof(ans)\nRegexTo check if a regex matches a string, use ismatch():julia> ismatch(r\"^\\s*(?:#|$)\", \"not a comment\")\nfalse\n\njulia> ismatch(r\"^\\s*(?:#|$)\", \"# a comment\")\ntrueAs one can see here, ismatch() simply returns true or false, indicating whether the given regex matches the string or not. Commonly, however, one wants to know not just whether a string matched, but also how it matched. To capture this information about a match, use the match() function instead:julia> match(r\"^\\s*(?:#|$)\", \"not a comment\")\n\njulia> match(r\"^\\s*(?:#|$)\", \"# a comment\")\nRegexMatch(\"#\")If the regular expression does not match the given string, match() returns nothing – a special value that does not print anything at the interactive prompt. Other than not printing, it is a completely normal value and you can test for it programmatically:m = match(r\"^\\s*(?:#|$)\", line)\nif m === nothing\n    println(\"not a comment\")\nelse\n    println(\"blank or comment\")\nendIf a regular expression does match, the value returned by match() is a RegexMatch object. These objects record how the expression matches, including the substring that the pattern matches and any captured substrings, if there are any. This example only captures the portion of the substring that matches, but perhaps we want to capture any non-blank text after the comment character. We could do the following:julia> m = match(r\"^\\s*(?:#\\s*(.*?)\\s*$|$)\", \"# a comment \")\nRegexMatch(\"# a comment \", 1=\"a comment\")When calling match(), you have the option to specify an index at which to start the search. For example:julia> m = match(r\"[0-9]\",\"aaaa1aaaa2aaaa3\",1)\nRegexMatch(\"1\")\n\njulia> m = match(r\"[0-9]\",\"aaaa1aaaa2aaaa3\",6)\nRegexMatch(\"2\")\n\njulia> m = match(r\"[0-9]\",\"aaaa1aaaa2aaaa3\",11)\nRegexMatch(\"3\")You can extract the following info from a RegexMatch object:the entire substring matched: m.match\nthe captured substrings as an array of strings: m.captures\nthe offset at which the whole match begins: m.offset\nthe offsets of the captured substrings as a vector: m.offsetsFor when a capture doesn\'t match, instead of a substring, m.captures contains nothing in that position, and m.offsets has a zero offset (recall that indices in Julia are 1-based, so a zero offset into a string is invalid). Here is a pair of somewhat contrived examples:julia> m = match(r\"(a|b)(c)?(d)\", \"acd\")\nRegexMatch(\"acd\", 1=\"a\", 2=\"c\", 3=\"d\")\n\njulia> m.match\n\"acd\"\n\njulia> m.captures\n3-element Array{Union{SubString{String}, Void},1}:\n \"a\"\n \"c\"\n \"d\"\n\njulia> m.offset\n1\n\njulia> m.offsets\n3-element Array{Int64,1}:\n 1\n 2\n 3\n\njulia> m = match(r\"(a|b)(c)?(d)\", \"ad\")\nRegexMatch(\"ad\", 1=\"a\", 2=nothing, 3=\"d\")\n\njulia> m.match\n\"ad\"\n\njulia> m.captures\n3-element Array{Union{SubString{String}, Void},1}:\n \"a\"\n nothing\n \"d\"\n\njulia> m.offset\n1\n\njulia> m.offsets\n3-element Array{Int64,1}:\n 1\n 0\n 2It is convenient to have captures returned as an array so that one can use destructuring syntax to bind them to local variables:julia> first, second, third = m.captures; first\n\"a\"Captures can also be accessed by indexing the RegexMatch object with the number or name of the capture group:julia> m=match(r\"(?<hour>\\d+):(?<minute>\\d+)\",\"12:45\")\nRegexMatch(\"12:45\", hour=\"12\", minute=\"45\")\n\njulia> m[:minute]\n\"45\"\n\njulia> m[2]\n\"45\"Captures can be referenced in a substitution string when using replace() by using \\n to refer to the nth capture group and prefixing the substitution string with s. Capture group 0 refers to the entire match object. Named capture groups can be referenced in the substitution with g<groupname>. For example:julia> replace(\"first second\", r\"(\\w+) (?<agroup>\\w+)\", s\"\\g<agroup> \\1\")\n\"second first\"Numbered capture groups can also be referenced as \\g<n> for disambiguation, as in:julia> replace(\"a\", r\".\", s\"\\g<0>1\")\n\"a1\"You can modify the behavior of regular expressions by some combination of the flags i, m, s, and x after the closing double quote mark. These flags have the same meaning as they do in Perl, as explained in this excerpt from the perlre manpage:i   Do case-insensitive pattern matching.\n\n    If locale matching rules are in effect, the case map is taken\n    from the current locale for code points less than 255, and\n    from Unicode rules for larger code points. However, matches\n    that would cross the Unicode rules/non-Unicode rules boundary\n    (ords 255/256) will not succeed.\n\nm   Treat string as multiple lines.  That is, change \"^\" and \"$\"\n    from matching the start or end of the string to matching the\n    start or end of any line anywhere within the string.\n\ns   Treat string as single line.  That is, change \".\" to match any\n    character whatsoever, even a newline, which normally it would\n    not match.\n\n    Used together, as r\"\"ms, they let the \".\" match any character\n    whatsoever, while still allowing \"^\" and \"$\" to match,\n    respectively, just after and just before newlines within the\n    string.\n\nx   Tells the regular expression parser to ignore most whitespace\n    that is neither backslashed nor within a character class. You\n    can use this to break up your regular expression into\n    (slightly) more readable parts. The \'#\' character is also\n    treated as a metacharacter introducing a comment, just as in\n    ordinary code.For example, the following regex has all three flags turned on:julia> r\"a+.*b+.*?d$\"ism\nr\"a+.*b+.*?d$\"ims\n\njulia> match(r\"a+.*b+.*?d$\"ism, \"Goodbye,\\nOh, angry,\\nBad world\\n\")\nRegexMatch(\"angry,\\nBad world\")Triple-quoted regex strings, of the form r\"\"\"...\"\"\", are also supported (and may be convenient for regular expressions containing quotation marks or newlines)."
},

{
    "location": "manual/strings/#man-byte-array-literals-1",
    "page": "Strings",
    "title": "Byte Array Literals",
    "category": "section",
    "text": "Another useful non-standard string literal is the byte-array string literal: b\"...\". This form lets you use string notation to express literal byte arrays – i.e. arrays of UInt8 values. The rules for byte array literals are the following:ASCII characters and ASCII escapes produce a single byte.\n\\x and octal escape sequences produce the byte corresponding to the escape value.\nUnicode escape sequences produce a sequence of bytes encoding that code point in UTF-8.There is some overlap between these rules since the behavior of \\x and octal escapes less than 0x80 (128) are covered by both of the first two rules, but here these rules agree. Together, these rules allow one to easily use ASCII characters, arbitrary byte values, and UTF-8 sequences to produce arrays of bytes. Here is an example using all three:julia> b\"DATA\\xff\\u2200\"\n8-element Array{UInt8,1}:\n 0x44\n 0x41\n 0x54\n 0x41\n 0xff\n 0xe2\n 0x88\n 0x80The ASCII string \"DATA\" corresponds to the bytes 68, 65, 84, 65. \\xff produces the single byte 255. The Unicode escape \\u2200 is encoded in UTF-8 as the three bytes 226, 136, 128. Note that the resulting byte array does not correspond to a valid UTF-8 string – if you try to use this as a regular string literal, you will get a syntax error:julia> \"DATA\\xff\\u2200\"\nERROR: syntax: invalid UTF-8 sequenceAlso observe the significant distinction between \\xff and \\uff: the former escape sequence encodes the byte 255, whereas the latter escape sequence represents the code point 255, which is encoded as two bytes in UTF-8:julia> b\"\\xff\"\n1-element Array{UInt8,1}:\n 0xff\n\njulia> b\"\\uff\"\n2-element Array{UInt8,1}:\n 0xc3\n 0xbfIn character literals, this distinction is glossed over and \\xff is allowed to represent the code point 255, because characters always represent code points. In strings, however, \\x escapes always represent bytes, not code points, whereas \\u and \\U escapes always represent code points, which are encoded in one or more bytes. For code points less than \\u80, it happens that the UTF-8 encoding of each code point is just the single byte produced by the corresponding \\x escape, so the distinction can safely be ignored. For the escapes \\x80 through \\xff as compared to \\u80 through \\uff, however, there is a major difference: the former escapes all encode single bytes, which – unless followed by very specific continuation bytes – do not form valid UTF-8 data, whereas the latter escapes all represent Unicode code points with two-byte encodings.If this is all extremely confusing, try reading \"The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets\". It\'s an excellent introduction to Unicode and UTF-8, and may help alleviate some confusion regarding the matter."
},

{
    "location": "manual/strings/#man-version-number-literals-1",
    "page": "Strings",
    "title": "Version Number Literals",
    "category": "section",
    "text": "Version numbers can easily be expressed with non-standard string literals of the form v\"...\". Version number literals create VersionNumber objects which follow the specifications of semantic versioning, and therefore are composed of major, minor and patch numeric values, followed by pre-release and build alpha-numeric annotations. For example, v\"0.2.1-rc1+win64\" is broken into major version 0, minor version 2, patch version 1, pre-release rc1 and build win64. When entering a version literal, everything except the major version number is optional, therefore e.g.  v\"0.2\" is equivalent to v\"0.2.0\" (with empty pre-release/build annotations), v\"2\" is equivalent to v\"2.0.0\", and so on.VersionNumber objects are mostly useful to easily and correctly compare two (or more) versions. For example, the constant VERSION holds Julia version number as a VersionNumber object, and therefore one can define some version-specific behavior using simple statements as:if v\"0.2\" <= VERSION < v\"0.3-\"\n    # do something specific to 0.2 release series\nendNote that in the above example the non-standard version number v\"0.3-\" is used, with a trailing -: this notation is a Julia extension of the standard, and it\'s used to indicate a version which is lower than any 0.3 release, including all of its pre-releases. So in the above example the code would only run with stable 0.2 versions, and exclude such versions as v\"0.3.0-rc1\". In order to also allow for unstable (i.e. pre-release) 0.2 versions, the lower bound check should be modified like this: v\"0.2-\" <= VERSION.Another non-standard version specification extension allows one to use a trailing + to express an upper limit on build versions, e.g.  VERSION > v\"0.2-rc1+\" can be used to mean any version above 0.2-rc1 and any of its builds: it will return false for version v\"0.2-rc1+win64\" and true for v\"0.2-rc2\".It is good practice to use such special versions in comparisons (particularly, the trailing - should always be used on upper bounds unless there\'s a good reason not to), but they must not be used as the actual version number of anything, as they are invalid in the semantic versioning scheme.Besides being used for the VERSION constant, VersionNumber objects are widely used in the Pkg module, to specify packages versions and their dependencies."
},

{
    "location": "manual/strings/#man-raw-string-literals-1",
    "page": "Strings",
    "title": "Raw String Literals",
    "category": "section",
    "text": "Raw strings without interpolation or unescaping can be expressed with non-standard string literals of the form raw\"...\". Raw string literals create ordinary String objects which contain the enclosed contents exactly as entered with no interpolation or unescaping. This is useful for strings which contain code or markup in other languages which use $ or \\ as special characters. The exception is quotation marks that still must be escaped, e.g. raw\"\\\"\" is equivalent to \"\\\"\"."
},

{
    "location": "manual/functions/#",
    "page": "Functions",
    "title": "Functions",
    "category": "page",
    "text": ""
},

{
    "location": "manual/functions/#man-functions-1",
    "page": "Functions",
    "title": "Functions",
    "category": "section",
    "text": "In Julia, a function is an object that maps a tuple of argument values to a return value. Julia functions are not pure mathematical functions, in the sense that functions can alter and be affected by the global state of the program. The basic syntax for defining functions in Julia is:julia> function f(x,y)\n           x + y\n       end\nf (generic function with 1 method)There is a second, more terse syntax for defining a function in Julia. The traditional function declaration syntax demonstrated above is equivalent to the following compact \"assignment form\":julia> f(x,y) = x + y\nf (generic function with 1 method)In the assignment form, the body of the function must be a single expression, although it can be a compound expression (see Compound Expressions). Short, simple function definitions are common in Julia. The short function syntax is accordingly quite idiomatic, considerably reducing both typing and visual noise.A function is called using the traditional parenthesis syntax:julia> f(2,3)\n5Without parentheses, the expression f refers to the function object, and can be passed around like any value:julia> g = f;\n\njulia> g(2,3)\n5As with variables, Unicode can also be used for function names:julia> ∑(x,y) = x + y\n∑ (generic function with 1 method)\n\njulia> ∑(2, 3)\n5"
},

{
    "location": "manual/functions/#Argument-Passing-Behavior-1",
    "page": "Functions",
    "title": "Argument Passing Behavior",
    "category": "section",
    "text": "Julia function arguments follow a convention sometimes called \"pass-by-sharing\", which means that values are not copied when they are passed to functions. Function arguments themselves act as new variable bindings (new locations that can refer to values), but the values they refer to are identical to the passed values. Modifications to mutable values (such as Arrays) made within a function will be visible to the caller. This is the same behavior found in Scheme, most Lisps, Python, Ruby and Perl, among other dynamic languages."
},

{
    "location": "manual/functions/#The-return-Keyword-1",
    "page": "Functions",
    "title": "The return Keyword",
    "category": "section",
    "text": "The value returned by a function is the value of the last expression evaluated, which, by default, is the last expression in the body of the function definition. In the example function, f, from the previous section this is the value of the expression x + y. As in C and most other imperative or functional languages, the return keyword causes a function to return immediately, providing an expression whose value is returned:function g(x,y)\n    return x * y\n    x + y\nendSince function definitions can be entered into interactive sessions, it is easy to compare these definitions:julia> f(x,y) = x + y\nf (generic function with 1 method)\n\njulia> function g(x,y)\n           return x * y\n           x + y\n       end\ng (generic function with 1 method)\n\njulia> f(2,3)\n5\n\njulia> g(2,3)\n6Of course, in a purely linear function body like g, the usage of return is pointless since the expression x + y is never evaluated and we could simply make x * y the last expression in the function and omit the return. In conjunction with other control flow, however, return is of real use. Here, for example, is a function that computes the hypotenuse length of a right triangle with sides of length x and y, avoiding overflow:julia> function hypot(x,y)\n           x = abs(x)\n           y = abs(y)\n           if x > y\n               r = y/x\n               return x*sqrt(1+r*r)\n           end\n           if y == 0\n               return zero(x)\n           end\n           r = x/y\n           return y*sqrt(1+r*r)\n       end\nhypot (generic function with 1 method)\n\njulia> hypot(3, 4)\n5.0There are three possible points of return from this function, returning the values of three different expressions, depending on the values of x and y. The return on the last line could be omitted since it is the last expression."
},

{
    "location": "manual/functions/#Operators-Are-Functions-1",
    "page": "Functions",
    "title": "Operators Are Functions",
    "category": "section",
    "text": "In Julia, most operators are just functions with support for special syntax. (The exceptions are operators with special evaluation semantics like && and ||. These operators cannot be functions since Short-Circuit Evaluation requires that their operands are not evaluated before evaluation of the operator.) Accordingly, you can also apply them using parenthesized argument lists, just as you would any other function:julia> 1 + 2 + 3\n6\n\njulia> +(1,2,3)\n6The infix form is exactly equivalent to the function application form – in fact the former is parsed to produce the function call internally. This also means that you can assign and pass around operators such as +() and *() just like you would with other function values:julia> f = +;\n\njulia> f(1,2,3)\n6Under the name f, the function does not support infix notation, however."
},

{
    "location": "manual/functions/#Operators-With-Special-Names-1",
    "page": "Functions",
    "title": "Operators With Special Names",
    "category": "section",
    "text": "A few special expressions correspond to calls to functions with non-obvious names. These are:Expression Calls\n[A B C ...] hcat()\n[A; B; C; ...] vcat()\n[A B; C D; ...] hvcat()\nA\' ctranspose()\nA.\' transpose()\n1:n colon()\nA[i] getindex()\nA[i]=x setindex!()These functions are included in the Base.Operators module even though they do not have operator-like names."
},

{
    "location": "manual/functions/#man-anonymous-functions-1",
    "page": "Functions",
    "title": "Anonymous Functions",
    "category": "section",
    "text": "Functions in Julia are first-class objects: they can be assigned to variables, and called using the standard function call syntax from the variable they have been assigned to. They can be used as arguments, and they can be returned as values. They can also be created anonymously, without being given a name, using either of these syntaxes:julia> x -> x^2 + 2x - 1\n(::#1) (generic function with 1 method)\n\njulia> function (x)\n           x^2 + 2x - 1\n       end\n(::#3) (generic function with 1 method)This creates a function taking one argument x and returning the value of the polynomial x^2 + 2x - 1 at that value. Notice that the result is a generic function, but with a compiler-generated name based on consecutive numbering.The primary use for anonymous functions is passing them to functions which take other functions as arguments. A classic example is map(), which applies a function to each value of an array and returns a new array containing the resulting values:julia> map(round, [1.2,3.5,1.7])\n3-element Array{Float64,1}:\n 1.0\n 4.0\n 2.0This is fine if a named function effecting the transform one wants already exists to pass as the first argument to map(). Often, however, a ready-to-use, named function does not exist. In these situations, the anonymous function construct allows easy creation of a single-use function object without needing a name:julia> map(x -> x^2 + 2x - 1, [1,3,-1])\n3-element Array{Int64,1}:\n  2\n 14\n -2An anonymous function accepting multiple arguments can be written using the syntax (x,y,z)->2x+y-z. A zero-argument anonymous function is written as ()->3. The idea of a function with no arguments may seem strange, but is useful for \"delaying\" a computation. In this usage, a block of code is wrapped in a zero-argument function, which is later invoked by calling it as f()."
},

{
    "location": "manual/functions/#Multiple-Return-Values-1",
    "page": "Functions",
    "title": "Multiple Return Values",
    "category": "section",
    "text": "In Julia, one returns a tuple of values to simulate returning multiple values. However, tuples can be created and destructured without needing parentheses, thereby providing an illusion that multiple values are being returned, rather than a single tuple value. For example, the following function returns a pair of values:julia> function foo(a,b)\n           a+b, a*b\n       end\nfoo (generic function with 1 method)If you call it in an interactive session without assigning the return value anywhere, you will see the tuple returned:julia> foo(2,3)\n(5, 6)A typical usage of such a pair of return values, however, extracts each value into a variable. Julia supports simple tuple \"destructuring\" that facilitates this:julia> x, y = foo(2,3)\n(5, 6)\n\njulia> x\n5\n\njulia> y\n6You can also return multiple values via an explicit usage of the return keyword:function foo(a,b)\n    return a+b, a*b\nendThis has the exact same effect as the previous definition of foo."
},

{
    "location": "manual/functions/#Varargs-Functions-1",
    "page": "Functions",
    "title": "Varargs Functions",
    "category": "section",
    "text": "It is often convenient to be able to write functions taking an arbitrary number of arguments. Such functions are traditionally known as \"varargs\" functions, which is short for \"variable number of arguments\". You can define a varargs function by following the last argument with an ellipsis:julia> bar(a,b,x...) = (a,b,x)\nbar (generic function with 1 method)The variables a and b are bound to the first two argument values as usual, and the variable x is bound to an iterable collection of the zero or more values passed to bar after its first two arguments:julia> bar(1,2)\n(1, 2, ())\n\njulia> bar(1,2,3)\n(1, 2, (3,))\n\njulia> bar(1, 2, 3, 4)\n(1, 2, (3, 4))\n\njulia> bar(1,2,3,4,5,6)\n(1, 2, (3, 4, 5, 6))In all these cases, x is bound to a tuple of the trailing values passed to bar.It is possible to constrain the number of values passed as a variable argument; this will be discussed later in Parametrically-constrained Varargs methods.On the flip side, it is often handy to \"splice\" the values contained in an iterable collection into a function call as individual arguments. To do this, one also uses ... but in the function call instead:julia> x = (3, 4)\n(3, 4)\n\njulia> bar(1,2,x...)\n(1, 2, (3, 4))In this case a tuple of values is spliced into a varargs call precisely where the variable number of arguments go. This need not be the case, however:julia> x = (2, 3, 4)\n(2, 3, 4)\n\njulia> bar(1,x...)\n(1, 2, (3, 4))\n\njulia> x = (1, 2, 3, 4)\n(1, 2, 3, 4)\n\njulia> bar(x...)\n(1, 2, (3, 4))Furthermore, the iterable object spliced into a function call need not be a tuple:julia> x = [3,4]\n2-element Array{Int64,1}:\n 3\n 4\n\njulia> bar(1,2,x...)\n(1, 2, (3, 4))\n\njulia> x = [1,2,3,4]\n4-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n\njulia> bar(x...)\n(1, 2, (3, 4))Also, the function that arguments are spliced into need not be a varargs function (although it often is):julia> baz(a,b) = a + b;\n\njulia> args = [1,2]\n2-element Array{Int64,1}:\n 1\n 2\n\njulia> baz(args...)\n3\n\njulia> args = [1,2,3]\n3-element Array{Int64,1}:\n 1\n 2\n 3\n\njulia> baz(args...)\nERROR: MethodError: no method matching baz(::Int64, ::Int64, ::Int64)\nClosest candidates are:\n  baz(::Any, ::Any) at none:1As you can see, if the wrong number of elements are in the spliced container, then the function call will fail, just as it would if too many arguments were given explicitly."
},

{
    "location": "manual/functions/#Optional-Arguments-1",
    "page": "Functions",
    "title": "Optional Arguments",
    "category": "section",
    "text": "In many cases, function arguments have sensible default values and therefore might not need to be passed explicitly in every call. For example, the library function parse(T, num, base) interprets a string as a number in some base. The base argument defaults to 10. This behavior can be expressed concisely as:function parse(T, num, base=10)\n    ###\nendWith this definition, the function can be called with either two or three arguments, and 10 is automatically passed when a third argument is not specified:julia> parse(Int,\"12\",10)\n12\n\njulia> parse(Int,\"12\",3)\n5\n\njulia> parse(Int,\"12\")\n12Optional arguments are actually just a convenient syntax for writing multiple method definitions with different numbers of arguments (see Note on Optional and keyword Arguments)."
},

{
    "location": "manual/functions/#Keyword-Arguments-1",
    "page": "Functions",
    "title": "Keyword Arguments",
    "category": "section",
    "text": "Some functions need a large number of arguments, or have a large number of behaviors. Remembering how to call such functions can be difficult. Keyword arguments can make these complex interfaces easier to use and extend by allowing arguments to be identified by name instead of only by position.For example, consider a function plot that plots a line. This function might have many options, for controlling line style, width, color, and so on. If it accepts keyword arguments, a possible call might look like plot(x, y, width=2), where we have chosen to specify only line width. Notice that this serves two purposes. The call is easier to read, since we can label an argument with its meaning. It also becomes possible to pass any subset of a large number of arguments, in any order.Functions with keyword arguments are defined using a semicolon in the signature:function plot(x, y; style=\"solid\", width=1, color=\"black\")\n    ###\nendWhen the function is called, the semicolon is optional: one can either call plot(x, y, width=2) or plot(x, y; width=2), but the former style is more common. An explicit semicolon is required only for passing varargs or computed keywords as described below.Keyword argument default values are evaluated only when necessary (when a corresponding keyword argument is not passed), and in left-to-right order. Therefore default expressions may refer to prior keyword arguments.The types of keyword arguments can be made explicit as follows:function f(;x::Int64=1)\n    ###\nendExtra keyword arguments can be collected using ..., as in varargs functions:function f(x; y=0, kwargs...)\n    ###\nendInside f, kwargs will be a collection of (key,value) tuples, where each key is a symbol. Such collections can be passed as keyword arguments using a semicolon in a call, e.g. f(x, z=1; kwargs...). Dictionaries can also be used for this purpose.One can also pass (key,value) tuples, or any iterable expression (such as a => pair) that can be assigned to such a tuple, explicitly after a semicolon. For example, plot(x, y; (:width,2)) and plot(x, y; :width => 2) are equivalent to plot(x, y, width=2). This is useful in situations where the keyword name is computed at runtime.The nature of keyword arguments makes it possible to specify the same argument more than once. For example, in the call plot(x, y; options..., width=2) it is possible that the options structure also contains a value for width. In such a case the rightmost occurrence takes precedence; in this example, width is certain to have the value 2."
},

{
    "location": "manual/functions/#Evaluation-Scope-of-Default-Values-1",
    "page": "Functions",
    "title": "Evaluation Scope of Default Values",
    "category": "section",
    "text": "Optional and keyword arguments differ slightly in how their default values are evaluated. When optional argument default expressions are evaluated, only previous arguments are in scope. In contrast, all the arguments are in scope when keyword arguments default expressions are evaluated. For example, given this definition:function f(x, a=b, b=1)\n    ###\nendthe b in a=b refers to a b in an outer scope, not the subsequent argument b. However, if a and b were keyword arguments instead, then both would be created in the same scope and the b in a=b would refer to the subsequent argument b (shadowing any b in an outer scope), which would result in an undefined variable error (since the default expressions are evaluated left-to-right, and b has not been assigned yet)."
},

{
    "location": "manual/functions/#Do-Block-Syntax-for-Function-Arguments-1",
    "page": "Functions",
    "title": "Do-Block Syntax for Function Arguments",
    "category": "section",
    "text": "Passing functions as arguments to other functions is a powerful technique, but the syntax for it is not always convenient. Such calls are especially awkward to write when the function argument requires multiple lines. As an example, consider calling map() on a function with several cases:map(x->begin\n           if x < 0 && iseven(x)\n               return 0\n           elseif x == 0\n               return 1\n           else\n               return x\n           end\n       end,\n    [A, B, C])Julia provides a reserved word do for rewriting this code more clearly:map([A, B, C]) do x\n    if x < 0 && iseven(x)\n        return 0\n    elseif x == 0\n        return 1\n    else\n        return x\n    end\nendThe do x syntax creates an anonymous function with argument x and passes it as the first argument to map(). Similarly, do a,b would create a two-argument anonymous function, and a plain do would declare that what follows is an anonymous function of the form () -> ....How these arguments are initialized depends on the \"outer\" function; here, map() will sequentially set x to A, B, C, calling the anonymous function on each, just as would happen in the syntax map(func, [A, B, C]).This syntax makes it easier to use functions to effectively extend the language, since calls look like normal code blocks. There are many possible uses quite different from map(), such as managing system state. For example, there is a version of open() that runs code ensuring that the opened file is eventually closed:open(\"outfile\", \"w\") do io\n    write(io, data)\nendThis is accomplished by the following definition:function open(f::Function, args...)\n    io = open(args...)\n    try\n        f(io)\n    finally\n        close(io)\n    end\nendHere, open() first opens the file for writing and then passes the resulting output stream to the anonymous function you defined in the do ... end block. After your function exits, open() will make sure that the stream is properly closed, regardless of whether your function exited normally or threw an exception. (The try/finally construct will be described in Control Flow.)With the do block syntax, it helps to check the documentation or implementation to know how the arguments of the user function are initialized."
},

{
    "location": "manual/functions/#man-vectorized-1",
    "page": "Functions",
    "title": "Dot Syntax for Vectorizing Functions",
    "category": "section",
    "text": "In technical-computing languages, it is common to have \"vectorized\" versions of functions, which simply apply a given function f(x) to each element of an array A to yield a new array via f(A). This kind of syntax is convenient for data processing, but in other languages vectorization is also often required for performance: if loops are slow, the \"vectorized\" version of a function can call fast library code written in a low-level language. In Julia, vectorized functions are not required for performance, and indeed it is often beneficial to write your own loops (see Performance Tips), but they can still be convenient. Therefore, any Julia function f can be applied elementwise to any array (or other collection) with the syntax f.(A). For example sin can be applied to all elements in the vector A, like so:julia> A = [1.0, 2.0, 3.0]\n3-element Array{Float64,1}:\n 1.0\n 2.0\n 3.0\n\njulia> sin.(A)\n3-element Array{Float64,1}:\n 0.841471\n 0.909297\n 0.14112Of course, you can omit the dot if you write a specialized \"vector\" method of f, e.g. via f(A::AbstractArray) = map(f, A), and this is just as efficient as f.(A). But that approach requires you to decide in advance which functions you want to vectorize.More generally, f.(args...) is actually equivalent to broadcast(f, args...), which allows you to operate on multiple arrays (even of different shapes), or a mix of arrays and scalars (see Broadcasting). For example, if you have f(x,y) = 3x + 4y, then f.(pi,A) will return a new array consisting of f(pi,a) for each a in A, and f.(vector1,vector2) will return a new vector consisting of f(vector1[i],vector2[i]) for each index i (throwing an exception if the vectors have different length).julia> f(x,y) = 3x + 4y;\n\njulia> A = [1.0, 2.0, 3.0];\n\njulia> B = [4.0, 5.0, 6.0];\n\njulia> f.(pi, A)\n3-element Array{Float64,1}:\n 13.4248\n 17.4248\n 21.4248\n\njulia> f.(A, B)\n3-element Array{Float64,1}:\n 19.0\n 26.0\n 33.0Moreover, nested f.(args...) calls are fused into a single broadcast loop. For example, sin.(cos.(X)) is equivalent to broadcast(x -> sin(cos(x)), X), similar to [sin(cos(x)) for x in X]: there is only a single loop over X, and a single array is allocated for the result. [In contrast, sin(cos(X)) in a typical \"vectorized\" language would first allocate one temporary array for tmp=cos(X), and then compute sin(tmp) in a separate loop, allocating a second array.] This loop fusion is not a compiler optimization that may or may not occur, it is a syntactic guarantee whenever nested f.(args...) calls are encountered. Technically, the fusion stops as soon as a \"non-dot\" function call is encountered; for example, in sin.(sort(cos.(X))) the sin and cos loops cannot be merged because of the intervening sort function.Finally, the maximum efficiency is typically achieved when the output array of a vectorized operation is pre-allocated, so that repeated calls do not allocate new arrays over and over again for the results (Pre-allocating outputs:). A convenient syntax for this is X .= ..., which is equivalent to broadcast!(identity, X, ...) except that, as above, the broadcast! loop is fused with any nested \"dot\" calls. For example, X .= sin.(Y) is equivalent to broadcast!(sin, X, Y), overwriting X with sin.(Y) in-place. If the left-hand side is an array-indexing expression, e.g. X[2:end] .= sin.(Y), then it translates to broadcast! on a view, e.g. broadcast!(sin, view(X, 2:endof(X)), Y), so that the left-hand side is updated in-place.Since adding dots to many operations and function calls in an expression can be tedious and lead to code that is difficult to read, the macro @. is provided to convert every function call, operation, and assignment in an expression into the \"dotted\" version.julia> Y = [1.0, 2.0, 3.0, 4.0];\n\njulia> X = similar(Y); # pre-allocate output array\n\njulia> @. X = sin(cos(Y)) # equivalent to X .= sin.(cos.(Y))\n4-element Array{Float64,1}:\n  0.514395\n -0.404239\n -0.836022\n -0.608083Binary (or unary) operators like .+ are handled with the same mechanism: they are equivalent to broadcast calls and are fused with other nested \"dot\" calls.  X .+= Y etcetera is equivalent to X .= X .+ Y and results in a fused in-place assignment;  see also dot operators."
},

{
    "location": "manual/functions/#Further-Reading-1",
    "page": "Functions",
    "title": "Further Reading",
    "category": "section",
    "text": "We should mention here that this is far from a complete picture of defining functions. Julia has a sophisticated type system and allows multiple dispatch on argument types. None of the examples given here provide any type annotations on their arguments, meaning that they are applicable to all types of arguments. The type system is described in Types and defining a function in terms of methods chosen by multiple dispatch on run-time argument types is described in Methods."
},

{
    "location": "manual/control-flow/#",
    "page": "Control Flow",
    "title": "Control Flow",
    "category": "page",
    "text": ""
},

{
    "location": "manual/control-flow/#Control-Flow-1",
    "page": "Control Flow",
    "title": "Control Flow",
    "category": "section",
    "text": "Julia provides a variety of control flow constructs:Compound Expressions: begin and (;).\nConditional Evaluation: if-elseif-else and ?: (ternary operator).\nShort-Circuit Evaluation: &&, || and chained comparisons.\nRepeated Evaluation: Loops: while and for.\nException Handling: try-catch, error() and throw().\nTasks (aka Coroutines): yieldto().The first five control flow mechanisms are standard to high-level programming languages. Tasks are not so standard: they provide non-local control flow, making it possible to switch between temporarily-suspended computations. This is a powerful construct: both exception handling and cooperative multitasking are implemented in Julia using tasks. Everyday programming requires no direct usage of tasks, but certain problems can be solved much more easily by using tasks."
},

{
    "location": "manual/control-flow/#man-compound-expressions-1",
    "page": "Control Flow",
    "title": "Compound Expressions",
    "category": "section",
    "text": "Sometimes it is convenient to have a single expression which evaluates several subexpressions in order, returning the value of the last subexpression as its value. There are two Julia constructs that accomplish this: begin blocks and (;) chains. The value of both compound expression constructs is that of the last subexpression. Here\'s an example of a begin block:julia> z = begin\n           x = 1\n           y = 2\n           x + y\n       end\n3Since these are fairly small, simple expressions, they could easily be placed onto a single line, which is where the (;) chain syntax comes in handy:julia> z = (x = 1; y = 2; x + y)\n3This syntax is particularly useful with the terse single-line function definition form introduced in Functions. Although it is typical, there is no requirement that begin blocks be multiline or that (;) chains be single-line:julia> begin x = 1; y = 2; x + y end\n3\n\njulia> (x = 1;\n        y = 2;\n        x + y)\n3"
},

{
    "location": "manual/control-flow/#man-conditional-evaluation-1",
    "page": "Control Flow",
    "title": "Conditional Evaluation",
    "category": "section",
    "text": "Conditional evaluation allows portions of code to be evaluated or not evaluated depending on the value of a boolean expression. Here is the anatomy of the if-elseif-else conditional syntax:if x < y\n    println(\"x is less than y\")\nelseif x > y\n    println(\"x is greater than y\")\nelse\n    println(\"x is equal to y\")\nendIf the condition expression x < y is true, then the corresponding block is evaluated; otherwise the condition expression x > y is evaluated, and if it is true, the corresponding block is evaluated; if neither expression is true, the else block is evaluated. Here it is in action:julia> function test(x, y)\n           if x < y\n               println(\"x is less than y\")\n           elseif x > y\n               println(\"x is greater than y\")\n           else\n               println(\"x is equal to y\")\n           end\n       end\ntest (generic function with 1 method)\n\njulia> test(1, 2)\nx is less than y\n\njulia> test(2, 1)\nx is greater than y\n\njulia> test(1, 1)\nx is equal to yThe elseif and else blocks are optional, and as many elseif blocks as desired can be used. The condition expressions in the if-elseif-else construct are evaluated until the first one evaluates to true, after which the associated block is evaluated, and no further condition expressions or blocks are evaluated.if blocks are \"leaky\", i.e. they do not introduce a local scope. This means that new variables defined inside the if clauses can be used after the if block, even if they weren\'t defined before. So, we could have defined the test function above asjulia> function test(x,y)\n           if x < y\n               relation = \"less than\"\n           elseif x == y\n               relation = \"equal to\"\n           else\n               relation = \"greater than\"\n           end\n           println(\"x is \", relation, \" y.\")\n       end\ntest (generic function with 1 method)\n\njulia> test(2, 1)\nx is greater than y.The variable relation is declared inside the if block, but used outside. However, when depending on this behavior, make sure all possible code paths define a value for the variable. The following change to the above function results in a runtime errorjulia> function test(x,y)\n           if x < y\n               relation = \"less than\"\n           elseif x == y\n               relation = \"equal to\"\n           end\n           println(\"x is \", relation, \" y.\")\n       end\ntest (generic function with 1 method)\n\njulia> test(1,2)\nx is less than y.\n\njulia> test(2,1)\nERROR: UndefVarError: relation not defined\nStacktrace:\n [1] test(::Int64, ::Int64) at ./none:7if blocks also return a value, which may seem unintuitive to users coming from many other languages. This value is simply the return value of the last executed statement in the branch that was chosen, sojulia> x = 3\n3\n\njulia> if x > 0\n           \"positive!\"\n       else\n           \"negative...\"\n       end\n\"positive!\"Note that very short conditional statements (one-liners) are frequently expressed using Short-Circuit Evaluation in Julia, as outlined in the next section.Unlike C, MATLAB, Perl, Python, and Ruby – but like Java, and a few other stricter, typed languages – it is an error if the value of a conditional expression is anything but true or false:julia> if 1\n           println(\"true\")\n       end\nERROR: TypeError: non-boolean (Int64) used in boolean contextThis error indicates that the conditional was of the wrong type: Int64 rather than the required Bool.The so-called \"ternary operator\", ?:, is closely related to the if-elseif-else syntax, but is used where a conditional choice between single expression values is required, as opposed to conditional execution of longer blocks of code. It gets its name from being the only operator in most languages taking three operands:a ? b : cThe expression a, before the ?, is a condition expression, and the ternary operation evaluates the expression b, before the :, if the condition a is true or the expression c, after the :, if it is false.The easiest way to understand this behavior is to see an example. In the previous example, the println call is shared by all three branches: the only real choice is which literal string to print. This could be written more concisely using the ternary operator. For the sake of clarity, let\'s try a two-way version first:julia> x = 1; y = 2;\n\njulia> println(x < y ? \"less than\" : \"not less than\")\nless than\n\njulia> x = 1; y = 0;\n\njulia> println(x < y ? \"less than\" : \"not less than\")\nnot less thanIf the expression x < y is true, the entire ternary operator expression evaluates to the string \"less than\" and otherwise it evaluates to the string \"not less than\". The original three-way example requires chaining multiple uses of the ternary operator together:julia> test(x, y) = println(x < y ? \"x is less than y\"    :\n                            x > y ? \"x is greater than y\" : \"x is equal to y\")\ntest (generic function with 1 method)\n\njulia> test(1, 2)\nx is less than y\n\njulia> test(2, 1)\nx is greater than y\n\njulia> test(1, 1)\nx is equal to yTo facilitate chaining, the operator associates from right to left.It is significant that like if-elseif-else, the expressions before and after the : are only evaluated if the condition expression evaluates to true or false, respectively:julia> v(x) = (println(x); x)\nv (generic function with 1 method)\n\njulia> 1 < 2 ? v(\"yes\") : v(\"no\")\nyes\n\"yes\"\n\njulia> 1 > 2 ? v(\"yes\") : v(\"no\")\nno\n\"no\""
},

{
    "location": "manual/control-flow/#Short-Circuit-Evaluation-1",
    "page": "Control Flow",
    "title": "Short-Circuit Evaluation",
    "category": "section",
    "text": "Short-circuit evaluation is quite similar to conditional evaluation. The behavior is found in most imperative programming languages having the && and || boolean operators: in a series of boolean expressions connected by these operators, only the minimum number of expressions are evaluated as are necessary to determine the final boolean value of the entire chain. Explicitly, this means that:In the expression a && b, the subexpression b is only evaluated if a evaluates to true.\nIn the expression a || b, the subexpression b is only evaluated if a evaluates to false.The reasoning is that a && b must be false if a is false, regardless of the value of b, and likewise, the value of a || b must be true if a is true, regardless of the value of b. Both && and || associate to the right, but && has higher precedence than || does. It\'s easy to experiment with this behavior:julia> t(x) = (println(x); true)\nt (generic function with 1 method)\n\njulia> f(x) = (println(x); false)\nf (generic function with 1 method)\n\njulia> t(1) && t(2)\n1\n2\ntrue\n\njulia> t(1) && f(2)\n1\n2\nfalse\n\njulia> f(1) && t(2)\n1\nfalse\n\njulia> f(1) && f(2)\n1\nfalse\n\njulia> t(1) || t(2)\n1\ntrue\n\njulia> t(1) || f(2)\n1\ntrue\n\njulia> f(1) || t(2)\n1\n2\ntrue\n\njulia> f(1) || f(2)\n1\n2\nfalseYou can easily experiment in the same way with the associativity and precedence of various combinations of && and || operators.This behavior is frequently used in Julia to form an alternative to very short if statements. Instead of if <cond> <statement> end, one can write <cond> && <statement> (which could be read as: <cond> and then <statement>). Similarly, instead of if ! <cond> <statement> end, one can write <cond> || <statement> (which could be read as: <cond> or else <statement>).For example, a recursive factorial routine could be defined like this:julia> function fact(n::Int)\n           n >= 0 || error(\"n must be non-negative\")\n           n == 0 && return 1\n           n * fact(n-1)\n       end\nfact (generic function with 1 method)\n\njulia> fact(5)\n120\n\njulia> fact(0)\n1\n\njulia> fact(-1)\nERROR: n must be non-negative\nStacktrace:\n [1] fact(::Int64) at ./none:2Boolean operations without short-circuit evaluation can be done with the bitwise boolean operators introduced in Mathematical Operations and Elementary Functions: & and |. These are normal functions, which happen to support infix operator syntax, but always evaluate their arguments:julia> f(1) & t(2)\n1\n2\nfalse\n\njulia> t(1) | t(2)\n1\n2\ntrueJust like condition expressions used in if, elseif or the ternary operator, the operands of && or || must be boolean values (true or false). Using a non-boolean value anywhere except for the last entry in a conditional chain is an error:julia> 1 && true\nERROR: TypeError: non-boolean (Int64) used in boolean contextOn the other hand, any type of expression can be used at the end of a conditional chain. It will be evaluated and returned depending on the preceding conditionals:julia> true && (x = (1, 2, 3))\n(1, 2, 3)\n\njulia> false && (x = (1, 2, 3))\nfalse"
},

{
    "location": "manual/control-flow/#man-loops-1",
    "page": "Control Flow",
    "title": "Repeated Evaluation: Loops",
    "category": "section",
    "text": "There are two constructs for repeated evaluation of expressions: the while loop and the for loop. Here is an example of a while loop:julia> i = 1;\n\njulia> while i <= 5\n           println(i)\n           i += 1\n       end\n1\n2\n3\n4\n5The while loop evaluates the condition expression (i <= 5 in this case), and as long it remains true, keeps also evaluating the body of the while loop. If the condition expression is false when the while loop is first reached, the body is never evaluated.The for loop makes common repeated evaluation idioms easier to write. Since counting up and down like the above while loop does is so common, it can be expressed more concisely with a for loop:julia> for i = 1:5\n           println(i)\n       end\n1\n2\n3\n4\n5Here the 1:5 is a Range object, representing the sequence of numbers 1, 2, 3, 4, 5. The for loop iterates through these values, assigning each one in turn to the variable i. One rather important distinction between the previous while loop form and the for loop form is the scope during which the variable is visible. If the variable i has not been introduced in an other scope, in the for loop form, it is visible only inside of the for loop, and not afterwards. You\'ll either need a new interactive session instance or a different variable name to test this:julia> for j = 1:5\n           println(j)\n       end\n1\n2\n3\n4\n5\n\njulia> j\nERROR: UndefVarError: j not definedSee Scope of Variables for a detailed explanation of variable scope and how it works in Julia.In general, the for loop construct can iterate over any container. In these cases, the alternative (but fully equivalent) keyword in or ∈ is typically used instead of =, since it makes the code read more clearly:julia> for i in [1,4,0]\n           println(i)\n       end\n1\n4\n0\n\njulia> for s ∈ [\"foo\",\"bar\",\"baz\"]\n           println(s)\n       end\nfoo\nbar\nbazVarious types of iterable containers will be introduced and discussed in later sections of the manual (see, e.g., Multi-dimensional Arrays).It is sometimes convenient to terminate the repetition of a while before the test condition is falsified or stop iterating in a for loop before the end of the iterable object is reached. This can be accomplished with the break keyword:julia> i = 1;\n\njulia> while true\n           println(i)\n           if i >= 5\n               break\n           end\n           i += 1\n       end\n1\n2\n3\n4\n5\n\njulia> for i = 1:1000\n           println(i)\n           if i >= 5\n               break\n           end\n       end\n1\n2\n3\n4\n5Without the break keyword, the above while loop would never terminate on its own, and the for loop would iterate up to 1000. These loops are both exited early by using break.In other circumstances, it is handy to be able to stop an iteration and move on to the next one immediately. The continue keyword accomplishes this:julia> for i = 1:10\n           if i % 3 != 0\n               continue\n           end\n           println(i)\n       end\n3\n6\n9This is a somewhat contrived example since we could produce the same behavior more clearly by negating the condition and placing the println call inside the if block. In realistic usage there is more code to be evaluated after the continue, and often there are multiple points from which one calls continue.Multiple nested for loops can be combined into a single outer loop, forming the cartesian product of its iterables:julia> for i = 1:2, j = 3:4\n           println((i, j))\n       end\n(1, 3)\n(1, 4)\n(2, 3)\n(2, 4)A break statement inside such a loop exits the entire nest of loops, not just the inner one."
},

{
    "location": "manual/control-flow/#Exception-Handling-1",
    "page": "Control Flow",
    "title": "Exception Handling",
    "category": "section",
    "text": "When an unexpected condition occurs, a function may be unable to return a reasonable value to its caller. In such cases, it may be best for the exceptional condition to either terminate the program, printing a diagnostic error message, or if the programmer has provided code to handle such exceptional circumstances, allow that code to take the appropriate action."
},

{
    "location": "manual/control-flow/#Built-in-Exceptions-1",
    "page": "Control Flow",
    "title": "Built-in Exceptions",
    "category": "section",
    "text": "Exceptions are thrown when an unexpected condition has occurred. The built-in Exceptions listed below all interrupt the normal flow of control.Exception\nArgumentError\nBoundsError\nCompositeException\nDivideError\nDomainError\nEOFError\nErrorException\nInexactError\nInitError\nInterruptException\nInvalidStateException\nKeyError\nLoadError\nOutOfMemoryError\nReadOnlyMemoryError\nRemoteException\nMethodError\nOverflowError\nParseError\nSystemError\nTypeError\nUndefRefError\nUndefVarError\nUnicodeErrorFor example, the sqrt() function throws a DomainError if applied to a negative real value:julia> sqrt(-1)\nERROR: DomainError:\nsqrt will only return a complex result if called with a complex argument. Try sqrt(complex(x)).\nStacktrace:\n [1] sqrt(::Int64) at ./math.jl:434You may define your own exceptions in the following way:julia> struct MyCustomException <: Exception end"
},

{
    "location": "manual/control-flow/#The-[throw()](@ref)-function-1",
    "page": "Control Flow",
    "title": "The throw() function",
    "category": "section",
    "text": "Exceptions can be created explicitly with throw(). For example, a function defined only for nonnegative numbers could be written to throw() a DomainError if the argument is negative:julia> f(x) = x>=0 ? exp(-x) : throw(DomainError())\nf (generic function with 1 method)\n\njulia> f(1)\n0.36787944117144233\n\njulia> f(-1)\nERROR: DomainError:\nStacktrace:\n [1] f(::Int64) at ./none:1Note that DomainError without parentheses is not an exception, but a type of exception. It needs to be called to obtain an Exception object:julia> typeof(DomainError()) <: Exception\ntrue\n\njulia> typeof(DomainError) <: Exception\nfalseAdditionally, some exception types take one or more arguments that are used for error reporting:julia> throw(UndefVarError(:x))\nERROR: UndefVarError: x not definedThis mechanism can be implemented easily by custom exception types following the way UndefVarError is written:julia> struct MyUndefVarError <: Exception\n           var::Symbol\n       end\n\njulia> Base.showerror(io::IO, e::MyUndefVarError) = print(io, e.var, \" not defined\")note: Note\nWhen writing an error message, it is preferred to make the first word lowercase. For example, size(A) == size(B) || throw(DimensionMismatch(\"size of A not equal to size of B\"))is preferred oversize(A) == size(B) || throw(DimensionMismatch(\"Size of A not equal to size of B\")).However, sometimes it makes sense to keep the uppercase first letter, for instance if an argument to a function is a capital letter: size(A,1) == size(B,2) || throw(DimensionMismatch(\"A has first dimension...\"))."
},

{
    "location": "manual/control-flow/#Errors-1",
    "page": "Control Flow",
    "title": "Errors",
    "category": "section",
    "text": "The error() function is used to produce an ErrorException that interrupts the normal flow of control.Suppose we want to stop execution immediately if the square root of a negative number is taken. To do this, we can define a fussy version of the sqrt() function that raises an error if its argument is negative:julia> fussy_sqrt(x) = x >= 0 ? sqrt(x) : error(\"negative x not allowed\")\nfussy_sqrt (generic function with 1 method)\n\njulia> fussy_sqrt(2)\n1.4142135623730951\n\njulia> fussy_sqrt(-1)\nERROR: negative x not allowed\nStacktrace:\n [1] fussy_sqrt(::Int64) at ./none:1If fussy_sqrt is called with a negative value from another function, instead of trying to continue execution of the calling function, it returns immediately, displaying the error message in the interactive session:julia> function verbose_fussy_sqrt(x)\n           println(\"before fussy_sqrt\")\n           r = fussy_sqrt(x)\n           println(\"after fussy_sqrt\")\n           return r\n       end\nverbose_fussy_sqrt (generic function with 1 method)\n\njulia> verbose_fussy_sqrt(2)\nbefore fussy_sqrt\nafter fussy_sqrt\n1.4142135623730951\n\njulia> verbose_fussy_sqrt(-1)\nbefore fussy_sqrt\nERROR: negative x not allowed\nStacktrace:\n [1] fussy_sqrt at ./none:1 [inlined]\n [2] verbose_fussy_sqrt(::Int64) at ./none:3"
},

{
    "location": "manual/control-flow/#Warnings-and-informational-messages-1",
    "page": "Control Flow",
    "title": "Warnings and informational messages",
    "category": "section",
    "text": "Julia also provides other functions that write messages to the standard error I/O, but do not throw any Exceptions and hence do not interrupt execution:julia> info(\"Hi\"); 1+1\nINFO: Hi\n2\n\njulia> warn(\"Hi\"); 1+1\nWARNING: Hi\n2\n\njulia> error(\"Hi\"); 1+1\nERROR: Hi\nStacktrace:\n [1] error(::String) at ./error.jl:21"
},

{
    "location": "manual/control-flow/#The-try/catch-statement-1",
    "page": "Control Flow",
    "title": "The try/catch statement",
    "category": "section",
    "text": "The try/catch statement allows for Exceptions to be tested for. For example, a customized square root function can be written to automatically call either the real or complex square root method on demand using Exceptions :julia> f(x) = try\n           sqrt(x)\n       catch\n           sqrt(complex(x, 0))\n       end\nf (generic function with 1 method)\n\njulia> f(1)\n1.0\n\njulia> f(-1)\n0.0 + 1.0imIt is important to note that in real code computing this function, one would compare x to zero instead of catching an exception. The exception is much slower than simply comparing and branching.try/catch statements also allow the Exception to be saved in a variable. In this contrived example, the following example calculates the square root of the second element of x if x is indexable, otherwise assumes x is a real number and returns its square root:julia> sqrt_second(x) = try\n           sqrt(x[2])\n       catch y\n           if isa(y, DomainError)\n               sqrt(complex(x[2], 0))\n           elseif isa(y, BoundsError)\n               sqrt(x)\n           end\n       end\nsqrt_second (generic function with 1 method)\n\njulia> sqrt_second([1 4])\n2.0\n\njulia> sqrt_second([1 -4])\n0.0 + 2.0im\n\njulia> sqrt_second(9)\n3.0\n\njulia> sqrt_second(-9)\nERROR: DomainError:\nStacktrace:\n [1] sqrt_second(::Int64) at ./none:7Note that the symbol following catch will always be interpreted as a name for the exception, so care is needed when writing try/catch expressions on a single line. The following code will not work to return the value of x in case of an error:try bad() catch x endInstead, use a semicolon or insert a line break after catch:try bad() catch; x end\n\ntry bad()\ncatch\n    x\nendThe catch clause is not strictly necessary; when omitted, the default return value is nothing.julia> try error() end # Returns nothingThe power of the try/catch construct lies in the ability to unwind a deeply nested computation immediately to a much higher level in the stack of calling functions. There are situations where no error has occurred, but the ability to unwind the stack and pass a value to a higher level is desirable. Julia provides the rethrow(), backtrace() and catch_backtrace() functions for more advanced error handling."
},

{
    "location": "manual/control-flow/#finally-Clauses-1",
    "page": "Control Flow",
    "title": "finally Clauses",
    "category": "section",
    "text": "In code that performs state changes or uses resources like files, there is typically clean-up work (such as closing files) that needs to be done when the code is finished. Exceptions potentially complicate this task, since they can cause a block of code to exit before reaching its normal end. The finally keyword provides a way to run some code when a given block of code exits, regardless of how it exits.For example, here is how we can guarantee that an opened file is closed:f = open(\"file\")\ntry\n    # operate on file f\nfinally\n    close(f)\nendWhen control leaves the try block (for example due to a return, or just finishing normally), close(f) will be executed. If the try block exits due to an exception, the exception will continue propagating. A catch block may be combined with try and finally as well. In this case the finally block will run after catch has handled the error."
},

{
    "location": "manual/control-flow/#man-tasks-1",
    "page": "Control Flow",
    "title": "Tasks (aka Coroutines)",
    "category": "section",
    "text": "Tasks are a control flow feature that allows computations to be suspended and resumed in a flexible manner. This feature is sometimes called by other names, such as symmetric coroutines, lightweight threads, cooperative multitasking, or one-shot continuations.When a piece of computing work (in practice, executing a particular function) is designated as a Task, it becomes possible to interrupt it by switching to another Task. The original Task can later be resumed, at which point it will pick up right where it left off. At first, this may seem similar to a function call. However there are two key differences. First, switching tasks does not use any space, so any number of task switches can occur without consuming the call stack. Second, switching among tasks can occur in any order, unlike function calls, where the called function must finish executing before control returns to the calling function.This kind of control flow can make it much easier to solve certain problems. In some problems, the various pieces of required work are not naturally related by function calls; there is no obvious \"caller\" or \"callee\" among the jobs that need to be done. An example is the producer-consumer problem, where one complex procedure is generating values and another complex procedure is consuming them. The consumer cannot simply call a producer function to get a value, because the producer may have more values to generate and so might not yet be ready to return. With tasks, the producer and consumer can both run as long as they need to, passing values back and forth as necessary.Julia provides a Channel mechanism for solving this problem. A Channel is a waitable first-in first-out queue which can have multiple tasks reading from and writing to it.Let\'s define a producer task, which produces values via the put! call. To consume values, we need to schedule the producer to run in a new task. A special Channel constructor which accepts a 1-arg function as an argument can be used to run a task bound to a channel. We can then take!() values repeatedly from the channel object:julia> function producer(c::Channel)\n           put!(c, \"start\")\n           for n=1:4\n               put!(c, 2n)\n           end\n           put!(c, \"stop\")\n       end;\n\njulia> chnl = Channel(producer);\n\njulia> take!(chnl)\n\"start\"\n\njulia> take!(chnl)\n2\n\njulia> take!(chnl)\n4\n\njulia> take!(chnl)\n6\n\njulia> take!(chnl)\n8\n\njulia> take!(chnl)\n\"stop\"One way to think of this behavior is that producer was able to return multiple times. Between calls to put!(), the producer\'s execution is suspended and the consumer has control.The returned Channel can be used as an iterable object in a for loop, in which case the loop variable takes on all the produced values. The loop is terminated when the channel is closed.julia> for x in Channel(producer)\n           println(x)\n       end\nstart\n2\n4\n6\n8\nstopNote that we did not have to explicitly close the channel in the producer. This is because the act of binding a Channel to a Task() associates the open lifetime of a channel with that of the bound task. The channel object is closed automatically when the task terminates. Multiple channels can be bound to a task, and vice-versa.While the Task() constructor expects a 0-argument function, the Channel() method which creates a channel bound task expects a function that accepts a single argument of type Channel. A common pattern is for the producer to be parameterized, in which case a partial function application is needed to create a 0 or 1 argument anonymous function.For Task() objects this can be done either directly or by use of a convenience macro:function mytask(myarg)\n    ...\nend\n\ntaskHdl = Task(() -> mytask(7))\n# or, equivalently\ntaskHdl = @task mytask(7)To orchestrate more advanced work distribution patterns, bind() and schedule() can be used in conjunction with Task() and Channel() constructors to explicitly link a set of channels with a set of producer/consumer tasks.Note that currently Julia tasks are not scheduled to run on separate CPU cores. True kernel threads are discussed under the topic of Parallel Computing."
},

{
    "location": "manual/control-flow/#Core-task-operations-1",
    "page": "Control Flow",
    "title": "Core task operations",
    "category": "section",
    "text": "Let us explore the low level construct yieldto() to underestand how task switching works. yieldto(task,value) suspends the current task, switches to the specified task, and causes that task\'s last yieldto() call to return the specified value. Notice that yieldto() is the only operation required to use task-style control flow; instead of calling and returning we are always just switching to a different task. This is why this feature is also called \"symmetric coroutines\"; each task is switched to and from using the same mechanism.yieldto() is powerful, but most uses of tasks do not invoke it directly. Consider why this might be. If you switch away from the current task, you will probably want to switch back to it at some point, but knowing when to switch back, and knowing which task has the responsibility of switching back, can require considerable coordination. For example, put!() and take!() are blocking operations, which, when used in the context of channels maintain state to remember who the consumers are. Not needing to manually keep track of the consuming task is what makes put!() easier to use than the low-level yieldto().In addition to yieldto(), a few other basic functions are needed to use tasks effectively.current_task() gets a reference to the currently-running task.\nistaskdone() queries whether a task has exited.\nistaskstarted() queries whether a task has run yet.\ntask_local_storage() manipulates a key-value store specific to the current task."
},

{
    "location": "manual/control-flow/#Tasks-and-events-1",
    "page": "Control Flow",
    "title": "Tasks and events",
    "category": "section",
    "text": "Most task switches occur as a result of waiting for events such as I/O requests, and are performed by a scheduler included in the standard library. The scheduler maintains a queue of runnable tasks, and executes an event loop that restarts tasks based on external events such as message arrival.The basic function for waiting for an event is wait(). Several objects implement wait(); for example, given a Process object, wait() will wait for it to exit. wait() is often implicit; for example, a wait() can happen inside a call to read() to wait for data to be available.In all of these cases, wait() ultimately operates on a Condition object, which is in charge of queueing and restarting tasks. When a task calls wait() on a Condition, the task is marked as non-runnable, added to the condition\'s queue, and switches to the scheduler. The scheduler will then pick another task to run, or block waiting for external events. If all goes well, eventually an event handler will call notify() on the condition, which causes tasks waiting for that condition to become runnable again.A task created explicitly by calling Task is initially not known to the scheduler. This allows you to manage tasks manually using yieldto() if you wish. However, when such a task waits for an event, it still gets restarted automatically when the event happens, as you would expect. It is also possible to make the scheduler run a task whenever it can, without necessarily waiting for any events. This is done by calling schedule(), or using the @schedule or @async macros (see Parallel Computing for more details)."
},

{
    "location": "manual/control-flow/#Task-states-1",
    "page": "Control Flow",
    "title": "Task states",
    "category": "section",
    "text": "Tasks have a state field that describes their execution status. A Task state is one of the following symbols:Symbol Meaning\n:runnable Currently running, or available to be switched to\n:waiting Blocked waiting for a specific event\n:queued In the scheduler\'s run queue about to be restarted\n:done Successfully finished executing\n:failed Finished with an uncaught exception"
},

{
    "location": "manual/variables-and-scoping/#",
    "page": "Scope of Variables",
    "title": "Scope of Variables",
    "category": "page",
    "text": ""
},

{
    "location": "manual/variables-and-scoping/#scope-of-variables-1",
    "page": "Scope of Variables",
    "title": "Scope of Variables",
    "category": "section",
    "text": "The scope of a variable is the region of code within which a variable is visible. Variable scoping helps avoid variable naming conflicts. The concept is intuitive: two functions can both have arguments called x without the two x\'s referring to the same thing. Similarly there are many other cases where different blocks of code can use the same name without referring to the same thing. The rules for when the same variable name does or doesn\'t refer to the same thing are called scope rules; this section spells them out in detail.Certain constructs in the language introduce scope blocks, which are regions of code that are eligible to be the scope of some set of variables. The scope of a variable cannot be an arbitrary set of source lines; instead, it will always line up with one of these blocks. There are two main types of scopes in Julia, global scope and local scope, the latter can be nested. The constructs introducing scope blocks are:Scope name block/construct introducing this kind of scope\nGlobal Scope module, baremodule, at interactive prompt (REPL)\nLocal Scope Soft Local Scope: for, while, comprehensions, try-catch-finally, let\nLocal Scope Hard Local Scope: functions (either syntax, anonymous & do-blocks), struct, macroNotably missing from this table are begin blocks and if blocks, which do not introduce new scope blocks. All three types of scopes follow somewhat different rules which will be explained below as well as some extra rules for certain blocks.Julia uses lexical scoping, meaning that a function\'s scope does not inherit from its caller\'s scope, but from the scope in which the function was defined. For example, in the following code the x inside foo refers to the x in the global scope of its module Bar:julia> module Bar\n           x = 1\n           foo() = x\n       end;and not a x in the scope where foo is used:julia> import .Bar\n\njulia> x = -1;\n\njulia> Bar.foo()\n1Thus lexical scope means that the scope of variables can be inferred from the source code alone."
},

{
    "location": "manual/variables-and-scoping/#Global-Scope-1",
    "page": "Scope of Variables",
    "title": "Global Scope",
    "category": "section",
    "text": "Each module introduces a new global scope, separate from the global scope of all other modules; there is no all-encompassing global scope. Modules can introduce variables of other modules into their scope through the using or import statements or through qualified access using the dot-notation, i.e. each module is a so-called namespace. Note that variable bindings can only be changed within their global scope and not from an outside module.julia> module A\n           a = 1 # a global in A\'s scope\n       end;\n\njulia> module B\n           module C\n               c = 2\n           end\n           b = C.c    # can access the namespace of a nested global scope\n                      # through a qualified access\n           import ..A # makes module A available\n           d = A.a\n       end;\n\njulia> module D\n           b = a # errors as D\'s global scope is separate from A\'s\n       end;\nERROR: UndefVarError: a not defined\n\njulia> module E\n           import ..A # make module A available\n           A.a = 2    # throws below error\n       end;\nERROR: cannot assign variables in other modulesNote that the interactive prompt (aka REPL) is in the global scope of the module Main."
},

{
    "location": "manual/variables-and-scoping/#Local-Scope-1",
    "page": "Scope of Variables",
    "title": "Local Scope",
    "category": "section",
    "text": "A new local scope is introduced by most code-blocks, see above table for a complete list.  A local scope usually inherits all the variables from its parent scope, both for reading and writing. There are two subtypes of local scopes, hard and soft, with slightly different rules concerning what variables are inherited. Unlike global scopes, local scopes are not namespaces, thus variables in an inner scope cannot be retrieved from the parent scope through some sort of qualified access.The following rules and examples pertain to both hard and soft local scopes. A newly introduced variable in a local scope does not back-propagate to its parent scope. For example, here the z is not introduced into the top-level scope:julia> for i = 1:10\n           z = i\n       end\n\njulia> z\nERROR: UndefVarError: z not defined(Note, in this and all following examples it is assumed that their top-level is a global scope with a clean workspace, for instance a newly started REPL.)Inside a local scope a variable can be forced to be a local variable using the local keyword:julia> x = 0;\n\njulia> for i = 1:10\n           local x\n           x = i + 1\n       end\n\njulia> x\n0Inside a local scope a new global variable can be defined using the keyword global:julia> for i = 1:10\n           global z\n           z = i\n       end\n\njulia> z\n10The location of both the local and global keywords within the scope block is irrelevant. The following is equivalent to the last example (although stylistically worse):julia> for i = 1:10\n           z = i\n           global z\n       end\n\njulia> z\n10"
},

{
    "location": "manual/variables-and-scoping/#Soft-Local-Scope-1",
    "page": "Scope of Variables",
    "title": "Soft Local Scope",
    "category": "section",
    "text": "In a soft local scope, all variables are inherited from its parent scope unless a variable is specifically marked with the keyword local.Soft local scopes are introduced by for-loops, while-loops, comprehensions, try-catch-finally-blocks, and let-blocks. There are some extra rules for Let Blocks and for For Loops and Comprehensions.In the following example the x and y refer always to the same variables as the soft local scope inherits both read and write variables:julia> x, y = 0, 1;\n\njulia> for i = 1:10\n           x = i + y + 1\n       end\n\njulia> x\n12Within soft scopes, the global keyword is never necessary, although allowed. The only case when it would change the semantics is (currently) a syntax error:julia> let\n           local j = 2\n           let\n               global j = 3\n           end\n       end\nERROR: syntax: `global j`: j is local variable in the enclosing scope"
},

{
    "location": "manual/variables-and-scoping/#Hard-Local-Scope-1",
    "page": "Scope of Variables",
    "title": "Hard Local Scope",
    "category": "section",
    "text": "Hard local scopes are introduced by function definitions (in all their forms), struct type definition blocks, and macro-definitions.In a hard local scope, all variables are inherited from its parent scope unless:an assignment would result in a modified global variable, or\na variable is specifically marked with the keyword local.Thus global variables are only inherited for reading but not for writing:julia> x, y = 1, 2;\n\njulia> function foo()\n           x = 2        # assignment introduces a new local\n           return x + y # y refers to the global\n       end;\n\njulia> foo()\n4\n\njulia> x\n1An explicit global is needed to assign to a global variable:julia> x = 1;\n\njulia> function foobar()\n           global x = 2\n       end;\n\njulia> foobar();\n\njulia> x\n2Note that nested functions can behave differently to functions defined in the global scope as they can modify their parent scope\'s local variables:julia> x, y = 1, 2;\n\njulia> function baz()\n           x = 2 # introduces a new local\n           function bar()\n               x = 10       # modifies the parent\'s x\n               return x + y # y is global\n           end\n           return bar() + x # 12 + 10 (x is modified in call of bar())\n       end;\n\njulia> baz()\n22\n\njulia> x, y\n(1, 2)The distinction between inheriting global and local variables for assignment can lead to some slight differences between functions defined in local vs. global scopes. Consider the modification of the last example by moving bar to the global scope:julia> x, y = 1, 2;\n\njulia> function bar()\n           x = 10 # local\n           return x + y\n       end;\n\njulia> function quz()\n           x = 2 # local\n           return bar() + x # 12 + 2 (x is not modified)\n       end;\n\njulia> quz()\n14\n\njulia> x, y\n(1, 2)Note that above subtlety does not pertain to type and macro definitions as they can only appear at the global scope. There are special scoping rules concerning the evaluation of default and keyword function arguments which are described in the Function section.An assignment introducing a variable used inside a function, type or macro definition need not come before its inner usage:julia> f = y -> y + a\n(::#1) (generic function with 1 method)\n\njulia> f(3)\nERROR: UndefVarError: a not defined\nStacktrace:\n [1] (::##1#2)(::Int64) at ./none:1\n\njulia> a = 1\n1\n\njulia> f(3)\n4This behavior may seem slightly odd for a normal variable, but allows for named functions – which are just normal variables holding function objects – to be used before they are defined. This allows functions to be defined in whatever order is intuitive and convenient, rather than forcing bottom up ordering or requiring forward declarations, as long as they are defined by the time they are actually called. As an example, here is an inefficient, mutually recursive way to test if positive integers are even or odd:julia> even(n) = n == 0 ? true : odd(n-1);\n\njulia> odd(n) = n == 0 ? false : even(n-1);\n\njulia> even(3)\nfalse\n\njulia> odd(3)\ntrueJulia provides built-in, efficient functions to test for oddness and evenness called iseven() and isodd() so the above definitions should only be taken as examples."
},

{
    "location": "manual/variables-and-scoping/#Hard-vs.-Soft-Local-Scope-1",
    "page": "Scope of Variables",
    "title": "Hard vs. Soft Local Scope",
    "category": "section",
    "text": "Blocks which introduce a soft local scope, such as loops, are generally used to manipulate the variables in their parent scope. Thus their default is to fully access all variables in their parent scope.Conversely, the code inside blocks which introduce a hard local scope (function, type, and macro definitions) can be executed at any place in a program. Remotely changing the state of global variables in other modules should be done with care and thus this is an opt-in feature requiring the global keyword.The reason to allow modifying local variables of parent scopes in nested functions is to allow constructing closures which have a private state, for instance the state variable in the following example:julia> let\n           state = 0\n           global counter\n           counter() = state += 1\n       end;\n\njulia> counter()\n1\n\njulia> counter()\n2See also the closures in the examples in the next two sections."
},

{
    "location": "manual/variables-and-scoping/#Let-Blocks-1",
    "page": "Scope of Variables",
    "title": "Let Blocks",
    "category": "section",
    "text": "Unlike assignments to local variables, let statements allocate new variable bindings each time they run. An assignment modifies an existing value location, and let creates new locations. This difference is usually not important, and is only detectable in the case of variables that outlive their scope via closures. The let syntax accepts a comma-separated series of assignments and variable names:julia> x, y, z = -1, -1, -1;\n\njulia> let x = 1, z\n           println(\"x: $x, y: $y\") # x is local variable, y the global\n           println(\"z: $z\") # errors as z has not been assigned yet but is local\n       end\nx: 1, y: -1\nERROR: UndefVarError: z not definedThe assignments are evaluated in order, with each right-hand side evaluated in the scope before the new variable on the left-hand side has been introduced. Therefore it makes sense to write something like let x = x since the two x variables are distinct and have separate storage. Here is an example where the behavior of let is needed:julia> Fs = Array{Any}(2); i = 1;\n\njulia> while i <= 2\n           Fs[i] = ()->i\n           i += 1\n       end\n\njulia> Fs[1]()\n3\n\njulia> Fs[2]()\n3Here we create and store two closures that return variable i. However, it is always the same variable i, so the two closures behave identically. We can use let to create a new binding for i:julia> Fs = Array{Any}(2); i = 1;\n\njulia> while i <= 2\n           let i = i\n               Fs[i] = ()->i\n           end\n           i += 1\n       end\n\njulia> Fs[1]()\n1\n\njulia> Fs[2]()\n2Since the begin construct does not introduce a new scope, it can be useful to use a zero-argument let to just introduce a new scope block without creating any new bindings:julia> let\n           local x = 1\n           let\n               local x = 2\n           end\n           x\n       end\n1Since let introduces a new scope block, the inner local x is a different variable than the outer local x."
},

{
    "location": "manual/variables-and-scoping/#For-Loops-and-Comprehensions-1",
    "page": "Scope of Variables",
    "title": "For Loops and Comprehensions",
    "category": "section",
    "text": "for loops and Comprehensions have the following behavior: any new variables introduced in their body scopes are freshly allocated for each loop iteration. This is in contrast to while loops which reuse the variables for all iterations. Therefore these constructs are similar to while loops with let blocks inside:julia> Fs = Array{Any}(2);\n\njulia> for j = 1:2\n           Fs[j] = ()->j\n       end\n\njulia> Fs[1]()\n1\n\njulia> Fs[2]()\n2for loops will reuse existing variables for its iteration variable:julia> i = 0;\n\njulia> for i = 1:3\n       end\n\njulia> i\n3However, comprehensions do not do this, and always freshly allocate their iteration variables:julia> x = 0;\n\njulia> [ x for x = 1:3 ];\n\njulia> x\n0"
},

{
    "location": "manual/variables-and-scoping/#Constants-1",
    "page": "Scope of Variables",
    "title": "Constants",
    "category": "section",
    "text": "A common use of variables is giving names to specific, unchanging values. Such variables are only assigned once. This intent can be conveyed to the compiler using the const keyword:julia> const e  = 2.71828182845904523536;\n\njulia> const pi = 3.14159265358979323846;The const declaration is allowed on both global and local variables, but is especially useful for globals. It is difficult for the compiler to optimize code involving global variables, since their values (or even their types) might change at almost any time. If a global variable will not change, adding a const declaration solves this performance problem.Local constants are quite different. The compiler is able to determine automatically when a local variable is constant, so local constant declarations are not necessary for performance purposes.Special top-level assignments, such as those performed by the function and struct keywords, are constant by default.Note that const only affects the variable binding; the variable may be bound to a mutable object (such as an array), and that object may still be modified."
},

{
    "location": "manual/types/#",
    "page": "Types",
    "title": "Types",
    "category": "page",
    "text": ""
},

{
    "location": "manual/types/#man-types-1",
    "page": "Types",
    "title": "Types",
    "category": "section",
    "text": "Type systems have traditionally fallen into two quite different camps: static type systems, where every program expression must have a type computable before the execution of the program, and dynamic type systems, where nothing is known about types until run time, when the actual values manipulated by the program are available. Object orientation allows some flexibility in statically typed languages by letting code be written without the precise types of values being known at compile time. The ability to write code that can operate on different types is called polymorphism. All code in classic dynamically typed languages is polymorphic: only by explicitly checking types, or when objects fail to support operations at run-time, are the types of any values ever restricted.Julia\'s type system is dynamic, but gains some of the advantages of static type systems by making it possible to indicate that certain values are of specific types. This can be of great assistance in generating efficient code, but even more significantly, it allows method dispatch on the types of function arguments to be deeply integrated with the language. Method dispatch is explored in detail in Methods, but is rooted in the type system presented here.The default behavior in Julia when types are omitted is to allow values to be of any type. Thus, one can write many useful Julia programs without ever explicitly using types. When additional expressiveness is needed, however, it is easy to gradually introduce explicit type annotations into previously \"untyped\" code. Doing so will typically increase both the performance and robustness of these systems, and perhaps somewhat counterintuitively, often significantly simplify them.Describing Julia in the lingo of type systems, it is: dynamic, nominative and parametric. Generic types can be parameterized, and the hierarchical relationships between types are explicitly declared, rather than implied by compatible structure. One particularly distinctive feature of Julia\'s type system is that concrete types may not subtype each other: all concrete types are final and may only have abstract types as their supertypes. While this might at first seem unduly restrictive, it has many beneficial consequences with surprisingly few drawbacks. It turns out that being able to inherit behavior is much more important than being able to inherit structure, and inheriting both causes significant difficulties in traditional object-oriented languages. Other high-level aspects of Julia\'s type system that should be mentioned up front are:There is no division between object and non-object values: all values in Julia are true objects having a type that belongs to a single, fully connected type graph, all nodes of which are equally first-class as types.\nThere is no meaningful concept of a \"compile-time type\": the only type a value has is its actual type when the program is running. This is called a \"run-time type\" in object-oriented languages where the combination of static compilation with polymorphism makes this distinction significant.\nOnly values, not variables, have types – variables are simply names bound to values.\nBoth abstract and concrete types can be parameterized by other types. They can also be parameterized by symbols, by values of any type for which isbits() returns true (essentially, things like numbers and bools that are stored like C types or structs with no pointers to other objects), and also by tuples thereof. Type parameters may be omitted when they do not need to be referenced or restricted.Julia\'s type system is designed to be powerful and expressive, yet clear, intuitive and unobtrusive. Many Julia programmers may never feel the need to write code that explicitly uses types. Some kinds of programming, however, become clearer, simpler, faster and more robust with declared types."
},

{
    "location": "manual/types/#Type-Declarations-1",
    "page": "Types",
    "title": "Type Declarations",
    "category": "section",
    "text": "The :: operator can be used to attach type annotations to expressions and variables in programs. There are two primary reasons to do this:As an assertion to help confirm that your program works the way you expect,\nTo provide extra type information to the compiler, which can then improve performance in some casesWhen appended to an expression computing a value, the :: operator is read as \"is an instance of\". It can be used anywhere to assert that the value of the expression on the left is an instance of the type on the right. When the type on the right is concrete, the value on the left must have that type as its implementation – recall that all concrete types are final, so no implementation is a subtype of any other. When the type is abstract, it suffices for the value to be implemented by a concrete type that is a subtype of the abstract type. If the type assertion is not true, an exception is thrown, otherwise, the left-hand value is returned:julia> (1+2)::AbstractFloat\nERROR: TypeError: typeassert: expected AbstractFloat, got Int64\n\njulia> (1+2)::Int\n3This allows a type assertion to be attached to any expression in-place.When appended to a variable on the left-hand side of an assignment, or as part of a local declaration, the :: operator means something a bit different: it declares the variable to always have the specified type, like a type declaration in a statically-typed language such as C. Every value assigned to the variable will be converted to the declared type using convert():julia> function foo()\n           x::Int8 = 100\n           x\n       end\nfoo (generic function with 1 method)\n\njulia> foo()\n100\n\njulia> typeof(ans)\nInt8This feature is useful for avoiding performance \"gotchas\" that could occur if one of the assignments to a variable changed its type unexpectedly.This \"declaration\" behavior only occurs in specific contexts:local x::Int8  # in a local declaration\nx::Int8 = 10   # as the left-hand side of an assignmentand applies to the whole current scope, even before the declaration. Currently, type declarations cannot be used in global scope, e.g. in the REPL, since Julia does not yet have constant-type globals.Declarations can also be attached to function definitions:function sinc(x)::Float64\n    if x == 0\n        return 1\n    end\n    return sin(pi*x)/(pi*x)\nendReturning from this function behaves just like an assignment to a variable with a declared type: the value is always converted to Float64."
},

{
    "location": "manual/types/#Abstract-Types-1",
    "page": "Types",
    "title": "Abstract Types",
    "category": "section",
    "text": "Abstract types cannot be instantiated, and serve only as nodes in the type graph, thereby describing sets of related concrete types: those concrete types which are their descendants. We begin with abstract types even though they have no instantiation because they are the backbone of the type system: they form the conceptual hierarchy which makes Julia\'s type system more than just a collection of object implementations.Recall that in Integers and Floating-Point Numbers, we introduced a variety of concrete types of numeric values: Int8, UInt8, Int16, UInt16, Int32, UInt32, Int64, UInt64, Int128, UInt128, Float16, Float32, and Float64. Although they have different representation sizes, Int8, Int16, Int32, Int64 and Int128 all have in common that they are signed integer types. Likewise UInt8, UInt16, UInt32, UInt64 and UInt128 are all unsigned integer types, while Float16, Float32 and Float64 are distinct in being floating-point types rather than integers. It is common for a piece of code to make sense, for example, only if its arguments are some kind of integer, but not really depend on what particular kind of integer. For example, the greatest common denominator algorithm works for all kinds of integers, but will not work for floating-point numbers. Abstract types allow the construction of a hierarchy of types, providing a context into which concrete types can fit. This allows you, for example, to easily program to any type that is an integer, without restricting an algorithm to a specific type of integer.Abstract types are declared using the abstract type keyword. The general syntaxes for declaring an abstract type are:abstract type «name» end\nabstract type «name» <: «supertype» endThe abstract type keyword introduces a new abstract type, whose name is given by «name». This name can be optionally followed by <: and an already-existing type, indicating that the newly declared abstract type is a subtype of this \"parent\" type.When no supertype is given, the default supertype is Any – a predefined abstract type that all objects are instances of and all types are subtypes of. In type theory, Any is commonly called \"top\" because it is at the apex of the type graph. Julia also has a predefined abstract \"bottom\" type, at the nadir of the type graph, which is written as Union{}. It is the exact opposite of Any: no object is an instance of Union{} and all types are supertypes of Union{}.Let\'s consider some of the abstract types that make up Julia\'s numerical hierarchy:abstract type Number end\nabstract type Real     <: Number end\nabstract type AbstractFloat <: Real end\nabstract type Integer  <: Real end\nabstract type Signed   <: Integer end\nabstract type Unsigned <: Integer endThe Number type is a direct child type of Any, and Real is its child. In turn, Real has two children (it has more, but only two are shown here; we\'ll get to the others later): Integer and AbstractFloat, separating the world into representations of integers and representations of real numbers. Representations of real numbers include, of course, floating-point types, but also include other types, such as rationals. Hence, AbstractFloat is a proper subtype of Real, including only floating-point representations of real numbers. Integers are further subdivided into Signed and Unsigned varieties.The <: operator in general means \"is a subtype of\", and, used in declarations like this, declares the right-hand type to be an immediate supertype of the newly declared type. It can also be used in expressions as a subtype operator which returns true when its left operand is a subtype of its right operand:julia> Integer <: Number\ntrue\n\njulia> Integer <: AbstractFloat\nfalseAn important use of abstract types is to provide default implementations for concrete types. To give a simple example, consider:function myplus(x,y)\n    x+y\nendThe first thing to note is that the above argument declarations are equivalent to x::Any and y::Any. When this function is invoked, say as myplus(2,5), the dispatcher chooses the most specific method named myplus that matches the given arguments. (See Methods for more information on multiple dispatch.)Assuming no method more specific than the above is found, Julia next internally defines and compiles a method called myplus specifically for two Int arguments based on the generic function given above, i.e., it implicitly defines and compiles:function myplus(x::Int,y::Int)\n    x+y\nendand finally, it invokes this specific method.Thus, abstract types allow programmers to write generic functions that can later be used as the default method by many combinations of concrete types. Thanks to multiple dispatch, the programmer has full control over whether the default or more specific method is used.An important point to note is that there is no loss in performance if the programmer relies on a function whose arguments are abstract types, because it is recompiled for each tuple of argument concrete types with which it is invoked. (There may be a performance issue, however, in the case of function arguments that are containers of abstract types; see Performance Tips.)"
},

{
    "location": "manual/types/#Primitive-Types-1",
    "page": "Types",
    "title": "Primitive Types",
    "category": "section",
    "text": "A primitive type is a concrete type whose data consists of plain old bits. Classic examples of primitive types are integers and floating-point values. Unlike most languages, Julia lets you declare your own primitive types, rather than providing only a fixed set of built-in ones. In fact, the standard primitive types are all defined in the language itself:primitive type Float16 <: AbstractFloat 16 end\nprimitive type Float32 <: AbstractFloat 32 end\nprimitive type Float64 <: AbstractFloat 64 end\n\nprimitive type Bool <: Integer 8 end\nprimitive type Char 32 end\n\nprimitive type Int8    <: Signed   8 end\nprimitive type UInt8   <: Unsigned 8 end\nprimitive type Int16   <: Signed   16 end\nprimitive type UInt16  <: Unsigned 16 end\nprimitive type Int32   <: Signed   32 end\nprimitive type UInt32  <: Unsigned 32 end\nprimitive type Int64   <: Signed   64 end\nprimitive type UInt64  <: Unsigned 64 end\nprimitive type Int128  <: Signed   128 end\nprimitive type UInt128 <: Unsigned 128 endThe general syntaxes for declaring a primitive type are:primitive type «name» «bits» end\nprimitive type «name» <: «supertype» «bits» endThe number of bits indicates how much storage the type requires and the name gives the new type a name. A primitive type can optionally be declared to be a subtype of some supertype. If a supertype is omitted, then the type defaults to having Any as its immediate supertype. The declaration of Bool above therefore means that a boolean value takes eight bits to store, and has Integer as its immediate supertype. Currently, only sizes that are multiples of 8 bits are supported. Therefore, boolean values, although they really need just a single bit, cannot be declared to be any smaller than eight bits.The types Bool, Int8 and UInt8 all have identical representations: they are eight-bit chunks of memory. Since Julia\'s type system is nominative, however, they are not interchangeable despite having identical structure. A fundamental difference between them is that they have different supertypes: Bool\'s direct supertype is Integer, Int8\'s is Signed, and UInt8\'s is Unsigned. All other differences between Bool, Int8, and UInt8 are matters of behavior – the way functions are defined to act when given objects of these types as arguments. This is why a nominative type system is necessary: if structure determined type, which in turn dictates behavior, then it would be impossible to make Bool behave any differently than Int8 or UInt8."
},

{
    "location": "manual/types/#Composite-Types-1",
    "page": "Types",
    "title": "Composite Types",
    "category": "section",
    "text": "Composite types are called records, structs, or objects in various languages. A composite type is a collection of named fields, an instance of which can be treated as a single value. In many languages, composite types are the only kind of user-definable type, and they are by far the most commonly used user-defined type in Julia as well.In mainstream object oriented languages, such as C++, Java, Python and Ruby, composite types also have named functions associated with them, and the combination is called an \"object\". In purer object-oriented languages, such as Ruby or Smalltalk, all values are objects whether they are composites or not. In less pure object oriented languages, including C++ and Java, some values, such as integers and floating-point values, are not objects, while instances of user-defined composite types are true objects with associated methods. In Julia, all values are objects, but functions are not bundled with the objects they operate on. This is necessary since Julia chooses which method of a function to use by multiple dispatch, meaning that the types of all of a function\'s arguments are considered when selecting a method, rather than just the first one (see Methods for more information on methods and dispatch). Thus, it would be inappropriate for functions to \"belong\" to only their first argument. Organizing methods into function objects rather than having named bags of methods \"inside\" each object ends up being a highly beneficial aspect of the language design.Composite types are introduced with the struct keyword followed by a block of field names, optionally annotated with types using the :: operator:julia> struct Foo\n           bar\n           baz::Int\n           qux::Float64\n       endFields with no type annotation default to Any, and can accordingly hold any type of value.New objects of type Foo are created by applying the Foo type object like a function to values for its fields:julia> foo = Foo(\"Hello, world.\", 23, 1.5)\nFoo(\"Hello, world.\", 23, 1.5)\n\njulia> typeof(foo)\nFooWhen a type is applied like a function it is called a constructor. Two constructors are generated automatically (these are called default constructors). One accepts any arguments and calls convert() to convert them to the types of the fields, and the other accepts arguments that match the field types exactly. The reason both of these are generated is that this makes it easier to add new definitions without inadvertently replacing a default constructor.Since the bar field is unconstrained in type, any value will do. However, the value for baz must be convertible to Int:julia> Foo((), 23.5, 1)\nERROR: InexactError()\nStacktrace:\n [1] convert(::Type{Int64}, ::Float64) at ./float.jl:679\n [2] Foo(::Tuple{}, ::Float64, ::Int64) at ./none:2You may find a list of field names using the fieldnames function.julia> fieldnames(foo)\n3-element Array{Symbol,1}:\n :bar\n :baz\n :quxYou can access the field values of a composite object using the traditional foo.bar notation:julia> foo.bar\n\"Hello, world.\"\n\njulia> foo.baz\n23\n\njulia> foo.qux\n1.5Composite objects declared with struct are immutable; they cannot be modified after construction. This may seem odd at first, but it has several advantages:It can be more efficient. Some structs can be packed efficiently into arrays, and in some cases the compiler is able to avoid allocating immutable objects entirely.\nIt is not possible to violate the invariants provided by the type\'s constructors.\nCode using immutable objects can be easier to reason about.An immutable object might contain mutable objects, such as arrays, as fields. Those contained objects will remain mutable; only the fields of the immutable object itself cannot be changed to point to different objects.Where required, mutable composite objects can be declared with the keyword mutable struct, to be discussed in the next section.Composite types with no fields are singletons; there can be only one instance of such types:julia> struct NoFields\n       end\n\njulia> NoFields() === NoFields()\ntrueThe === function confirms that the \"two\" constructed instances of NoFields are actually one and the same. Singleton types are described in further detail below.There is much more to say about how instances of composite types are created, but that discussion depends on both Parametric Types and on Methods, and is sufficiently important to be addressed in its own section: Constructors."
},

{
    "location": "manual/types/#Mutable-Composite-Types-1",
    "page": "Types",
    "title": "Mutable Composite Types",
    "category": "section",
    "text": "If a composite type is declared with mutable struct instead of struct, then instances of it can be modified:julia> mutable struct Bar\n           baz\n           qux::Float64\n       end\n\njulia> bar = Bar(\"Hello\", 1.5);\n\njulia> bar.qux = 2.0\n2.0\n\njulia> bar.baz = 1//2\n1//2In order to support mutation, such objects are generally allocated on the heap, and have stable memory addresses. A mutable object is like a little container that might hold different values over time, and so can only be reliably identified with its address. In contrast, an instance of an immutable type is associated with specific field values –- the field values alone tell you everything about the object. In deciding whether to make a type mutable, ask whether two instances with the same field values would be considered identical, or if they might need to change independently over time. If they would be considered identical, the type should probably be immutable.To recap, two essential properties define immutability in Julia:An object with an immutable type is passed around (both in assignment statements and in function calls) by copying, whereas a mutable type is passed around by reference.\nIt is not permitted to modify the fields of a composite immutable type.It is instructive, particularly for readers whose background is C/C++, to consider why these two properties go hand in hand.  If they were separated, i.e., if the fields of objects passed around by copying could be modified, then it would become more difficult to reason about certain instances of generic code.  For example, suppose x is a function argument of an abstract type, and suppose that the function changes a field: x.isprocessed = true.  Depending on whether x is passed by copying or by reference, this statement may or may not alter the actual argument in the calling routine.  Julia sidesteps the possibility of creating functions with unknown effects in this scenario by forbidding modification of fields of objects passed around by copying."
},

{
    "location": "manual/types/#Declared-Types-1",
    "page": "Types",
    "title": "Declared Types",
    "category": "section",
    "text": "The three kinds of types discussed in the previous three sections are actually all closely related. They share the same key properties:They are explicitly declared.\nThey have names.\nThey have explicitly declared supertypes.\nThey may have parameters.Because of these shared properties, these types are internally represented as instances of the same concept, DataType, which is the type of any of these types:julia> typeof(Real)\nDataType\n\njulia> typeof(Int)\nDataTypeA DataType may be abstract or concrete. If it is concrete, it has a specified size, storage layout, and (optionally) field names. Thus a bits type is a DataType with nonzero size, but no field names. A composite type is a DataType that has field names or is empty (zero size).Every concrete value in the system is an instance of some DataType."
},

{
    "location": "manual/types/#Type-Unions-1",
    "page": "Types",
    "title": "Type Unions",
    "category": "section",
    "text": "A type union is a special abstract type which includes as objects all instances of any of its argument types, constructed using the special Union function:julia> IntOrString = Union{Int,AbstractString}\nUnion{AbstractString, Int64}\n\njulia> 1 :: IntOrString\n1\n\njulia> \"Hello!\" :: IntOrString\n\"Hello!\"\n\njulia> 1.0 :: IntOrString\nERROR: TypeError: typeassert: expected Union{AbstractString, Int64}, got Float64The compilers for many languages have an internal union construct for reasoning about types; Julia simply exposes it to the programmer."
},

{
    "location": "manual/types/#Parametric-Types-1",
    "page": "Types",
    "title": "Parametric Types",
    "category": "section",
    "text": "An important and powerful feature of Julia\'s type system is that it is parametric: types can take parameters, so that type declarations actually introduce a whole family of new types – one for each possible combination of parameter values. There are many languages that support some version of generic programming, wherein data structures and algorithms to manipulate them may be specified without specifying the exact types involved. For example, some form of generic programming exists in ML, Haskell, Ada, Eiffel, C++, Java, C#, F#, and Scala, just to name a few. Some of these languages support true parametric polymorphism (e.g. ML, Haskell, Scala), while others support ad-hoc, template-based styles of generic programming (e.g. C++, Java). With so many different varieties of generic programming and parametric types in various languages, we won\'t even attempt to compare Julia\'s parametric types to other languages, but will instead focus on explaining Julia\'s system in its own right. We will note, however, that because Julia is a dynamically typed language and doesn\'t need to make all type decisions at compile time, many traditional difficulties encountered in static parametric type systems can be relatively easily handled.All declared types (the DataType variety) can be parameterized, with the same syntax in each case. We will discuss them in the following order: first, parametric composite types, then parametric abstract types, and finally parametric bits types."
},

{
    "location": "manual/types/#Parametric-Composite-Types-1",
    "page": "Types",
    "title": "Parametric Composite Types",
    "category": "section",
    "text": "Type parameters are introduced immediately after the type name, surrounded by curly braces:julia> struct Point{T}\n           x::T\n           y::T\n       endThis declaration defines a new parametric type, Point{T}, holding two \"coordinates\" of type T. What, one may ask, is T? Well, that\'s precisely the point of parametric types: it can be any type at all (or a value of any bits type, actually, although here it\'s clearly used as a type). Point{Float64} is a concrete type equivalent to the type defined by replacing T in the definition of Point with Float64. Thus, this single declaration actually declares an unlimited number of types: Point{Float64}, Point{AbstractString}, Point{Int64}, etc. Each of these is now a usable concrete type:julia> Point{Float64}\nPoint{Float64}\n\njulia> Point{AbstractString}\nPoint{AbstractString}The type Point{Float64} is a point whose coordinates are 64-bit floating-point values, while the type Point{AbstractString} is a \"point\" whose \"coordinates\" are string objects (see Strings).Point itself is also a valid type object, containing all instances Point{Float64}, Point{AbstractString}, etc. as subtypes:julia> Point{Float64} <: Point\ntrue\n\njulia> Point{AbstractString} <: Point\ntrueOther types, of course, are not subtypes of it:julia> Float64 <: Point\nfalse\n\njulia> AbstractString <: Point\nfalseConcrete Point types with different values of T are never subtypes of each other:julia> Point{Float64} <: Point{Int64}\nfalse\n\njulia> Point{Float64} <: Point{Real}\nfalsewarning: Warning\nThis last point is very important: even though Float64 <: Real we DO NOT have Point{Float64} <: Point{Real}.In other words, in the parlance of type theory, Julia\'s type parameters are invariant, rather than being covariant (or even contravariant). This is for practical reasons: while any instance of Point{Float64} may conceptually be like an instance of Point{Real} as well, the two types have different representations in memory:An instance of Point{Float64} can be represented compactly and efficiently as an immediate pair of 64-bit values;\nAn instance of Point{Real} must be able to hold any pair of instances of Real. Since objects that are instances of Real can be of arbitrary size and structure, in practice an instance of Point{Real} must be represented as a pair of pointers to individually allocated Real objects.The efficiency gained by being able to store Point{Float64} objects with immediate values is magnified enormously in the case of arrays: an Array{Float64} can be stored as a contiguous memory block of 64-bit floating-point values, whereas an Array{Real} must be an array of pointers to individually allocated Real objects – which may well be boxed 64-bit floating-point values, but also might be arbitrarily large, complex objects, which are declared to be implementations of the Real abstract type.Since Point{Float64} is not a subtype of Point{Real}, the following method can\'t be applied to arguments of type Point{Float64}:function norm(p::Point{Real})\n    sqrt(p.x^2 + p.y^2)\nendA correct way to define a method that accepts all arguments of type Point{T} where T is a subtype of Real is:function norm(p::Point{<:Real})\n    sqrt(p.x^2 + p.y^2)\nend(Equivalently, one could define function norm{T<:Real}(p::Point{T}) or function norm(p::Point{T} where T<:Real); see UnionAll Types.)More examples will be discussed later in Methods.How does one construct a Point object? It is possible to define custom constructors for composite types, which will be discussed in detail in Constructors, but in the absence of any special constructor declarations, there are two default ways of creating new composite objects, one in which the type parameters are explicitly given and the other in which they are implied by the arguments to the object constructor.Since the type Point{Float64} is a concrete type equivalent to Point declared with Float64 in place of T, it can be applied as a constructor accordingly:julia> Point{Float64}(1.0, 2.0)\nPoint{Float64}(1.0, 2.0)\n\njulia> typeof(ans)\nPoint{Float64}For the default constructor, exactly one argument must be supplied for each field:julia> Point{Float64}(1.0)\nERROR: MethodError: Cannot `convert` an object of type Float64 to an object of type Point{Float64}\nThis may have arisen from a call to the constructor Point{Float64}(...),\nsince type constructors fall back to convert methods.\nStacktrace:\n [1] Point{Float64}(::Float64) at ./sysimg.jl:77\n\njulia> Point{Float64}(1.0,2.0,3.0)\nERROR: MethodError: no method matching Point{Float64}(::Float64, ::Float64, ::Float64)Only one default constructor is generated for parametric types, since overriding it is not possible. This constructor accepts any arguments and converts them to the field types.In many cases, it is redundant to provide the type of Point object one wants to construct, since the types of arguments to the constructor call already implicitly provide type information. For that reason, you can also apply Point itself as a constructor, provided that the implied value of the parameter type T is unambiguous:julia> Point(1.0,2.0)\nPoint{Float64}(1.0, 2.0)\n\njulia> typeof(ans)\nPoint{Float64}\n\njulia> Point(1,2)\nPoint{Int64}(1, 2)\n\njulia> typeof(ans)\nPoint{Int64}In the case of Point, the type of T is unambiguously implied if and only if the two arguments to Point have the same type. When this isn\'t the case, the constructor will fail with a MethodError:julia> Point(1,2.5)\nERROR: MethodError: no method matching Point(::Int64, ::Float64)\nClosest candidates are:\n  Point(::T, !Matched::T) where T at none:2Constructor methods to appropriately handle such mixed cases can be defined, but that will not be discussed until later on in Constructors."
},

{
    "location": "manual/types/#Parametric-Abstract-Types-1",
    "page": "Types",
    "title": "Parametric Abstract Types",
    "category": "section",
    "text": "Parametric abstract type declarations declare a collection of abstract types, in much the same way:julia> abstract type Pointy{T} endWith this declaration, Pointy{T} is a distinct abstract type for each type or integer value of T. As with parametric composite types, each such instance is a subtype of Pointy:julia> Pointy{Int64} <: Pointy\ntrue\n\njulia> Pointy{1} <: Pointy\ntrueParametric abstract types are invariant, much as parametric composite types are:julia> Pointy{Float64} <: Pointy{Real}\nfalse\n\njulia> Pointy{Real} <: Pointy{Float64}\nfalseThe notation Pointy{<:Real} can be used to express the Julia analogue of a covariant type, while Pointy{>:Int} the analogue of a contravariant type, but technically these represent sets of types (see UnionAll Types).julia> Pointy{Float64} <: Pointy{<:Real}\ntrue\n\njulia> Pointy{Real} <: Pointy{>:Int}\ntrueMuch as plain old abstract types serve to create a useful hierarchy of types over concrete types, parametric abstract types serve the same purpose with respect to parametric composite types. We could, for example, have declared Point{T} to be a subtype of Pointy{T} as follows:julia> struct Point{T} <: Pointy{T}\n           x::T\n           y::T\n       endGiven such a declaration, for each choice of T, we have Point{T} as a subtype of Pointy{T}:julia> Point{Float64} <: Pointy{Float64}\ntrue\n\njulia> Point{Real} <: Pointy{Real}\ntrue\n\njulia> Point{AbstractString} <: Pointy{AbstractString}\ntrueThis relationship is also invariant:julia> Point{Float64} <: Pointy{Real}\nfalse\n\njulia> Point{Float64} <: Pointy{<:Real}\ntrueWhat purpose do parametric abstract types like Pointy serve? Consider if we create a point-like implementation that only requires a single coordinate because the point is on the diagonal line x = y:julia> struct DiagPoint{T} <: Pointy{T}\n           x::T\n       endNow both Point{Float64} and DiagPoint{Float64} are implementations of the Pointy{Float64} abstraction, and similarly for every other possible choice of type T. This allows programming to a common interface shared by all Pointy objects, implemented for both Point and DiagPoint. This cannot be fully demonstrated, however, until we have introduced methods and dispatch in the next section, Methods.There are situations where it may not make sense for type parameters to range freely over all possible types. In such situations, one can constrain the range of T like so:julia> abstract type Pointy{T<:Real} endWith such a declaration, it is acceptable to use any type that is a subtype of Real in place of T, but not types that are not subtypes of Real:julia> Pointy{Float64}\nPointy{Float64}\n\njulia> Pointy{Real}\nPointy{Real}\n\njulia> Pointy{AbstractString}\nERROR: TypeError: Pointy: in T, expected T<:Real, got Type{AbstractString}\n\njulia> Pointy{1}\nERROR: TypeError: Pointy: in T, expected T<:Real, got Int64Type parameters for parametric composite types can be restricted in the same manner:struct Point{T<:Real} <: Pointy{T}\n    x::T\n    y::T\nendTo give a real-world example of how all this parametric type machinery can be useful, here is the actual definition of Julia\'s Rational immutable type (except that we omit the constructor here for simplicity), representing an exact ratio of integers:struct Rational{T<:Integer} <: Real\n    num::T\n    den::T\nendIt only makes sense to take ratios of integer values, so the parameter type T is restricted to being a subtype of Integer, and a ratio of integers represents a value on the real number line, so any Rational is an instance of the Real abstraction."
},

{
    "location": "manual/types/#Tuple-Types-1",
    "page": "Types",
    "title": "Tuple Types",
    "category": "section",
    "text": "Tuples are an abstraction of the arguments of a function – without the function itself. The salient aspects of a function\'s arguments are their order and their types. Therefore a tuple type is similar to a parameterized immutable type where each parameter is the type of one field. For example, a 2-element tuple type resembles the following immutable type:struct Tuple2{A,B}\n    a::A\n    b::B\nendHowever, there are three key differences:Tuple types may have any number of parameters.\nTuple types are covariant in their parameters: Tuple{Int} is a subtype of Tuple{Any}. Therefore Tuple{Any} is considered an abstract type, and tuple types are only concrete if their parameters are.\nTuples do not have field names; fields are only accessed by index.Tuple values are written with parentheses and commas. When a tuple is constructed, an appropriate tuple type is generated on demand:julia> typeof((1,\"foo\",2.5))\nTuple{Int64,String,Float64}Note the implications of covariance:julia> Tuple{Int,AbstractString} <: Tuple{Real,Any}\ntrue\n\njulia> Tuple{Int,AbstractString} <: Tuple{Real,Real}\nfalse\n\njulia> Tuple{Int,AbstractString} <: Tuple{Real,}\nfalseIntuitively, this corresponds to the type of a function\'s arguments being a subtype of the function\'s signature (when the signature matches)."
},

{
    "location": "manual/types/#Vararg-Tuple-Types-1",
    "page": "Types",
    "title": "Vararg Tuple Types",
    "category": "section",
    "text": "The last parameter of a tuple type can be the special type Vararg, which denotes any number of trailing elements:julia> mytupletype = Tuple{AbstractString,Vararg{Int}}\nTuple{AbstractString,Vararg{Int64,N} where N}\n\njulia> isa((\"1\",), mytupletype)\ntrue\n\njulia> isa((\"1\",1), mytupletype)\ntrue\n\njulia> isa((\"1\",1,2), mytupletype)\ntrue\n\njulia> isa((\"1\",1,2,3.0), mytupletype)\nfalseNotice that Vararg{T} corresponds to zero or more elements of type T. Vararg tuple types are used to represent the arguments accepted by varargs methods (see Varargs Functions).The type Vararg{T,N} corresponds to exactly N elements of type T.  NTuple{N,T} is a convenient alias for Tuple{Vararg{T,N}}, i.e. a tuple type containing exactly N elements of type T."
},

{
    "location": "manual/types/#man-singleton-types-1",
    "page": "Types",
    "title": "Singleton Types",
    "category": "section",
    "text": "There is a special kind of abstract parametric type that must be mentioned here: singleton types. For each type, T, the \"singleton type\" Type{T} is an abstract type whose only instance is the object T. Since the definition is a little difficult to parse, let\'s look at some examples:julia> isa(Float64, Type{Float64})\ntrue\n\njulia> isa(Real, Type{Float64})\nfalse\n\njulia> isa(Real, Type{Real})\ntrue\n\njulia> isa(Float64, Type{Real})\nfalseIn other words, isa(A,Type{B}) is true if and only if A and B are the same object and that object is a type. Without the parameter, Type is simply an abstract type which has all type objects as its instances, including, of course, singleton types:julia> isa(Type{Float64}, Type)\ntrue\n\njulia> isa(Float64, Type)\ntrue\n\njulia> isa(Real, Type)\ntrueAny object that is not a type is not an instance of Type:julia> isa(1, Type)\nfalse\n\njulia> isa(\"foo\", Type)\nfalseUntil we discuss Parametric Methods and conversions, it is difficult to explain the utility of the singleton type construct, but in short, it allows one to specialize function behavior on specific type values. This is useful for writing methods (especially parametric ones) whose behavior depends on a type that is given as an explicit argument rather than implied by the type of one of its arguments.A few popular languages have singleton types, including Haskell, Scala and Ruby. In general usage, the term \"singleton type\" refers to a type whose only instance is a single value. This meaning applies to Julia\'s singleton types, but with that caveat that only type objects have singleton types."
},

{
    "location": "manual/types/#Parametric-Primitive-Types-1",
    "page": "Types",
    "title": "Parametric Primitive Types",
    "category": "section",
    "text": "Primitive types can also be declared parametrically. For example, pointers are represented as primitive types which would be declared in Julia like this:# 32-bit system:\nprimitive type Ptr{T} 32 end\n\n# 64-bit system:\nprimitive type Ptr{T} 64 endThe slightly odd feature of these declarations as compared to typical parametric composite types, is that the type parameter T is not used in the definition of the type itself – it is just an abstract tag, essentially defining an entire family of types with identical structure, differentiated only by their type parameter. Thus, Ptr{Float64} and Ptr{Int64} are distinct types, even though they have identical representations. And of course, all specific pointer types are subtypes of the umbrella Ptr type:julia> Ptr{Float64} <: Ptr\ntrue\n\njulia> Ptr{Int64} <: Ptr\ntrue"
},

{
    "location": "manual/types/#UnionAll-Types-1",
    "page": "Types",
    "title": "UnionAll Types",
    "category": "section",
    "text": "We have said that a parametric type like Ptr acts as a supertype of all its instances (Ptr{Int64} etc.). How does this work? Ptr itself cannot be a normal data type, since without knowing the type of the referenced data the type clearly cannot be used for memory operations. The answer is that Ptr (or other parametric types like Array) is a different kind of type called a UnionAll type. Such a type expresses the iterated union of types for all values of some parameter.UnionAll types are usually written using the keyword where. For example Ptr could be more accurately written as Ptr{T} where T, meaning all values whose type is Ptr{T} for some value of T. In this context, the parameter T is also often called a \"type variable\" since it is like a variable that ranges over types. Each where introduces a single type variable, so these expressions are nested for types with multiple parameters, for example Array{T,N} where N where T.The type application syntax A{B,C} requires A to be a UnionAll type, and first substitutes B for the outermost type variable in A. The result is expected to be another UnionAll type, into which C is then substituted. So A{B,C} is equivalent to A{B}{C}. This explains why it is possible to partially instantiate a type, as in Array{Float64}: the first parameter value has been fixed, but the second still ranges over all possible values. Using explicit where syntax, any subset of parameters can be fixed. For example, the type of all 1-dimensional arrays can be written as Array{T,1} where T.Type variables can be restricted with subtype relations. Array{T} where T<:Integer refers to all arrays whose element type is some kind of Integer. The syntax Array{<:Integer} is a convenient shorthand for Array{T} where T<:Integer. Type variables can have both lower and upper bounds. Array{T} where Int<:T<:Number refers to all arrays of Numbers that are able to contain Ints (since T must be at least as big as Int). The syntax where T>:Int also works to specify only the lower bound of a type variable, and Array{>:Int} is equivalent to Array{T} where T>:Int.Since where expressions nest, type variable bounds can refer to outer type variables. For example Tuple{T,Array{S}} where S<:AbstractArray{T} where T<:Real refers to 2-tuples whose first element is some Real, and whose second element is an Array of any kind of array whose element type contains the type of the first tuple element.The where keyword itself can be nested inside a more complex declaration. For example, consider the two types created by the following declarations:julia> const T1 = Array{Array{T,1} where T, 1}\nArray{Array{T,1} where T,1}\n\njulia> const T2 = Array{Array{T,1}, 1} where T\nArray{Array{T,1},1} where TType T1 defines a 1-dimensional array of 1-dimensional arrays; each of the inner arrays consists of objects of the same type, but this type may vary from one inner array to the next. On the other hand, type T2 defines a 1-dimensional array of 1-dimensional arrays all of whose inner arrays must have the same type.  Note that T2 is an abstract type, e.g., Array{Array{Int,1},1} <: T2, whereas T1 is a concrete type. As a consequence, T1 can be constructed with a zero-argument constructor a=T1() but T2 cannot.There is a convenient syntax for naming such types, similar to the short form of function definition syntax:Vector{T} = Array{T,1}This is equivalent to const Vector = Array{T,1} where T. Writing Vector{Float64} is equivalent to writing Array{Float64,1}, and the umbrella type Vector has as instances all Array objects where the second parameter – the number of array dimensions – is 1, regardless of what the element type is. In languages where parametric types must always be specified in full, this is not especially helpful, but in Julia, this allows one to write just Vector for the abstract type including all one-dimensional dense arrays of any element type."
},

{
    "location": "manual/types/#Type-Aliases-1",
    "page": "Types",
    "title": "Type Aliases",
    "category": "section",
    "text": "Sometimes it is convenient to introduce a new name for an already expressible type. This can be done with a simple assignment statement. For example, UInt is aliased to either UInt32 or UInt64 as is appropriate for the size of pointers on the system:# 32-bit system:\njulia> UInt\nUInt32\n\n# 64-bit system:\njulia> UInt\nUInt64This is accomplished via the following code in base/boot.jl:if Int === Int64\n    const UInt = UInt64\nelse\n    const UInt = UInt32\nendOf course, this depends on what Int is aliased to – but that is predefined to be the correct type – either Int32 or Int64.(Note that unlike Int, Float does not exist as a type alias for a specific sized AbstractFloat. Unlike with integer registers, the floating point register sizes are specified by the IEEE-754 standard. Whereas the size of Int reflects the size of a native pointer on that machine.)"
},

{
    "location": "manual/types/#Operations-on-Types-1",
    "page": "Types",
    "title": "Operations on Types",
    "category": "section",
    "text": "Since types in Julia are themselves objects, ordinary functions can operate on them. Some functions that are particularly useful for working with or exploring types have already been introduced, such as the <: operator, which indicates whether its left hand operand is a subtype of its right hand operand.The isa function tests if an object is of a given type and returns true or false:julia> isa(1, Int)\ntrue\n\njulia> isa(1, AbstractFloat)\nfalseThe typeof() function, already used throughout the manual in examples, returns the type of its argument. Since, as noted above, types are objects, they also have types, and we can ask what their types are:julia> typeof(Rational{Int})\nDataType\n\njulia> typeof(Union{Real,Float64,Rational})\nDataType\n\njulia> typeof(Union{Real,String})\nUnionWhat if we repeat the process? What is the type of a type of a type? As it happens, types are all composite values and thus all have a type of DataType:julia> typeof(DataType)\nDataType\n\njulia> typeof(Union)\nDataTypeDataType is its own type.Another operation that applies to some types is supertype(), which reveals a type\'s supertype. Only declared types (DataType) have unambiguous supertypes:julia> supertype(Float64)\nAbstractFloat\n\njulia> supertype(Number)\nAny\n\njulia> supertype(AbstractString)\nAny\n\njulia> supertype(Any)\nAnyIf you apply supertype() to other type objects (or non-type objects), a MethodError is raised:julia> supertype(Union{Float64,Int64})\nERROR: MethodError: no method matching supertype(::Type{Union{Float64, Int64}})\nClosest candidates are:\n  supertype(!Matched::DataType) at operators.jl:41\n  supertype(!Matched::UnionAll) at operators.jl:46"
},

{
    "location": "manual/types/#Custom-pretty-printing-1",
    "page": "Types",
    "title": "Custom pretty-printing",
    "category": "section",
    "text": "Often, one wants to customize how instances of a type are displayed.  This is accomplished by overloading the show() function.  For example, suppose we define a type to represent complex numbers in polar form:julia> struct Polar{T<:Real} <: Number\n           r::T\n           Θ::T\n       end\n\njulia> Polar(r::Real,Θ::Real) = Polar(promote(r,Θ)...)\nPolarHere, we\'ve added a custom constructor function so that it can take arguments of different Real types and promote them to a common type (see Constructors and Conversion and Promotion). (Of course, we would have to define lots of other methods, too, to make it act like a Number, e.g. +, *, one, zero, promotion rules and so on.) By default, instances of this type display rather simply, with information about the type name and the field values, as e.g. Polar{Float64}(3.0,4.0).If we want it to display instead as 3.0 * exp(4.0im), we would define the following method to print the object to a given output object io (representing a file, terminal, buffer, etcetera; see Networking and Streams):julia> Base.show(io::IO, z::Polar) = print(io, z.r, \" * exp(\", z.Θ, \"im)\")More fine-grained control over display of Polar objects is possible. In particular, sometimes one wants both a verbose multi-line printing format, used for displaying a single object in the REPL and other interactive environments, and also a more compact single-line format used for print() or for displaying the object as part of another object (e.g. in an array). Although by default the show(io, z) function is called in both cases, you can define a different multi-line format for displaying an object by overloading a three-argument form of show that takes the text/plain MIME type as its second argument (see Multimedia I/O), for example:julia> Base.show{T}(io::IO, ::MIME\"text/plain\", z::Polar{T}) =\n           print(io, \"Polar{$T} complex number:\\n   \", z)(Note that print(..., z) here will call the 2-argument show(io, z) method.) This results in:julia> Polar(3, 4.0)\nPolar{Float64} complex number:\n   3.0 * exp(4.0im)\n\njulia> [Polar(3, 4.0), Polar(4.0,5.3)]\n2-element Array{Polar{Float64},1}:\n 3.0 * exp(4.0im)\n 4.0 * exp(5.3im)where the single-line show(io, z) form is still used for an array of Polar values.   Technically, the REPL calls display(z) to display the result of executing a line, which defaults to show(STDOUT, MIME(\"text/plain\"), z), which in turn defaults to show(STDOUT, z), but you should not define new display() methods unless you are defining a new multimedia display handler (see Multimedia I/O).Moreover, you can also define show methods for other MIME types in order to enable richer display (HTML, images, etcetera) of objects in environments that support this (e.g. IJulia).   For example, we can define formatted HTML display of Polar objects, with superscripts and italics, via:julia> Base.show{T}(io::IO, ::MIME\"text/html\", z::Polar{T}) =\n           println(io, \"<code>Polar{$T}</code> complex number: \",\n                   z.r, \" <i>e</i><sup>\", z.Θ, \" <i>i</i></sup>\")A Polar object will then display automatically using HTML in an environment that supports HTML display, but you can call show manually to get HTML output if you want:julia> show(STDOUT, \"text/html\", Polar(3.0,4.0))\n<code>Polar{Float64}</code> complex number: 3.0 <i>e</i><sup>4.0 <i>i</i></sup><p>An HTML renderer would display this as: <code>Polar{Float64}</code> complex number: 3.0 <i>e</i><sup>4.0 <i>i</i></sup></p>"
},

{
    "location": "manual/types/#\"Value-types\"-1",
    "page": "Types",
    "title": "\"Value types\"",
    "category": "section",
    "text": "In Julia, you can\'t dispatch on a value such as true or false. However, you can dispatch on parametric types, and Julia allows you to include \"plain bits\" values (Types, Symbols, Integers, floating-point numbers, tuples, etc.) as type parameters.  A common example is the dimensionality parameter in Array{T,N}, where T is a type (e.g., Float64) but N is just an Int.You can create your own custom types that take values as parameters, and use them to control dispatch of custom types. By way of illustration of this idea, let\'s introduce a parametric type, Val{T}, which serves as a customary way to exploit this technique for cases where you don\'t need a more elaborate hierarchy.Val is defined as:julia> struct Val{T}\n       endThere is no more to the implementation of Val than this.  Some functions in Julia\'s standard library accept Val types as arguments, and you can also use it to write your own functions.  For example:julia> firstlast(::Type{Val{true}}) = \"First\"\nfirstlast (generic function with 1 method)\n\njulia> firstlast(::Type{Val{false}}) = \"Last\"\nfirstlast (generic function with 2 methods)\n\njulia> firstlast(Val{true})\n\"First\"\n\njulia> firstlast(Val{false})\n\"Last\"For consistency across Julia, the call site should always pass a Valtype rather than creating an instance, i.e., use foo(Val{:bar}) rather than foo(Val{:bar}()).It\'s worth noting that it\'s extremely easy to mis-use parametric \"value\" types, including Val; in unfavorable cases, you can easily end up making the performance of your code much worse.  In particular, you would never want to write actual code as illustrated above.  For more information about the proper (and improper) uses of Val, please read the more extensive discussion in the performance tips."
},

{
    "location": "manual/types/#man-nullable-types-1",
    "page": "Types",
    "title": "Nullable Types: Representing Missing Values",
    "category": "section",
    "text": "In many settings, you need to interact with a value of type T that may or may not exist. To handle these settings, Julia provides a parametric type called Nullable{T}, which can be thought of as a specialized container type that can contain either zero or one values. Nullable{T} provides a minimal interface designed to ensure that interactions with missing values are safe. At present, the interface consists of several possible interactions:Construct a Nullable object.\nCheck if a Nullable object has a missing value.\nAccess the value of a Nullable object with a guarantee that a NullException will be thrown if the object\'s value is missing.\nAccess the value of a Nullable object with a guarantee that a default value of type T will be returned if the object\'s value is missing.\nPerform an operation on the value (if it exists) of a Nullable object, getting a Nullable result. The result will be missing if the original value was missing.\nPerforming a test on the value (if it exists) of a Nullable object, getting a result that is missing if either the Nullable itself was missing, or the test failed.\nPerform general operations on single Nullable objects, propagating the missing data."
},

{
    "location": "manual/types/#Constructing-[Nullable](@ref)-objects-1",
    "page": "Types",
    "title": "Constructing Nullable objects",
    "category": "section",
    "text": "To construct an object representing a missing value of type T, use the Nullable{T}() function:julia> x1 = Nullable{Int64}()\nNullable{Int64}()\n\njulia> x2 = Nullable{Float64}()\nNullable{Float64}()\n\njulia> x3 = Nullable{Vector{Int64}}()\nNullable{Array{Int64,1}}()To construct an object representing a non-missing value of type T, use the Nullable(x::T) function:julia> x1 = Nullable(1)\nNullable{Int64}(1)\n\njulia> x2 = Nullable(1.0)\nNullable{Float64}(1.0)\n\njulia> x3 = Nullable([1, 2, 3])\nNullable{Array{Int64,1}}([1, 2, 3])Note the core distinction between these two ways of constructing a Nullable object: in one style, you provide a type, T, as a function parameter; in the other style, you provide a single value of type T as an argument."
},

{
    "location": "manual/types/#Checking-if-a-Nullable-object-has-a-value-1",
    "page": "Types",
    "title": "Checking if a Nullable object has a value",
    "category": "section",
    "text": "You can check if a Nullable object has any value using isnull():julia> isnull(Nullable{Float64}())\ntrue\n\njulia> isnull(Nullable(0.0))\nfalse"
},

{
    "location": "manual/types/#Safely-accessing-the-value-of-a-Nullable-object-1",
    "page": "Types",
    "title": "Safely accessing the value of a Nullable object",
    "category": "section",
    "text": "You can safely access the value of a Nullable object using get():julia> get(Nullable{Float64}())\nERROR: NullException()\nStacktrace:\n [1] get(::Nullable{Float64}) at ./nullable.jl:92\n\njulia> get(Nullable(1.0))\n1.0If the value is not present, as it would be for Nullable{Float64}, a NullException error will be thrown. The error-throwing nature of the get() function ensures that any attempt to access a missing value immediately fails.In cases for which a reasonable default value exists that could be used when a Nullable object\'s value turns out to be missing, you can provide this default value as a second argument to get():julia> get(Nullable{Float64}(), 0.0)\n0.0\n\njulia> get(Nullable(1.0), 0.0)\n1.0tip: Tip\nMake sure the type of the default value passed to get() and that of the Nullable object match to avoid type instability, which could hurt performance. Use convert() manually if needed."
},

{
    "location": "manual/types/#Performing-operations-on-Nullable-objects-1",
    "page": "Types",
    "title": "Performing operations on Nullable objects",
    "category": "section",
    "text": "Nullable objects represent values that are possibly missing, and it is possible to write all code using these objects by first testing to see if the value is missing with isnull(), and then doing an appropriate action. However, there are some common use cases where the code could be more concise or clear by using a higher-order function.The map function takes as arguments a function f and a Nullable value x. It produces a Nullable:If x is a missing value, then it produces a missing value;\nIf x has a value, then it produces a Nullable containing f(get(x)) as value.This is useful for performing simple operations on values that might be missing if the desired behaviour is to simply propagate the missing values forward.The filter function takes as arguments a predicate function p (that is, a function returning a boolean) and a Nullable value x. It produces a Nullable value:If x is a missing value, then it produces a missing value;\nIf p(get(x)) is true, then it produces the original value x;\nIf p(get(x)) is false, then it produces a missing value.In this way, filter can be thought of as selecting only allowable values, and converting non-allowable values to missing values.While map and filter are useful in specific cases, by far the most useful higher-order function is broadcast, which can handle a wide variety of cases, including making existing operations work and propagate Nullables. An example will motivate the need for broadcast. Suppose we have a function that computes the greater of two real roots of a quadratic equation, using the quadratic formula:julia> root(a::Real, b::Real, c::Real) = (-b + √(b^2 - 4a*c)) / 2a\nroot (generic function with 1 method)We may verify that the result of root(1, -9, 20) is 5.0, as we expect, since 5.0 is the greater of two real roots of the quadratic equation.Suppose now that we want to find the greatest real root of a quadratic equations where the coefficients might be missing values. Having missing values in datasets is a common occurrence in real-world data, and so it is important to be able to deal with them. But we cannot find the roots of an equation if we do not know all the coefficients. The best solution to this will depend on the particular use case; perhaps we should throw an error. However, for this example, we will assume that the best solution is to propagate the missing values forward; that is, if any input is missing, we simply produce a missing output.The broadcast() function makes this task easy; we can simply pass the root function we wrote to broadcast:julia> broadcast(root, Nullable(1), Nullable(-9), Nullable(20))\nNullable{Float64}(5.0)\n\njulia> broadcast(root, Nullable(1), Nullable{Int}(), Nullable{Int}())\nNullable{Float64}()\n\njulia> broadcast(root, Nullable{Int}(), Nullable(-9), Nullable(20))\nNullable{Float64}()If one or more of the inputs is missing, then the output of broadcast() will be missing.There exists special syntactic sugar for the broadcast() function using a dot notation:julia> root.(Nullable(1), Nullable(-9), Nullable(20))\nNullable{Float64}(5.0)In particular, the regular arithmetic operators can be broadcast() conveniently using .-prefixed operators:julia> Nullable(2) ./ Nullable(3) .+ Nullable(1.0)\nNullable{Float64}(1.66667)"
},

{
    "location": "manual/methods/#",
    "page": "Methods",
    "title": "Methods",
    "category": "page",
    "text": ""
},

{
    "location": "manual/methods/#Methods-1",
    "page": "Methods",
    "title": "Methods",
    "category": "section",
    "text": "Recall from Functions that a function is an object that maps a tuple of arguments to a return value, or throws an exception if no appropriate value can be returned. It is common for the same conceptual function or operation to be implemented quite differently for different types of arguments: adding two integers is very different from adding two floating-point numbers, both of which are distinct from adding an integer to a floating-point number. Despite their implementation differences, these operations all fall under the general concept of \"addition\". Accordingly, in Julia, these behaviors all belong to a single object: the + function.To facilitate using many different implementations of the same concept smoothly, functions need not be defined all at once, but can rather be defined piecewise by providing specific behaviors for certain combinations of argument types and counts. A definition of one possible behavior for a function is called a method. Thus far, we have presented only examples of functions defined with a single method, applicable to all types of arguments. However, the signatures of method definitions can be annotated to indicate the types of arguments in addition to their number, and more than a single method definition may be provided. When a function is applied to a particular tuple of arguments, the most specific method applicable to those arguments is applied. Thus, the overall behavior of a function is a patchwork of the behaviors of its various method definitions. If the patchwork is well designed, even though the implementations of the methods may be quite different, the outward behavior of the function will appear seamless and consistent.The choice of which method to execute when a function is applied is called dispatch. Julia allows the dispatch process to choose which of a function\'s methods to call based on the number of arguments given, and on the types of all of the function\'s arguments. This is different than traditional object-oriented languages, where dispatch occurs based only on the first argument, which often has a special argument syntax, and is sometimes implied rather than explicitly written as an argument. [1] Using all of a function\'s arguments to choose which method should be invoked, rather than just the first, is known as multiple dispatch. Multiple dispatch is particularly useful for mathematical code, where it makes little sense to artificially deem the operations to \"belong\" to one argument more than any of the others: does the addition operation in x + y belong to x any more than it does to y? The implementation of a mathematical operator generally depends on the types of all of its arguments. Even beyond mathematical operations, however, multiple dispatch ends up being a powerful and convenient paradigm for structuring and organizing programs.[1]: In C++ or Java, for example, in a method call like obj.meth(arg1,arg2), the object obj \"receives\" the method call and is implicitly passed to the method via the this keyword, rather than as an explicit method argument. When the current this object is the receiver of a method call, it can be omitted altogether, writing just meth(arg1,arg2), with this implied as the receiving object."
},

{
    "location": "manual/methods/#Defining-Methods-1",
    "page": "Methods",
    "title": "Defining Methods",
    "category": "section",
    "text": "Until now, we have, in our examples, defined only functions with a single method having unconstrained argument types. Such functions behave just like they would in traditional dynamically typed languages. Nevertheless, we have used multiple dispatch and methods almost continually without being aware of it: all of Julia\'s standard functions and operators, like the aforementioned + function, have many methods defining their behavior over various possible combinations of argument type and count.When defining a function, one can optionally constrain the types of parameters it is applicable to, using the :: type-assertion operator, introduced in the section on Composite Types:julia> f(x::Float64, y::Float64) = 2x + y\nf (generic function with 1 method)This function definition applies only to calls where x and y are both values of type Float64:julia> f(2.0, 3.0)\n7.0Applying it to any other types of arguments will result in a MethodError:julia> f(2.0, 3)\nERROR: MethodError: no method matching f(::Float64, ::Int64)\nClosest candidates are:\n  f(::Float64, !Matched::Float64) at none:1\n\njulia> f(Float32(2.0), 3.0)\nERROR: MethodError: no method matching f(::Float32, ::Float64)\nClosest candidates are:\n  f(!Matched::Float64, ::Float64) at none:1\n\njulia> f(2.0, \"3.0\")\nERROR: MethodError: no method matching f(::Float64, ::String)\nClosest candidates are:\n  f(::Float64, !Matched::Float64) at none:1\n\njulia> f(\"2.0\", \"3.0\")\nERROR: MethodError: no method matching f(::String, ::String)As you can see, the arguments must be precisely of type Float64. Other numeric types, such as integers or 32-bit floating-point values, are not automatically converted to 64-bit floating-point, nor are strings parsed as numbers. Because Float64 is a concrete type and concrete types cannot be subclassed in Julia, such a definition can only be applied to arguments that are exactly of type Float64. It may often be useful, however, to write more general methods where the declared parameter types are abstract:julia> f(x::Number, y::Number) = 2x - y\nf (generic function with 2 methods)\n\njulia> f(2.0, 3)\n1.0This method definition applies to any pair of arguments that are instances of Number. They need not be of the same type, so long as they are each numeric values. The problem of handling disparate numeric types is delegated to the arithmetic operations in the expression 2x - y.To define a function with multiple methods, one simply defines the function multiple times, with different numbers and types of arguments. The first method definition for a function creates the function object, and subsequent method definitions add new methods to the existing function object. The most specific method definition matching the number and types of the arguments will be executed when the function is applied. Thus, the two method definitions above, taken together, define the behavior for f over all pairs of instances of the abstract type Number – but with a different behavior specific to pairs of Float64 values. If one of the arguments is a 64-bit float but the other one is not, then the f(Float64,Float64) method cannot be called and the more general f(Number,Number) method must be used:julia> f(2.0, 3.0)\n7.0\n\njulia> f(2, 3.0)\n1.0\n\njulia> f(2.0, 3)\n1.0\n\njulia> f(2, 3)\n1The 2x + y definition is only used in the first case, while the 2x - y definition is used in the others. No automatic casting or conversion of function arguments is ever performed: all conversion in Julia is non-magical and completely explicit. Conversion and Promotion, however, shows how clever application of sufficiently advanced technology can be indistinguishable from magic. [Clarke61]For non-numeric values, and for fewer or more than two arguments, the function f remains undefined, and applying it will still result in a MethodError:julia> f(\"foo\", 3)\nERROR: MethodError: no method matching f(::String, ::Int64)\nClosest candidates are:\n  f(!Matched::Number, ::Number) at none:1\n\njulia> f()\nERROR: MethodError: no method matching f()\nClosest candidates are:\n  f(!Matched::Float64, !Matched::Float64) at none:1\n  f(!Matched::Number, !Matched::Number) at none:1You can easily see which methods exist for a function by entering the function object itself in an interactive session:julia> f\nf (generic function with 2 methods)This output tells us that f is a function object with two methods. To find out what the signatures of those methods are, use the methods() function:julia> methods(f)\n# 2 methods for generic function \"f\":\nf(x::Float64, y::Float64) in Main at none:1\nf(x::Number, y::Number) in Main at none:1which shows that f has two methods, one taking two Float64 arguments and one taking arguments of type Number. It also indicates the file and line number where the methods were defined: because these methods were defined at the REPL, we get the apparent line number none:1.In the absence of a type declaration with ::, the type of a method parameter is Any by default, meaning that it is unconstrained since all values in Julia are instances of the abstract type Any. Thus, we can define a catch-all method for f like so:julia> f(x,y) = println(\"Whoa there, Nelly.\")\nf (generic function with 3 methods)\n\njulia> f(\"foo\", 1)\nWhoa there, Nelly.This catch-all is less specific than any other possible method definition for a pair of parameter values, so it will only be called on pairs of arguments to which no other method definition applies.Although it seems a simple concept, multiple dispatch on the types of values is perhaps the single most powerful and central feature of the Julia language. Core operations typically have dozens of methods:julia> methods(+)\n# 180 methods for generic function \"+\":\n+(x::Bool, z::Complex{Bool}) in Base at complex.jl:224\n+(x::Bool, y::Bool) in Base at bool.jl:89\n+(x::Bool) in Base at bool.jl:86\n+(x::Bool, y::T) where T<:AbstractFloat in Base at bool.jl:96\n+(x::Bool, z::Complex) in Base at complex.jl:231\n+(a::Float16, b::Float16) in Base at float.jl:372\n+(x::Float32, y::Float32) in Base at float.jl:374\n+(x::Float64, y::Float64) in Base at float.jl:375\n+(z::Complex{Bool}, x::Bool) in Base at complex.jl:225\n+(z::Complex{Bool}, x::Real) in Base at complex.jl:239\n+(x::Char, y::Integer) in Base at char.jl:40\n+(c::BigInt, x::BigFloat) in Base.MPFR at mpfr.jl:303\n+(a::BigInt, b::BigInt, c::BigInt, d::BigInt, e::BigInt) in Base.GMP at gmp.jl:303\n+(a::BigInt, b::BigInt, c::BigInt, d::BigInt) in Base.GMP at gmp.jl:296\n+(a::BigInt, b::BigInt, c::BigInt) in Base.GMP at gmp.jl:290\n+(x::BigInt, y::BigInt) in Base.GMP at gmp.jl:258\n+(x::BigInt, c::Union{UInt16, UInt32, UInt64, UInt8}) in Base.GMP at gmp.jl:315\n...\n+(a, b, c, xs...) at operators.jl:119Multiple dispatch together with the flexible parametric type system give Julia its ability to abstractly express high-level algorithms decoupled from implementation details, yet generate efficient, specialized code to handle each case at run time."
},

{
    "location": "manual/methods/#man-ambiguities-1",
    "page": "Methods",
    "title": "Method Ambiguities",
    "category": "section",
    "text": "It is possible to define a set of function methods such that there is no unique most specific method applicable to some combinations of arguments:julia> g(x::Float64, y) = 2x + y\ng (generic function with 1 method)\n\njulia> g(x, y::Float64) = x + 2y\ng (generic function with 2 methods)\n\njulia> g(2.0, 3)\n7.0\n\njulia> g(2, 3.0)\n8.0\n\njulia> g(2.0, 3.0)\nERROR: MethodError: g(::Float64, ::Float64) is ambiguous.\n[...]Here the call g(2.0, 3.0) could be handled by either the g(Float64, Any) or the g(Any, Float64) method, and neither is more specific than the other. In such cases, Julia raises a MethodError rather than arbitrarily picking a method. You can avoid method ambiguities by specifying an appropriate method for the intersection case:julia> g(x::Float64, y::Float64) = 2x + 2y\ng (generic function with 3 methods)\n\njulia> g(2.0, 3)\n7.0\n\njulia> g(2, 3.0)\n8.0\n\njulia> g(2.0, 3.0)\n10.0It is recommended that the disambiguating method be defined first, since otherwise the ambiguity exists, if transiently, until the more specific method is defined.In more complex cases, resolving method ambiguities involves a certain element of design; this topic is explored further below."
},

{
    "location": "manual/methods/#Parametric-Methods-1",
    "page": "Methods",
    "title": "Parametric Methods",
    "category": "section",
    "text": "Method definitions can optionally have type parameters qualifying the signature:julia> same_type(x::T, y::T) where {T} = true\nsame_type (generic function with 1 method)\n\njulia> same_type(x,y) = false\nsame_type (generic function with 2 methods)The first method applies whenever both arguments are of the same concrete type, regardless of what type that is, while the second method acts as a catch-all, covering all other cases. Thus, overall, this defines a boolean function that checks whether its two arguments are of the same type:julia> same_type(1, 2)\ntrue\n\njulia> same_type(1, 2.0)\nfalse\n\njulia> same_type(1.0, 2.0)\ntrue\n\njulia> same_type(\"foo\", 2.0)\nfalse\n\njulia> same_type(\"foo\", \"bar\")\ntrue\n\njulia> same_type(Int32(1), Int64(2))\nfalseSuch definitions correspond to methods whose type signatures are UnionAll types (see UnionAll Types).This kind of definition of function behavior by dispatch is quite common – idiomatic, even – in Julia. Method type parameters are not restricted to being used as the types of arguments: they can be used anywhere a value would be in the signature of the function or body of the function. Here\'s an example where the method type parameter T is used as the type parameter to the parametric type Vector{T} in the method signature:julia> myappend(v::Vector{T}, x::T) where {T} = [v..., x]\nmyappend (generic function with 1 method)\n\njulia> myappend([1,2,3],4)\n4-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n\njulia> myappend([1,2,3],2.5)\nERROR: MethodError: no method matching myappend(::Array{Int64,1}, ::Float64)\nClosest candidates are:\n  myappend(::Array{T,1}, !Matched::T) where T at none:1\n\njulia> myappend([1.0,2.0,3.0],4.0)\n4-element Array{Float64,1}:\n 1.0\n 2.0\n 3.0\n 4.0\n\njulia> myappend([1.0,2.0,3.0],4)\nERROR: MethodError: no method matching myappend(::Array{Float64,1}, ::Int64)\nClosest candidates are:\n  myappend(::Array{T,1}, !Matched::T) where T at none:1As you can see, the type of the appended element must match the element type of the vector it is appended to, or else a MethodError is raised. In the following example, the method type parameter T is used as the return value:julia> mytypeof(x::T) where {T} = T\nmytypeof (generic function with 1 method)\n\njulia> mytypeof(1)\nInt64\n\njulia> mytypeof(1.0)\nFloat64Just as you can put subtype constraints on type parameters in type declarations (see Parametric Types), you can also constrain type parameters of methods:julia> same_type_numeric(x::T, y::T) where {T<:Number} = true\nsame_type_numeric (generic function with 1 method)\n\njulia> same_type_numeric(x::Number, y::Number) = false\nsame_type_numeric (generic function with 2 methods)\n\njulia> same_type_numeric(1, 2)\ntrue\n\njulia> same_type_numeric(1, 2.0)\nfalse\n\njulia> same_type_numeric(1.0, 2.0)\ntrue\n\njulia> same_type_numeric(\"foo\", 2.0)\nERROR: MethodError: no method matching same_type_numeric(::String, ::Float64)\nClosest candidates are:\n  same_type_numeric(!Matched::T<:Number, ::T<:Number) where T<:Number at none:1\n  same_type_numeric(!Matched::Number, ::Number) at none:1\n\njulia> same_type_numeric(\"foo\", \"bar\")\nERROR: MethodError: no method matching same_type_numeric(::String, ::String)\n\njulia> same_type_numeric(Int32(1), Int64(2))\nfalseThe same_type_numeric function behaves much like the same_type function defined above, but is only defined for pairs of numbers.Parametric methods allow the same syntax as where expressions used to write types (see UnionAll Types). If there is only a single parameter, the enclosing curly braces (in where {T}) can be omitted, but are often preferred for clarity. Multiple parameters can be separated with commas, e.g. where {T, S<:Real}, or written using nested where, e.g. where S<:Real where T."
},

{
    "location": "manual/methods/#Redefining-Methods-1",
    "page": "Methods",
    "title": "Redefining Methods",
    "category": "section",
    "text": "When redefining a method or adding new methods, it is important to realize that these changes don\'t take effect immediately. This is key to Julia\'s ability to statically infer and compile code to run fast, without the usual JIT tricks and overhead. Indeed, any new method definition won\'t be visible to the current runtime environment, including Tasks and Threads (and any previously defined @generated functions). Let\'s start with an example to see what this means:julia> function tryeval()\n           @eval newfun() = 1\n           newfun()\n       end\ntryeval (generic function with 1 method)\n\njulia> tryeval()\nERROR: MethodError: no method matching newfun()\nThe applicable method may be too new: running in world age xxxx1, while current world is xxxx2.\nClosest candidates are:\n  newfun() at none:1 (method too new to be called from this world context.)\n in tryeval() at none:1\n ...\n\njulia> newfun()\n1In this example, observe that the new definition for newfun has been created, but can\'t be immediately called. The new global is immediately visible to the tryeval function, so you could write return newfun (without parentheses). But neither you, nor any of your callers, nor the functions they call, or etc. can call this new method definition!But there\'s an exception: future calls to newfun from the REPL work as expected, being able to both see and call the new definition of newfun.However, future calls to tryeval will continue to see the definition of newfun as it was at the previous statement at the REPL, and thus before that call to tryeval.You may want to try this for yourself to see how it works.The implementation of this behavior is a \"world age counter\". This monotonically increasing value tracks each method definition operation. This allows describing \"the set of method definitions visible to a given runtime environment\" as a single number, or \"world age\". It also allows comparing the methods available in two worlds just by comparing their ordinal value. In the example above, we see that the \"current world\" (in which the method newfun() exists), is one greater than the task-local \"runtime world\" that was fixed when the execution of tryeval started.Sometimes it is necessary to get around this (for example, if you are implementing the above REPL). Fortunately, there is an easy solution: call the function using Base.invokelatest:julia> function tryeval2()\n           @eval newfun2() = 2\n           Base.invokelatest(newfun2)\n       end\ntryeval2 (generic function with 1 method)\n\njulia> tryeval2()\n2Finally, let\'s take a look at some more complex examples where this rule comes into play. Define a function f(x), which initially has one method:julia> f(x) = \"original definition\"\nf (generic function with 1 method)Start some other operations that use f(x):julia> g(x) = f(x)\ng (generic function with 1 method)\n\njulia> t = @async f(wait()); yield();Now we add some new methods to f(x):julia> f(x::Int) = \"definition for Int\"\nf (generic function with 2 methods)\n\njulia> f(x::Type{Int}) = \"definition for Type{Int}\"\nf (generic function with 3 methods)Compare how these results differ:julia> f(1)\n\"definition for Int\"\n\njulia> g(1)\n\"definition for Int\"\n\njulia> wait(schedule(t, 1))\n\"original definition\"\n\njulia> t = @async f(wait()); yield();\n\njulia> wait(schedule(t, 1))\n\"definition for Int\""
},

{
    "location": "manual/methods/#Parametrically-constrained-Varargs-methods-1",
    "page": "Methods",
    "title": "Parametrically-constrained Varargs methods",
    "category": "section",
    "text": "Function parameters can also be used to constrain the number of arguments that may be supplied to a \"varargs\" function (Varargs Functions).  The notation Vararg{T,N} is used to indicate such a constraint.  For example:julia> bar(a,b,x::Vararg{Any,2}) = (a,b,x)\nbar (generic function with 1 method)\n\njulia> bar(1,2,3)\nERROR: MethodError: no method matching bar(::Int64, ::Int64, ::Int64)\nClosest candidates are:\n  bar(::Any, ::Any, ::Any, !Matched::Any) at none:1\n\njulia> bar(1,2,3,4)\n(1, 2, (3, 4))\n\njulia> bar(1,2,3,4,5)\nERROR: MethodError: no method matching bar(::Int64, ::Int64, ::Int64, ::Int64, ::Int64)\nClosest candidates are:\n  bar(::Any, ::Any, ::Any, ::Any) at none:1More usefully, it is possible to constrain varargs methods by a parameter. For example:function getindex(A::AbstractArray{T,N}, indexes::Vararg{Number,N}) where {T,N}would be called only when the number of indexes matches the dimensionality of the array."
},

{
    "location": "manual/methods/#Note-on-Optional-and-keyword-Arguments-1",
    "page": "Methods",
    "title": "Note on Optional and keyword Arguments",
    "category": "section",
    "text": "As mentioned briefly in Functions, optional arguments are implemented as syntax for multiple method definitions. For example, this definition:f(a=1,b=2) = a+2btranslates to the following three methods:f(a,b) = a+2b\nf(a) = f(a,2)\nf() = f(1,2)This means that calling f() is equivalent to calling f(1,2). In this case the result is 5, because f(1,2) invokes the first method of f above. However, this need not always be the case. If you define a fourth method that is more specialized for integers:f(a::Int,b::Int) = a-2bthen the result of both f() and f(1,2) is -3. In other words, optional arguments are tied to a function, not to any specific method of that function. It depends on the types of the optional arguments which method is invoked. When optional arguments are defined in terms of a global variable, the type of the optional argument may even change at run-time.Keyword arguments behave quite differently from ordinary positional arguments. In particular, they do not participate in method dispatch. Methods are dispatched based only on positional arguments, with keyword arguments processed after the matching method is identified."
},

{
    "location": "manual/methods/#Function-like-objects-1",
    "page": "Methods",
    "title": "Function-like objects",
    "category": "section",
    "text": "Methods are associated with types, so it is possible to make any arbitrary Julia object \"callable\" by adding methods to its type. (Such \"callable\" objects are sometimes called \"functors.\")For example, you can define a type that stores the coefficients of a polynomial, but behaves like a function evaluating the polynomial:julia> struct Polynomial{R}\n           coeffs::Vector{R}\n       end\n\njulia> function (p::Polynomial)(x)\n           v = p.coeffs[end]\n           for i = (length(p.coeffs)-1):-1:1\n               v = v*x + p.coeffs[i]\n           end\n           return v\n       endNotice that the function is specified by type instead of by name. In the function body, p will refer to the object that was called. A Polynomial can be used as follows:julia> p = Polynomial([1,10,100])\nPolynomial{Int64}([1, 10, 100])\n\njulia> p(3)\n931This mechanism is also the key to how type constructors and closures (inner functions that refer to their surrounding environment) work in Julia, discussed later in the manual."
},

{
    "location": "manual/methods/#Empty-generic-functions-1",
    "page": "Methods",
    "title": "Empty generic functions",
    "category": "section",
    "text": "Occasionally it is useful to introduce a generic function without yet adding methods. This can be used to separate interface definitions from implementations. It might also be done for the purpose of documentation or code readability. The syntax for this is an empty function block without a tuple of arguments:function emptyfunc\nend"
},

{
    "location": "manual/methods/#man-method-design-ambiguities-1",
    "page": "Methods",
    "title": "Method design and the avoidance of ambiguities",
    "category": "section",
    "text": "Julia\'s method polymorphism is one of its most powerful features, yet exploiting this power can pose design challenges.  In particular, in more complex method hierarchies it is not uncommon for ambiguities to arise.Above, it was pointed out that one can resolve ambiguities likef(x, y::Int) = 1\nf(x::Int, y) = 2by defining a methodf(x::Int, y::Int) = 3This is often the right strategy; however, there are circumstances where following this advice blindly can be counterproductive. In particular, the more methods a generic function has, the more possibilities there are for ambiguities. When your method hierarchies get more complicated than this simple example, it can be worth your while to think carefully about alternative strategies.Below we discuss particular challenges and some alternative ways to resolve such issues."
},

{
    "location": "manual/methods/#Tuple-and-NTuple-arguments-1",
    "page": "Methods",
    "title": "Tuple and NTuple arguments",
    "category": "section",
    "text": "Tuple (and NTuple) arguments present special challenges. For example,f(x::NTuple{N,Int}) where {N} = 1\nf(x::NTuple{N,Float64}) where {N} = 2are ambiguous because of the possibility that N == 0: there are no elements to determine whether the Int or Float64 variant should be called. To resolve the ambiguity, one approach is define a method for the empty tuple:f(x::Tuple{}) = 3Alternatively, for all methods but one you can insist that there is at least one element in the tuple:f(x::NTuple{N,Int}) where {N} = 1           # this is the fallback\nf(x::Tuple{Float64, Vararg{Float64}}) = 2   # this requires at least one Float64"
},

{
    "location": "manual/methods/#man-methods-orthogonalize-1",
    "page": "Methods",
    "title": "Orthogonalize your design",
    "category": "section",
    "text": "When you might be tempted to dispatch on two or more arguments, consider whether a \"wrapper\" function might make for a simpler design. For example, instead of writing multiple variants:f(x::A, y::A) = ...\nf(x::A, y::B) = ...\nf(x::B, y::A) = ...\nf(x::B, y::B) = ...you might consider definingf(x::A, y::A) = ...\nf(x, y) = f(g(x), g(y))where g converts the argument to type A. This is a very specific example of the more general principle of orthogonal design, in which separate concepts are assigned to separate methods. Here, g will most likely need a fallback definitiong(x::A) = xA related strategy exploits promote to bring x and y to a common type:f(x::T, y::T) where {T} = ...\nf(x, y) = f(promote(x, y)...)One risk with this design is the possibility that if there is no suitable promotion method converting x and y to the same type, the second method will recurse on itself infinitely and trigger a stack overflow. The non-exported function Base.promote_noncircular can be used as an alternative; when promotion fails it will still throw an error, but one that fails faster with a more specific error message."
},

{
    "location": "manual/methods/#Dispatch-on-one-argument-at-a-time-1",
    "page": "Methods",
    "title": "Dispatch on one argument at a time",
    "category": "section",
    "text": "If you need to dispatch on multiple arguments, and there are many fallbacks with too many combinations to make it practical to define all possible variants, then consider introducing a \"name cascade\" where (for example) you dispatch on the first argument and then call an internal method:f(x::A, y) = _fA(x, y)\nf(x::B, y) = _fB(x, y)Then the internal methods _fA and _fB can dispatch on y without concern about ambiguities with each other with respect to x.Be aware that this strategy has at least one major disadvantage: in many cases, it is not possible for users to further customize the behavior of f by defining further specializations of your exported function f. Instead, they have to define specializations for your internal methods _fA and _fB, and this blurs the lines between exported and internal methods."
},

{
    "location": "manual/methods/#Abstract-containers-and-element-types-1",
    "page": "Methods",
    "title": "Abstract containers and element types",
    "category": "section",
    "text": "Where possible, try to avoid defining methods that dispatch on specific element types of abstract containers. For example,-(A::AbstractArray{T}, b::Date) where {T<:Date}generates ambiguities for anyone who defines a method-(A::MyArrayType{T}, b::T) where {T}The best approach is to avoid defining either of these methods: instead, rely on a generic method -(A::AbstractArray, b) and make sure this method is implemented with generic calls (like similar and -) that do the right thing for each container type and element type separately. This is just a more complex variant of the advice to orthogonalize your methods.When this approach is not possible, it may be worth starting a discussion with other developers about resolving the ambiguity; just because one method was defined first does not necessarily mean that it can\'t be modified or eliminated.  As a last resort, one developer can define the \"band-aid\" method-(A::MyArrayType{T}, b::Date) where {T<:Date} = ...that resolves the ambiguity by brute force."
},

{
    "location": "manual/methods/#Complex-method-\"cascades\"-with-default-arguments-1",
    "page": "Methods",
    "title": "Complex method \"cascades\" with default arguments",
    "category": "section",
    "text": "If you are defining a method \"cascade\" that supplies defaults, be careful about dropping any arguments that correspond to potential defaults. For example, suppose you\'re writing a digital filtering algorithm and you have a method that handles the edges of the signal by applying padding:function myfilter(A, kernel, ::Replicate)\n    Apadded = replicate_edges(A, size(kernel))\n    myfilter(Apadded, kernel)  # now perform the \"real\" computation\nendThis will run afoul of a method that supplies default padding:myfilter(A, kernel) = myfilter(A, kernel, Replicate()) # replicate the edge by defaultTogether, these two methods generate an infinite recursion with A constantly growing bigger.The better design would be to define your call hierarchy like this:struct NoPad end  # indicate that no padding is desired, or that it\'s already applied\n\nmyfilter(A, kernel) = myfilter(A, kernel, Replicate())  # default boundary conditions\n\nfunction myfilter(A, kernel, ::Replicate)\n    Apadded = replicate_edges(A, size(kernel))\n    myfilter(Apadded, kernel, NoPad())  # indicate the new boundary conditions\nend\n\n# other padding methods go here\n\nfunction myfilter(A, kernel, ::NoPad)\n    # Here\'s the \"real\" implementation of the core computation\nendNoPad is supplied in the same argument position as any other kind of padding, so it keeps the dispatch hierarchy well organized and with reduced likelihood of ambiguities. Moreover, it extends the \"public\" myfilter interface: a user who wants to control the padding explicitly can call the NoPad variant directly.[Clarke61]: Arthur C. Clarke, Profiles of the Future (1961): Clarke\'s Third Law."
},

{
    "location": "manual/constructors/#",
    "page": "Constructors",
    "title": "Constructors",
    "category": "page",
    "text": ""
},

{
    "location": "manual/constructors/#man-constructors-1",
    "page": "Constructors",
    "title": "Constructors",
    "category": "section",
    "text": "Constructors [1] are functions that create new objects – specifically, instances of Composite Types. In Julia, type objects also serve as constructor functions: they create new instances of themselves when applied to an argument tuple as a function. This much was already mentioned briefly when composite types were introduced. For example:julia> struct Foo\n           bar\n           baz\n       end\n\njulia> foo = Foo(1, 2)\nFoo(1, 2)\n\njulia> foo.bar\n1\n\njulia> foo.baz\n2For many types, forming new objects by binding their field values together is all that is ever needed to create instances. There are, however, cases where more functionality is required when creating composite objects. Sometimes invariants must be enforced, either by checking arguments or by transforming them. Recursive data structures, especially those that may be self-referential, often cannot be constructed cleanly without first being created in an incomplete state and then altered programmatically to be made whole, as a separate step from object creation. Sometimes, it\'s just convenient to be able to construct objects with fewer or different types of parameters than they have fields. Julia\'s system for object construction addresses all of these cases and more.[1]: Nomenclature: while the term \"constructor\" generally refers to the entire function which constructs objects of a type, it is common to abuse terminology slightly and refer to specific constructor methods as \"constructors\". In such situations, it is generally clear from context that the term is used to mean \"constructor method\" rather than \"constructor function\", especially as it is often used in the sense of singling out a particular method of the constructor from all of the others."
},

{
    "location": "manual/constructors/#Outer-Constructor-Methods-1",
    "page": "Constructors",
    "title": "Outer Constructor Methods",
    "category": "section",
    "text": "A constructor is just like any other function in Julia in that its overall behavior is defined by the combined behavior of its methods. Accordingly, you can add functionality to a constructor by simply defining new methods. For example, let\'s say you want to add a constructor method for Foo objects that takes only one argument and uses the given value for both the bar and baz fields. This is simple:julia> Foo(x) = Foo(x,x)\nFoo\n\njulia> Foo(1)\nFoo(1, 1)You could also add a zero-argument Foo constructor method that supplies default values for both of the bar and baz fields:julia> Foo() = Foo(0)\nFoo\n\njulia> Foo()\nFoo(0, 0)Here the zero-argument constructor method calls the single-argument constructor method, which in turn calls the automatically provided two-argument constructor method. For reasons that will become clear very shortly, additional constructor methods declared as normal methods like this are called outer constructor methods. Outer constructor methods can only ever create a new instance by calling another constructor method, such as the automatically provided default ones."
},

{
    "location": "manual/constructors/#Inner-Constructor-Methods-1",
    "page": "Constructors",
    "title": "Inner Constructor Methods",
    "category": "section",
    "text": "While outer constructor methods succeed in addressing the problem of providing additional convenience methods for constructing objects, they fail to address the other two use cases mentioned in the introduction of this chapter: enforcing invariants, and allowing construction of self-referential objects. For these problems, one needs inner constructor methods. An inner constructor method is much like an outer constructor method, with two differences:It is declared inside the block of a type declaration, rather than outside of it like normal methods.\nIt has access to a special locally existent function called new that creates objects of the block\'s type.For example, suppose one wants to declare a type that holds a pair of real numbers, subject to the constraint that the first number is not greater than the second one. One could declare it like this:julia> struct OrderedPair\n           x::Real\n           y::Real\n           OrderedPair(x,y) = x > y ? error(\"out of order\") : new(x,y)\n       end\nNow OrderedPair objects can only be constructed such that x <= y:julia> OrderedPair(1, 2)\nOrderedPair(1, 2)\n\njulia> OrderedPair(2,1)\nERROR: out of order\nStacktrace:\n [1] OrderedPair(::Int64, ::Int64) at ./none:4If the type were declared mutable, you could reach in and directly change the field values to violate this invariant, but messing around with an object\'s internals uninvited is considered poor form. You (or someone else) can also provide additional outer constructor methods at any later point, but once a type is declared, there is no way to add more inner constructor methods. Since outer constructor methods can only create objects by calling other constructor methods, ultimately, some inner constructor must be called to create an object. This guarantees that all objects of the declared type must come into existence by a call to one of the inner constructor methods provided with the type, thereby giving some degree of enforcement of a type\'s invariants.If any inner constructor method is defined, no default constructor method is provided: it is presumed that you have supplied yourself with all the inner constructors you need. The default constructor is equivalent to writing your own inner constructor method that takes all of the object\'s fields as parameters (constrained to be of the correct type, if the corresponding field has a type), and passes them to new, returning the resulting object:julia> struct Foo\n           bar\n           baz\n           Foo(bar,baz) = new(bar,baz)\n       end\nThis declaration has the same effect as the earlier definition of the Foo type without an explicit inner constructor method. The following two types are equivalent – one with a default constructor, the other with an explicit constructor:julia> struct T1\n           x::Int64\n       end\n\njulia> struct T2\n           x::Int64\n           T2(x) = new(x)\n       end\n\njulia> T1(1)\nT1(1)\n\njulia> T2(1)\nT2(1)\n\njulia> T1(1.0)\nT1(1)\n\njulia> T2(1.0)\nT2(1)It is considered good form to provide as few inner constructor methods as possible: only those taking all arguments explicitly and enforcing essential error checking and transformation. Additional convenience constructor methods, supplying default values or auxiliary transformations, should be provided as outer constructors that call the inner constructors to do the heavy lifting. This separation is typically quite natural."
},

{
    "location": "manual/constructors/#Incomplete-Initialization-1",
    "page": "Constructors",
    "title": "Incomplete Initialization",
    "category": "section",
    "text": "The final problem which has still not been addressed is construction of self-referential objects, or more generally, recursive data structures. Since the fundamental difficulty may not be immediately obvious, let us briefly explain it. Consider the following recursive type declaration:julia> mutable struct SelfReferential\n           obj::SelfReferential\n       end\nThis type may appear innocuous enough, until one considers how to construct an instance of it. If a is an instance of SelfReferential, then a second instance can be created by the call:julia> b = SelfReferential(a)But how does one construct the first instance when no instance exists to provide as a valid value for its obj field? The only solution is to allow creating an incompletely initialized instance of SelfReferential with an unassigned obj field, and using that incomplete instance as a valid value for the obj field of another instance, such as, for example, itself.To allow for the creation of incompletely initialized objects, Julia allows the new function to be called with fewer than the number of fields that the type has, returning an object with the unspecified fields uninitialized. The inner constructor method can then use the incomplete object, finishing its initialization before returning it. Here, for example, we take another crack at defining the SelfReferential type, with a zero-argument inner constructor returning instances having obj fields pointing to themselves:julia> mutable struct SelfReferential\n           obj::SelfReferential\n           SelfReferential() = (x = new(); x.obj = x)\n       end\nWe can verify that this constructor works and constructs objects that are, in fact, self-referential:julia> x = SelfReferential();\n\njulia> x === x\ntrue\n\njulia> x === x.obj\ntrue\n\njulia> x === x.obj.obj\ntrueAlthough it is generally a good idea to return a fully initialized object from an inner constructor, incompletely initialized objects can be returned:julia> mutable struct Incomplete\n           xx\n           Incomplete() = new()\n       end\n\njulia> z = Incomplete();While you are allowed to create objects with uninitialized fields, any access to an uninitialized reference is an immediate error:julia> z.xx\nERROR: UndefRefError: access to undefined referenceThis avoids the need to continually check for null values. However, not all object fields are references. Julia considers some types to be \"plain data\", meaning all of their data is self-contained and does not reference other objects. The plain data types consist of primitive types (e.g. Int) and immutable structs of other plain data types. The initial contents of a plain data type is undefined:julia> struct HasPlain\n           n::Int\n           HasPlain() = new()\n       end\n\njulia> HasPlain()\nHasPlain(438103441441)Arrays of plain data types exhibit the same behavior.You can pass incomplete objects to other functions from inner constructors to delegate their completion:julia> mutable struct Lazy\n           xx\n           Lazy(v) = complete_me(new(), v)\n       endAs with incomplete objects returned from constructors, if complete_me or any of its callees try to access the xx field of the Lazy object before it has been initialized, an error will be thrown immediately."
},

{
    "location": "manual/constructors/#Parametric-Constructors-1",
    "page": "Constructors",
    "title": "Parametric Constructors",
    "category": "section",
    "text": "Parametric types add a few wrinkles to the constructor story. Recall from Parametric Types that, by default, instances of parametric composite types can be constructed either with explicitly given type parameters or with type parameters implied by the types of the arguments given to the constructor. Here are some examples:julia> struct Point{T<:Real}\n           x::T\n           y::T\n       end\n\njulia> Point(1,2) ## implicit T ##\nPoint{Int64}(1, 2)\n\njulia> Point(1.0,2.5) ## implicit T ##\nPoint{Float64}(1.0, 2.5)\n\njulia> Point(1,2.5) ## implicit T ##\nERROR: MethodError: no method matching Point(::Int64, ::Float64)\nClosest candidates are:\n  Point(::T<:Real, !Matched::T<:Real) where T<:Real at none:2\n\njulia> Point{Int64}(1, 2) ## explicit T ##\nPoint{Int64}(1, 2)\n\njulia> Point{Int64}(1.0,2.5) ## explicit T ##\nERROR: InexactError()\nStacktrace:\n [1] convert(::Type{Int64}, ::Float64) at ./float.jl:679\n [2] Point{Int64}(::Float64, ::Float64) at ./none:2\n\njulia> Point{Float64}(1.0, 2.5) ## explicit T ##\nPoint{Float64}(1.0, 2.5)\n\njulia> Point{Float64}(1,2) ## explicit T ##\nPoint{Float64}(1.0, 2.0)As you can see, for constructor calls with explicit type parameters, the arguments are converted to the implied field types: Point{Int64}(1,2) works, but Point{Int64}(1.0,2.5) raises an InexactError when converting 2.5 to Int64. When the type is implied by the arguments to the constructor call, as in Point(1,2), then the types of the arguments must agree – otherwise the T cannot be determined – but any pair of real arguments with matching type may be given to the generic Point constructor.What\'s really going on here is that Point, Point{Float64} and Point{Int64} are all different constructor functions. In fact, Point{T} is a distinct constructor function for each type T. Without any explicitly provided inner constructors, the declaration of the composite type Point{T<:Real} automatically provides an inner constructor, Point{T}, for each possible type T<:Real, that behaves just like non-parametric default inner constructors do. It also provides a single general outer Point constructor that takes pairs of real arguments, which must be of the same type. This automatic provision of constructors is equivalent to the following explicit declaration:julia> struct Point{T<:Real}\n           x::T\n           y::T\n           Point{T}(x,y) where {T<:Real} = new(x,y)\n       end\n\njulia> Point(x::T, y::T) where {T<:Real} = Point{T}(x,y);Notice that each definition looks like the form of constructor call that it handles. The call Point{Int64}(1,2) will invoke the definition Point{T}(x,y) inside the type block. The outer constructor declaration, on the other hand, defines a method for the general Point constructor which only applies to pairs of values of the same real type. This declaration makes constructor calls without explicit type parameters, like Point(1,2) and Point(1.0,2.5), work. Since the method declaration restricts the arguments to being of the same type, calls like Point(1,2.5), with arguments of different types, result in \"no method\" errors.Suppose we wanted to make the constructor call Point(1,2.5) work by \"promoting\" the integer value 1 to the floating-point value 1.0. The simplest way to achieve this is to define the following additional outer constructor method:julia> Point(x::Int64, y::Float64) = Point(convert(Float64,x),y);This method uses the convert() function to explicitly convert x to Float64 and then delegates construction to the general constructor for the case where both arguments are Float64. With this method definition what was previously a MethodError now successfully creates a point of type Point{Float64}:julia> Point(1,2.5)\nPoint{Float64}(1.0, 2.5)\n\njulia> typeof(ans)\nPoint{Float64}However, other similar calls still don\'t work:julia> Point(1.5,2)\nERROR: MethodError: no method matching Point(::Float64, ::Int64)\nClosest candidates are:\n  Point(::T<:Real, !Matched::T<:Real) where T<:Real at none:1For a more general way to make all such calls work sensibly, see Conversion and Promotion. At the risk of spoiling the suspense, we can reveal here that all it takes is the following outer method definition to make all calls to the general Point constructor work as one would expect:julia> Point(x::Real, y::Real) = Point(promote(x,y)...);The promote function converts all its arguments to a common type – in this case Float64. With this method definition, the Point constructor promotes its arguments the same way that numeric operators like + do, and works for all kinds of real numbers:julia> Point(1.5,2)\nPoint{Float64}(1.5, 2.0)\n\njulia> Point(1,1//2)\nPoint{Rational{Int64}}(1//1, 1//2)\n\njulia> Point(1.0,1//2)\nPoint{Float64}(1.0, 0.5)Thus, while the implicit type parameter constructors provided by default in Julia are fairly strict, it is possible to make them behave in a more relaxed but sensible manner quite easily. Moreover, since constructors can leverage all of the power of the type system, methods, and multiple dispatch, defining sophisticated behavior is typically quite simple."
},

{
    "location": "manual/constructors/#Case-Study:-Rational-1",
    "page": "Constructors",
    "title": "Case Study: Rational",
    "category": "section",
    "text": "Perhaps the best way to tie all these pieces together is to present a real world example of a parametric composite type and its constructor methods. To that end, here is the (slightly modified) beginning of rational.jl, which implements Julia\'s Rational Numbers:julia> struct OurRational{T<:Integer} <: Real\n           num::T\n           den::T\n           function OurRational{T}(num::T, den::T) where T<:Integer\n               if num == 0 && den == 0\n                    error(\"invalid rational: 0//0\")\n               end\n               g = gcd(den, num)\n               num = div(num, g)\n               den = div(den, g)\n               new(num, den)\n           end\n       end\n\njulia> OurRational(n::T, d::T) where {T<:Integer} = OurRational{T}(n,d)\nOurRational\n\njulia> OurRational(n::Integer, d::Integer) = OurRational(promote(n,d)...)\nOurRational\n\njulia> OurRational(n::Integer) = OurRational(n,one(n))\nOurRational\n\njulia> //(n::Integer, d::Integer) = OurRational(n,d)\n// (generic function with 1 method)\n\njulia> //(x::OurRational, y::Integer) = x.num // (x.den*y)\n// (generic function with 2 methods)\n\njulia> //(x::Integer, y::OurRational) = (x*y.den) // y.num\n// (generic function with 3 methods)\n\njulia> //(x::Complex, y::Real) = complex(real(x)//y, imag(x)//y)\n// (generic function with 4 methods)\n\njulia> //(x::Real, y::Complex) = x*y\'//real(y*y\')\n// (generic function with 5 methods)\n\njulia> function //(x::Complex, y::Complex)\n           xy = x*y\'\n           yy = real(y*y\')\n           complex(real(xy)//yy, imag(xy)//yy)\n       end\n// (generic function with 6 methods)The first line – struct OurRational{T<:Integer} <: Real – declares that OurRational takes one type parameter of an integer type, and is itself a real type. The field declarations num::T and den::T indicate that the data held in a OurRational{T} object are a pair of integers of type T, one representing the rational value\'s numerator and the other representing its denominator.Now things get interesting. OurRational has a single inner constructor method which checks that both of num and den aren\'t zero and ensures that every rational is constructed in \"lowest terms\" with a non-negative denominator. This is accomplished by dividing the given numerator and denominator values by their greatest common divisor, computed using the gcd function. Since gcd returns the greatest common divisor of its arguments with sign matching the first argument (den here), after this division the new value of den is guaranteed to be non-negative. Because this is the only inner constructor for OurRational, we can be certain that OurRational objects are always constructed in this normalized form.OurRational also provides several outer constructor methods for convenience. The first is the \"standard\" general constructor that infers the type parameter T from the type of the numerator and denominator when they have the same type. The second applies when the given numerator and denominator values have different types: it promotes them to a common type and then delegates construction to the outer constructor for arguments of matching type. The third outer constructor turns integer values into rationals by supplying a value of 1 as the denominator.Following the outer constructor definitions, we have a number of methods for the // operator, which provides a syntax for writing rationals. Before these definitions, // is a completely undefined operator with only syntax and no meaning. Afterwards, it behaves just as described in Rational Numbers – its entire behavior is defined in these few lines. The first and most basic definition just makes a//b construct a OurRational by applying the OurRational constructor to a and b when they are integers. When one of the operands of // is already a rational number, we construct a new rational for the resulting ratio slightly differently; this behavior is actually identical to division of a rational with an integer. Finally, applying // to complex integral values creates an instance of Complex{OurRational} – a complex number whose real and imaginary parts are rationals:julia> ans = (1 + 2im)//(1 - 2im);\n\njulia> typeof(ans)\nComplex{OurRational{Int64}}\n\njulia> ans <: Complex{OurRational}\nfalseThus, although the // operator usually returns an instance of OurRational, if either of its arguments are complex integers, it will return an instance of Complex{OurRational} instead. The interested reader should consider perusing the rest of rational.jl: it is short, self-contained, and implements an entire basic Julia type."
},

{
    "location": "manual/constructors/#constructors-and-conversion-1",
    "page": "Constructors",
    "title": "Constructors and Conversion",
    "category": "section",
    "text": "Constructors T(args...) in Julia are implemented like other callable objects: methods are added to their types. The type of a type is Type, so all constructor methods are stored in the method table for the Type type. This means that you can declare more flexible constructors, e.g. constructors for abstract types, by explicitly defining methods for the appropriate types.However, in some cases you could consider adding methods to Base.convert instead of defining a constructor, because Julia falls back to calling convert() if no matching constructor is found. For example, if no constructor T(args...) = ... exists Base.convert(::Type{T}, args...) = ... is called.convert is used extensively throughout Julia whenever one type needs to be converted to another (e.g. in assignment, ccall, etcetera), and should generally only be defined (or successful) if the conversion is lossless.  For example, convert(Int, 3.0) produces 3, but convert(Int, 3.2) throws an InexactError.  If you want to define a constructor for a lossless conversion from one type to another, you should probably define a convert method instead.On the other hand, if your constructor does not represent a lossless conversion, or doesn\'t represent \"conversion\" at all, it is better to leave it as a constructor rather than a convert method. For example, the Array{Int}() constructor creates a zero-dimensional Array of the type Int, but is not really a \"conversion\" from Int to an Array."
},

{
    "location": "manual/constructors/#Outer-only-constructors-1",
    "page": "Constructors",
    "title": "Outer-only constructors",
    "category": "section",
    "text": "As we have seen, a typical parametric type has inner constructors that are called when type parameters are known; e.g. they apply to Point{Int} but not to Point. Optionally, outer constructors that determine type parameters automatically can be added, for example constructing a Point{Int} from the call Point(1,2). Outer constructors call inner constructors to do the core work of making an instance. However, in some cases one would rather not provide inner constructors, so that specific type parameters cannot be requested manually.For example, say we define a type that stores a vector along with an accurate representation of its sum:julia> struct SummedArray{T<:Number,S<:Number}\n           data::Vector{T}\n           sum::S\n       end\n\njulia> SummedArray(Int32[1; 2; 3], Int32(6))\nSummedArray{Int32,Int32}(Int32[1, 2, 3], 6)The problem is that we want S to be a larger type than T, so that we can sum many elements with less information loss. For example, when T is Int32, we would like S to be Int64. Therefore we want to avoid an interface that allows the user to construct instances of the type SummedArray{Int32,Int32}. One way to do this is to provide a constructor only for SummedArray, but inside the type definition block to suppress generation of default constructors:julia> struct SummedArray{T<:Number,S<:Number}\n           data::Vector{T}\n           sum::S\n           function SummedArray(a::Vector{T}) where T\n               S = widen(T)\n               new{T,S}(a, sum(S, a))\n           end\n       end\n\njulia> SummedArray(Int32[1; 2; 3], Int32(6))\nERROR: MethodError: no method matching SummedArray(::Array{Int32,1}, ::Int32)\nClosest candidates are:\n  SummedArray(::Array{T,1}) where T at none:5This constructor will be invoked by the syntax SummedArray(a). The syntax new{T,S} allows specifying parameters for the type to be constructed, i.e. this call will return a SummedArray{T,S}. new{T,S} can be used in any constructor definition, but for convenience the parameters to new{} are automatically derived from the type being constructed when possible."
},

{
    "location": "manual/conversion-and-promotion/#",
    "page": "Conversion and Promotion",
    "title": "Conversion and Promotion",
    "category": "page",
    "text": ""
},

{
    "location": "manual/conversion-and-promotion/#conversion-and-promotion-1",
    "page": "Conversion and Promotion",
    "title": "Conversion and Promotion",
    "category": "section",
    "text": "Julia has a system for promoting arguments of mathematical operators to a common type, which has been mentioned in various other sections, including Integers and Floating-Point Numbers, Mathematical Operations and Elementary Functions, Types, and Methods. In this section, we explain how this promotion system works, as well as how to extend it to new types and apply it to functions besides built-in mathematical operators. Traditionally, programming languages fall into two camps with respect to promotion of arithmetic arguments:Automatic promotion for built-in arithmetic types and operators. In most languages, built-in numeric types, when used as operands to arithmetic operators with infix syntax, such as +, -, *, and /, are automatically promoted to a common type to produce the expected results. C, Java, Perl, and Python, to name a few, all correctly compute the sum 1 + 1.5 as the floating-point value 2.5, even though one of the operands to + is an integer. These systems are convenient and designed carefully enough that they are generally all-but-invisible to the programmer: hardly anyone consciously thinks of this promotion taking place when writing such an expression, but compilers and interpreters must perform conversion before addition since integers and floating-point values cannot be added as-is. Complex rules for such automatic conversions are thus inevitably part of specifications and implementations for such languages.\nNo automatic promotion. This camp includes Ada and ML – very \"strict\" statically typed languages. In these languages, every conversion must be explicitly specified by the programmer. Thus, the example expression 1 + 1.5 would be a compilation error in both Ada and ML. Instead one must write real(1) + 1.5, explicitly converting the integer 1 to a floating-point value before performing addition. Explicit conversion everywhere is so inconvenient, however, that even Ada has some degree of automatic conversion: integer literals are promoted to the expected integer type automatically, and floating-point literals are similarly promoted to appropriate floating-point types.In a sense, Julia falls into the \"no automatic promotion\" category: mathematical operators are just functions with special syntax, and the arguments of functions are never automatically converted. However, one may observe that applying mathematical operations to a wide variety of mixed argument types is just an extreme case of polymorphic multiple dispatch – something which Julia\'s dispatch and type systems are particularly well-suited to handle. \"Automatic\" promotion of mathematical operands simply emerges as a special application: Julia comes with pre-defined catch-all dispatch rules for mathematical operators, invoked when no specific implementation exists for some combination of operand types. These catch-all rules first promote all operands to a common type using user-definable promotion rules, and then invoke a specialized implementation of the operator in question for the resulting values, now of the same type. User-defined types can easily participate in this promotion system by defining methods for conversion to and from other types, and providing a handful of promotion rules defining what types they should promote to when mixed with other types."
},

{
    "location": "manual/conversion-and-promotion/#Conversion-1",
    "page": "Conversion and Promotion",
    "title": "Conversion",
    "category": "section",
    "text": "Conversion of values to various types is performed by the convert function. The convert function generally takes two arguments: the first is a type object while the second is a value to convert to that type; the returned value is the value converted to an instance of given type. The simplest way to understand this function is to see it in action:julia> x = 12\n12\n\njulia> typeof(x)\nInt64\n\njulia> convert(UInt8, x)\n0x0c\n\njulia> typeof(ans)\nUInt8\n\njulia> convert(AbstractFloat, x)\n12.0\n\njulia> typeof(ans)\nFloat64\n\njulia> a = Any[1 2 3; 4 5 6]\n2×3 Array{Any,2}:\n 1  2  3\n 4  5  6\n\njulia> convert(Array{Float64}, a)\n2×3 Array{Float64,2}:\n 1.0  2.0  3.0\n 4.0  5.0  6.0Conversion isn\'t always possible, in which case a no method error is thrown indicating that convert doesn\'t know how to perform the requested conversion:julia> convert(AbstractFloat, \"foo\")\nERROR: MethodError: Cannot `convert` an object of type String to an object of type AbstractFloat\nThis may have arisen from a call to the constructor AbstractFloat(...),\nsince type constructors fall back to convert methods.Some languages consider parsing strings as numbers or formatting numbers as strings to be conversions (many dynamic languages will even perform conversion for you automatically), however Julia does not: even though some strings can be parsed as numbers, most strings are not valid representations of numbers, and only a very limited subset of them are. Therefore in Julia the dedicated parse() function must be used to perform this operation, making it more explicit."
},

{
    "location": "manual/conversion-and-promotion/#Defining-New-Conversions-1",
    "page": "Conversion and Promotion",
    "title": "Defining New Conversions",
    "category": "section",
    "text": "To define a new conversion, simply provide a new method for convert(). That\'s really all there is to it. For example, the method to convert a real number to a boolean is this:convert(::Type{Bool}, x::Real) = x==0 ? false : x==1 ? true : throw(InexactError())The type of the first argument of this method is a singleton type, Type{Bool}, the only instance of which is Bool. Thus, this method is only invoked when the first argument is the type value Bool. Notice the syntax used for the first argument: the argument name is omitted prior to the :: symbol, and only the type is given. This is the syntax in Julia for a function argument whose type is specified but whose value is never used in the function body. In this example, since the type is a singleton, there would never be any reason to use its value within the body. When invoked, the method determines whether a numeric value is true or false as a boolean, by comparing it to one and zero:julia> convert(Bool, 1)\ntrue\n\njulia> convert(Bool, 0)\nfalse\n\njulia> convert(Bool, 1im)\nERROR: InexactError()\nStacktrace:\n [1] convert(::Type{Bool}, ::Complex{Int64}) at ./complex.jl:31\n\njulia> convert(Bool, 0im)\nfalseThe method signatures for conversion methods are often quite a bit more involved than this example, especially for parametric types. The example above is meant to be pedagogical, and is not the actual Julia behaviour. This is the actual implementation in Julia:convert(::Type{T}, z::Complex) where {T<:Real} =\n    (imag(z) == 0 ? convert(T, real(z)) : throw(InexactError()))"
},

{
    "location": "manual/conversion-and-promotion/#man-rational-conversion-1",
    "page": "Conversion and Promotion",
    "title": "Case Study: Rational Conversions",
    "category": "section",
    "text": "To continue our case study of Julia\'s Rational type, here are the conversions declared in rational.jl, right after the declaration of the type and its constructors:convert(::Type{Rational{T}}, x::Rational) where {T<:Integer} = Rational(convert(T,x.num),convert(T,x.den))\nconvert(::Type{Rational{T}}, x::Integer) where {T<:Integer} = Rational(convert(T,x), convert(T,1))\n\nfunction convert(::Type{Rational{T}}, x::AbstractFloat, tol::Real) where T<:Integer\n    if isnan(x); return zero(T)//zero(T); end\n    if isinf(x); return sign(x)//zero(T); end\n    y = x\n    a = d = one(T)\n    b = c = zero(T)\n    while true\n        f = convert(T,round(y)); y -= f\n        a, b, c, d = f*a+c, f*b+d, a, b\n        if y == 0 || abs(a/b-x) <= tol\n            return a//b\n        end\n        y = 1/y\n    end\nend\nconvert(rt::Type{Rational{T}}, x::AbstractFloat) where {T<:Integer} = convert(rt,x,eps(x))\n\nconvert(::Type{T}, x::Rational) where {T<:AbstractFloat} = convert(T,x.num)/convert(T,x.den)\nconvert(::Type{T}, x::Rational) where {T<:Integer} = div(convert(T,x.num),convert(T,x.den))The initial four convert methods provide conversions to rational types. The first method converts one type of rational to another type of rational by converting the numerator and denominator to the appropriate integer type. The second method does the same conversion for integers by taking the denominator to be 1. The third method implements a standard algorithm for approximating a floating-point number by a ratio of integers to within a given tolerance, and the fourth method applies it, using machine epsilon at the given value as the threshold. In general, one should have a//b == convert(Rational{Int64}, a/b).The last two convert methods provide conversions from rational types to floating-point and integer types. To convert to floating point, one simply converts both numerator and denominator to that floating point type and then divides. To convert to integer, one can use the div operator for truncated integer division (rounded towards zero)."
},

{
    "location": "manual/conversion-and-promotion/#Promotion-1",
    "page": "Conversion and Promotion",
    "title": "Promotion",
    "category": "section",
    "text": "Promotion refers to converting values of mixed types to a single common type. Although it is not strictly necessary, it is generally implied that the common type to which the values are converted can faithfully represent all of the original values. In this sense, the term \"promotion\" is appropriate since the values are converted to a \"greater\" type – i.e. one which can represent all of the input values in a single common type. It is important, however, not to confuse this with object-oriented (structural) super-typing, or Julia\'s notion of abstract super-types: promotion has nothing to do with the type hierarchy, and everything to do with converting between alternate representations. For instance, although every Int32 value can also be represented as a Float64 value, Int32 is not a subtype of Float64.Promotion to a common \"greater\" type is performed in Julia by the promote function, which takes any number of arguments, and returns a tuple of the same number of values, converted to a common type, or throws an exception if promotion is not possible. The most common use case for promotion is to convert numeric arguments to a common type:julia> promote(1, 2.5)\n(1.0, 2.5)\n\njulia> promote(1, 2.5, 3)\n(1.0, 2.5, 3.0)\n\njulia> promote(2, 3//4)\n(2//1, 3//4)\n\njulia> promote(1, 2.5, 3, 3//4)\n(1.0, 2.5, 3.0, 0.75)\n\njulia> promote(1.5, im)\n(1.5 + 0.0im, 0.0 + 1.0im)\n\njulia> promote(1 + 2im, 3//4)\n(1//1 + 2//1*im, 3//4 + 0//1*im)Floating-point values are promoted to the largest of the floating-point argument types. Integer values are promoted to the larger of either the native machine word size or the largest integer argument type. Mixtures of integers and floating-point values are promoted to a floating-point type big enough to hold all the values. Integers mixed with rationals are promoted to rationals. Rationals mixed with floats are promoted to floats. Complex values mixed with real values are promoted to the appropriate kind of complex value.That is really all there is to using promotions. The rest is just a matter of clever application, the most typical \"clever\" application being the definition of catch-all methods for numeric operations like the arithmetic operators +, -, * and /. Here are some of the catch-all method definitions given in promotion.jl:+(x::Number, y::Number) = +(promote(x,y)...)\n-(x::Number, y::Number) = -(promote(x,y)...)\n*(x::Number, y::Number) = *(promote(x,y)...)\n/(x::Number, y::Number) = /(promote(x,y)...)These method definitions say that in the absence of more specific rules for adding, subtracting, multiplying and dividing pairs of numeric values, promote the values to a common type and then try again. That\'s all there is to it: nowhere else does one ever need to worry about promotion to a common numeric type for arithmetic operations – it just happens automatically. There are definitions of catch-all promotion methods for a number of other arithmetic and mathematical functions in promotion.jl, but beyond that, there are hardly any calls to promote required in the Julia standard library. The most common usages of promote occur in outer constructors methods, provided for convenience, to allow constructor calls with mixed types to delegate to an inner type with fields promoted to an appropriate common type. For example, recall that rational.jl provides the following outer constructor method:Rational(n::Integer, d::Integer) = Rational(promote(n,d)...)This allows calls like the following to work:julia> Rational(Int8(15),Int32(-5))\n-3//1\n\njulia> typeof(ans)\nRational{Int32}For most user-defined types, it is better practice to require programmers to supply the expected types to constructor functions explicitly, but sometimes, especially for numeric problems, it can be convenient to do promotion automatically."
},

{
    "location": "manual/conversion-and-promotion/#Defining-Promotion-Rules-1",
    "page": "Conversion and Promotion",
    "title": "Defining Promotion Rules",
    "category": "section",
    "text": "Although one could, in principle, define methods for the promote function directly, this would require many redundant definitions for all possible permutations of argument types. Instead, the behavior of promote is defined in terms of an auxiliary function called promote_rule, which one can provide methods for. The promote_rule function takes a pair of type objects and returns another type object, such that instances of the argument types will be promoted to the returned type. Thus, by defining the rule:promote_rule(::Type{Float64}, ::Type{Float32}) = Float64one declares that when 64-bit and 32-bit floating-point values are promoted together, they should be promoted to 64-bit floating-point. The promotion type does not need to be one of the argument types, however; the following promotion rules both occur in Julia\'s standard library:promote_rule(::Type{UInt8}, ::Type{Int8}) = Int\npromote_rule(::Type{BigInt}, ::Type{Int8}) = BigIntIn the latter case, the result type is BigInt since BigInt is the only type large enough to hold integers for arbitrary-precision integer arithmetic. Also note that one does not need to define both promote_rule(::Type{A}, ::Type{B}) and promote_rule(::Type{B}, ::Type{A}) – the symmetry is implied by the way promote_rule is used in the promotion process.The promote_rule function is used as a building block to define a second function called promote_type, which, given any number of type objects, returns the common type to which those values, as arguments to promote should be promoted. Thus, if one wants to know, in absence of actual values, what type a collection of values of certain types would promote to, one can use promote_type:julia> promote_type(Int8, UInt16)\nInt64Internally, promote_type is used inside of promote to determine what type argument values should be converted to for promotion. It can, however, be useful in its own right. The curious reader can read the code in promotion.jl, which defines the complete promotion mechanism in about 35 lines."
},

{
    "location": "manual/conversion-and-promotion/#Case-Study:-Rational-Promotions-1",
    "page": "Conversion and Promotion",
    "title": "Case Study: Rational Promotions",
    "category": "section",
    "text": "Finally, we finish off our ongoing case study of Julia\'s rational number type, which makes relatively sophisticated use of the promotion mechanism with the following promotion rules:promote_rule(::Type{Rational{T}}, ::Type{S}) where {T<:Integer,S<:Integer} = Rational{promote_type(T,S)}\npromote_rule(::Type{Rational{T}}, ::Type{Rational{S}}) where {T<:Integer,S<:Integer} = Rational{promote_type(T,S)}\npromote_rule(::Type{Rational{T}}, ::Type{S}) where {T<:Integer,S<:AbstractFloat} = promote_type(T,S)The first rule says that promoting a rational number with any other integer type promotes to a rational type whose numerator/denominator type is the result of promotion of its numerator/denominator type with the other integer type. The second rule applies the same logic to two different types of rational numbers, resulting in a rational of the promotion of their respective numerator/denominator types. The third and final rule dictates that promoting a rational with a float results in the same type as promoting the numerator/denominator type with the float.This small handful of promotion rules, together with the conversion methods discussed above, are sufficient to make rational numbers interoperate completely naturally with all of Julia\'s other numeric types – integers, floating-point numbers, and complex numbers. By providing appropriate conversion methods and promotion rules in the same manner, any user-defined numeric type can interoperate just as naturally with Julia\'s predefined numerics."
},

{
    "location": "manual/interfaces/#",
    "page": "Interfaces",
    "title": "Interfaces",
    "category": "page",
    "text": ""
},

{
    "location": "manual/interfaces/#Interfaces-1",
    "page": "Interfaces",
    "title": "Interfaces",
    "category": "section",
    "text": "A lot of the power and extensibility in Julia comes from a collection of informal interfaces.  By extending a few specific methods to work for a custom type, objects of that type not only receive those functionalities, but they are also able to be used in other methods that are written to generically build upon those behaviors."
},

{
    "location": "manual/interfaces/#man-interface-iteration-1",
    "page": "Interfaces",
    "title": "Iteration",
    "category": "section",
    "text": "Required methods   Brief description\nstart(iter)   Returns the initial iteration state\nnext(iter, state)   Returns the current item and the next state\ndone(iter, state)   Tests if there are any items remaining\nImportant optional methods Default definition Brief description\niteratorsize(IterType) HasLength() One of HasLength(), HasShape(), IsInfinite(), or SizeUnknown() as appropriate\niteratoreltype(IterType) HasEltype() Either EltypeUnknown() or HasEltype() as appropriate\neltype(IterType) Any The type the items returned by next()\nlength(iter) (undefined) The number of items, if known\nsize(iter, [dim...]) (undefined) The number of items in each dimension, if knownValue returned by iteratorsize(IterType) Required Methods\nHasLength() length(iter)\nHasShape() length(iter)  and size(iter, [dim...])\nIsInfinite() (none)\nSizeUnknown() (none)Value returned by iteratoreltype(IterType) Required Methods\nHasEltype() eltype(IterType)\nEltypeUnknown() (none)Sequential iteration is implemented by the methods start(), done(), and next(). Instead of mutating objects as they are iterated over, Julia provides these three methods to keep track of the iteration state externally from the object. The start(iter) method returns the initial state for the iterable object iter. That state gets passed along to done(iter, state), which tests if there are any elements remaining, and next(iter, state), which returns a tuple containing the current element and an updated state. The state object can be anything, and is generally considered to be an implementation detail private to the iterable object.Any object defines these three methods is iterable and can be used in the many functions that rely upon iteration. It can also be used directly in a for loop since the syntax:for i in iter   # or  \"for i = iter\"\n    # body\nendis translated into:state = start(iter)\nwhile !done(iter, state)\n    (i, state) = next(iter, state)\n    # body\nendA simple example is an iterable sequence of square numbers with a defined length:julia> struct Squares\n           count::Int\n       end\n\njulia> Base.start(::Squares) = 1\n\njulia> Base.next(S::Squares, state) = (state*state, state+1)\n\njulia> Base.done(S::Squares, state) = state > S.count\n\njulia> Base.eltype(::Type{Squares}) = Int # Note that this is defined for the type\n\njulia> Base.length(S::Squares) = S.countWith only start, next, and done definitions, the Squares type is already pretty powerful. We can iterate over all the elements:julia> for i in Squares(7)\n           println(i)\n       end\n1\n4\n9\n16\n25\n36\n49We can use many of the builtin methods that work with iterables, like in(), mean() and std():julia> 25 in Squares(10)\ntrue\n\njulia> mean(Squares(100))\n3383.5\n\njulia> std(Squares(100))\n3024.355854282583There are a few more methods we can extend to give Julia more information about this iterable collection.  We know that the elements in a Squares sequence will always be Int. By extending the eltype() method, we can give that information to Julia and help it make more specialized code in the more complicated methods. We also know the number of elements in our sequence, so we can extend length(), too.Now, when we ask Julia to collect() all the elements into an array it can preallocate a Vector{Int} of the right size instead of blindly push!ing each element into a Vector{Any}:julia> collect(Squares(10))\' # transposed to save space\n1×10 RowVector{Int64,Array{Int64,1}}:\n 1  4  9  16  25  36  49  64  81  100While we can rely upon generic implementations, we can also extend specific methods where we know there is a simpler algorithm. For example, there\'s a formula to compute the sum of squares, so we can override the generic iterative version with a more performant solution:julia> Base.sum(S::Squares) = (n = S.count; return n*(n+1)*(2n+1)÷6)\n\njulia> sum(Squares(1803))\n1955361914This is a very common pattern throughout the Julia standard library: a small set of required methods define an informal interface that enable many fancier behaviors. In some cases, types will want to additionally specialize those extra behaviors when they know a more efficient algorithm can be used in their specific case."
},

{
    "location": "manual/interfaces/#Indexing-1",
    "page": "Interfaces",
    "title": "Indexing",
    "category": "section",
    "text": "Methods to implement Brief description\ngetindex(X, i) X[i], indexed element access\nsetindex!(X, v, i) X[i] = v, indexed assignment\nendof(X) The last index, used in X[end]For the Squares iterable above, we can easily compute the ith element of the sequence by squaring it.  We can expose this as an indexing expression S[i]. To opt into this behavior, Squares simply needs to define getindex():julia> function Base.getindex(S::Squares, i::Int)\n           1 <= i <= S.count || throw(BoundsError(S, i))\n           return i*i\n       end\n\njulia> Squares(100)[23]\n529Additionally, to support the syntax S[end], we must define endof() to specify the last valid index:julia> Base.endof(S::Squares) = length(S)\n\njulia> Squares(23)[end]\n529Note, though, that the above only defines getindex() with one integer index. Indexing with anything other than an Int will throw a MethodError saying that there was no matching method. In order to support indexing with ranges or vectors of Ints, separate methods must be written:julia> Base.getindex(S::Squares, i::Number) = S[convert(Int, i)]\n\njulia> Base.getindex(S::Squares, I) = [S[i] for i in I]\n\njulia> Squares(10)[[3,4.,5]]\n3-element Array{Int64,1}:\n  9\n 16\n 25While this is starting to support more of the indexing operations supported by some of the builtin types, there\'s still quite a number of behaviors missing. This Squares sequence is starting to look more and more like a vector as we\'ve added behaviors to it. Instead of defining all these behaviors ourselves, we can officially define it as a subtype of an AbstractArray."
},

{
    "location": "manual/interfaces/#man-interface-array-1",
    "page": "Interfaces",
    "title": "Abstract Arrays",
    "category": "section",
    "text": "Methods to implement   Brief description\nsize(A)   Returns a tuple containing the dimensions of A\ngetindex(A, i::Int)   (if IndexLinear) Linear scalar indexing\ngetindex(A, I::Vararg{Int, N})   (if IndexCartesian, where N = ndims(A)) N-dimensional scalar indexing\nsetindex!(A, v, i::Int)   (if IndexLinear) Scalar indexed assignment\nsetindex!(A, v, I::Vararg{Int, N})   (if IndexCartesian, where N = ndims(A)) N-dimensional scalar indexed assignment\nOptional methods Default definition Brief description\nIndexStyle(::Type) IndexCartesian() Returns either IndexLinear() or IndexCartesian(). See the description below.\ngetindex(A, I...) defined in terms of scalar getindex() Multidimensional and nonscalar indexing\nsetindex!(A, I...) defined in terms of scalar setindex!() Multidimensional and nonscalar indexed assignment\nstart()/next()/done() defined in terms of scalar getindex() Iteration\nlength(A) prod(size(A)) Number of elements\nsimilar(A) similar(A, eltype(A), size(A)) Return a mutable array with the same shape and element type\nsimilar(A, ::Type{S}) similar(A, S, size(A)) Return a mutable array with the same shape and the specified element type\nsimilar(A, dims::NTuple{Int}) similar(A, eltype(A), dims) Return a mutable array with the same element type and size dims\nsimilar(A, ::Type{S}, dims::NTuple{Int}) Array{S}(dims) Return a mutable array with the specified element type and size\nNon-traditional indices Default definition Brief description\nindices(A) map(OneTo, size(A)) Return the AbstractUnitRange of valid indices\nBase.similar(A, ::Type{S}, inds::NTuple{Ind}) similar(A, S, Base.to_shape(inds)) Return a mutable array with the specified indices inds (see below)\nBase.similar(T::Union{Type,Function}, inds) T(Base.to_shape(inds)) Return an array similar to T with the specified indices inds (see below)If a type is defined as a subtype of AbstractArray, it inherits a very large set of rich behaviors including iteration and multidimensional indexing built on top of single-element access.  See the arrays manual page and standard library section for more supported methods.A key part in defining an AbstractArray subtype is IndexStyle. Since indexing is such an important part of an array and often occurs in hot loops, it\'s important to make both indexing and indexed assignment as efficient as possible.  Array data structures are typically defined in one of two ways: either it most efficiently accesses its elements using just one index (linear indexing) or it intrinsically accesses the elements with indices specified for every dimension.  These two modalities are identified by Julia as IndexLinear() and IndexCartesian().  Converting a linear index to multiple indexing subscripts is typically very expensive, so this provides a traits-based mechanism to enable efficient generic code for all array types.This distinction determines which scalar indexing methods the type must define. IndexLinear() arrays are simple: just define getindex(A::ArrayType, i::Int).  When the array is subsequently indexed with a multidimensional set of indices, the fallback getindex(A::AbstractArray, I...)() efficiently converts the indices into one linear index and then calls the above method. IndexCartesian() arrays, on the other hand, require methods to be defined for each supported dimensionality with ndims(A) Int indices. For example, the built-in SparseMatrixCSC type only supports two dimensions, so it just defines getindex(A::SparseMatrixCSC, i::Int, j::Int). The same holds for setindex!().Returning to the sequence of squares from above, we could instead define it as a subtype of an AbstractArray{Int, 1}:julia> struct SquaresVector <: AbstractArray{Int, 1}\n           count::Int\n       end\n\njulia> Base.size(S::SquaresVector) = (S.count,)\n\njulia> Base.IndexStyle(::Type{<:SquaresVector}) = IndexLinear()\n\njulia> Base.getindex(S::SquaresVector, i::Int) = i*iNote that it\'s very important to specify the two parameters of the AbstractArray; the first defines the eltype(), and the second defines the ndims(). That supertype and those three methods are all it takes for SquaresVector to be an iterable, indexable, and completely functional array:julia> s = SquaresVector(7)\n7-element SquaresVector:\n  1\n  4\n  9\n 16\n 25\n 36\n 49\n\njulia> s[s .> 20]\n3-element Array{Int64,1}:\n 25\n 36\n 49\n\njulia> s \\ [1 2; 3 4; 5 6; 7 8; 9 10; 11 12; 13 14]\n1×2 Array{Float64,2}:\n 0.305389  0.335329\n\njulia> s ⋅ s # dot(s, s)\n4676As a more complicated example, let\'s define our own toy N-dimensional sparse-like array type built on top of Dict:julia> struct SparseArray{T,N} <: AbstractArray{T,N}\n           data::Dict{NTuple{N,Int}, T}\n           dims::NTuple{N,Int}\n       end\n\njulia> SparseArray{T}(::Type{T}, dims::Int...) = SparseArray(T, dims);\n\njulia> SparseArray{T,N}(::Type{T}, dims::NTuple{N,Int}) = SparseArray{T,N}(Dict{NTuple{N,Int}, T}(), dims);\n\njulia> Base.size(A::SparseArray) = A.dims\n\njulia> Base.similar(A::SparseArray, ::Type{T}, dims::Dims) where {T} = SparseArray(T, dims)\n\njulia> Base.getindex(A::SparseArray{T,N}, I::Vararg{Int,N}) where {T,N} = get(A.data, I, zero(T))\n\njulia> Base.setindex!(A::SparseArray{T,N}, v, I::Vararg{Int,N}) where {T,N} = (A.data[I] = v)Notice that this is an IndexCartesian array, so we must manually define getindex() and setindex!() at the dimensionality of the array. Unlike the SquaresVector, we are able to define setindex!(), and so we can mutate the array:julia> A = SparseArray(Float64, 3, 3)\n3×3 SparseArray{Float64,2}:\n 0.0  0.0  0.0\n 0.0  0.0  0.0\n 0.0  0.0  0.0\n\njulia> fill!(A, 2)\n3×3 SparseArray{Float64,2}:\n 2.0  2.0  2.0\n 2.0  2.0  2.0\n 2.0  2.0  2.0\n\njulia> A[:] = 1:length(A); A\n3×3 SparseArray{Float64,2}:\n 1.0  4.0  7.0\n 2.0  5.0  8.0\n 3.0  6.0  9.0The result of indexing an AbstractArray can itself be an array (for instance when indexing by a Range). The AbstractArray fallback methods use similar() to allocate an Array of the appropriate size and element type, which is filled in using the basic indexing method described above. However, when implementing an array wrapper you often want the result to be wrapped as well:julia> A[1:2,:]\n2×3 SparseArray{Float64,2}:\n 1.0  4.0  7.0\n 2.0  5.0  8.0In this example it is accomplished by defining Base.similar{T}(A::SparseArray, ::Type{T}, dims::Dims) to create the appropriate wrapped array. (Note that while similar supports 1- and 2-argument forms, in most case you only need to specialize the 3-argument form.) For this to work it\'s important that SparseArray is mutable (supports setindex!). Defining similar(), getindex() and setindex!() for SparseArray also makes it possible to copy() the array:julia> copy(A)\n3×3 SparseArray{Float64,2}:\n 1.0  4.0  7.0\n 2.0  5.0  8.0\n 3.0  6.0  9.0In addition to all the iterable and indexable methods from above, these types can also interact with each other and use most of the methods defined in the standard library for AbstractArrays:julia> A[SquaresVector(3)]\n3-element SparseArray{Float64,1}:\n 1.0\n 4.0\n 9.0\n\njulia> dot(A[:,1],A[:,2])\n32.0If you are defining an array type that allows non-traditional indexing (indices that start at something other than 1), you should specialize indices. You should also specialize similar so that the dims argument (ordinarily a Dims size-tuple) can accept AbstractUnitRange objects, perhaps range-types Ind of your own design. For more information, see Arrays with custom indices."
},

{
    "location": "manual/modules/#",
    "page": "Modules",
    "title": "Modules",
    "category": "page",
    "text": ""
},

{
    "location": "manual/modules/#modules-1",
    "page": "Modules",
    "title": "Modules",
    "category": "section",
    "text": "Modules in Julia are separate variable workspaces, i.e. they introduce a new global scope. They are delimited syntactically, inside module Name ... end. Modules allow you to create top-level definitions (aka global variables) without worrying about name conflicts when your code is used together with somebody else\'s. Within a module, you can control which names from other modules are visible (via importing), and specify which of your names are intended to be public (via exporting).The following example demonstrates the major features of modules. It is not meant to be run, but is shown for illustrative purposes:module MyModule\nusing Lib\n\nusing BigLib: thing1, thing2\n\nimport Base.show\n\nimportall OtherLib\n\nexport MyType, foo\n\nstruct MyType\n    x\nend\n\nbar(x) = 2x\nfoo(a::MyType) = bar(a.x) + 1\n\nshow(io::IO, a::MyType) = print(io, \"MyType $(a.x)\")\nendNote that the style is not to indent the body of the module, since that would typically lead to whole files being indented.This module defines a type MyType, and two functions. Function foo and type MyType are exported, and so will be available for importing into other modules.  Function bar is private to MyModule.The statement using Lib means that a module called Lib will be available for resolving names as needed. When a global variable is encountered that has no definition in the current module, the system will search for it among variables exported by Lib and import it if it is found there. This means that all uses of that global within the current module will resolve to the definition of that variable in Lib.The statement using BigLib: thing1, thing2 is a syntactic shortcut for using BigLib.thing1, BigLib.thing2.The import keyword supports all the same syntax as using, but only operates on a single name at a time. It does not add modules to be searched the way using does. import also differs from using in that functions must be imported using import to be extended with new methods.In MyModule above we wanted to add a method to the standard show function, so we had to write import Base.show. Functions whose names are only visible via using cannot be extended.The keyword importall explicitly imports all names exported by the specified module, as if import were individually used on all of them.Once a variable is made visible via using or import, a module may not create its own variable with the same name. Imported variables are read-only; assigning to a global variable always affects a variable owned by the current module, or else raises an error."
},

{
    "location": "manual/modules/#Summary-of-module-usage-1",
    "page": "Modules",
    "title": "Summary of module usage",
    "category": "section",
    "text": "To load a module, two main keywords can be used: using and import. To understand their differences, consider the following example:module MyModule\n\nexport x, y\n\nx() = \"x\"\ny() = \"y\"\np() = \"p\"\n\nendIn this module we export the x and y functions (with the keyword export), and also have the non-exported function p. There are several different ways to load the Module and its inner functions into the current workspace:Import Command What is brought into scope Available for method extension\nusing MyModule All exported names (x and y), MyModule.x, MyModule.y and MyModule.p MyModule.x, MyModule.y and MyModule.p\nusing MyModule.x, MyModule.p x and p  \nusing MyModule: x, p x and p  \nimport MyModule MyModule.x, MyModule.y and MyModule.p MyModule.x, MyModule.y and MyModule.p\nimport MyModule.x, MyModule.p x and p x and p\nimport MyModule: x, p x and p x and p\nimportall MyModule All exported names (x and y) x and y"
},

{
    "location": "manual/modules/#Modules-and-files-1",
    "page": "Modules",
    "title": "Modules and files",
    "category": "section",
    "text": "Files and file names are mostly unrelated to modules; modules are associated only with module expressions. One can have multiple files per module, and multiple modules per file:module Foo\n\ninclude(\"file1.jl\")\ninclude(\"file2.jl\")\n\nendIncluding the same code in different modules provides mixin-like behavior. One could use this to run the same code with different base definitions, for example testing code by running it with \"safe\" versions of some operators:module Normal\ninclude(\"mycode.jl\")\nend\n\nmodule Testing\ninclude(\"safe_operators.jl\")\ninclude(\"mycode.jl\")\nend"
},

{
    "location": "manual/modules/#Standard-modules-1",
    "page": "Modules",
    "title": "Standard modules",
    "category": "section",
    "text": "There are three important standard modules: Main, Core, and Base.Main is the top-level module, and Julia starts with Main set as the current module.  Variables defined at the prompt go in Main, and whos() lists variables in Main.Core contains all identifiers considered \"built in\" to the language, i.e. part of the core language and not libraries. Every module implicitly specifies using Core, since you can\'t do anything without those definitions.Base is the standard library (the contents of base/). All modules implicitly contain using Base, since this is needed in the vast majority of cases."
},

{
    "location": "manual/modules/#Default-top-level-definitions-and-bare-modules-1",
    "page": "Modules",
    "title": "Default top-level definitions and bare modules",
    "category": "section",
    "text": "In addition to using Base, modules also automatically contain a definition of the eval function, which evaluates expressions within the context of that module.If these default definitions are not wanted, modules can be defined using the keyword baremodule instead (note: Core is still imported, as per above). In terms of baremodule, a standard module looks like this:baremodule Mod\n\nusing Base\n\neval(x) = Core.eval(Mod, x)\neval(m,x) = Core.eval(m, x)\n\n...\n\nend"
},

{
    "location": "manual/modules/#Relative-and-absolute-module-paths-1",
    "page": "Modules",
    "title": "Relative and absolute module paths",
    "category": "section",
    "text": "Given the statement using Foo, the system looks for Foo within Main. If the module does not exist, the system attempts to require(\"Foo\"), which typically results in loading code from an installed package.However, some modules contain submodules, which means you sometimes need to access a module that is not directly available in Main. There are two ways to do this. The first is to use an absolute path, for example using Base.Sort. The second is to use a relative path, which makes it easier to import submodules of the current module or any of its enclosing modules:module Parent\n\nmodule Utils\n...\nend\n\nusing .Utils\n\n...\nendHere module Parent contains a submodule Utils, and code in Parent wants the contents of Utils to be visible. This is done by starting the using path with a period. Adding more leading periods moves up additional levels in the module hierarchy. For example using ..Utils would look for Utils in Parent\'s enclosing module rather than in Parent itself.Note that relative-import qualifiers are only valid in using and import statements."
},

{
    "location": "manual/modules/#Module-file-paths-1",
    "page": "Modules",
    "title": "Module file paths",
    "category": "section",
    "text": "The global variable LOAD_PATH contains the directories Julia searches for modules when calling require. It can be extended using push!:push!(LOAD_PATH, \"/Path/To/My/Module/\")Putting this statement in the file ~/.juliarc.jl will extend LOAD_PATH on every Julia startup. Alternatively, the module load path can be extended by defining the environment variable JULIA_LOAD_PATH."
},

{
    "location": "manual/modules/#Namespace-miscellanea-1",
    "page": "Modules",
    "title": "Namespace miscellanea",
    "category": "section",
    "text": "If a name is qualified (e.g. Base.sin), then it can be accessed even if it is not exported. This is often useful when debugging. It can also have methods added to it by using the qualified name as the function name. However, due to syntactic ambiguities that arise, if you wish to add methods to a function in a different module whose name contains only symbols, such as an operator, Base.+ for example, you must use Base.:+ to refer to it. If the operator is more than one character in length you must surround it in brackets, such as: Base.:(==).Macro names are written with @ in import and export statements, e.g. import Mod.@mac. Macros in other modules can be invoked as Mod.@mac or @Mod.mac.The syntax M.x = y does not work to assign a global in another module; global assignment is always module-local.A variable can be \"reserved\" for the current module without assigning to it by declaring it as global x at the top level. This can be used to prevent name conflicts for globals initialized after load time."
},

{
    "location": "manual/modules/#Module-initialization-and-precompilation-1",
    "page": "Modules",
    "title": "Module initialization and precompilation",
    "category": "section",
    "text": "Large modules can take several seconds to load because executing all of the statements in a module often involves compiling a large amount of code. Julia provides the ability to create precompiled versions of modules to reduce this time.To create an incremental precompiled module file, add __precompile__() at the top of your module file (before the module starts). This will cause it to be automatically compiled the first time it is imported. Alternatively, you can manually call Base.compilecache(modulename). The resulting cache files will be stored in Base.LOAD_CACHE_PATH[1]. Subsequently, the module is automatically recompiled upon import whenever any of its dependencies change; dependencies are modules it imports, the Julia build, files it includes, or explicit dependencies declared by include_dependency(path) in the module file(s).For file dependencies, a change is determined by examining whether the modification time (mtime) of each file loaded by include or added explicitly by include_dependency is unchanged, or equal to the modification time truncated to the nearest second (to accommodate systems that can\'t copy mtime with sub-second accuracy). It also takes into account whether the path to the file chosen by the search logic in require matches the path that had created the precompile file.It also takes into account the set of dependencies already loaded into the current process and won\'t recompile those modules, even if their files change or disappear, in order to avoid creating incompatibilities between the running system and the precompile cache. If you want to have changes to the source reflected in the running system, you should call reload(\"Module\") on the module you changed, and any module that depended on it in which you want to see the change reflected.Precompiling a module also recursively precompiles any modules that are imported therein. If you know that it is not safe to precompile your module (for the reasons described below), you should put __precompile__(false) in the module file to cause Base.compilecache to throw an error (and thereby prevent the module from being imported by any other precompiled module).__precompile__() should not be used in a module unless all of its dependencies are also using __precompile__(). Failure to do so can result in a runtime error when loading the module.In order to make your module work with precompilation, however, you may need to change your module to explicitly separate any initialization steps that must occur at runtime from steps that can occur at compile time.  For this purpose, Julia allows you to define an __init__() function in your module that executes any initialization steps that must occur at runtime. This function will not be called during compilation (--output-* or __precompile__()). You may, of course, call it manually if necessary, but the default is to assume this function deals with computing state for the local machine, which does not need to be – or even should not be – captured in the compiled image. It will be called after the module is loaded into a process, including if it is being loaded into an incremental compile (--output-incremental=yes), but not if it is being loaded into a full-compilation process.In particular, if you define a function __init__() in a module, then Julia will call __init__() immediately after the module is loaded (e.g., by import, using, or require) at runtime for the first time (i.e., __init__ is only called once, and only after all statements in the module have been executed). Because it is called after the module is fully imported, any submodules or other imported modules have their __init__ functions called before the __init__ of the enclosing module.Two typical uses of __init__ are calling runtime initialization functions of external C libraries and initializing global constants that involve pointers returned by external libraries.  For example, suppose that we are calling a C library libfoo that requires us to call a foo_init() initialization function at runtime. Suppose that we also want to define a global constant foo_data_ptr that holds the return value of a void *foo_data() function defined by libfoo – this constant must be initialized at runtime (not at compile time) because the pointer address will change from run to run.  You could accomplish this by defining the following __init__ function in your module:const foo_data_ptr = Ref{Ptr{Void}}(0)\nfunction __init__()\n    ccall((:foo_init, :libfoo), Void, ())\n    foo_data_ptr[] = ccall((:foo_data, :libfoo), Ptr{Void}, ())\nendNotice that it is perfectly possible to define a global inside a function like __init__; this is one of the advantages of using a dynamic language. But by making it a constant at global scope, we can ensure that the type is known to the compiler and allow it to generate better optimized code. Obviously, any other globals in your module that depends on foo_data_ptr would also have to be initialized in __init__.Constants involving most Julia objects that are not produced by ccall do not need to be placed in __init__: their definitions can be precompiled and loaded from the cached module image. This includes complicated heap-allocated objects like arrays. However, any routine that returns a raw pointer value must be called at runtime for precompilation to work (Ptr objects will turn into null pointers unless they are hidden inside an isbits object). This includes the return values of the Julia functions cfunction and pointer.Dictionary and set types, or in general anything that depends on the output of a hash(key) method, are a trickier case.  In the common case where the keys are numbers, strings, symbols, ranges, Expr, or compositions of these types (via arrays, tuples, sets, pairs, etc.) they are safe to precompile.  However, for a few other key types, such as Function or DataType and generic user-defined types where you haven\'t defined a hash method, the fallback hash method depends on the memory address of the object (via its object_id) and hence may change from run to run. If you have one of these key types, or if you aren\'t sure, to be safe you can initialize this dictionary from within your __init__ function. Alternatively, you can use the ObjectIdDict dictionary type, which is specially handled by precompilation so that it is safe to initialize at compile-time.When using precompilation, it is important to keep a clear sense of the distinction between the compilation phase and the execution phase. In this mode, it will often be much more clearly apparent that Julia is a compiler which allows execution of arbitrary Julia code, not a standalone interpreter that also generates compiled code.Other known potential failure scenarios include:Global counters (for example, for attempting to uniquely identify objects) Consider the following code snippet:\nmutable struct UniquedById\n    myid::Int\n    let counter = 0\n        UniquedById() = new(counter += 1)\n    end\nend\nwhile the intent of this code was to give every instance a unique id, the counter value is recorded at the end of compilation. All subsequent usages of this incrementally compiled module will start from that same counter value.\nNote that object_id (which works by hashing the memory pointer) has similar issues (see notes on Dict usage below).\nOne alternative is to store both current_module() and the current counter value, however, it may be better to redesign the code to not depend on this global state.\nAssociative collections (such as Dict and Set) need to be re-hashed in __init__. (In the future, a mechanism may be provided to register an initializer function.)\nDepending on compile-time side-effects persisting through load-time. Example include: modifying arrays or other variables in other Julia modules; maintaining handles to open files or devices; storing pointers to other system resources (including memory);\nCreating accidental \"copies\" of global state from another module, by referencing it directly instead of via its lookup path. For example, (in global scope):\n#mystdout = Base.STDOUT #= will not work correctly, since this will copy Base.STDOUT into this module =#\n# instead use accessor functions:\ngetstdout() = Base.STDOUT #= best option =#\n# or move the assignment into the runtime:\n__init__() = global mystdout = Base.STDOUT #= also works =#Several additional restrictions are placed on the operations that can be done while precompiling code to help the user avoid other wrong-behavior situations:Calling eval to cause a side-effect in another module. This will also cause a warning to be emitted when the incremental precompile flag is set.\nglobal const statements from local scope after __init__() has been started (see issue #12010 for plans to add an error for this)\nReplacing a module (or calling workspace()) is a runtime error while doing an incremental precompile.A few other points to be aware of:No code reload / cache invalidation is performed after changes are made to the source files themselves, (including by Pkg.update), and no cleanup is done after Pkg.rm\nThe memory sharing behavior of a reshaped array is disregarded by precompilation (each view gets its own copy)\nExpecting the filesystem to be unchanged between compile-time and runtime e.g. @__FILE__/source_path() to find resources at runtime, or the BinDeps @checked_lib macro. Sometimes this is unavoidable. However, when possible, it can be good practice to copy resources into the module at compile-time so they won\'t need to be found at runtime.\nWeakRef objects and finalizers are not currently handled properly by the serializer (this will be fixed in an upcoming release).\nIt is usually best to avoid capturing references to instances of internal metadata objects such as Method, MethodInstance, MethodTable, TypeMapLevel, TypeMapEntry and fields of those objects, as this can confuse the serializer and may not lead to the outcome you desire. It is not necessarily an error to do this, but you simply need to be prepared that the system will try to copy some of these and to create a single unique instance of others.It is sometimes helpful during module development to turn off incremental precompilation. The command line flag --compilecache={yes|no} enables you to toggle module precompilation on and off. When Julia is started with --compilecache=no the serialized modules in the compile cache are ignored when loading modules and module dependencies. Base.compilecache() can still be called manually and it will respect __precompile__() directives for the module. The state of this command line flag is passed to Pkg.build() to disable automatic precompilation triggering when installing, updating, and explicitly building packages."
},

{
    "location": "manual/documentation/#",
    "page": "Documentation",
    "title": "Documentation",
    "category": "page",
    "text": ""
},

{
    "location": "manual/documentation/#Documentation-1",
    "page": "Documentation",
    "title": "Documentation",
    "category": "section",
    "text": "Julia enables package developers and users to document functions, types and other objects easily via a built-in documentation system since Julia 0.4.The basic syntax is very simple: any string appearing at the top-level right before an object (function, macro, type or instance) will be interpreted as documenting it (these are called docstrings). Here is a very simple example:\"Tell whether there are too foo items in the array.\"\nfoo(xs::Array) = ...Documentation is interpreted as Markdown, so you can use indentation and code fences to delimit code examples from text. Technically, any object can be associated with any other as metadata; Markdown happens to be the default, but one can construct other string macros and pass them to the @doc macro just as well.Here is a more complex example, still using Markdown:\"\"\"\n    bar(x[, y])\n\nCompute the Bar index between `x` and `y`. If `y` is missing, compute\nthe Bar index between all pairs of columns of `x`.\n\n# Examples\n```julia-repl\njulia> bar([1, 2], [1, 2])\n1\n```\n\"\"\"\nfunction bar(x, y) ...As in the example above, we recommend following some simple conventions when writing documentation:Always show the signature of a function at the top of the documentation, with a four-space indent so that it is printed as Julia code.\nThis can be identical to the signature present in the Julia code (like mean(x::AbstractArray)), or a simplified form. Optional arguments should be represented with their default values (i.e. f(x, y=1)) when possible, following the actual Julia syntax. Optional arguments which do not have a default value should be put in brackets (i.e. f(x[, y]) and f(x[, y[, z]])). An alternative solution is to use several lines: one without optional arguments, the other(s) with them. This solution can also be used to document several related methods of a given function. When a function accepts many keyword arguments, only include a <keyword arguments> placeholder in the signature (i.e. f(x; <keyword arguments>)), and give the complete list under an # Arguments section (see point 4 below).\nInclude a single one-line sentence describing what the function does or what the object represents after the simplified signature block. If needed, provide more details in a second paragraph, after a blank line.\nThe one-line sentence should use the imperative form (\"Do this\", \"Return that\") instead of the third person (do not write \"Returns the length...\") when documenting functions. It should end with a period. If the meaning of a function cannot be summarized easily, splitting it into separate composable parts could be beneficial (this should not be taken as an absolute requirement for every single case though).\nDo not repeat yourself.\nSince the function name is given by the signature, there is no need to start the documentation with \"The function bar...\": go straight to the point. Similarly, if the signature specifies the types of the arguments, mentioning them in the description is redundant.\nOnly provide an argument list when really necessary.\nFor simple functions, it is often clearer to mention the role of the arguments directly in the description of the function\'s purpose. An argument list would only repeat information already provided elsewhere. However, providing an argument list can be a good idea for complex functions with many arguments (in particular keyword arguments). In that case, insert it after the general description of the function, under an # Arguments header, with one - bullet for each argument. The list should mention the types and default values (if any) of the arguments:\n\"\"\"\n...\n# Arguments\n- `n::Integer`: the number of elements to compute.\n- `dim::Integer=1`: the dimensions along which to perform the computation.\n...\n\"\"\"\nInclude any code examples in an # Examples section.\nExamples should, whenever possible, be written as doctests. A doctest is a fenced code block (see Code blocks) starting with ```jldoctest and contains any number of julia> prompts together with inputs and expected outputs that mimic the Julia REPL.\nFor example in the following docstring a variable a is defined and the expected result, as printed in a Julia REPL, appears afterwards:\n\"\"\"\nSome nice documentation here.\n\n# Examples\n\n```jldoctest\njulia> a = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n```\n\"\"\"\nwarning: Warning\nCalling rand and other RNG-related functions should be avoided in doctests since they will not produce consistent outputs during different Julia sessions.Operating system word size (Int32 or Int64) as well as path separator differences (/ or \\) will also affect the reproducibility of some doctests.Note that whitespace in your doctest is significant! The doctest will fail if you misalign the output of pretty-printing an array, for example.\nYou can then run make -C doc doctest to run all the doctests in the Julia Manual, which will ensure that your example works.\nExamples that are untestable should be written within fenced code blocks starting with ```julia so that they are highlighted correctly in the generated documentation.\ntip: Tip\nWherever possible examples should be self-contained and runnable so that readers are able to try them out without having to include any dependencies.\nUse backticks to identify code and equations.\nJulia identifiers and code excerpts should always appear between backticks ` to enable highlighting. Equations in the LaTeX syntax can be inserted between double backticks ``. Use Unicode characters rather than their LaTeX escape sequence, i.e. ``α = 1`` rather than ``\\\\alpha = 1``.\nPlace the starting and ending \"\"\" characters on lines by themselves.\nThat is, write:\n\"\"\"\n...\n\n...\n\"\"\"\nf(x, y) = ...\nrather than:\n\"\"\"...\n\n...\"\"\"\nf(x, y) = ...\nThis makes it more clear where docstrings start and end.\nRespect the line length limit used in the surrounding code.\nDocstrings are edited using the same tools as code. Therefore, the same conventions should apply. It it advised to add line breaks after 92 characters."
},

{
    "location": "manual/documentation/#Accessing-Documentation-1",
    "page": "Documentation",
    "title": "Accessing Documentation",
    "category": "section",
    "text": "Documentation can be accessed at the REPL or in IJulia by typing ? followed by the name of a function or macro, and pressing Enter. For example,?fft\n?@time\n?r\"\"will bring up docs for the relevant function, macro or string macro respectively. In Juno using Ctrl-J, Ctrl-D will bring up documentation for the object under the cursor."
},

{
    "location": "manual/documentation/#Functions-and-Methods-1",
    "page": "Documentation",
    "title": "Functions & Methods",
    "category": "section",
    "text": "Functions in Julia may have multiple implementations, known as methods. While it\'s good practice for generic functions to have a single purpose, Julia allows methods to be documented individually if necessary. In general, only the most generic method should be documented, or even the function itself (i.e. the object created without any methods by function bar end). Specific methods should only be documented if their behaviour differs from the more generic ones. In any case, they should not repeat the information provided elsewhere. For example:\"\"\"\n    *(x, y, z...)\n\nMultiplication operator. `x * y * z *...` calls this function with multiple\narguments, i.e. `*(x, y, z...)`.\n\"\"\"\nfunction *(x, y, z...)\n    # ... [implementation sold separately] ...\nend\n\n\"\"\"\n    *(x::AbstractString, y::AbstractString, z::AbstractString...)\n\nWhen applied to strings, concatenates them.\n\"\"\"\nfunction *(x::AbstractString, y::AbstractString, z::AbstractString...)\n    # ... [insert secret sauce here] ...\nend\n\nhelp?> *\nsearch: * .*\n\n  *(x, y, z...)\n\n  Multiplication operator. x * y * z *... calls this function with multiple\n  arguments, i.e. *(x,y,z...).\n\n  *(x::AbstractString, y::AbstractString, z::AbstractString...)\n\n  When applied to strings, concatenates them.When retrieving documentation for a generic function, the metadata for each method is concatenated with the catdoc function, which can of course be overridden for custom types."
},

{
    "location": "manual/documentation/#Advanced-Usage-1",
    "page": "Documentation",
    "title": "Advanced Usage",
    "category": "section",
    "text": "The @doc macro associates its first argument with its second in a per-module dictionary called META. By default, documentation is expected to be written in Markdown, and the doc\"\" string macro simply creates an object representing the Markdown content. In the future it is likely to do more advanced things such as allowing for relative image or link paths.When used for retrieving documentation, the @doc macro (or equally, the doc function) will search all META dictionaries for metadata relevant to the given object and return it. The returned object (some Markdown content, for example) will by default display itself intelligently. This design also makes it easy to use the doc system in a programmatic way; for example, to re-use documentation between different versions of a function:@doc \"...\" foo!\n@doc (@doc foo!) fooOr for use with Julia\'s metaprogramming functionality:for (f, op) in ((:add, :+), (:subtract, :-), (:multiply, :*), (:divide, :/))\n    @eval begin\n        $f(a,b) = $op(a,b)\n    end\nend\n@doc \"`add(a,b)` adds `a` and `b` together\" add\n@doc \"`subtract(a,b)` subtracts `b` from `a`\" subtractDocumentation written in non-toplevel blocks, such as begin, if, for, and let, is added to the documentation system as blocks are evaluated. For example:if VERSION > v\"0.5\"\n    \"...\"\n    f(x) = x\nendwill add documentation to f(x) when the condition is true. Note that even if f(x) goes out of scope at the end of the block, its documentation will remain."
},

{
    "location": "manual/documentation/#Dynamic-documentation-1",
    "page": "Documentation",
    "title": "Dynamic documentation",
    "category": "section",
    "text": "Sometimes the appropriate documentation for an instance of a type depends on the field values of that instance, rather than just on the type itself. In these cases, you can add a method to Docs.getdoc for your custom type that returns the documentation on a per-instance basis. For instance,struct MyType\n    value::String\nend\n\nDocs.getdoc(t::MyType) = \"Documentation for MyType with value $(t.value)\"\n\nx = MyType(\"x\")\ny = MyType(\"y\")?x will display \"Documentation for MyType with value x\" while ?y will display \"Documentation for MyType with value y\"."
},

{
    "location": "manual/documentation/#Syntax-Guide-1",
    "page": "Documentation",
    "title": "Syntax Guide",
    "category": "section",
    "text": "A comprehensive overview of all documentable Julia syntax.In the following examples \"...\" is used to illustrate an arbitrary docstring which may be one of the follow four variants and contain arbitrary text:\"...\"\n\ndoc\"...\"\n\n\"\"\"\n...\n\"\"\"\n\ndoc\"\"\"\n...\n\"\"\"@doc_str should only be used when the docstring contains $ or \\ characters that should not be parsed by Julia such as LaTeX syntax or Julia source code examples containing interpolation."
},

{
    "location": "manual/documentation/#Functions-and-Methods-2",
    "page": "Documentation",
    "title": "Functions and Methods",
    "category": "section",
    "text": "\"...\"\nfunction f end\n\n\"...\"\nfAdds docstring \"...\" to Functionf. The first version is the preferred syntax, however both are equivalent.\"...\"\nf(x) = x\n\n\"...\"\nfunction f(x)\n    x\nend\n\n\"...\"\nf(x)Adds docstring \"...\" to Methodf(::Any).\"...\"\nf(x, y = 1) = x + yAdds docstring \"...\" to two Methods, namely f(::Any) and f(::Any, ::Any)."
},

{
    "location": "manual/documentation/#Macros-1",
    "page": "Documentation",
    "title": "Macros",
    "category": "section",
    "text": "\"...\"\nmacro m(x) endAdds docstring \"...\" to the @m(::Any) macro definition.\"...\"\n:(@m)Adds docstring \"...\" to the macro named @m."
},

{
    "location": "manual/documentation/#Types-1",
    "page": "Documentation",
    "title": "Types",
    "category": "section",
    "text": "\"...\"\nabstract type T1 end\n\n\"...\"\nmutable struct T2\n    ...\nend\n\n\"...\"\nstruct T3\n    ...\nendAdds the docstring \"...\" to types T1, T2, and T3.\"...\"\nstruct T\n    \"x\"\n    x\n    \"y\"\n    y\nendAdds docstring \"...\" to type T, \"x\" to field T.x and \"y\" to field T.y. Also applicable to mutable struct types."
},

{
    "location": "manual/documentation/#Modules-1",
    "page": "Documentation",
    "title": "Modules",
    "category": "section",
    "text": "\"...\"\nmodule M end\n\nmodule M\n\n\"...\"\nM\n\nendAdds docstring \"...\" to the ModuleM. Adding the docstring above the Module is the preferred syntax, however both are equivalent.\"...\"\nbaremodule M\n# ...\nend\n\nbaremodule M\n\nimport Base: @doc\n\n\"...\"\nf(x) = x\n\nendDocumenting a baremodule by placing a docstring above the expression automatically imports @doc into the module. These imports must be done manually when the module expression is not documented. Empty baremodules cannot be documented."
},

{
    "location": "manual/documentation/#Global-Variables-1",
    "page": "Documentation",
    "title": "Global Variables",
    "category": "section",
    "text": "\"...\"\nconst a = 1\n\n\"...\"\nb = 2\n\n\"...\"\nglobal c = 3Adds docstring \"...\" to the Bindings a, b, and c.Bindings are used to store a reference to a particular Symbol in a Module without storing the referenced value itself.note: Note\nWhen a const definition is only used to define an alias of another definition, such as is the case with the function div and its alias ÷ in Base, do not document the alias and instead document the actual function.If the alias is documented and not the real definition then the docsystem (? mode) will not return the docstring attached to the alias when the real definition is searched for.For example you should write\"...\"\nf(x) = x + 1\nconst alias = frather thanf(x) = x + 1\n\"...\"\nconst alias = f\"...\"\nsymAdds docstring \"...\" to the value associated with sym. Users should prefer documenting sym at it\'s definition."
},

{
    "location": "manual/documentation/#Multiple-Objects-1",
    "page": "Documentation",
    "title": "Multiple Objects",
    "category": "section",
    "text": "\"...\"\na, bAdds docstring \"...\" to a and b each of which should be a documentable expression. This syntax is equivalent to\"...\"\na\n\n\"...\"\nbAny number of expressions many be documented together in this way. This syntax can be useful when two functions are related, such as non-mutating and mutating versions f and f!."
},

{
    "location": "manual/documentation/#Core.@__doc__",
    "page": "Documentation",
    "title": "Core.@__doc__",
    "category": "macro",
    "text": "@__doc__(ex)\n\nLow-level macro used to mark expressions returned by a macro that should be documented. If more than one expression is marked then the same docstring is applied to each expression.\n\nmacro example(f)\n    quote\n        $(f)() = 0\n        @__doc__ $(f)(x) = 1\n        $(f)(x, y) = 2\n    end |> esc\nend\n\n@__doc__ has no effect when a macro that uses it is not documented.\n\n\n\n"
},

{
    "location": "manual/documentation/#Macro-generated-code-1",
    "page": "Documentation",
    "title": "Macro-generated code",
    "category": "section",
    "text": "\"...\"\n@m expressionAdds docstring \"...\" to expression generated by expanding @m expression. This allows for expressions decorated with @inline, @noinline, @generated, or any other macro to be documented in the same way as undecorated expressions.Macro authors should take note that only macros that generate a single expression will automatically support docstrings. If a macro returns a block containing multiple subexpressions then the subexpression that should be documented must be marked using the @__doc__ macro.The @enum macro makes use of @__doc__ to allow for documenting Enums. Examining it\'s definition should serve as an example of how to use @__doc__ correctly.Core.@__doc__"
},

{
    "location": "manual/documentation/#Markdown-syntax-1",
    "page": "Documentation",
    "title": "Markdown syntax",
    "category": "section",
    "text": "The following markdown syntax is supported in Julia."
},

{
    "location": "manual/documentation/#Inline-elements-1",
    "page": "Documentation",
    "title": "Inline elements",
    "category": "section",
    "text": "Here \"inline\" refers to elements that can be found within blocks of text, i.e. paragraphs. These include the following elements."
},

{
    "location": "manual/documentation/#Bold-1",
    "page": "Documentation",
    "title": "Bold",
    "category": "section",
    "text": "Surround words with two asterisks, **, to display the enclosed text in boldface.A paragraph containing a **bold** word."
},

{
    "location": "manual/documentation/#Italics-1",
    "page": "Documentation",
    "title": "Italics",
    "category": "section",
    "text": "Surround words with one asterisk, *, to display the enclosed text in italics.A paragraph containing an *emphasised* word."
},

{
    "location": "manual/documentation/#Literals-1",
    "page": "Documentation",
    "title": "Literals",
    "category": "section",
    "text": "Surround text that should be displayed exactly as written with single backticks, ` .A paragraph containing a `literal` word.Literals should be used when writing text that refers to names of variables, functions, or other parts of a Julia program.tip: Tip\nTo include a backtick character within literal text use three backticks rather than one to enclose the text.A paragraph containing a ``` `backtick` character ```.By extension any odd number of backticks may be used to enclose a lesser number of backticks."
},

{
    "location": "manual/documentation/#\\LaTeX-1",
    "page": "Documentation",
    "title": "LaTeX",
    "category": "section",
    "text": "Surround text that should be displayed as mathematics using LaTeX syntax with double backticks, `` .A paragraph containing some ``\\LaTeX`` markup.tip: Tip\nAs with literals in the previous section, if literal backticks need to be written within double backticks use an even number greater than two. Note that if a single literal backtick needs to be included within LaTeX markup then two enclosing backticks is sufficient."
},

{
    "location": "manual/documentation/#Links-1",
    "page": "Documentation",
    "title": "Links",
    "category": "section",
    "text": "Links to either external or internal addresses can be written using the following syntax, where the text enclosed in square brackets, [ ], is the name of the link and the text enclosed in parentheses, ( ), is the URL.A paragraph containing a link to [Julia](http://www.julialang.org).It\'s also possible to add cross-references to other documented functions/methods/variables within the Julia documentation itself. For example:\"\"\"\n    eigvals!(A,[irange,][vl,][vu]) -> values\n\nSame as [`eigvals`](@ref), but saves space by overwriting the input `A`, instead of creating a copy.\n\"\"\"This will create a link in the generated docs to the eigvals documentation (which has more information about what this function actually does). It\'s good to include cross references to mutating/non-mutating versions of a function, or to highlight a difference between two similar-seeming functions.note: Note\nThe above cross referencing is not a Markdown feature, and relies on Documenter.jl, which is used to build base Julia\'s documentation."
},

{
    "location": "manual/documentation/#Footnote-references-1",
    "page": "Documentation",
    "title": "Footnote references",
    "category": "section",
    "text": "Named and numbered footnote references can be written using the following syntax. A footnote name must be a single alphanumeric word containing no punctuation.A paragraph containing a numbered footnote [^1] and a named one [^named].note: Note\nThe text associated with a footnote can be written anywhere within the same page as the footnote reference. The syntax used to define the footnote text is discussed in the Footnotes section below."
},

{
    "location": "manual/documentation/#Toplevel-elements-1",
    "page": "Documentation",
    "title": "Toplevel elements",
    "category": "section",
    "text": "The following elements can be written either at the \"toplevel\" of a document or within another \"toplevel\" element."
},

{
    "location": "manual/documentation/#Paragraphs-1",
    "page": "Documentation",
    "title": "Paragraphs",
    "category": "section",
    "text": "A paragraph is a block of plain text, possibly containing any number of inline elements defined in the Inline elements section above, with one or more blank lines above and below it.This is a paragraph.\n\nAnd this is *another* one containing some emphasised text.\nA new line, but still part of the same paragraph."
},

{
    "location": "manual/documentation/#Headers-1",
    "page": "Documentation",
    "title": "Headers",
    "category": "section",
    "text": "A document can be split up into different sections using headers. Headers use the following syntax:# Level One\n## Level Two\n### Level Three\n#### Level Four\n##### Level Five\n###### Level SixA header line can contain any inline syntax in the same way as a paragraph can.tip: Tip\nTry to avoid using too many levels of header within a single document. A heavily nested document may be indicative of a need to restructure it or split it into several pages covering separate topics."
},

{
    "location": "manual/documentation/#Code-blocks-1",
    "page": "Documentation",
    "title": "Code blocks",
    "category": "section",
    "text": "Source code can be displayed as a literal block using an indent of four spaces as shown in the following example.This is a paragraph.\n\n    function func(x)\n        # ...\n    end\n\nAnother paragraph.Additionally, code blocks can be enclosed using triple backticks with an optional \"language\" to specify how a block of code should be highlighted.A code block without a \"language\":\n\n```\nfunction func(x)\n    # ...\nend\n```\n\nand another one with the \"language\" specified as `julia`:\n\n```julia\nfunction func(x)\n    # ...\nend\n```note: Note\n\"Fenced\" code blocks, as shown in the last example, should be prefered over indented code blocks since there is no way to specify what language an indented code block is written in."
},

{
    "location": "manual/documentation/#Block-quotes-1",
    "page": "Documentation",
    "title": "Block quotes",
    "category": "section",
    "text": "Text from external sources, such as quotations from books or websites, can be quoted using > characters prepended to each line of the quote as follows.Here\'s a quote:\n\n> Julia is a high-level, high-performance dynamic programming language for\n> technical computing, with syntax that is familiar to users of other\n> technical computing environments.Note that a single space must appear after the > character on each line. Quoted blocks may themselves contain other toplevel or inline elements."
},

{
    "location": "manual/documentation/#Images-1",
    "page": "Documentation",
    "title": "Images",
    "category": "section",
    "text": "The syntax for images is similar to the link syntax mentioned above. Prepending a ! character to a link will display an image from the specified URL rather than a link to it.![alternative text](link/to/image.png)"
},

{
    "location": "manual/documentation/#Lists-1",
    "page": "Documentation",
    "title": "Lists",
    "category": "section",
    "text": "Unordered lists can be written by prepending each item in a list with either *, +, or -.A list of items:\n\n  * item one\n  * item two\n  * item threeNote the two spaces before each * and the single space after each one.Lists can contain other nested toplevel elements such as lists, code blocks, or quoteblocks. A blank line should be left between each list item when including any toplevel elements within a list.Another list:\n\n  * item one\n\n  * item two\n\n    ```\n    f(x) = x\n    ```\n\n  * And a sublist:\n\n      + sub-item one\n      + sub-item twonote: Note\nThe contents of each item in the list must line up with the first line of the item. In the above example the fenced code block must be indented by four spaces to align with the i in item two.Ordered lists are written by replacing the \"bullet\" character, either *, +, or -, with a positive integer followed by either . or ).Two ordered lists:\n\n 1. item one\n 2. item two\n 3. item three\n\n 5) item five\n 6) item six\n 7) item sevenAn ordered list may start from a number other than one, as in the second list of the above example, where it is numbered from five. As with unordered lists, ordered lists can contain nested toplevel elements."
},

{
    "location": "manual/documentation/#Display-equations-1",
    "page": "Documentation",
    "title": "Display equations",
    "category": "section",
    "text": "Large LaTeX equations that do not fit inline within a paragraph may be written as display equations using a fenced code block with the \"language\" math as in the example below.```math\nf(a) = \\frac{1}{2\\pi}\\int_{0}^{2\\pi} (\\alpha+R\\cos(\\theta))d\\theta\n```"
},

{
    "location": "manual/documentation/#Footnotes-1",
    "page": "Documentation",
    "title": "Footnotes",
    "category": "section",
    "text": "This syntax is paired with the inline syntax for Footnote references. Make sure to read that section as well.Footnote text is defined using the following syntax, which is similar to footnote reference syntax, aside from the : character that is appended to the footnote label.[^1]: Numbered footnote text.\n\n[^note]:\n\n    Named footnote text containing several toplevel elements.\n\n      * item one\n      * item two\n      * item three\n\n    ```julia\n    function func(x)\n        # ...\n    end\n    ```note: Note\nNo checks are done during parsing to make sure that all footnote references have matching footnotes."
},

{
    "location": "manual/documentation/#Horizontal-rules-1",
    "page": "Documentation",
    "title": "Horizontal rules",
    "category": "section",
    "text": "The equivalent of an <hr> HTML tag can be written using the following syntax:Text above the line.\n\n---\n\nAnd text below the line."
},

{
    "location": "manual/documentation/#Tables-1",
    "page": "Documentation",
    "title": "Tables",
    "category": "section",
    "text": "Basic tables can be written using the syntax described below. Note that markdown tables have limited features and cannot contain nested toplevel elements unlike other elements discussed above – only inline elements are allowed. Tables must always contain a header row with column names. Cells cannot span multiple rows or columns of the table.| Column One | Column Two | Column Three |\n|:---------- | ---------- |:------------:|\n| Row `1`    | Column `2` |              |\n| *Row* 2    | **Row** 2  | Column ``3`` |note: Note\nAs illustrated in the above example each column of | characters must be aligned vertically.A : character on either end of a column\'s header separator (the row containing - characters) specifies whether the row is left-aligned, right-aligned, or (when : appears on both ends) center-aligned. Providing no : characters will default to right-aligning the column."
},

{
    "location": "manual/documentation/#Admonitions-1",
    "page": "Documentation",
    "title": "Admonitions",
    "category": "section",
    "text": "Specially formatted blocks with titles such as \"Notes\", \"Warning\", or \"Tips\" are known as admonitions and are used when some part of a document needs special attention. They can be defined using the following !!! syntax:!!! note\n\n    This is the content of the note.\n\n!!! warning \"Beware!\"\n\n    And this is another one.\n\n    This warning admonition has a custom title: `\"Beware!\"`.Admonitions, like most other toplevel elements, can contain other toplevel elements. When no title text, specified after the admonition type in double quotes, is included then the title used will be the type of the block, i.e. \"Note\" in the case of the note admonition."
},

{
    "location": "manual/documentation/#Markdown-Syntax-Extensions-1",
    "page": "Documentation",
    "title": "Markdown Syntax Extensions",
    "category": "section",
    "text": "Julia\'s markdown supports interpolation in a very similar way to basic string literals, with the difference that it will store the object itself in the Markdown tree (as opposed to converting it to a string). When the Markdown content is rendered the usual show methods will be called, and these can be overridden as usual. This design allows the Markdown to be extended with arbitrarily complex features (such as references) without cluttering the basic syntax.In principle, the Markdown parser itself can also be arbitrarily extended by packages, or an entirely custom flavour of Markdown can be used, but this should generally be unnecessary."
},

{
    "location": "manual/metaprogramming/#",
    "page": "Metaprogramming",
    "title": "Metaprogramming",
    "category": "page",
    "text": ""
},

{
    "location": "manual/metaprogramming/#Metaprogramming-1",
    "page": "Metaprogramming",
    "title": "Metaprogramming",
    "category": "section",
    "text": "The strongest legacy of Lisp in the Julia language is its metaprogramming support. Like Lisp, Julia represents its own code as a data structure of the language itself. Since code is represented by objects that can be created and manipulated from within the language, it is possible for a program to transform and generate its own code. This allows sophisticated code generation without extra build steps, and also allows true Lisp-style macros operating at the level of abstract syntax trees. In contrast, preprocessor \"macro\" systems, like that of C and C++, perform textual manipulation and substitution before any actual parsing or interpretation occurs. Because all data types and code in Julia are represented by Julia data structures, powerful reflection capabilities are available to explore the internals of a program and its types just like any other data."
},

{
    "location": "manual/metaprogramming/#Program-representation-1",
    "page": "Metaprogramming",
    "title": "Program representation",
    "category": "section",
    "text": "Every Julia program starts life as a string:julia> prog = \"1 + 1\"\n\"1 + 1\"What happens next?The next step is to parse each string into an object called an expression, represented by the Julia type Expr:julia> ex1 = parse(prog)\n:(1 + 1)\n\njulia> typeof(ex1)\nExprExpr objects contain two parts:a Symbol identifying the kind of expression. A symbol is an interned string identifier (more discussion below).julia> ex1.head\n:callthe expression arguments, which may be symbols, other expressions, or literal values:julia> ex1.args\n3-element Array{Any,1}:\n  :+\n 1\n 1Expressions may also be constructed directly in prefix notation:julia> ex2 = Expr(:call, :+, 1, 1)\n:(1 + 1)The two expressions constructed above – by parsing and by direct construction – are equivalent:julia> ex1 == ex2\ntrueThe key point here is that Julia code is internally represented as a data structure that is accessible from the language itself.The dump() function provides indented and annotated display of Expr objects:julia> dump(ex2)\nExpr\n  head: Symbol call\n  args: Array{Any}((3,))\n    1: Symbol +\n    2: Int64 1\n    3: Int64 1\n  typ: AnyExpr objects may also be nested:julia> ex3 = parse(\"(4 + 4) / 2\")\n:((4 + 4) / 2)Another way to view expressions is with Meta.show_sexpr, which displays the S-expression form of a given Expr, which may look very familiar to users of Lisp. Here\'s an example illustrating the display on a nested Expr:julia> Meta.show_sexpr(ex3)\n(:call, :/, (:call, :+, 4, 4), 2)"
},

{
    "location": "manual/metaprogramming/#Symbols-1",
    "page": "Metaprogramming",
    "title": "Symbols",
    "category": "section",
    "text": "The : character has two syntactic purposes in Julia. The first form creates a Symbol, an interned string used as one building-block of expressions:julia> :foo\n:foo\n\njulia> typeof(ans)\nSymbolThe Symbol constructor takes any number of arguments and creates a new symbol by concatenating their string representations together:julia> :foo == Symbol(\"foo\")\ntrue\n\njulia> Symbol(\"func\",10)\n:func10\n\njulia> Symbol(:var,\'_\',\"sym\")\n:var_symIn the context of an expression, symbols are used to indicate access to variables; when an expression is evaluated, a symbol is replaced with the value bound to that symbol in the appropriate scope.Sometimes extra parentheses around the argument to : are needed to avoid ambiguity in parsing.:julia> :(:)\n:(:)\n\njulia> :(::)\n:(::)"
},

{
    "location": "manual/metaprogramming/#Expressions-and-evaluation-1",
    "page": "Metaprogramming",
    "title": "Expressions and evaluation",
    "category": "section",
    "text": ""
},

{
    "location": "manual/metaprogramming/#Quoting-1",
    "page": "Metaprogramming",
    "title": "Quoting",
    "category": "section",
    "text": "The second syntactic purpose of the : character is to create expression objects without using the explicit Expr constructor. This is referred to as quoting. The : character, followed by paired parentheses around a single statement of Julia code, produces an Expr object based on the enclosed code. Here is example of the short form used to quote an arithmetic expression:julia> ex = :(a+b*c+1)\n:(a + b * c + 1)\n\njulia> typeof(ex)\nExpr(to view the structure of this expression, try ex.head and ex.args, or use dump() as above)Note that equivalent expressions may be constructed using parse() or the direct Expr form:julia>      :(a + b*c + 1)  ==\n       parse(\"a + b*c + 1\") ==\n       Expr(:call, :+, :a, Expr(:call, :*, :b, :c), 1)\ntrueExpressions provided by the parser generally only have symbols, other expressions, and literal values as their args, whereas expressions constructed by Julia code can have arbitrary run-time values without literal forms as args. In this specific example, + and a are symbols, *(b,c) is a subexpression, and 1 is a literal 64-bit signed integer.There is a second syntactic form of quoting for multiple expressions: blocks of code enclosed in quote ... end. Note that this form introduces QuoteNode elements to the expression tree, which must be considered when directly manipulating an expression tree generated from quote blocks. For other purposes, :( ... ) and quote .. end blocks are treated identically.julia> ex = quote\n           x = 1\n           y = 2\n           x + y\n       end\nquote  # none, line 2:\n    x = 1 # none, line 3:\n    y = 2 # none, line 4:\n    x + y\nend\n\njulia> typeof(ex)\nExpr"
},

{
    "location": "manual/metaprogramming/#Interpolation-1",
    "page": "Metaprogramming",
    "title": "Interpolation",
    "category": "section",
    "text": "Direct construction of Expr objects with value arguments is powerful, but Expr constructors can be tedious compared to \"normal\" Julia syntax. As an alternative, Julia allows \"splicing\" or interpolation of literals or expressions into quoted expressions. Interpolation is indicated by the $ prefix.In this example, the literal value of a is interpolated:julia> a = 1;\n\njulia> ex = :($a + b)\n:(1 + b)Interpolating into an unquoted expression is not supported and will cause a compile-time error:julia> $a + b\nERROR: unsupported or misplaced expression $\n ...In this example, the tuple (1,2,3) is interpolated as an expression into a conditional test:julia> ex = :(a in $:((1,2,3)) )\n:(a in (1, 2, 3))Interpolating symbols into a nested expression requires enclosing each symbol in an enclosing quote block:julia> :( :a in $( :(:a + :b) ) )\n                   ^^^^^^^^^^\n                   quoted inner expressionThe use of $ for expression interpolation is intentionally reminiscent of string interpolation and command interpolation. Expression interpolation allows convenient, readable programmatic construction of complex Julia expressions."
},

{
    "location": "manual/metaprogramming/#[eval()](@ref)-and-effects-1",
    "page": "Metaprogramming",
    "title": "eval() and effects",
    "category": "section",
    "text": "Given an expression object, one can cause Julia to evaluate (execute) it at global scope using eval():julia> :(1 + 2)\n:(1 + 2)\n\njulia> eval(ans)\n3\n\njulia> ex = :(a + b)\n:(a + b)\n\njulia> eval(ex)\nERROR: UndefVarError: b not defined\n[...]\n\njulia> a = 1; b = 2;\n\njulia> eval(ex)\n3Every module has its own eval() function that evaluates expressions in its global scope. Expressions passed to eval() are not limited to returning values – they can also have side-effects that alter the state of the enclosing module\'s environment:julia> ex = :(x = 1)\n:(x = 1)\n\njulia> x\nERROR: UndefVarError: x not defined\n\njulia> eval(ex)\n1\n\njulia> x\n1Here, the evaluation of an expression object causes a value to be assigned to the global variable x.Since expressions are just Expr objects which can be constructed programmatically and then evaluated, it is possible to dynamically generate arbitrary code which can then be run using eval(). Here is a simple example:julia> a = 1;\n\njulia> ex = Expr(:call, :+, a, :b)\n:(1 + b)\n\njulia> a = 0; b = 2;\n\njulia> eval(ex)\n3The value of a is used to construct the expression ex which applies the + function to the value 1 and the variable b. Note the important distinction between the way a and b are used:The value of the variablea at expression construction time is used as an immediate value in the expression. Thus, the value of a when the expression is evaluated no longer matters: the value in the expression is already 1, independent of whatever the value of a might be.\nOn the other hand, the symbol:b is used in the expression construction, so the value of the variable b at that time is irrelevant – :b is just a symbol and the variable b need not even be defined. At expression evaluation time, however, the value of the symbol :b is resolved by looking up the value of the variable b."
},

{
    "location": "manual/metaprogramming/#Functions-on-Expressions-1",
    "page": "Metaprogramming",
    "title": "Functions on Expressions",
    "category": "section",
    "text": "As hinted above, one extremely useful feature of Julia is the capability to generate and manipulate Julia code within Julia itself. We have already seen one example of a function returning Expr objects: the parse() function, which takes a string of Julia code and returns the corresponding Expr. A function can also take one or more Expr objects as arguments, and return another Expr. Here is a simple, motivating example:julia> function math_expr(op, op1, op2)\n           expr = Expr(:call, op, op1, op2)\n           return expr\n       end\nmath_expr (generic function with 1 method)\n\njulia>  ex = math_expr(:+, 1, Expr(:call, :*, 4, 5))\n:(1 + 4 * 5)\n\njulia> eval(ex)\n21As another example, here is a function that doubles any numeric argument, but leaves expressions alone:julia> function make_expr2(op, opr1, opr2)\n           opr1f, opr2f = map(x -> isa(x, Number) ? 2*x : x, (opr1, opr2))\n           retexpr = Expr(:call, op, opr1f, opr2f)\n           return retexpr\n       end\nmake_expr2 (generic function with 1 method)\n\njulia> make_expr2(:+, 1, 2)\n:(2 + 4)\n\njulia> ex = make_expr2(:+, 1, Expr(:call, :*, 5, 8))\n:(2 + 5 * 8)\n\njulia> eval(ex)\n42"
},

{
    "location": "manual/metaprogramming/#man-macros-1",
    "page": "Metaprogramming",
    "title": "Macros",
    "category": "section",
    "text": "Macros provide a method to include generated code in the final body of a program. A macro maps a tuple of arguments to a returned expression, and the resulting expression is compiled directly rather than requiring a runtime eval() call. Macro arguments may include expressions, literal values, and symbols."
},

{
    "location": "manual/metaprogramming/#Basics-1",
    "page": "Metaprogramming",
    "title": "Basics",
    "category": "section",
    "text": "Here is an extraordinarily simple macro:julia> macro sayhello()\n           return :( println(\"Hello, world!\") )\n       end\n@sayhello (macro with 1 method)Macros have a dedicated character in Julia\'s syntax: the @ (at-sign), followed by the unique name declared in a macro NAME ... end block. In this example, the compiler will replace all instances of @sayhello with::( println(\"Hello, world!\") )When @sayhello is entered in the REPL, the expression executes immediately, thus we only see the evaluation result:julia> @sayhello()\nHello, world!Now, consider a slightly more complex macro:julia> macro sayhello(name)\n           return :( println(\"Hello, \", $name) )\n       end\n@sayhello (macro with 1 method)This macro takes one argument: name. When @sayhello is encountered, the quoted expression is expanded to interpolate the value of the argument into the final expression:julia> @sayhello(\"human\")\nHello, humanWe can view the quoted return expression using the function macroexpand() (important note: this is an extremely useful tool for debugging macros):julia> ex = macroexpand( :(@sayhello(\"human\")) )\n:((println)(\"Hello, \", \"human\"))\n\njulia> typeof(ex)\nExprWe can see that the \"human\" literal has been interpolated into the expression.There also exists a macro @macroexpand that is perhaps a bit more convenient than the macroexpand function:julia> @macroexpand @sayhello \"human\"\n:((println)(\"Hello, \", \"human\"))"
},

{
    "location": "manual/metaprogramming/#Hold-up:-why-macros?-1",
    "page": "Metaprogramming",
    "title": "Hold up: why macros?",
    "category": "section",
    "text": "We have already seen a function f(::Expr...) -> Expr in a previous section. In fact, macroexpand() is also such a function. So, why do macros exist?Macros are necessary because they execute when code is parsed, therefore, macros allow the programmer to generate and include fragments of customized code before the full program is run. To illustrate the difference, consider the following example:julia> macro twostep(arg)\n           println(\"I execute at parse time. The argument is: \", arg)\n           return :(println(\"I execute at runtime. The argument is: \", $arg))\n       end\n@twostep (macro with 1 method)\n\njulia> ex = macroexpand( :(@twostep :(1, 2, 3)) );\nI execute at parse time. The argument is: $(Expr(:quote, :((1, 2, 3))))The first call to println() is executed when macroexpand() is called. The resulting expression contains only the second println:julia> typeof(ex)\nExpr\n\njulia> ex\n:((println)(\"I execute at runtime. The argument is: \", $(Expr(:copyast, :($(QuoteNode(:((1, 2, 3)))))))))\n\njulia> eval(ex)\nI execute at runtime. The argument is: (1, 2, 3)"
},

{
    "location": "manual/metaprogramming/#Macro-invocation-1",
    "page": "Metaprogramming",
    "title": "Macro invocation",
    "category": "section",
    "text": "Macros are invoked with the following general syntax:@name expr1 expr2 ...\n@name(expr1, expr2, ...)Note the distinguishing @ before the macro name and the lack of commas between the argument expressions in the first form, and the lack of whitespace after @name in the second form. The two styles should not be mixed. For example, the following syntax is different from the examples above; it passes the tuple (expr1, expr2, ...) as one argument to the macro:@name (expr1, expr2, ...)It is important to emphasize that macros receive their arguments as expressions, literals, or symbols. One way to explore macro arguments is to call the show() function within the macro body:julia> macro showarg(x)\n           show(x)\n           # ... remainder of macro, returning an expression\n       end\n@showarg (macro with 1 method)\n\njulia> @showarg(a)\n:a\n\njulia> @showarg(1+1)\n:(1 + 1)\n\njulia> @showarg(println(\"Yo!\"))\n:(println(\"Yo!\"))"
},

{
    "location": "manual/metaprogramming/#Building-an-advanced-macro-1",
    "page": "Metaprogramming",
    "title": "Building an advanced macro",
    "category": "section",
    "text": "Here is a simplified definition of Julia\'s @assert macro:julia> macro assert(ex)\n           return :( $ex ? nothing : throw(AssertionError($(string(ex)))) )\n       end\n@assert (macro with 1 method)This macro can be used like this:julia> @assert 1 == 1.0\n\njulia> @assert 1 == 0\nERROR: AssertionError: 1 == 0In place of the written syntax, the macro call is expanded at parse time to its returned result. This is equivalent to writing:1 == 1.0 ? nothing : throw(AssertionError(\"1 == 1.0\"))\n1 == 0 ? nothing : throw(AssertionError(\"1 == 0\"))That is, in the first call, the expression :(1 == 1.0) is spliced into the test condition slot, while the value of string(:(1 == 1.0)) is spliced into the assertion message slot. The entire expression, thus constructed, is placed into the syntax tree where the @assert macro call occurs. Then at execution time, if the test expression evaluates to true, then nothing is returned, whereas if the test is false, an error is raised indicating the asserted expression that was false. Notice that it would not be possible to write this as a function, since only the value of the condition is available and it would be impossible to display the expression that computed it in the error message.The actual definition of @assert in the standard library is more complicated. It allows the user to optionally specify their own error message, instead of just printing the failed expression. Just like in functions with a variable number of arguments, this is specified with an ellipses following the last argument:julia> macro assert(ex, msgs...)\n           msg_body = isempty(msgs) ? ex : msgs[1]\n           msg = string(msg_body)\n           return :($ex ? nothing : throw(AssertionError($msg)))\n       end\n@assert (macro with 1 method)Now @assert has two modes of operation, depending upon the number of arguments it receives! If there\'s only one argument, the tuple of expressions captured by msgs will be empty and it will behave the same as the simpler definition above. But now if the user specifies a second argument, it is printed in the message body instead of the failing expression. You can inspect the result of a macro expansion with the aptly named macroexpand() function:julia> macroexpand(:(@assert a == b))\n:(if a == b\n        nothing\n    else\n        (throw)((AssertionError)(\"a == b\"))\n    end)\n\njulia> macroexpand(:(@assert a==b \"a should equal b!\"))\n:(if a == b\n        nothing\n    else\n        (throw)((AssertionError)(\"a should equal b!\"))\n    end)There is yet another case that the actual @assert macro handles: what if, in addition to printing \"a should equal b,\" we wanted to print their values? One might naively try to use string interpolation in the custom message, e.g., @assert a==b \"a ($a) should equal b ($b)!\", but this won\'t work as expected with the above macro. Can you see why? Recall from string interpolation that an interpolated string is rewritten to a call to string(). Compare:julia> typeof(:(\"a should equal b\"))\nString\n\njulia> typeof(:(\"a ($a) should equal b ($b)!\"))\nExpr\n\njulia> dump(:(\"a ($a) should equal b ($b)!\"))\nExpr\n  head: Symbol string\n  args: Array{Any}((5,))\n    1: String \"a (\"\n    2: Symbol a\n    3: String \") should equal b (\"\n    4: Symbol b\n    5: String \")!\"\n  typ: AnySo now instead of getting a plain string in msg_body, the macro is receiving a full expression that will need to be evaluated in order to display as expected. This can be spliced directly into the returned expression as an argument to the string() call; see error.jl for the complete implementation.The @assert macro makes great use of splicing into quoted expressions to simplify the manipulation of expressions inside the macro body."
},

{
    "location": "manual/metaprogramming/#Hygiene-1",
    "page": "Metaprogramming",
    "title": "Hygiene",
    "category": "section",
    "text": "An issue that arises in more complex macros is that of hygiene. In short, macros must ensure that the variables they introduce in their returned expressions do not accidentally clash with existing variables in the surrounding code they expand into. Conversely, the expressions that are passed into a macro as arguments are often expected to evaluate in the context of the surrounding code, interacting with and modifying the existing variables. Another concern arises from the fact that a macro may be called in a different module from where it was defined. In this case we need to ensure that all global variables are resolved to the correct module. Julia already has a major advantage over languages with textual macro expansion (like C) in that it only needs to consider the returned expression. All the other variables (such as msg in @assert above) follow the normal scoping block behavior.To demonstrate these issues, let us consider writing a @time macro that takes an expression as its argument, records the time, evaluates the expression, records the time again, prints the difference between the before and after times, and then has the value of the expression as its final value. The macro might look like this:macro time(ex)\n    return quote\n        local t0 = time()\n        local val = $ex\n        local t1 = time()\n        println(\"elapsed time: \", t1-t0, \" seconds\")\n        val\n    end\nendHere, we want t0, t1, and val to be private temporary variables, and we want time to refer to the time() function in the standard library, not to any time variable the user might have (the same applies to println). Imagine the problems that could occur if the user expression ex also contained assignments to a variable called t0, or defined its own time variable. We might get errors, or mysteriously incorrect behavior.Julia\'s macro expander solves these problems in the following way. First, variables within a macro result are classified as either local or global. A variable is considered local if it is assigned to (and not declared global), declared local, or used as a function argument name. Otherwise, it is considered global. Local variables are then renamed to be unique (using the gensym() function, which generates new symbols), and global variables are resolved within the macro definition environment. Therefore both of the above concerns are handled; the macro\'s locals will not conflict with any user variables, and time and println will refer to the standard library definitions.One problem remains however. Consider the following use of this macro:module MyModule\nimport Base.@time\n\ntime() = ... # compute something\n\n@time time()\nendHere the user expression ex is a call to time, but not the same time function that the macro uses. It clearly refers to MyModule.time. Therefore we must arrange for the code in ex to be resolved in the macro call environment. This is done by \"escaping\" the expression with esc():macro time(ex)\n    ...\n    local val = $(esc(ex))\n    ...\nendAn expression wrapped in this manner is left alone by the macro expander and simply pasted into the output verbatim. Therefore it will be resolved in the macro call environment.This escaping mechanism can be used to \"violate\" hygiene when necessary, in order to introduce or manipulate user variables. For example, the following macro sets x to zero in the call environment:julia> macro zerox()\n           return esc(:(x = 0))\n       end\n@zerox (macro with 1 method)\n\njulia> function foo()\n           x = 1\n           @zerox\n           return x # is zero\n       end\nfoo (generic function with 1 method)\n\njulia> foo()\n0This kind of manipulation of variables should be used judiciously, but is occasionally quite handy."
},

{
    "location": "manual/metaprogramming/#Code-Generation-1",
    "page": "Metaprogramming",
    "title": "Code Generation",
    "category": "section",
    "text": "When a significant amount of repetitive boilerplate code is required, it is common to generate it programmatically to avoid redundancy. In most languages, this requires an extra build step, and a separate program to generate the repetitive code. In Julia, expression interpolation and eval() allow such code generation to take place in the normal course of program execution. For example, the following code defines a series of operators on three arguments in terms of their 2-argument forms:for op = (:+, :*, :&, :|, :$)\n    eval(quote\n        ($op)(a,b,c) = ($op)(($op)(a,b),c)\n    end)\nendIn this manner, Julia acts as its own preprocessor, and allows code generation from inside the language. The above code could be written slightly more tersely using the : prefix quoting form:for op = (:+, :*, :&, :|, :$)\n    eval(:(($op)(a,b,c) = ($op)(($op)(a,b),c)))\nendThis sort of in-language code generation, however, using the eval(quote(...)) pattern, is common enough that Julia comes with a macro to abbreviate this pattern:for op = (:+, :*, :&, :|, :$)\n    @eval ($op)(a,b,c) = ($op)(($op)(a,b),c)\nendThe @eval macro rewrites this call to be precisely equivalent to the above longer versions. For longer blocks of generated code, the expression argument given to @eval can be a block:@eval begin\n    # multiple lines\nend"
},

{
    "location": "manual/metaprogramming/#Non-Standard-String-Literals-1",
    "page": "Metaprogramming",
    "title": "Non-Standard String Literals",
    "category": "section",
    "text": "Recall from Strings that string literals prefixed by an identifier are called non-standard string literals, and can have different semantics than un-prefixed string literals. For example:r\"^\\s*(?:#|$)\" produces a regular expression object rather than a string\nb\"DATA\\xff\\u2200\" is a byte array literal for [68,65,84,65,255,226,136,128].Perhaps surprisingly, these behaviors are not hard-coded into the Julia parser or compiler. Instead, they are custom behaviors provided by a general mechanism that anyone can use: prefixed string literals are parsed as calls to specially-named macros. For example, the regular expression macro is just the following:macro r_str(p)\n    Regex(p)\nendThat\'s all. This macro says that the literal contents of the string literal r\"^\\s*(?:#|$)\" should be passed to the @r_str macro and the result of that expansion should be placed in the syntax tree where the string literal occurs. In other words, the expression r\"^\\s*(?:#|$)\" is equivalent to placing the following object directly into the syntax tree:Regex(\"^\\\\s*(?:#|\\$)\")Not only is the string literal form shorter and far more convenient, but it is also more efficient: since the regular expression is compiled and the Regex object is actually created when the code is compiled, the compilation occurs only once, rather than every time the code is executed. Consider if the regular expression occurs in a loop:for line = lines\n    m = match(r\"^\\s*(?:#|$)\", line)\n    if m === nothing\n        # non-comment\n    else\n        # comment\n    end\nendSince the regular expression r\"^\\s*(?:#|$)\" is compiled and inserted into the syntax tree when this code is parsed, the expression is only compiled once instead of each time the loop is executed. In order to accomplish this without macros, one would have to write this loop like this:re = Regex(\"^\\\\s*(?:#|\\$)\")\nfor line = lines\n    m = match(re, line)\n    if m === nothing\n        # non-comment\n    else\n        # comment\n    end\nendMoreover, if the compiler could not determine that the regex object was constant over all loops, certain optimizations might not be possible, making this version still less efficient than the more convenient literal form above. Of course, there are still situations where the non-literal form is more convenient: if one needs to interpolate a variable into the regular expression, one must take this more verbose approach; in cases where the regular expression pattern itself is dynamic, potentially changing upon each loop iteration, a new regular expression object must be constructed on each iteration. In the vast majority of use cases, however, regular expressions are not constructed based on run-time data. In this majority of cases, the ability to write regular expressions as compile-time values is invaluable.Like non-standard string literals, non-standard command literals exist using a prefixed variant of the command literal syntax. The command literal custom`literal` is parsed as @custom_cmd \"literal\". Julia itself does not contain any non-standard command literals, but packages can make use of this syntax. Aside from the different syntax and the _cmd suffix instead of the _str suffix, non-standard command literals behave exactly like non-standard string literals.In the event that two modules provide non-standard string or command literals with the same name, it is possible to qualify the string or command literal with a module name. For instance, if both Foo and Bar provide non-standard string literal @x_str, then one can write Foo.x\"literal\" or Bar.x\"literal\" to disambiguate between the two.The mechanism for user-defined string literals is deeply, profoundly powerful. Not only are Julia\'s non-standard literals implemented using it, but also the command literal syntax (`echo \"Hello, $person\"`) is implemented with the following innocuous-looking macro:macro cmd(str)\n    :(cmd_gen($(shell_parse(str)[1])))\nendOf course, a large amount of complexity is hidden in the functions used in this macro definition, but they are just functions, written entirely in Julia. You can read their source and see precisely what they do – and all they do is construct expression objects to be inserted into your program\'s syntax tree."
},

{
    "location": "manual/metaprogramming/#Generated-functions-1",
    "page": "Metaprogramming",
    "title": "Generated functions",
    "category": "section",
    "text": "A very special macro is @generated, which allows you to define so-called generated functions. These have the capability to generate specialized code depending on the types of their arguments with more flexibility and/or less code than what can be achieved with multiple dispatch. While macros work with expressions at parsing-time and cannot access the types of their inputs, a generated function gets expanded at a time when the types of the arguments are known, but the function is not yet compiled.Instead of performing some calculation or action, a generated function declaration returns a quoted expression which then forms the body for the method corresponding to the types of the arguments. When called, the body expression is first evaluated and compiled, then the returned expression is compiled and run. To make this efficient, the result is often cached. And to make this inferable, only a limited subset of the language is usable. Thus, generated functions provide a flexible framework to move work from run-time to compile-time, at the expense of greater restrictions on the allowable constructs.When defining generated functions, there are four main differences to ordinary functions:You annotate the function declaration with the @generated macro. This adds some information to the AST that lets the compiler know that this is a generated function.\nIn the body of the generated function you only have access to the types of the arguments – not their values – and any function that was defined before the definition of the generated function.\nInstead of calculating something or performing some action, you return a quoted expression which, when evaluated, does what you want.\nGenerated functions must not mutate or observe any non-constant global state (including, for example, IO, locks, non-local dictionaries, or using method_exists). This means they can only read global constants, and cannot have any side effects. In other words, they must be completely pure. Due to an implementation limitation, this also means that they currently cannot define a closure or untyped generator.It\'s easiest to illustrate this with an example. We can declare a generated function foo asjulia> @generated function foo(x)\n           Core.println(x)\n           return :(x * x)\n       end\nfoo (generic function with 1 method)Note that the body returns a quoted expression, namely :(x * x), rather than just the value of x * x.From the caller\'s perspective, they are very similar to regular functions; in fact, you don\'t have to know if you\'re calling a regular or generated function - the syntax and result of the call is just the same. Let\'s see how foo behaves:julia> x = foo(2); # note: output is from println() statement in the body\nInt64\n\njulia> x           # now we print x\n4\n\njulia> y = foo(\"bar\");\nString\n\njulia> y\n\"barbar\"So, we see that in the body of the generated function, x is the type of the passed argument, and the value returned by the generated function, is the result of evaluating the quoted expression we returned from the definition, now with the value of x.What happens if we evaluate foo again with a type that we have already used?julia> foo(4)\n16Note that there is no printout of Int64. We can see that the body of the generated function was only executed once here, for the specific set of argument types, and the result was cached. After that, for this example, the expression returned from the generated function on the first invocation was re-used as the method body. However, the actual caching behavior is an implementation-defined performance optimization, so it is invalid to depend too closely on this behavior.The number of times a generated function is generated might be only once, but it might also be more often, or appear to not happen at all. As a consequence, you should never write a generated function with side effects - when, and how often, the side effects occur is undefined. (This is true for macros too - and just like for macros, the use of eval() in a generated function is a sign that you\'re doing something the wrong way.) However, unlike macros, the runtime system cannot correctly handle a call to eval(), so it is disallowed.It is also important to see how @generated functions interact with method redefinition. Following the principle that a correct @generated function must not observe any mutable state or cause any mutation of global state, we see the following behavior. Observe that the generated function cannot call any method that was not defined prior to the definition of the generated function itself.Initially f(x) has one definitionjulia> f(x) = \"original definition\";Define other operations that use f(x):julia> g(x) = f(x);\n\njulia> @generated gen1(x) = f(x);\n\njulia> @generated gen2(x) = :(f(x));We now add some new definitions for f(x):julia> f(x::Int) = \"definition for Int\";\n\njulia> f(x::Type{Int}) = \"definition for Type{Int}\";and compare how these results differ:julia> f(1)\n\"definition for Int\"\n\njulia> g(1)\n\"definition for Int\"\n\njulia> gen1(1)\n\"original definition\"\n\njulia> gen2(1)\n\"definition for Int\"Each method of a generated function has its own view of defined functions:julia> @generated gen1(x::Real) = f(x);\n\njulia> gen1(1)\n\"definition for Type{Int}\"The example generated function foo above did not do anything a normal function foo(x) = x * x could not do (except printing the type on the first invocation, and incurring higher overhead). However, the power of a generated function lies in its ability to compute different quoted expressions depending on the types passed to it:julia> @generated function bar(x)\n           if x <: Integer\n               return :(x ^ 2)\n           else\n               return :(x)\n           end\n       end\nbar (generic function with 1 method)\n\njulia> bar(4)\n16\n\njulia> bar(\"baz\")\n\"baz\"(although of course this contrived example would be more easily implemented using multiple dispatch...)Abusing this will corrupt the runtime system and cause undefined behavior:julia> @generated function baz(x)\n           if rand() < .9\n               return :(x^2)\n           else\n               return :(\"boo!\")\n           end\n       end\nbaz (generic function with 1 method)Since the body of the generated function is non-deterministic, its behavior, and the behavior of all subsequent code is undefined.Don\'t copy these examples!These examples are hopefully helpful to illustrate how generated functions work, both in the definition end and at the call site; however, don\'t copy them, for the following reasons:the foo function has side-effects (the call to Core.println), and it is undefined exactly when, how often or how many times these side-effects will occur\nthe bar function solves a problem that is better solved with multiple dispatch - defining bar(x) = x and bar(x::Integer) = x ^ 2 will do the same thing, but it is both simpler and faster.\nthe baz function is pathologically insaneNote that the set of operations that should not be attempted in a generated function is unbounded, and the runtime system can currently only detect a subset of the invalid operations. There are many other operations that will simply corrupt the runtime system without notification, usually in subtle ways not obviously connected to the bad definition. Because the function generator is run during inference, it must respect all of the limitations of that code.Some operations that should not be attempted include:Caching of native pointers.\nInteracting with the contents or methods of Core.Inference in any way.\nObserving any mutable state.\nInference on the generated function may be run at any time, including while your code is attempting to observe or mutate this state.\nTaking any locks: C code you call out to may use locks internally, (for example, it is not problematic to call malloc, even though most implementations require locks internally) but don\'t attempt to hold or acquire any while executing Julia code.\nCalling any function that is defined after the body of the generated function. This condition is relaxed for incrementally-loaded precompiled modules to allow calling any function in the module.Alright, now that we have a better understanding of how generated functions work, let\'s use them to build some more advanced (and valid) functionality..."
},

{
    "location": "manual/metaprogramming/#An-advanced-example-1",
    "page": "Metaprogramming",
    "title": "An advanced example",
    "category": "section",
    "text": "Julia\'s base library has a sub2ind() function to calculate a linear index into an n-dimensional array, based on a set of n multilinear indices - in other words, to calculate the index i that can be used to index into an array A using A[i], instead of A[x,y,z,...]. One possible implementation is the following:julia> function sub2ind_loop(dims::NTuple{N}, I::Integer...) where N\n           ind = I[N] - 1\n           for i = N-1:-1:1\n               ind = I[i]-1 + dims[i]*ind\n           end\n           return ind + 1\n       end\nsub2ind_loop (generic function with 1 method)\n\njulia> sub2ind_loop((3, 5), 1, 2)\n4The same thing can be done using recursion:julia> sub2ind_rec(dims::Tuple{}) = 1;\n\njulia> sub2ind_rec(dims::Tuple{}, i1::Integer, I::Integer...) =\n           i1 == 1 ? sub2ind_rec(dims, I...) : throw(BoundsError());\n\njulia> sub2ind_rec(dims::Tuple{Integer, Vararg{Integer}}, i1::Integer) = i1;\n\njulia> sub2ind_rec(dims::Tuple{Integer, Vararg{Integer}}, i1::Integer, I::Integer...) =\n           i1 + dims[1] * (sub2ind_rec(Base.tail(dims), I...) - 1);\n\njulia> sub2ind_rec((3, 5), 1, 2)\n4Both these implementations, although different, do essentially the same thing: a runtime loop over the dimensions of the array, collecting the offset in each dimension into the final index.However, all the information we need for the loop is embedded in the type information of the arguments. Thus, we can utilize generated functions to move the iteration to compile-time; in compiler parlance, we use generated functions to manually unroll the loop. The body becomes almost identical, but instead of calculating the linear index, we build up an expression that calculates the index:julia> @generated function sub2ind_gen(dims::NTuple{N}, I::Integer...) where N\n           ex = :(I[$N] - 1)\n           for i = (N - 1):-1:1\n               ex = :(I[$i] - 1 + dims[$i] * $ex)\n           end\n           return :($ex + 1)\n       end\nsub2ind_gen (generic function with 1 method)\n\njulia> sub2ind_gen((3, 5), 1, 2)\n4What code will this generate?An easy way to find out is to extract the body into another (regular) function:julia> @generated function sub2ind_gen(dims::NTuple{N}, I::Integer...) where N\n           return sub2ind_gen_impl(dims, I...)\n       end\nsub2ind_gen (generic function with 1 method)\n\njulia> function sub2ind_gen_impl(dims::Type{T}, I...) where T <: NTuple{N,Any} where N\n           length(I) == N || return :(error(\"partial indexing is unsupported\"))\n           ex = :(I[$N] - 1)\n           for i = (N - 1):-1:1\n               ex = :(I[$i] - 1 + dims[$i] * $ex)\n           end\n           return :($ex + 1)\n       end\nsub2ind_gen_impl (generic function with 1 method)We can now execute sub2ind_gen_impl and examine the expression it returns:julia> sub2ind_gen_impl(Tuple{Int,Int}, Int, Int)\n:(((I[1] - 1) + dims[1] * (I[2] - 1)) + 1)So, the method body that will be used here doesn\'t include a loop at all - just indexing into the two tuples, multiplication and addition/subtraction. All the looping is performed compile-time, and we avoid looping during execution entirely. Thus, we only loop once per type, in this case once per N (except in edge cases where the function is generated more than once - see disclaimer above)."
},

{
    "location": "manual/arrays/#",
    "page": "Multi-dimensional Arrays",
    "title": "Multi-dimensional Arrays",
    "category": "page",
    "text": ""
},

{
    "location": "manual/arrays/#man-multi-dim-arrays-1",
    "page": "Multi-dimensional Arrays",
    "title": "Multi-dimensional Arrays",
    "category": "section",
    "text": "Julia, like most technical computing languages, provides a first-class array implementation. Most technical computing languages pay a lot of attention to their array implementation at the expense of other containers. Julia does not treat arrays in any special way. The array library is implemented almost completely in Julia itself, and derives its performance from the compiler, just like any other code written in Julia. As such, it\'s also possible to define custom array types by inheriting from AbstractArray. See the manual section on the AbstractArray interface for more details on implementing a custom array type.An array is a collection of objects stored in a multi-dimensional grid. In the most general case, an array may contain objects of type Any. For most computational purposes, arrays should contain objects of a more specific type, such as Float64 or Int32.In general, unlike many other technical computing languages, Julia does not expect programs to be written in a vectorized style for performance. Julia\'s compiler uses type inference and generates optimized code for scalar array indexing, allowing programs to be written in a style that is convenient and readable, without sacrificing performance, and using less memory at times.In Julia, all arguments to functions are passed by reference. Some technical computing languages pass arrays by value, and this is convenient in many cases. In Julia, modifications made to input arrays within a function will be visible in the parent function. The entire Julia array library ensures that inputs are not modified by library functions. User code, if it needs to exhibit similar behavior, should take care to create a copy of inputs that it may modify."
},

{
    "location": "manual/arrays/#Arrays-1",
    "page": "Multi-dimensional Arrays",
    "title": "Arrays",
    "category": "section",
    "text": ""
},

{
    "location": "manual/arrays/#Basic-Functions-1",
    "page": "Multi-dimensional Arrays",
    "title": "Basic Functions",
    "category": "section",
    "text": "Function Description\neltype(A) the type of the elements contained in A\nlength(A) the number of elements in A\nndims(A) the number of dimensions of A\nsize(A) a tuple containing the dimensions of A\nsize(A,n) the size of A along dimension n\nindices(A) a tuple containing the valid indices of A\nindices(A,n) a range expressing the valid indices along dimension n\neachindex(A) an efficient iterator for visiting each position in A\nstride(A,k) the stride (linear index distance between adjacent elements) along dimension k\nstrides(A) a tuple of the strides in each dimension"
},

{
    "location": "manual/arrays/#Construction-and-Initialization-1",
    "page": "Multi-dimensional Arrays",
    "title": "Construction and Initialization",
    "category": "section",
    "text": "Many functions for constructing and initializing arrays are provided. In the following list of such functions, calls with a dims... argument can either take a single tuple of dimension sizes or a series of dimension sizes passed as a variable number of arguments. Most of these functions also accept a first input T, which is the element type of the array. If the type T is omitted it will default to Float64.Function Description\nArray{T}(dims...) an uninitialized dense Array\nzeros(T, dims...) an Array of all zeros\nzeros(A) an array of all zeros with the same type, element type and shape as A\nones(T, dims...) an Array of all ones\nones(A) an array of all ones with the same type, element type and shape as A\ntrues(dims...) a BitArray with all values true\ntrues(A) a BitArray with all values true and the same shape as A\nfalses(dims...) a BitArray with all values false\nfalses(A) a BitArray with all values false and the same shape as A\nreshape(A, dims...) an array containing the same data as A, but with different dimensions\ncopy(A) copy A\ndeepcopy(A) copy A, recursively copying its elements\nsimilar(A, T, dims...) an uninitialized array of the same type as A (dense, sparse, etc.), but with the specified element type and dimensions. The second and third arguments are both optional, defaulting to the element type and dimensions of A if omitted.\nreinterpret(T, A) an array with the same binary data as A, but with element type T\nrand(T, dims...) an Array with random, iid [1] and uniformly distributed values in the half-open interval 0 1)\nrandn(T, dims...) an Array with random, iid and standard normally distributed values\neye(T, n) n-by-n identity matrix\neye(T, m, n) m-by-n identity matrix\nlinspace(start, stop, n) range of n linearly spaced elements from start to stop\nfill!(A, x) fill the array A with the value x\nfill(x, dims...) an Array filled with the value x[1]: iid, independently and identically distributed.The syntax [A, B, C, ...] constructs a 1-d array (vector) of its arguments. If all arguments have a common promotion type then they get converted to that type using convert()."
},

{
    "location": "manual/arrays/#Concatenation-1",
    "page": "Multi-dimensional Arrays",
    "title": "Concatenation",
    "category": "section",
    "text": "Arrays can be constructed and also concatenated using the following functions:Function Description\ncat(k, A...) concatenate input n-d arrays along the dimension k\nvcat(A...) shorthand for cat(1, A...)\nhcat(A...) shorthand for cat(2, A...)Scalar values passed to these functions are treated as 1-element arrays.The concatenation functions are used so often that they have special syntax:Expression Calls\n[A; B; C; ...] vcat()\n[A B C ...] hcat()\n[A B; C D; ...] hvcat()hvcat() concatenates in both dimension 1 (with semicolons) and dimension 2 (with spaces)."
},

{
    "location": "manual/arrays/#Typed-array-initializers-1",
    "page": "Multi-dimensional Arrays",
    "title": "Typed array initializers",
    "category": "section",
    "text": "An array with a specific element type can be constructed using the syntax T[A, B, C, ...]. This will construct a 1-d array with element type T, initialized to contain elements A, B, C, etc. For example Any[x, y, z] constructs a heterogeneous array that can contain any values.Concatenation syntax can similarly be prefixed with a type to specify the element type of the result.julia> [[1 2] [3 4]]\n1×4 Array{Int64,2}:\n 1  2  3  4\n\njulia> Int8[[1 2] [3 4]]\n1×4 Array{Int8,2}:\n 1  2  3  4"
},

{
    "location": "manual/arrays/#Comprehensions-1",
    "page": "Multi-dimensional Arrays",
    "title": "Comprehensions",
    "category": "section",
    "text": "Comprehensions provide a general and powerful way to construct arrays. Comprehension syntax is similar to set construction notation in mathematics:A = [ F(x,y,...) for x=rx, y=ry, ... ]The meaning of this form is that F(x,y,...) is evaluated with the variables x, y, etc. taking on each value in their given list of values. Values can be specified as any iterable object, but will commonly be ranges like 1:n or 2:(n-1), or explicit arrays of values like [1.2, 3.4, 5.7]. The result is an N-d dense array with dimensions that are the concatenation of the dimensions of the variable ranges rx, ry, etc. and each F(x,y,...) evaluation returns a scalar.The following example computes a weighted average of the current element and its left and right neighbor along a 1-d grid. :julia> x = rand(8)\n8-element Array{Float64,1}:\n 0.843025\n 0.869052\n 0.365105\n 0.699456\n 0.977653\n 0.994953\n 0.41084\n 0.809411\n\njulia> [ 0.25*x[i-1] + 0.5*x[i] + 0.25*x[i+1] for i=2:length(x)-1 ]\n6-element Array{Float64,1}:\n 0.736559\n 0.57468\n 0.685417\n 0.912429\n 0.8446\n 0.656511The resulting array type depends on the types of the computed elements. In order to control the type explicitly, a type can be prepended to the comprehension. For example, we could have requested the result in single precision by writing:Float32[ 0.25*x[i-1] + 0.5*x[i] + 0.25*x[i+1] for i=2:length(x)-1 ]"
},

{
    "location": "manual/arrays/#Generator-Expressions-1",
    "page": "Multi-dimensional Arrays",
    "title": "Generator Expressions",
    "category": "section",
    "text": "Comprehensions can also be written without the enclosing square brackets, producing an object known as a generator. This object can be iterated to produce values on demand, instead of allocating an array and storing them in advance (see Iteration). For example, the following expression sums a series without allocating memory:julia> sum(1/n^2 for n=1:1000)\n1.6439345666815615When writing a generator expression with multiple dimensions inside an argument list, parentheses are needed to separate the generator from subsequent arguments:julia> map(tuple, 1/(i+j) for i=1:2, j=1:2, [1:4;])\nERROR: syntax: invalid iteration specificationAll comma-separated expressions after for are interpreted as ranges. Adding parentheses lets us add a third argument to map:julia> map(tuple, (1/(i+j) for i=1:2, j=1:2), [1 3; 2 4])\n2×2 Array{Tuple{Float64,Int64},2}:\n (0.5, 1)       (0.333333, 3)\n (0.333333, 2)  (0.25, 4)Ranges in generators and comprehensions can depend on previous ranges by writing multiple for keywords:julia> [(i,j) for i=1:3 for j=1:i]\n6-element Array{Tuple{Int64,Int64},1}:\n (1, 1)\n (2, 1)\n (2, 2)\n (3, 1)\n (3, 2)\n (3, 3)In such cases, the result is always 1-d.Generated values can be filtered using the if keyword:julia> [(i,j) for i=1:3 for j=1:i if i+j == 4]\n2-element Array{Tuple{Int64,Int64},1}:\n (2, 2)\n (3, 1)"
},

{
    "location": "manual/arrays/#man-array-indexing-1",
    "page": "Multi-dimensional Arrays",
    "title": "Indexing",
    "category": "section",
    "text": "The general syntax for indexing into an n-dimensional array A is:X = A[I_1, I_2, ..., I_n]where each I_k may be a scalar integer, an array of integers, or any other supported index. This includes Colon (:) to select all indices within the entire dimension, ranges of the form a:c or a:b:c to select contiguous or strided subsections, and arrays of booleans to select elements at their true indices.If all the indices are scalars, then the result X is a single element from the array A. Otherwise, X is an array with the same number of dimensions as the sum of the dimensionalities of all the indices.If all indices are vectors, for example, then the shape of X would be (length(I_1), length(I_2), ..., length(I_n)), with location (i_1, i_2, ..., i_n) of X containing the value A[I_1[i_1], I_2[i_2], ..., I_n[i_n]]. If I_1 is changed to a two-dimensional matrix, then X becomes an n+1-dimensional array of shape (size(I_1, 1), size(I_1, 2), length(I_2), ..., length(I_n)). The matrix adds a dimension. The location (i_1, i_2, i_3, ..., i_{n+1}) contains the value at A[I_1[i_1, i_2], I_2[i_3], ..., I_n[i_{n+1}]]. All dimensions indexed with scalars are dropped. For example, the result of A[2, I, 3] is an array with size size(I). Its ith element is populated by A[2, I[i], 3].As a special part of this syntax, the end keyword may be used to represent the last index of each dimension within the indexing brackets, as determined by the size of the innermost array being indexed. Indexing syntax without the end keyword is equivalent to a call to getindex:X = getindex(A, I_1, I_2, ..., I_n)Example:julia> x = reshape(1:16, 4, 4)\n4×4 Base.ReshapedArray{Int64,2,UnitRange{Int64},Tuple{}}:\n 1  5   9  13\n 2  6  10  14\n 3  7  11  15\n 4  8  12  16\n\njulia> x[2:3, 2:end-1]\n2×2 Array{Int64,2}:\n 6  10\n 7  11\n\njulia> x[1, [2 3; 4 1]]\n2×2 Array{Int64,2}:\n  5  9\n 13  1Empty ranges of the form n:n-1 are sometimes used to indicate the inter-index location between n-1 and n. For example, the searchsorted() function uses this convention to indicate the insertion point of a value not found in a sorted array:julia> a = [1,2,5,6,7];\n\njulia> searchsorted(a, 3)\n3:2"
},

{
    "location": "manual/arrays/#Assignment-1",
    "page": "Multi-dimensional Arrays",
    "title": "Assignment",
    "category": "section",
    "text": "The general syntax for assigning values in an n-dimensional array A is:A[I_1, I_2, ..., I_n] = Xwhere each I_k may be a scalar integer, an array of integers, or any other supported index. This includes Colon (:) to select all indices within the entire dimension, ranges of the form a:c or a:b:c to select contiguous or strided subsections, and arrays of booleans to select elements at their true indices.If X is an array, it must have the same number of elements as the product of the lengths of the indices: prod(length(I_1), length(I_2), ..., length(I_n)). The value in location I_1[i_1], I_2[i_2], ..., I_n[i_n] of A is overwritten with the value X[i_1, i_2, ..., i_n]. If X is not an array, its value is written to all referenced locations of A.Just as in Indexing, the end keyword may be used to represent the last index of each dimension within the indexing brackets, as determined by the size of the array being assigned into. Indexed assignment syntax without the end keyword is equivalent to a call to setindex!():setindex!(A, X, I_1, I_2, ..., I_n)Example:julia> x = collect(reshape(1:9, 3, 3))\n3×3 Array{Int64,2}:\n 1  4  7\n 2  5  8\n 3  6  9\n\njulia> x[1:2, 2:3] = -1\n-1\n\njulia> x\n3×3 Array{Int64,2}:\n 1  -1  -1\n 2  -1  -1\n 3   6   9"
},

{
    "location": "manual/arrays/#man-supported-index-types-1",
    "page": "Multi-dimensional Arrays",
    "title": "Supported index types",
    "category": "section",
    "text": "In the expression A[I_1, I_2, ..., I_n], each I_k may be a scalar index, an array of scalar indices, or an object that represents an array of scalar indices and can be converted to such by to_indices:A scalar index. By default this includes:\nNon-boolean integers\nCartesianIndex{N}s, which behave like an N-tuple of integers spanning multiple dimensions (see below for more details)\nAn array of scalar indices. This includes:\nVectors and multidimensional arrays of integers\nEmpty arrays like [], which select no elements\nRanges of the form a:c or a:b:c, which select contiguous or strided subsections from a to c (inclusive)\nAny custom array of scalar indices that is a subtype of AbstractArray\nArrays of CartesianIndex{N} (see below for more details)\nAn object that represents an array of scalar indices and can be converted to such by to_indices. By default this includes:\nColon() (:), which represents all indices within an entire dimension or across the entire array\nArrays of booleans, which select elements at their true indices (see below for more details)"
},

{
    "location": "manual/arrays/#Cartesian-indices-1",
    "page": "Multi-dimensional Arrays",
    "title": "Cartesian indices",
    "category": "section",
    "text": "The special CartesianIndex{N} object represents a scalar index that behaves like an N-tuple of integers spanning multiple dimensions.  For example:julia> A = reshape(1:32, 4, 4, 2);\n\njulia> A[3, 2, 1]\n7\n\njulia> A[CartesianIndex(3, 2, 1)] == A[3, 2, 1] == 7\ntrueConsidered alone, this may seem relatively trivial; CartesianIndex simply gathers multiple integers together into one object that represents a single multidimensional index. When combined with other indexing forms and iterators that yield CartesianIndexes, however, this can lead directly to very elegant and efficient code. See Iteration below, and for some more advanced examples, see this blog post on multidimensional algorithms and iteration.Arrays of CartesianIndex{N} are also supported. They represent a collection of scalar indices that each span N dimensions, enabling a form of indexing that is sometimes referred to as pointwise indexing. For example, it enables accessing the diagonal elements from the first \"page\" of A from above:julia> page = A[:,:,1]\n4×4 Array{Int64,2}:\n 1  5   9  13\n 2  6  10  14\n 3  7  11  15\n 4  8  12  16\n\njulia> page[[CartesianIndex(1,1),\n             CartesianIndex(2,2),\n             CartesianIndex(3,3),\n             CartesianIndex(4,4)]]\n4-element Array{Int64,1}:\n  1\n  6\n 11\n 16This can be expressed much more simply with dot broadcasting and by combining it with a normal integer index (instead of extracting the first page from A as a separate step). It can even be combined with a : to extract both diagonals from the two pages at the same time:julia> A[CartesianIndex.(indices(A, 1), indices(A, 2)), 1]\n4-element Array{Int64,1}:\n  1\n  6\n 11\n 16\n\njulia> A[CartesianIndex.(indices(A, 1), indices(A, 2)), :]\n4×2 Array{Int64,2}:\n  1  17\n  6  22\n 11  27\n 16  32warning: Warning\nCartesianIndex and arrays of CartesianIndex are not compatible with the end keyword to represent the last index of a dimension. Do not use end in indexing expressions that may contain either CartesianIndex or arrays thereof."
},

{
    "location": "manual/arrays/#Logical-indexing-1",
    "page": "Multi-dimensional Arrays",
    "title": "Logical indexing",
    "category": "section",
    "text": "Often referred to as logical indexing or indexing with a logical mask, indexing by a boolean array selects elements at the indices where its values are true. Indexing by a boolean vector B is effectively the same as indexing by the vector of integers that is returned by find(B). Similarly, indexing by a N-dimensional boolean array is effectively the same as indexing by the vector of CartesianIndex{N}s where its values are true. A logical index must be a vector of the same length as the dimension it indexes into, or it must be the only index provided and match the size and dimensionality of the array it indexes into. It is generally more efficient to use boolean arrays as indices directly instead of first calling find().julia> x = reshape(1:16, 4, 4)\n4×4 Base.ReshapedArray{Int64,2,UnitRange{Int64},Tuple{}}:\n 1  5   9  13\n 2  6  10  14\n 3  7  11  15\n 4  8  12  16\n\njulia> x[[false, true, true, false], :]\n2×4 Array{Int64,2}:\n 2  6  10  14\n 3  7  11  15\n\njulia> mask = map(ispow2, x)\n4×4 Array{Bool,2}:\n  true  false  false  false\n  true  false  false  false\n false  false  false  false\n  true   true  false   true\n\njulia> x[mask]\n5-element Array{Int64,1}:\n  1\n  2\n  4\n  8\n 16"
},

{
    "location": "manual/arrays/#Iteration-1",
    "page": "Multi-dimensional Arrays",
    "title": "Iteration",
    "category": "section",
    "text": "The recommended ways to iterate over a whole array arefor a in A\n    # Do something with the element a\nend\n\nfor i in eachindex(A)\n    # Do something with i and/or A[i]\nendThe first construct is used when you need the value, but not index, of each element. In the second construct, i will be an Int if A is an array type with fast linear indexing; otherwise, it will be a CartesianIndex:julia> A = rand(4,3);\n\njulia> B = view(A, 1:3, 2:3);\n\njulia> for i in eachindex(B)\n           @show i\n       end\ni = CartesianIndex{2}((1, 1))\ni = CartesianIndex{2}((2, 1))\ni = CartesianIndex{2}((3, 1))\ni = CartesianIndex{2}((1, 2))\ni = CartesianIndex{2}((2, 2))\ni = CartesianIndex{2}((3, 2))In contrast with for i = 1:length(A), iterating with eachindex provides an efficient way to iterate over any array type."
},

{
    "location": "manual/arrays/#Array-traits-1",
    "page": "Multi-dimensional Arrays",
    "title": "Array traits",
    "category": "section",
    "text": "If you write a custom AbstractArray type, you can specify that it has fast linear indexing usingBase.IndexStyle(::Type{<:MyArray}) = IndexLinear()This setting will cause eachindex iteration over a MyArray to use integers. If you don\'t specify this trait, the default value IndexCartesian() is used."
},

{
    "location": "manual/arrays/#Array-and-Vectorized-Operators-and-Functions-1",
    "page": "Multi-dimensional Arrays",
    "title": "Array and Vectorized Operators and Functions",
    "category": "section",
    "text": "The following operators are supported for arrays:Unary arithmetic – -, +\nBinary arithmetic – -, +, *, /, \\, ^\nComparison – ==, !=, ≈ (isapprox), ≉Most of the binary arithmetic operators listed above also operate elementwise when one argument is scalar: -, +, and * when either argument is scalar, and / and \\ when the denominator is scalar. For example, [1, 2] + 3 == [4, 5] and [6, 4] / 2 == [3, 2].Additionally, to enable convenient vectorization of mathematical and other operations, Julia provides the dot syntax f.(args...), e.g. sin.(x) or min.(x,y), for elementwise operations over arrays or mixtures of arrays and scalars (a Broadcasting operation); these have the additional advantage of \"fusing\" into a single loop when combined with other dot calls, e.g. sin.(cos.(x)).Also, every binary operator supports a dot version that can be applied to arrays (and combinations of arrays and scalars) in such fused broadcasting operations, e.g. z .== sin.(x .* y).Note that comparisons such as == operate on whole arrays, giving a single boolean answer. Use dot operators like .== for elementwise comparisons. (For comparison operations like <, only the elementwise .< version is applicable to arrays.)Also notice the difference between max.(a,b), which broadcasts max() elementwise over a and b, and maximum(a), which finds the largest value within a. The same relationship holds for min.(a,b) and minimum(a)."
},

{
    "location": "manual/arrays/#Broadcasting-1",
    "page": "Multi-dimensional Arrays",
    "title": "Broadcasting",
    "category": "section",
    "text": "It is sometimes useful to perform element-by-element binary operations on arrays of different sizes, such as adding a vector to each column of a matrix. An inefficient way to do this would be to replicate the vector to the size of the matrix:julia> a = rand(2,1); A = rand(2,3);\n\njulia> repmat(a,1,3)+A\n2×3 Array{Float64,2}:\n 1.20813  1.82068  1.25387\n 1.56851  1.86401  1.67846This is wasteful when dimensions get large, so Julia offers broadcast(), which expands singleton dimensions in array arguments to match the corresponding dimension in the other array without using extra memory, and applies the given function elementwise:julia> broadcast(+, a, A)\n2×3 Array{Float64,2}:\n 1.20813  1.82068  1.25387\n 1.56851  1.86401  1.67846\n\njulia> b = rand(1,2)\n1×2 Array{Float64,2}:\n 0.867535  0.00457906\n\njulia> broadcast(+, a, b)\n2×2 Array{Float64,2}:\n 1.71056  0.847604\n 1.73659  0.873631Dotted operators such as .+ and .* are equivalent to broadcast calls (except that they fuse, as described below). There is also a broadcast!() function to specify an explicit destination (which can also be accessed in a fusing fashion by .= assignment), and functions broadcast_getindex() and broadcast_setindex!() that broadcast the indices before indexing. Moreover, f.(args...) is equivalent to broadcast(f, args...), providing a convenient syntax to broadcast any function (dot syntax). Nested \"dot calls\" f.(...) (including calls to .+ etcetera) automatically fuse into a single broadcast call.Additionally, broadcast() is not limited to arrays (see the function documentation), it also handles tuples and treats any argument that is not an array, tuple or Ref (except for Ptr) as a \"scalar\".julia> convert.(Float32, [1, 2])\n2-element Array{Float32,1}:\n 1.0\n 2.0\n\njulia> ceil.((UInt8,), [1.2 3.4; 5.6 6.7])\n2×2 Array{UInt8,2}:\n 0x02  0x04\n 0x06  0x07\n\njulia> string.(1:3, \". \", [\"First\", \"Second\", \"Third\"])\n3-element Array{String,1}:\n \"1. First\"\n \"2. Second\"\n \"3. Third\""
},

{
    "location": "manual/arrays/#Implementation-1",
    "page": "Multi-dimensional Arrays",
    "title": "Implementation",
    "category": "section",
    "text": "The base array type in Julia is the abstract type AbstractArray{T,N}. It is parametrized by the number of dimensions N and the element type T. AbstractVector and AbstractMatrix are aliases for the 1-d and 2-d cases. Operations on AbstractArray objects are defined using higher level operators and functions, in a way that is independent of the underlying storage. These operations generally work correctly as a fallback for any specific array implementation.The AbstractArray type includes anything vaguely array-like, and implementations of it might be quite different from conventional arrays. For example, elements might be computed on request rather than stored. However, any concrete AbstractArray{T,N} type should generally implement at least size(A) (returning an Int tuple), getindex(A,i) and getindex(A,i1,...,iN); mutable arrays should also implement setindex!(). It is recommended that these operations have nearly constant time complexity, or technically Õ(1) complexity, as otherwise some array functions may be unexpectedly slow. Concrete types should also typically provide a similar(A,T=eltype(A),dims=size(A)) method, which is used to allocate a similar array for copy() and other out-of-place operations. No matter how an AbstractArray{T,N} is represented internally, T is the type of object returned by integer indexing (A[1, ..., 1], when A is not empty) and N should be the length of the tuple returned by size().DenseArray is an abstract subtype of AbstractArray intended to include all arrays that are laid out at regular offsets in memory, and which can therefore be passed to external C and Fortran functions expecting this memory layout. Subtypes should provide a method stride(A,k) that returns the \"stride\" of dimension k: increasing the index of dimension k by 1 should increase the index i of getindex(A,i) by stride(A,k). If a pointer conversion method Base.unsafe_convert(Ptr{T}, A) is provided, the memory layout should correspond in the same way to these strides.The Array type is a specific instance of DenseArray where elements are stored in column-major order (see additional notes in Performance Tips). Vector and Matrix are aliases for the 1-d and 2-d cases. Specific operations such as scalar indexing, assignment, and a few other basic storage-specific operations are all that have to be implemented for Array, so that the rest of the array library can be implemented in a generic manner.SubArray is a specialization of AbstractArray that performs indexing by reference rather than by copying. A SubArray is created with the view() function, which is called the same way as getindex() (with an array and a series of index arguments). The result of view() looks the same as the result of getindex(), except the data is left in place. view() stores the input index vectors in a SubArray object, which can later be used to index the original array indirectly.  By putting the @views macro in front of an expression or block of code, any array[...] slice in that expression will be converted to create a SubArray view instead.StridedVector and StridedMatrix are convenient aliases defined to make it possible for Julia to call a wider range of BLAS and LAPACK functions by passing them either Array or SubArray objects, and thus saving inefficiencies from memory allocation and copying.The following example computes the QR decomposition of a small section of a larger array, without creating any temporaries, and by calling the appropriate LAPACK function with the right leading dimension size and stride parameters.julia> a = rand(10,10)\n10×10 Array{Float64,2}:\n 0.561255   0.226678   0.203391  0.308912   …  0.750307  0.235023   0.217964\n 0.718915   0.537192   0.556946  0.996234      0.666232  0.509423   0.660788\n 0.493501   0.0565622  0.118392  0.493498      0.262048  0.940693   0.252965\n 0.0470779  0.736979   0.264822  0.228787      0.161441  0.897023   0.567641\n 0.343935   0.32327    0.795673  0.452242      0.468819  0.628507   0.511528\n 0.935597   0.991511   0.571297  0.74485    …  0.84589   0.178834   0.284413\n 0.160706   0.672252   0.133158  0.65554       0.371826  0.770628   0.0531208\n 0.306617   0.836126   0.301198  0.0224702     0.39344   0.0370205  0.536062\n 0.890947   0.168877   0.32002   0.486136      0.096078  0.172048   0.77672\n 0.507762   0.573567   0.220124  0.165816      0.211049  0.433277   0.539476\n\njulia> b = view(a, 2:2:8,2:2:4)\n4×2 SubArray{Float64,2,Array{Float64,2},Tuple{StepRange{Int64,Int64},StepRange{Int64,Int64}},false}:\n 0.537192  0.996234\n 0.736979  0.228787\n 0.991511  0.74485\n 0.836126  0.0224702\n\njulia> (q,r) = qr(b);\n\njulia> q\n4×2 Array{Float64,2}:\n -0.338809   0.78934\n -0.464815  -0.230274\n -0.625349   0.194538\n -0.527347  -0.534856\n\njulia> r\n2×2 Array{Float64,2}:\n -1.58553  -0.921517\n  0.0       0.866567"
},

{
    "location": "manual/arrays/#Sparse-Vectors-and-Matrices-1",
    "page": "Multi-dimensional Arrays",
    "title": "Sparse Vectors and Matrices",
    "category": "section",
    "text": "Julia has built-in support for sparse vectors and sparse matrices. Sparse arrays are arrays that contain enough zeros that storing them in a special data structure leads to savings in space and execution time, compared to dense arrays."
},

{
    "location": "manual/arrays/#man-csc-1",
    "page": "Multi-dimensional Arrays",
    "title": "Compressed Sparse Column (CSC) Sparse Matrix Storage",
    "category": "section",
    "text": "In Julia, sparse matrices are stored in the Compressed Sparse Column (CSC) format. Julia sparse matrices have the type SparseMatrixCSC{Tv,Ti}, where Tv is the type of the stored values, and Ti is the integer type for storing column pointers and row indices. The internal representation of SparseMatrixCSC is as follows:struct SparseMatrixCSC{Tv,Ti<:Integer} <: AbstractSparseMatrix{Tv,Ti}\n    m::Int                  # Number of rows\n    n::Int                  # Number of columns\n    colptr::Vector{Ti}      # Column i is in colptr[i]:(colptr[i+1]-1)\n    rowval::Vector{Ti}      # Row indices of stored values\n    nzval::Vector{Tv}       # Stored values, typically nonzeros\nendThe compressed sparse column storage makes it easy and quick to access the elements in the column of a sparse matrix, whereas accessing the sparse matrix by rows is considerably slower. Operations such as insertion of previously unstored entries one at a time in the CSC structure tend to be slow. This is because all elements of the sparse matrix that are beyond the point of insertion have to be moved one place over.All operations on sparse matrices are carefully implemented to exploit the CSC data structure for performance, and to avoid expensive operations.If you have data in CSC format from a different application or library, and wish to import it in Julia, make sure that you use 1-based indexing. The row indices in every column need to be sorted. If your SparseMatrixCSC object contains unsorted row indices, one quick way to sort them is by doing a double transpose.In some applications, it is convenient to store explicit zero values in a SparseMatrixCSC. These are accepted by functions in Base (but there is no guarantee that they will be preserved in mutating operations). Such explicitly stored zeros are treated as structural nonzeros by many routines. The nnz() function returns the number of elements explicitly stored in the sparse data structure, including structural nonzeros. In order to count the exact number of numerical nonzeros, use countnz(), which inspects every stored element of a sparse matrix. dropzeros(), and the in-place dropzeros!(), can be used to remove stored zeros from the sparse matrix.julia> A = sparse([1, 2, 3], [1, 2, 3], [0, 2, 0])\n3×3 SparseMatrixCSC{Int64,Int64} with 3 stored entries:\n  [1, 1]  =  0\n  [2, 2]  =  2\n  [3, 3]  =  0\n\njulia> dropzeros(A)\n3×3 SparseMatrixCSC{Int64,Int64} with 1 stored entry:\n  [2, 2]  =  2"
},

{
    "location": "manual/arrays/#Sparse-Vector-Storage-1",
    "page": "Multi-dimensional Arrays",
    "title": "Sparse Vector Storage",
    "category": "section",
    "text": "Sparse vectors are stored in a close analog to compressed sparse column format for sparse matrices. In Julia, sparse vectors have the type SparseVector{Tv,Ti} where Tv is the type of the stored values and Ti the integer type for the indices. The internal representation is as follows:struct SparseVector{Tv,Ti<:Integer} <: AbstractSparseVector{Tv,Ti}\n    n::Int              # Length of the sparse vector\n    nzind::Vector{Ti}   # Indices of stored values\n    nzval::Vector{Tv}   # Stored values, typically nonzeros\nendAs for SparseMatrixCSC, the SparseVector type can also contain explicitly stored zeros. (See Sparse Matrix Storage.)."
},

{
    "location": "manual/arrays/#Sparse-Vector-and-Matrix-Constructors-1",
    "page": "Multi-dimensional Arrays",
    "title": "Sparse Vector and Matrix Constructors",
    "category": "section",
    "text": "The simplest way to create sparse arrays is to use functions equivalent to the zeros() and eye() functions that Julia provides for working with dense arrays. To produce sparse arrays instead, you can use the same names with an sp prefix:julia> spzeros(3)\n3-element SparseVector{Float64,Int64} with 0 stored entries\n\njulia> speye(3,5)\n3×5 SparseMatrixCSC{Float64,Int64} with 3 stored entries:\n  [1, 1]  =  1.0\n  [2, 2]  =  1.0\n  [3, 3]  =  1.0The sparse() function is often a handy way to construct sparse arrays. For example, to construct a sparse matrix we can input a vector I of row indices, a vector J of column indices, and a vector V of stored values (this is also known as the COO (coordinate) format). sparse(I,J,V) then constructs a sparse matrix such that S[I[k], J[k]] = V[k]. The equivalent sparse vector constructor is sparsevec, which takes the (row) index vector I and the vector V with the stored values and constructs a sparse vector R such that R[I[k]] = V[k].julia> I = [1, 4, 3, 5]; J = [4, 7, 18, 9]; V = [1, 2, -5, 3];\n\njulia> S = sparse(I,J,V)\n5×18 SparseMatrixCSC{Int64,Int64} with 4 stored entries:\n  [1 ,  4]  =  1\n  [4 ,  7]  =  2\n  [5 ,  9]  =  3\n  [3 , 18]  =  -5\n\njulia> R = sparsevec(I,V)\n5-element SparseVector{Int64,Int64} with 4 stored entries:\n  [1]  =  1\n  [3]  =  -5\n  [4]  =  2\n  [5]  =  3The inverse of the sparse() and sparsevec functions is findnz(), which retrieves the inputs used to create the sparse array. There is also a findn function which only returns the index vectors.julia> findnz(S)\n([1, 4, 5, 3], [4, 7, 9, 18], [1, 2, 3, -5])\n\njulia> findn(S)\n([1, 4, 5, 3], [4, 7, 9, 18])\n\njulia> findnz(R)\n([1, 3, 4, 5], [1, -5, 2, 3])\n\njulia> findn(R)\n4-element Array{Int64,1}:\n 1\n 3\n 4\n 5Another way to create a sparse array is to convert a dense array into a sparse array using the sparse() function:julia> sparse(eye(5))\n5×5 SparseMatrixCSC{Float64,Int64} with 5 stored entries:\n  [1, 1]  =  1.0\n  [2, 2]  =  1.0\n  [3, 3]  =  1.0\n  [4, 4]  =  1.0\n  [5, 5]  =  1.0\n\njulia> sparse([1.0, 0.0, 1.0])\n3-element SparseVector{Float64,Int64} with 2 stored entries:\n  [1]  =  1.0\n  [3]  =  1.0You can go in the other direction using the Array constructor. The issparse() function can be used to query if a matrix is sparse.julia> issparse(speye(5))\ntrue"
},

{
    "location": "manual/arrays/#Sparse-matrix-operations-1",
    "page": "Multi-dimensional Arrays",
    "title": "Sparse matrix operations",
    "category": "section",
    "text": "Arithmetic operations on sparse matrices also work as they do on dense matrices. Indexing of, assignment into, and concatenation of sparse matrices work in the same way as dense matrices. Indexing operations, especially assignment, are expensive, when carried out one element at a time. In many cases it may be better to convert the sparse matrix into (I,J,V) format using findnz(), manipulate the values or the structure in the dense vectors (I,J,V), and then reconstruct the sparse matrix."
},

{
    "location": "manual/arrays/#Correspondence-of-dense-and-sparse-methods-1",
    "page": "Multi-dimensional Arrays",
    "title": "Correspondence of dense and sparse methods",
    "category": "section",
    "text": "The following table gives a correspondence between built-in methods on sparse matrices and their corresponding methods on dense matrix types. In general, methods that generate sparse matrices differ from their dense counterparts in that the resulting matrix follows the same sparsity pattern as a given sparse matrix S, or that the resulting sparse matrix has density d, i.e. each matrix element has a probability d of being non-zero.Details can be found in the Sparse Vectors and Matrices section of the standard library reference.Sparse Dense Description\nspzeros(m,n) zeros(m,n) Creates a m-by-n matrix of zeros. (spzeros(m,n) is empty.)\nspones(S) ones(m,n) Creates a matrix filled with ones. Unlike the dense version, spones() has the same sparsity pattern as S.\nspeye(n) eye(n) Creates a n-by-n identity matrix.\nfull(S) sparse(A) Interconverts between dense and sparse formats.\nsprand(m,n,d) rand(m,n) Creates a m-by-n random matrix (of density d) with iid non-zero elements distributed uniformly on the half-open interval 0 1).\nsprandn(m,n,d) randn(m,n) Creates a m-by-n random matrix (of density d) with iid non-zero elements distributed according to the standard normal (Gaussian) distribution.\nsprandn(m,n,d,X) randn(m,n,X) Creates a m-by-n random matrix (of density d) with iid non-zero elements distributed according to the X distribution. (Requires the Distributions package.)"
},

{
    "location": "manual/linear-algebra/#",
    "page": "Linear algebra",
    "title": "Linear algebra",
    "category": "page",
    "text": ""
},

{
    "location": "manual/linear-algebra/#Linear-algebra-1",
    "page": "Linear algebra",
    "title": "Linear algebra",
    "category": "section",
    "text": "In addition to (and as part of) its support for multi-dimensional arrays, Julia provides native implementations of many common and useful linear algebra operations. Basic operations, such as trace, det, and inv are all supported:julia> A = [1 2 3; 4 1 6; 7 8 1]\n3×3 Array{Int64,2}:\n 1  2  3\n 4  1  6\n 7  8  1\n\njulia> trace(A)\n3\n\njulia> det(A)\n104.0\n\njulia> inv(A)\n3×3 Array{Float64,2}:\n -0.451923   0.211538    0.0865385\n  0.365385  -0.192308    0.0576923\n  0.240385   0.0576923  -0.0673077As well as other useful operations, such as finding eigenvalues or eigenvectors:julia> A = [1.5 2 -4; 3 -1 -6; -10 2.3 4]\n3×3 Array{Float64,2}:\n   1.5   2.0  -4.0\n   3.0  -1.0  -6.0\n -10.0   2.3   4.0\n\njulia> eigvals(A)\n3-element Array{Complex{Float64},1}:\n  9.31908+0.0im\n -2.40954+2.72095im\n -2.40954-2.72095im\n\njulia> eigvecs(A)\n3×3 Array{Complex{Float64},2}:\n -0.488645+0.0im  0.182546-0.39813im   0.182546+0.39813im\n -0.540358+0.0im  0.692926+0.0im       0.692926-0.0im\n   0.68501+0.0im  0.254058-0.513301im  0.254058+0.513301imIn addition, Julia provides many factorizations which can be used to speed up problems such as linear solve or matrix exponentiation by pre-factorizing a matrix into a form more amenable (for performance or memory reasons) to the problem. See the documentation on factorize for more information. As an example:julia> A = [1.5 2 -4; 3 -1 -6; -10 2.3 4]\n3×3 Array{Float64,2}:\n   1.5   2.0  -4.0\n   3.0  -1.0  -6.0\n -10.0   2.3   4.0\n\njulia> factorize(A)\nBase.LinAlg.LU{Float64,Array{Float64,2}} with factors L and U:\n[1.0 0.0 0.0; -0.15 1.0 0.0; -0.3 -0.132196 1.0]\n[-10.0 2.3 4.0; 0.0 2.345 -3.4; 0.0 0.0 -5.24947]Since A is not Hermitian, symmetric, triangular, tridiagonal, or bidiagonal, an LU factorization may be the best we can do. Compare with:julia> B = [1.5 2 -4; 2 -1 -3; -4 -3 5]\n3×3 Array{Float64,2}:\n  1.5   2.0  -4.0\n  2.0  -1.0  -3.0\n -4.0  -3.0   5.0\n\njulia> factorize(B)\nBase.LinAlg.BunchKaufman{Float64,Array{Float64,2}}([-1.64286 0.142857 -0.8; 2.0 -2.8 -0.6; -4.0 -3.0 5.0], [1, 2, 3], \'U\', true, false, 0)Here, Julia was able to detect that B is in fact symmetric, and used a more appropriate factorization. Often it\'s possible to write more efficient code for a matrix that is known to have certain properties e.g. it is symmetric, or tridiagonal. Julia provides some special types so that you can \"tag\" matrices as having these properties. For instance:julia> B = [1.5 2 -4; 2 -1 -3; -4 -3 5]\n3×3 Array{Float64,2}:\n  1.5   2.0  -4.0\n  2.0  -1.0  -3.0\n -4.0  -3.0   5.0\n\njulia> sB = Symmetric(B)\n3×3 Symmetric{Float64,Array{Float64,2}}:\n  1.5   2.0  -4.0\n  2.0  -1.0  -3.0\n -4.0  -3.0   5.0sB has been tagged as a matrix that\'s (real) symmetric, so for later operations we might perform on it, such as eigenfactorization or computing matrix-vector products, efficiencies can be found by only referencing half of it. For example:julia> B = [1.5 2 -4; 2 -1 -3; -4 -3 5]\n3×3 Array{Float64,2}:\n  1.5   2.0  -4.0\n  2.0  -1.0  -3.0\n -4.0  -3.0   5.0\n\njulia> sB = Symmetric(B)\n3×3 Symmetric{Float64,Array{Float64,2}}:\n  1.5   2.0  -4.0\n  2.0  -1.0  -3.0\n -4.0  -3.0   5.0\n\njulia> x = [1; 2; 3]\n3-element Array{Int64,1}:\n 1\n 2\n 3\n\njulia> sB\\x\n3-element Array{Float64,1}:\n -1.73913\n -1.1087\n -1.45652The \\ operation here performs the linear solution. Julia\'s parser provides convenient dispatch to specialized methods for the transpose of a matrix left-divided by a vector, or for the various combinations of transpose operations in matrix-matrix solutions. Many of these are further specialized for certain special matrix types. For example, A\\B will end up calling Base.LinAlg.A_ldiv_B! while A\'\\B will end up calling Base.LinAlg.Ac_ldiv_B, even though we used the same left-division operator. This works for matrices too: A.\'\\B.\' would call Base.LinAlg.At_ldiv_Bt. The left-division operator is pretty powerful and it\'s easy to write compact, readable code that is flexible enough to solve all sorts of systems of linear equations."
},

{
    "location": "manual/linear-algebra/#Special-matrices-1",
    "page": "Linear algebra",
    "title": "Special matrices",
    "category": "section",
    "text": "Matrices with special symmetries and structures arise often in linear algebra and are frequently associated with various matrix factorizations. Julia features a rich collection of special matrix types, which allow for fast computation with specialized routines that are specially developed for particular matrix types.The following tables summarize the types of special matrices that have been implemented in Julia, as well as whether hooks to various optimized methods for them in LAPACK are available.Type Description\nHermitian Hermitian matrix\nUpperTriangular Upper triangular matrix\nLowerTriangular Lower triangular matrix\nTridiagonal Tridiagonal matrix\nSymTridiagonal Symmetric tridiagonal matrix\nBidiagonal Upper/lower bidiagonal matrix\nDiagonal Diagonal matrix\nUniformScaling Uniform scaling operator"
},

{
    "location": "manual/linear-algebra/#Elementary-operations-1",
    "page": "Linear algebra",
    "title": "Elementary operations",
    "category": "section",
    "text": "Matrix type + - * \\ Other functions with optimized methods\nHermitian       MV inv(), sqrtm(), expm()\nUpperTriangular     MV MV inv(), det()\nLowerTriangular     MV MV inv(), det()\nSymTridiagonal M M MS MV eigmax(), eigmin()\nTridiagonal M M MS MV  \nBidiagonal M M MS MV  \nDiagonal M M MV MV inv(), det(), logdet(), /()\nUniformScaling M M MVS MVS /()Legend:Key Description\nM (matrix) An optimized method for matrix-matrix operations is available\nV (vector) An optimized method for matrix-vector operations is available\nS (scalar) An optimized method for matrix-scalar operations is available"
},

{
    "location": "manual/linear-algebra/#Matrix-factorizations-1",
    "page": "Linear algebra",
    "title": "Matrix factorizations",
    "category": "section",
    "text": "Matrix type LAPACK eig() eigvals() eigvecs() svd() svdvals()\nHermitian HE   ARI      \nUpperTriangular TR A A A    \nLowerTriangular TR A A A    \nSymTridiagonal ST A ARI AV    \nTridiagonal GT          \nBidiagonal BD       A A\nDiagonal DI   A      Legend:Key Description Example\nA (all) An optimized method to find all the characteristic values and/or vectors is available e.g. eigvals(M)\nR (range) An optimized method to find the ilth through the ihth characteristic values are available eigvals(M, il, ih)\nI (interval) An optimized method to find the characteristic values in the interval [vl, vh] is available eigvals(M, vl, vh)\nV (vectors) An optimized method to find the characteristic vectors corresponding to the characteristic values x=[x1, x2,...] is available eigvecs(M, x)"
},

{
    "location": "manual/linear-algebra/#The-uniform-scaling-operator-1",
    "page": "Linear algebra",
    "title": "The uniform scaling operator",
    "category": "section",
    "text": "A UniformScaling operator represents a scalar times the identity operator, λ*I. The identity operator  I is defined as a constant and is an instance of UniformScaling. The size of these operators are generic and match the other matrix in the binary operations +, -, * and \\. For A+I and A-I this means that A must be square. Multiplication with the identity operator I is a noop (except for checking that the scaling factor is one) and therefore almost without overhead."
},

{
    "location": "manual/linear-algebra/#man-linalg-factorizations-1",
    "page": "Linear algebra",
    "title": "Matrix factorizations",
    "category": "section",
    "text": "Matrix factorizations (a.k.a. matrix decompositions) compute the factorization of a matrix into a product of matrices, and are one of the central concepts in linear algebra.The following table summarizes the types of matrix factorizations that have been implemented in Julia. Details of their associated methods can be found in the Linear Algebra section of the standard library documentation.Type Description\nCholesky Cholesky factorization\nCholeskyPivoted Pivoted Cholesky factorization\nLU LU factorization\nLUTridiagonal LU factorization for Tridiagonal matrices\nUmfpackLU LU factorization for sparse matrices (computed by UMFPack)\nQR QR factorization\nQRCompactWY Compact WY form of the QR factorization\nQRPivoted Pivoted QR factorization\nHessenberg Hessenberg decomposition\nEigen Spectral decomposition\nSVD Singular value decomposition\nGeneralizedSVD Generalized SVD"
},

{
    "location": "manual/networking-and-streams/#",
    "page": "Networking and Streams",
    "title": "Networking and Streams",
    "category": "page",
    "text": ""
},

{
    "location": "manual/networking-and-streams/#Networking-and-Streams-1",
    "page": "Networking and Streams",
    "title": "Networking and Streams",
    "category": "section",
    "text": "Julia provides a rich interface to deal with streaming I/O objects such as terminals, pipes and TCP sockets. This interface, though asynchronous at the system level, is presented in a synchronous manner to the programmer and it is usually unnecessary to think about the underlying asynchronous operation. This is achieved by making heavy use of Julia cooperative threading (coroutine) functionality."
},

{
    "location": "manual/networking-and-streams/#Basic-Stream-I/O-1",
    "page": "Networking and Streams",
    "title": "Basic Stream I/O",
    "category": "section",
    "text": "All Julia streams expose at least a read() and a write() method, taking the stream as their first argument, e.g.:julia> write(STDOUT,\"Hello World\");  # suppress return value 11 with ;\nHello World\njulia> read(STDIN,Char)\n\n\'\\n\': ASCII/Unicode U+000a (category Cc: Other, control)Note that write() returns 11, the number of bytes (in \"Hello World\") written to STDOUT, but this return value is suppressed with the ;.Here Enter was pressed again so that Julia would read the newline. Now, as you can see from this example, write() takes the data to write as its second argument, while read() takes the type of the data to be read as the second argument.For example, to read a simple byte array, we could do:julia> x = zeros(UInt8, 4)\n4-element Array{UInt8,1}:\n 0x00\n 0x00\n 0x00\n 0x00\n\njulia> read!(STDIN, x)\nabcd\n4-element Array{UInt8,1}:\n 0x61\n 0x62\n 0x63\n 0x64However, since this is slightly cumbersome, there are several convenience methods provided. For example, we could have written the above as:julia> read(STDIN,4)\nabcd\n4-element Array{UInt8,1}:\n 0x61\n 0x62\n 0x63\n 0x64or if we had wanted to read the entire line instead:julia> readline(STDIN)\nabcd\n\"abcd\"Note that depending on your terminal settings, your TTY may be line buffered and might thus require an additional enter before the data is sent to Julia.To read every line from STDIN you can use eachline():for line in eachline(STDIN)\n    print(\"Found $line\")\nendor read() if you wanted to read by character instead:while !eof(STDIN)\n    x = read(STDIN, Char)\n    println(\"Found: $x\")\nend"
},

{
    "location": "manual/networking-and-streams/#Text-I/O-1",
    "page": "Networking and Streams",
    "title": "Text I/O",
    "category": "section",
    "text": "Note that the write() method mentioned above operates on binary streams. In particular, values do not get converted to any canonical text representation but are written out as is:julia> write(STDOUT,0x61);  # suppress return value 1 with ;\naNote that a is written to STDOUT by the write() function and that the returned value is 1 (since 0x61 is one byte).For text I/O, use the print() or show() methods, depending on your needs (see the standard library reference for a detailed discussion of the difference between the two):julia> print(STDOUT, 0x61)\n97"
},

{
    "location": "manual/networking-and-streams/#IO-Output-Contextual-Properties-1",
    "page": "Networking and Streams",
    "title": "IO Output Contextual Properties",
    "category": "section",
    "text": "Sometimes IO output can benefit from the ability to pass contextual information into show methods. The IOContext object provides this framework for associating arbitrary metadata with an IO object. For example, showcompact adds a hinting parameter to the IO object that the invoked show method should print a shorter output (if applicable)."
},

{
    "location": "manual/networking-and-streams/#Working-with-Files-1",
    "page": "Networking and Streams",
    "title": "Working with Files",
    "category": "section",
    "text": "Like many other environments, Julia has an open() function, which takes a filename and returns an IOStream object that you can use to read and write things from the file. For example if we have a file, hello.txt, whose contents are Hello, World!:julia> f = open(\"hello.txt\")\nIOStream(<file hello.txt>)\n\njulia> readlines(f)\n1-element Array{String,1}:\n \"Hello, World!\"If you want to write to a file, you can open it with the write (\"w\") flag:julia> f = open(\"hello.txt\",\"w\")\nIOStream(<file hello.txt>)\n\njulia> write(f,\"Hello again.\")\n12If you examine the contents of hello.txt at this point, you will notice that it is empty; nothing has actually been written to disk yet. This is because the IOStream must be closed before the write is actually flushed to disk:julia> close(f)Examining hello.txt again will show its contents have been changed.Opening a file, doing something to its contents, and closing it again is a very common pattern. To make this easier, there exists another invocation of open() which takes a function as its first argument and filename as its second, opens the file, calls the function with the file as an argument, and then closes it again. For example, given a function:function read_and_capitalize(f::IOStream)\n    return uppercase(readstring(f))\nendYou can call:julia> open(read_and_capitalize, \"hello.txt\")\n\"HELLO AGAIN.\"to open hello.txt, call read_and_capitalize on it, close hello.txt and return the capitalized contents.To avoid even having to define a named function, you can use the do syntax, which creates an anonymous function on the fly:julia> open(\"hello.txt\") do f\n           uppercase(readstring(f))\n       end\n\"HELLO AGAIN.\""
},

{
    "location": "manual/networking-and-streams/#A-simple-TCP-example-1",
    "page": "Networking and Streams",
    "title": "A simple TCP example",
    "category": "section",
    "text": "Let\'s jump right in with a simple example involving TCP sockets. Let\'s first create a simple server:julia> @async begin\n           server = listen(2000)\n           while true\n               sock = accept(server)\n               println(\"Hello World\\n\")\n           end\n       end\nTask (runnable) @0x00007fd31dc11ae0To those familiar with the Unix socket API, the method names will feel familiar, though their usage is somewhat simpler than the raw Unix socket API. The first call to listen() will create a server waiting for incoming connections on the specified port (2000) in this case. The same function may also be used to create various other kinds of servers:julia> listen(2000) # Listens on localhost:2000 (IPv4)\nTCPServer(active)\n\njulia> listen(ip\"127.0.0.1\",2000) # Equivalent to the first\nTCPServer(active)\n\njulia> listen(ip\"::1\",2000) # Listens on localhost:2000 (IPv6)\nTCPServer(active)\n\njulia> listen(IPv4(0),2001) # Listens on port 2001 on all IPv4 interfaces\nTCPServer(active)\n\njulia> listen(IPv6(0),2001) # Listens on port 2001 on all IPv6 interfaces\nTCPServer(active)\n\njulia> listen(\"testsocket\") # Listens on a UNIX domain socket/named pipe\nPipeServer(active)Note that the return type of the last invocation is different. This is because this server does not listen on TCP, but rather on a named pipe (Windows) or UNIX domain socket. The difference is subtle and has to do with the accept() and connect() methods. The accept() method retrieves a connection to the client that is connecting on the server we just created, while the connect() function connects to a server using the specified method. The connect() function takes the same arguments as listen(), so, assuming the environment (i.e. host, cwd, etc.) is the same you should be able to pass the same arguments to connect() as you did to listen to establish the connection. So let\'s try that out (after having created the server above):julia> connect(2000)\nTCPSocket(open, 0 bytes waiting)\n\njulia> Hello WorldAs expected we saw \"Hello World\" printed. So, let\'s actually analyze what happened behind the scenes. When we called connect(), we connect to the server we had just created. Meanwhile, the accept function returns a server-side connection to the newly created socket and prints \"Hello World\" to indicate that the connection was successful.A great strength of Julia is that since the API is exposed synchronously even though the I/O is actually happening asynchronously, we didn\'t have to worry callbacks or even making sure that the server gets to run. When we called connect() the current task waited for the connection to be established and only continued executing after that was done. In this pause, the server task resumed execution (because a connection request was now available), accepted the connection, printed the message and waited for the next client. Reading and writing works in the same way. To see this, consider the following simple echo server:julia> @async begin\n           server = listen(2001)\n           while true\n               sock = accept(server)\n               @async while isopen(sock)\n                   write(sock,readline(sock))\n               end\n           end\n       end\nTask (runnable) @0x00007fd31dc12e60\n\njulia> clientside = connect(2001)\nTCPSocket(RawFD(28) open, 0 bytes waiting)\n\njulia> @async while true\n           write(STDOUT,readline(clientside))\n       end\nTask (runnable) @0x00007fd31dc11870\n\njulia> println(clientside,\"Hello World from the Echo Server\")\nHello World from the Echo ServerAs with other streams, use close() to disconnect the socket:julia> close(clientside)"
},

{
    "location": "manual/networking-and-streams/#Resolving-IP-Addresses-1",
    "page": "Networking and Streams",
    "title": "Resolving IP Addresses",
    "category": "section",
    "text": "One of the connect() methods that does not follow the listen() methods is connect(host::String,port), which will attempt to connect to the host given by the host parameter on the port given by the port parameter. It allows you to do things like:julia> connect(\"google.com\",80)\nTCPSocket(RawFD(30) open, 0 bytes waiting)At the base of this functionality is getaddrinfo(), which will do the appropriate address resolution:julia> getaddrinfo(\"google.com\")\nip\"74.125.226.225\""
},

{
    "location": "manual/parallel-computing/#",
    "page": "Parallel Computing",
    "title": "Parallel Computing",
    "category": "page",
    "text": ""
},

{
    "location": "manual/parallel-computing/#Parallel-Computing-1",
    "page": "Parallel Computing",
    "title": "Parallel Computing",
    "category": "section",
    "text": "Most modern computers possess more than one CPU, and several computers can be combined together in a cluster. Harnessing the power of these multiple CPUs allows many computations to be completed more quickly. There are two major factors that influence performance: the speed of the CPUs themselves, and the speed of their access to memory. In a cluster, it\'s fairly obvious that a given CPU will have fastest access to the RAM within the same computer (node). Perhaps more surprisingly, similar issues are relevant on a typical multicore laptop, due to differences in the speed of main memory and the cache. Consequently, a good multiprocessing environment should allow control over the \"ownership\" of a chunk of memory by a particular CPU. Julia provides a multiprocessing environment based on message passing to allow programs to run on multiple processes in separate memory domains at once.Julia\'s implementation of message passing is different from other environments such as MPI [1]. Communication in Julia is generally \"one-sided\", meaning that the programmer needs to explicitly manage only one process in a two-process operation. Furthermore, these operations typically do not look like \"message send\" and \"message receive\" but rather resemble higher-level operations like calls to user functions.Parallel programming in Julia is built on two primitives: remote references and remote calls. A remote reference is an object that can be used from any process to refer to an object stored on a particular process. A remote call is a request by one process to call a certain function on certain arguments on another (possibly the same) process.Remote references come in two flavors: Future and RemoteChannel.A remote call returns a Future to its result. Remote calls return immediately; the process that made the call proceeds to its next operation while the remote call happens somewhere else. You can wait for a remote call to finish by calling wait() on the returned Future, and you can obtain the full value of the result using fetch().On the other hand, RemoteChannel s are rewritable. For example, multiple processes can co-ordinate their processing by referencing the same remote Channel.Each process has an associated identifier. The process providing the interactive Julia prompt always has an id equal to 1. The processes used by default for parallel operations are referred to as \"workers\". When there is only one process, process 1 is considered a worker. Otherwise, workers are considered to be all processes other than process 1.Let\'s try this out. Starting with julia -p n provides n worker processes on the local machine. Generally it makes sense for n to equal the number of CPU cores on the machine.$ ./julia -p 2\n\njulia> r = remotecall(rand, 2, 2, 2)\nFuture(2, 1, 4, Nullable{Any}())\n\njulia> s = @spawnat 2 1 .+ fetch(r)\nFuture(2, 1, 5, Nullable{Any}())\n\njulia> fetch(s)\n2×2 Array{Float64,2}:\n 1.18526  1.50912\n 1.16296  1.60607The first argument to remotecall() is the function to call. Most parallel programming in Julia does not reference specific processes or the number of processes available, but remotecall() is considered a low-level interface providing finer control. The second argument to remotecall() is the id of the process that will do the work, and the remaining arguments will be passed to the function being called.As you can see, in the first line we asked process 2 to construct a 2-by-2 random matrix, and in the second line we asked it to add 1 to it. The result of both calculations is available in the two futures, r and s. The @spawnat macro evaluates the expression in the second argument on the process specified by the first argument.Occasionally you might want a remotely-computed value immediately. This typically happens when you read from a remote object to obtain data needed by the next local operation. The function remotecall_fetch() exists for this purpose. It is equivalent to fetch(remotecall(...)) but is more efficient.julia> remotecall_fetch(getindex, 2, r, 1, 1)\n0.18526337335308085Remember that getindex(r,1,1) is equivalent to r[1,1], so this call fetches the first element of the future r.The syntax of remotecall() is not especially convenient. The macro @spawn makes things easier. It operates on an expression rather than a function, and picks where to do the operation for you:julia> r = @spawn rand(2,2)\nFuture(2, 1, 4, Nullable{Any}())\n\njulia> s = @spawn 1 .+ fetch(r)\nFuture(3, 1, 5, Nullable{Any}())\n\njulia> fetch(s)\n2×2 Array{Float64,2}:\n 1.38854  1.9098\n 1.20939  1.57158Note that we used 1 .+ fetch(r) instead of 1 .+ r. This is because we do not know where the code will run, so in general a fetch() might be required to move r to the process doing the addition. In this case, @spawn is smart enough to perform the computation on the process that owns r, so the fetch() will be a no-op (no work is done).(It is worth noting that @spawn is not built-in but defined in Julia as a macro. It is possible to define your own such constructs.)An important thing to remember is that, once fetched, a Future will cache its value locally. Further fetch() calls do not entail a network hop. Once all referencing Futures have fetched, the remote stored value is deleted."
},

{
    "location": "manual/parallel-computing/#Code-Availability-and-Loading-Packages-1",
    "page": "Parallel Computing",
    "title": "Code Availability and Loading Packages",
    "category": "section",
    "text": "Your code must be available on any process that runs it. For example, type the following into the Julia prompt:julia> function rand2(dims...)\n           return 2*rand(dims...)\n       end\n\njulia> rand2(2,2)\n2×2 Array{Float64,2}:\n 0.153756  0.368514\n 1.15119   0.918912\n\njulia> fetch(@spawn rand2(2,2))\nERROR: RemoteException(2, CapturedException(UndefVarError(Symbol(\"#rand2\"))\n[...]Process 1 knew about the function rand2, but process 2 did not.Most commonly you\'ll be loading code from files or packages, and you have a considerable amount of flexibility in controlling which processes load code. Consider a file, DummyModule.jl, containing the following code:module DummyModule\n\nexport MyType, f\n\nmutable struct MyType\n    a::Int\nend\n\nf(x) = x^2+1\n\nprintln(\"loaded\")\n\nendStarting Julia with julia -p 2, you can use this to verify the following:include(\"DummyModule.jl\") loads the file on just a single process (whichever one executes the statement).\nusing DummyModule causes the module to be loaded on all processes; however, the module is brought into scope only on the one executing the statement.\nAs long as DummyModule is loaded on process 2, commands like\nrr = RemoteChannel(2)\nput!(rr, MyType(7))\nallow you to store an object of type MyType on process 2 even if DummyModule is not in scope on process 2.You can force a command to run on all processes using the @everywhere macro. For example, @everywhere can also be used to directly define a function on all processes:julia> @everywhere id = myid()\n\njulia> remotecall_fetch(()->id, 2)\n2A file can also be preloaded on multiple processes at startup, and a driver script can be used to drive the computation:julia -p <n> -L file1.jl -L file2.jl driver.jlThe Julia process running the driver script in the example above has an id equal to 1, just like a process providing an interactive prompt.The base Julia installation has in-built support for two types of clusters:A local cluster specified with the -p option as shown above.\nA cluster spanning machines using the --machinefile option. This uses a passwordless ssh login to start Julia worker processes (from the same path as the current host) on the specified machines.Functions addprocs(), rmprocs(), workers(), and others are available as a programmatic means of adding, removing and querying the processes in a cluster.Note that workers do not run a .juliarc.jl startup script, nor do they synchronize their global state (such as global variables, new method definitions, and loaded modules) with any of the other running processes.Other types of clusters can be supported by writing your own custom ClusterManager, as described below in the ClusterManagers section."
},

{
    "location": "manual/parallel-computing/#Data-Movement-1",
    "page": "Parallel Computing",
    "title": "Data Movement",
    "category": "section",
    "text": "Sending messages and moving data constitute most of the overhead in a parallel program. Reducing the number of messages and the amount of data sent is critical to achieving performance and scalability. To this end, it is important to understand the data movement performed by Julia\'s various parallel programming constructs.fetch() can be considered an explicit data movement operation, since it directly asks that an object be moved to the local machine. @spawn (and a few related constructs) also moves data, but this is not as obvious, hence it can be called an implicit data movement operation. Consider these two approaches to constructing and squaring a random matrix:Method 1:julia> A = rand(1000,1000);\n\njulia> Bref = @spawn A^2;\n\n[...]\n\njulia> fetch(Bref);Method 2:julia> Bref = @spawn rand(1000,1000)^2;\n\n[...]\n\njulia> fetch(Bref);The difference seems trivial, but in fact is quite significant due to the behavior of @spawn. In the first method, a random matrix is constructed locally, then sent to another process where it is squared. In the second method, a random matrix is both constructed and squared on another process. Therefore the second method sends much less data than the first.In this toy example, the two methods are easy to distinguish and choose from. However, in a real program designing data movement might require more thought and likely some measurement. For example, if the first process needs matrix A then the first method might be better. Or, if computing A is expensive and only the current process has it, then moving it to another process might be unavoidable. Or, if the current process has very little to do between the @spawn and fetch(Bref), it might be better to eliminate the parallelism altogether. Or imagine rand(1000,1000) is replaced with a more expensive operation. Then it might make sense to add another @spawn statement just for this step."
},

{
    "location": "manual/parallel-computing/#Global-variables-1",
    "page": "Parallel Computing",
    "title": "Global variables",
    "category": "section",
    "text": "Expressions executed remotely via @spawn, or closures specified for remote execution using remotecall may refer to global variables. Global bindings under module Main are treated a little differently compared to global bindings in other modules. Consider the following code snippet:A = rand(10,10)\nremotecall_fetch(()->foo(A), 2)Note that A is a global variable defined in the local workspace. Worker 2 does not have a variable called A under Main. The act of shipping the closure ()->foo(A) to worker 2 results in Main.A being defined on 2. Main.A continues to exist on worker 2 even after the call remotecall_fetch returns. Remote calls with embedded global references (under Main module only) manage globals as follows:New global bindings are created on destination workers if they are referenced as part of a remote call.\nGlobal constants are declared as constants on remote nodes too.\nGlobals are re-sent to a destination worker only in the context of a remote call, and then only if its value has changed. Also, the cluster does not synchronize global bindings across nodes. For example:\nA = rand(10,10)\nremotecall_fetch(()->foo(A), 2) # worker 2\nA = rand(10,10)\nremotecall_fetch(()->foo(A), 3) # worker 3\nA = nothing\nExecuting the above snippet results in Main.A on worker 2 having a different value from Main.A on worker 3, while the value of Main.A on node 1 is set to nothing.As you may have realized, while memory associated with globals may be collected when they are reassigned on the master, no such action is taken on the workers as the bindings continue to be valid. clear! can be used to manually reassign specific globals on remote nodes to nothing once they are no longer required. This will release any memory associated with them as part of a regular garbage collection cycle.Thus programs should be careful referencing globals in remote calls. In fact, it is preferable to avoid them altogether if possible. If you must reference globals, consider using let blocks to localize global variables.For example:julia> A = rand(10,10);\n\njulia> remotecall_fetch(()->A, 2);\n\njulia> B = rand(10,10);\n\njulia> let B = B\n           remotecall_fetch(()->B, 2)\n       end;\n\njulia> @spawnat 2 whos();\n\njulia>  From worker 2:                               A    800 bytes  10×10 Array{Float64,2}\n        From worker 2:                            Base               Module\n        From worker 2:                            Core               Module\n        From worker 2:                            Main               ModuleAs can be seen, global variable A is defined on worker 2, but B is captured as a local variable and hence a binding for B does not exist on worker 2."
},

{
    "location": "manual/parallel-computing/#Parallel-Map-and-Loops-1",
    "page": "Parallel Computing",
    "title": "Parallel Map and Loops",
    "category": "section",
    "text": "Fortunately, many useful parallel computations do not require data movement. A common example is a Monte Carlo simulation, where multiple processes can handle independent simulation trials simultaneously. We can use @spawn to flip coins on two processes. First, write the following function in count_heads.jl:function count_heads(n)\n    c::Int = 0\n    for i = 1:n\n        c += rand(Bool)\n    end\n    c\nendThe function count_heads simply adds together n random bits. Here is how we can perform some trials on two machines, and add together the results:julia> @everywhere include(\"count_heads.jl\")\n\njulia> a = @spawn count_heads(100000000)\nFuture(2, 1, 6, Nullable{Any}())\n\njulia> b = @spawn count_heads(100000000)\nFuture(3, 1, 7, Nullable{Any}())\n\njulia> fetch(a)+fetch(b)\n100001564This example demonstrates a powerful and often-used parallel programming pattern. Many iterations run independently over several processes, and then their results are combined using some function. The combination process is called a reduction, since it is generally tensor-rank-reducing: a vector of numbers is reduced to a single number, or a matrix is reduced to a single row or column, etc. In code, this typically looks like the pattern x = f(x,v[i]), where x is the accumulator, f is the reduction function, and the v[i] are the elements being reduced. It is desirable for f to be associative, so that it does not matter what order the operations are performed in.Notice that our use of this pattern with count_heads can be generalized. We used two explicit @spawn statements, which limits the parallelism to two processes. To run on any number of processes, we can use a parallel for loop, which can be written in Julia using @parallel like this:nheads = @parallel (+) for i = 1:200000000\n    Int(rand(Bool))\nendThis construct implements the pattern of assigning iterations to multiple processes, and combining them with a specified reduction (in this case (+)). The result of each iteration is taken as the value of the last expression inside the loop. The whole parallel loop expression itself evaluates to the final answer.Note that although parallel for loops look like serial for loops, their behavior is dramatically different. In particular, the iterations do not happen in a specified order, and writes to variables or arrays will not be globally visible since iterations run on different processes. Any variables used inside the parallel loop will be copied and broadcast to each process.For example, the following code will not work as intended:a = zeros(100000)\n@parallel for i = 1:100000\n    a[i] = i\nendThis code will not initialize all of a, since each process will have a separate copy of it. Parallel for loops like these must be avoided. Fortunately, Shared Arrays can be used to get around this limitation:a = SharedArray{Float64}(10)\n@parallel for i = 1:10\n    a[i] = i\nendUsing \"outside\" variables in parallel loops is perfectly reasonable if the variables are read-only:a = randn(1000)\n@parallel (+) for i = 1:100000\n    f(a[rand(1:end)])\nendHere each iteration applies f to a randomly-chosen sample from a vector a shared by all processes.As you could see, the reduction operator can be omitted if it is not needed. In that case, the loop executes asynchronously, i.e. it spawns independent tasks on all available workers and returns an array of Future immediately without waiting for completion. The caller can wait for the Future completions at a later point by calling fetch() on them, or wait for completion at the end of the loop by prefixing it with @sync, like @sync @parallel for.In some cases no reduction operator is needed, and we merely wish to apply a function to all integers in some range (or, more generally, to all elements in some collection). This is another useful operation called parallel map, implemented in Julia as the pmap() function. For example, we could compute the singular values of several large random matrices in parallel as follows:julia> M = Matrix{Float64}[rand(1000,1000) for i = 1:10];\n\njulia> pmap(svd, M);Julia\'s pmap() is designed for the case where each function call does a large amount of work. In contrast, @parallel for can handle situations where each iteration is tiny, perhaps merely summing two numbers. Only worker processes are used by both pmap() and @parallel for for the parallel computation. In case of @parallel for, the final reduction is done on the calling process."
},

{
    "location": "manual/parallel-computing/#Synchronization-With-Remote-References-1",
    "page": "Parallel Computing",
    "title": "Synchronization With Remote References",
    "category": "section",
    "text": ""
},

{
    "location": "manual/parallel-computing/#Scheduling-1",
    "page": "Parallel Computing",
    "title": "Scheduling",
    "category": "section",
    "text": "Julia\'s parallel programming platform uses Tasks (aka Coroutines) to switch among multiple computations. Whenever code performs a communication operation like fetch() or wait(), the current task is suspended and a scheduler picks another task to run. A task is restarted when the event it is waiting for completes.For many problems, it is not necessary to think about tasks directly. However, they can be used to wait for multiple events at the same time, which provides for dynamic scheduling. In dynamic scheduling, a program decides what to compute or where to compute it based on when other jobs finish. This is needed for unpredictable or unbalanced workloads, where we want to assign more work to processes only when they finish their current tasks.As an example, consider computing the singular values of matrices of different sizes:julia> M = Matrix{Float64}[rand(800,800), rand(600,600), rand(800,800), rand(600,600)];\n\njulia> pmap(svd, M);If one process handles both 800×800 matrices and another handles both 600×600 matrices, we will not get as much scalability as we could. The solution is to make a local task to \"feed\" work to each process when it completes its current task. For example, consider a simple pmap() implementation:function pmap(f, lst)\n    np = nprocs()  # determine the number of processes available\n    n = length(lst)\n    results = Vector{Any}(n)\n    i = 1\n    # function to produce the next work item from the queue.\n    # in this case it\'s just an index.\n    nextidx() = (idx=i; i+=1; idx)\n    @sync begin\n        for p=1:np\n            if p != myid() || np == 1\n                @async begin\n                    while true\n                        idx = nextidx()\n                        if idx > n\n                            break\n                        end\n                        results[idx] = remotecall_fetch(f, p, lst[idx])\n                    end\n                end\n            end\n        end\n    end\n    results\nend@async is similar to @spawn, but only runs tasks on the local process. We use it to create a \"feeder\" task for each process. Each task picks the next index that needs to be computed, then waits for its process to finish, then repeats until we run out of indexes. Note that the feeder tasks do not begin to execute until the main task reaches the end of the @sync block, at which point it surrenders control and waits for all the local tasks to complete before returning from the function. The feeder tasks are able to share state via nextidx() because they all run on the same process. No locking is required, since the threads are scheduled cooperatively and not preemptively. This means context switches only occur at well-defined points: in this case, when remotecall_fetch() is called."
},

{
    "location": "manual/parallel-computing/#Channels-1",
    "page": "Parallel Computing",
    "title": "Channels",
    "category": "section",
    "text": "The section on Tasks in Control Flow discussed the execution of multiple functions in a co-operative manner. Channels can be quite useful to pass data between running tasks, particularly those involving I/O operations.Examples of operations involving I/O include reading/writing to files, accessing web services, executing external programs, etc. In all these cases, overall execution time can be improved if other tasks can be run while a file is being read, or while waiting for an external service/program to complete.A channel can be visualized as a pipe, i.e., it has a write end and read end.Multiple writers in different tasks can write to the same channel concurrently via put!() calls.\nMultiple readers in different tasks can read data concurrently via take!() calls.\nAs an example:\n# Given Channels c1 and c2,\nc1 = Channel(32)\nc2 = Channel(32)\n\n# and a function `foo()` which reads items from from c1, processes the item read\n# and writes a result to c2,\nfunction foo()\n    while true\n        data = take!(c1)\n        [...]               # process data\n        put!(c2, result)    # write out result\n    end\nend\n\n# we can schedule `n` instances of `foo()` to be active concurrently.\nfor _ in 1:n\n    @schedule foo()\nend\nChannels are created via the Channel{T}(sz) constructor. The channel will only hold objects of type T. If the type is not specified, the channel can hold objects of any type. sz refers to the maximum number of elements that can be held in the channel at any time. For example, Channel(32) creates a channel that can hold a maximum of 32 objects of any type. A Channel{MyType}(64) can hold up to 64 objects of MyType at any time.\nIf a Channel is empty, readers (on a take!() call) will block until data is available.\nIf a Channel is full, writers (on a put!() call) will block until space becomes available.\nisready() tests for the presence of any object in the channel, while wait() waits for an object to become available.\nA Channel is in an open state initially. This means that it can be read from and written to freely via take!() and put!() calls. close() closes a Channel. On a closed Channel, put!() will fail. For example:julia> c = Channel(2);\n\njulia> put!(c, 1) # `put!` on an open channel succeeds\n1\n\njulia> close(c);\n\njulia> put!(c, 2) # `put!` on a closed channel throws an exception.\nERROR: InvalidStateException(\"Channel is closed.\",:closed)\n[...]take!() and fetch() (which retrieves but does not remove the value) on a closed channel successfully return any existing values until it is emptied. Continuing the above example:julia> fetch(c) # Any number of `fetch` calls succeed.\n1\n\njulia> fetch(c)\n1\n\njulia> take!(c) # The first `take!` removes the value.\n1\n\njulia> take!(c) # No more data available on a closed channel.\nERROR: InvalidStateException(\"Channel is closed.\",:closed)\n[...]A Channel can be used as an iterable object in a for loop, in which case the loop runs as long as the Channel has data or is open. The loop variable takes on all values added to the Channel. The for loop is terminated once the Channel is closed and emptied.For example, the following would cause the for loop to wait for more data:julia> c = Channel{Int}(10);\n\njulia> foreach(i->put!(c, i), 1:3) # add a few entries\n\njulia> data = [i for i in c]while this will return after reading all data:julia> c = Channel{Int}(10);\n\njulia> foreach(i->put!(c, i), 1:3); # add a few entries\n\njulia> close(c);                    # `for` loops can exit\n\njulia> data = [i for i in c]\n3-element Array{Int64,1}:\n 1\n 2\n 3Consider a simple example using channels for inter-task communication. We start 4 tasks to process data from a single jobs channel. Jobs, identified by an id (job_id), are written to the channel. Each task in this simulation reads a job_id, waits for a random amout of time and writes back a tuple of job_id and the simulated time to the results channel. Finally all the results are printed out.julia> const jobs = Channel{Int}(32);\n\njulia> const results = Channel{Tuple}(32);\n\njulia> function do_work()\n           for job_id in jobs\n               exec_time = rand()\n               sleep(exec_time)                # simulates elapsed time doing actual work\n                                               # typically performed externally.\n               put!(results, (job_id, exec_time))\n           end\n       end;\n\njulia> function make_jobs(n)\n           for i in 1:n\n               put!(jobs, i)\n           end\n       end;\n\njulia> n = 12;\n\njulia> @schedule make_jobs(n); # feed the jobs channel with \"n\" jobs\n\njulia> for i in 1:4 # start 4 tasks to process requests in parallel\n           @schedule do_work()\n       end\n\njulia> @elapsed while n > 0 # print out results\n           job_id, exec_time = take!(results)\n           println(\"$job_id finished in $(round(exec_time,2)) seconds\")\n           n = n - 1\n       end\n4 finished in 0.22 seconds\n3 finished in 0.45 seconds\n1 finished in 0.5 seconds\n7 finished in 0.14 seconds\n2 finished in 0.78 seconds\n5 finished in 0.9 seconds\n9 finished in 0.36 seconds\n6 finished in 0.87 seconds\n8 finished in 0.79 seconds\n10 finished in 0.64 seconds\n12 finished in 0.5 seconds\n11 finished in 0.97 seconds\n0.029772311The current version of Julia multiplexes all tasks onto a single OS thread. Thus, while tasks involving I/O operations benefit from parallel execution, compute bound tasks are effectively executed sequentially on a single OS thread. Future versions of Julia may support scheduling of tasks on multiple threads, in which case compute bound tasks will see benefits of parallel execution too."
},

{
    "location": "manual/parallel-computing/#Remote-References-and-AbstractChannels-1",
    "page": "Parallel Computing",
    "title": "Remote References and AbstractChannels",
    "category": "section",
    "text": "Remote references always refer to an implementation of an AbstractChannel.A concrete implementation of an AbstractChannel (like Channel), is required to implement put!(), take!(), fetch(), isready() and wait(). The remote object referred to by a Future is stored in a Channel{Any}(1), i.e., a Channel of size 1 capable of holding objects of Any type.RemoteChannel, which is rewritable, can point to any type and size of channels, or any other implementation of an AbstractChannel.The constructor RemoteChannel(f::Function, pid)() allows us to construct references to channels holding more than one value of a specific type. f() is a function executed on pid and it must return an AbstractChannel.For example, RemoteChannel(()->Channel{Int}(10), pid), will return a reference to a channel of type Int and size 10. The channel exists on worker pid.Methods put!(), take!(), fetch(), isready() and wait() on a RemoteChannel are proxied onto the backing store on the remote process.RemoteChannel can thus be used to refer to user implemented AbstractChannel objects. A simple example of this is provided in examples/dictchannel.jl which uses a dictionary as its remote store."
},

{
    "location": "manual/parallel-computing/#Channels-and-RemoteChannels-1",
    "page": "Parallel Computing",
    "title": "Channels and RemoteChannels",
    "category": "section",
    "text": "A Channel is local to a process. Worker 2 cannot directly refer to a Channel on worker 3 and vice-versa. A RemoteChannel, however, can put and take values across workers.\nA RemoteChannel can be thought of as a handle to a Channel.\nThe process id, pid, associated with a RemoteChannel identifies the process where the backing store, i.e., the backing Channel exists.\nAny process with a reference to a RemoteChannel can put and take items from the channel. Data is automatically sent to (or retrieved from) the process a RemoteChannel is associated with.\nSerializing  a Channel also serializes any data present in the channel. Deserializing it therefore effectively makes a copy of the original object.\nOn the other hand, serializing a RemoteChannel only involves the serialization of an identifier that identifies the location and instance of Channel referred to by the handle. A deserialized RemoteChannel object (on any worker), therefore also points to the same backing store as the original.The channels example from above can be modified for interprocess communication, as shown below.We start 4 workers to process a single jobs remote channel. Jobs, identified by an id (job_id), are written to the channel. Each remotely executing task in this simulation reads a job_id, waits for a random amount of time and writes back a tuple of job_id, time taken and its own pid to the results channel. Finally all the results are printed out on the master process.julia> addprocs(4); # add worker processes\n\njulia> const jobs = RemoteChannel(()->Channel{Int}(32));\n\njulia> const results = RemoteChannel(()->Channel{Tuple}(32));\n\njulia> @everywhere function do_work(jobs, results) # define work function everywhere\n           while true\n               job_id = take!(jobs)\n               exec_time = rand()\n               sleep(exec_time) # simulates elapsed time doing actual work\n               put!(results, (job_id, exec_time, myid()))\n           end\n       end\n\njulia> function make_jobs(n)\n           for i in 1:n\n               put!(jobs, i)\n           end\n       end;\n\njulia> n = 12;\n\njulia> @schedule make_jobs(n); # feed the jobs channel with \"n\" jobs\n\njulia> for p in workers() # start tasks on the workers to process requests in parallel\n           @async remote_do(do_work, p, jobs, results)\n       end\n\njulia> @elapsed while n > 0 # print out results\n           job_id, exec_time, where = take!(results)\n           println(\"$job_id finished in $(round(exec_time,2)) seconds on worker $where\")\n           n = n - 1\n       end\n1 finished in 0.18 seconds on worker 4\n2 finished in 0.26 seconds on worker 5\n6 finished in 0.12 seconds on worker 4\n7 finished in 0.18 seconds on worker 4\n5 finished in 0.35 seconds on worker 5\n4 finished in 0.68 seconds on worker 2\n3 finished in 0.73 seconds on worker 3\n11 finished in 0.01 seconds on worker 3\n12 finished in 0.02 seconds on worker 3\n9 finished in 0.26 seconds on worker 5\n8 finished in 0.57 seconds on worker 4\n10 finished in 0.58 seconds on worker 2\n0.055971741"
},

{
    "location": "manual/parallel-computing/#Remote-References-and-Distributed-Garbage-Collection-1",
    "page": "Parallel Computing",
    "title": "Remote References and Distributed Garbage Collection",
    "category": "section",
    "text": "Objects referred to by remote references can be freed only when all held references in the cluster are deleted.The node where the value is stored keeps track of which of the workers have a reference to it. Every time a RemoteChannel or a (unfetched) Future is serialized to a worker, the node pointed to by the reference is notified. And every time a RemoteChannel or a (unfetched) Future is garbage collected locally, the node owning the value is again notified.The notifications are done via sending of \"tracking\" messages–an \"add reference\" message when a reference is serialized to a different process and a \"delete reference\" message when a reference is locally garbage collected.Since Futures are write-once and cached locally, the act of fetch()ing a Future also updates reference tracking information on the node owning the value.The node which owns the value frees it once all references to it are cleared.With Futures, serializing an already fetched Future to a different node also sends the value since the original remote store may have collected the value by this time.It is important to note that when an object is locally garbage collected depends on the size of the object and the current memory pressure in the system.In case of remote references, the size of the local reference object is quite small, while the value stored on the remote node may be quite large. Since the local object may not be collected immediately, it is a good practice to explicitly call finalize() on local instances of a RemoteChannel, or on unfetched Futures. Since calling fetch() on a Future also removes its reference from the remote store, this is not required on fetched Futures. Explicitly calling finalize() results in an immediate message sent to the remote node to go ahead and remove its reference to the value.Once finalized, a reference becomes invalid and cannot be used in any further calls."
},

{
    "location": "manual/parallel-computing/#man-shared-arrays-1",
    "page": "Parallel Computing",
    "title": "Shared Arrays",
    "category": "section",
    "text": "Shared Arrays use system shared memory to map the same array across many processes. While there are some similarities to a DArray, the behavior of a SharedArray is quite different. In a DArray, each process has local access to just a chunk of the data, and no two processes share the same chunk; in contrast, in a SharedArray each \"participating\" process has access to the entire array.  A SharedArray is a good choice when you want to have a large amount of data jointly accessible to two or more processes on the same machine.SharedArray indexing (assignment and accessing values) works just as with regular arrays, and is efficient because the underlying memory is available to the local process. Therefore, most algorithms work naturally on SharedArrays, albeit in single-process mode. In cases where an algorithm insists on an Array input, the underlying array can be retrieved from a SharedArray by calling sdata(). For other AbstractArray types, sdata() just returns the object itself, so it\'s safe to use sdata() on any Array-type object.The constructor for a shared array is of the form:SharedArray{T,N}(dims::NTuple; init=false, pids=Int[])which creates an N-dimensional shared array of a bits type T and size dims across the processes specified by pids. Unlike distributed arrays, a shared array is accessible only from those participating workers specified by the pids named argument (and the creating process too, if it is on the same host).If an init function, of signature initfn(S::SharedArray), is specified, it is called on all the participating workers. You can specify that each worker runs the init function on a distinct portion of the array, thereby parallelizing initialization.Here\'s a brief example:julia> addprocs(3)\n3-element Array{Int64,1}:\n 2\n 3\n 4\n\njulia> S = SharedArray{Int,2}((3,4), init = S -> S[Base.localindexes(S)] = myid())\n3×4 SharedArray{Int64,2}:\n 2  2  3  4\n 2  3  3  4\n 2  3  4  4\n\njulia> S[3,2] = 7\n7\n\njulia> S\n3×4 SharedArray{Int64,2}:\n 2  2  3  4\n 2  3  3  4\n 2  7  4  4Base.localindexes() provides disjoint one-dimensional ranges of indexes, and is sometimes convenient for splitting up tasks among processes. You can, of course, divide the work any way you wish:julia> S = SharedArray{Int,2}((3,4), init = S -> S[indexpids(S):length(procs(S)):length(S)] = myid())\n3×4 SharedArray{Int64,2}:\n 2  2  2  2\n 3  3  3  3\n 4  4  4  4Since all processes have access to the underlying data, you do have to be careful not to set up conflicts. For example:@sync begin\n    for p in procs(S)\n        @async begin\n            remotecall_wait(fill!, p, S, p)\n        end\n    end\nendwould result in undefined behavior. Because each process fills the entire array with its own pid, whichever process is the last to execute (for any particular element of S) will have its pid retained.As a more extended and complex example, consider running the following \"kernel\" in parallel:q[i,j,t+1] = q[i,j,t] + u[i,j,t]In this case, if we try to split up the work using a one-dimensional index, we are likely to run into trouble: if q[i,j,t] is near the end of the block assigned to one worker and q[i,j,t+1] is near the beginning of the block assigned to another, it\'s very likely that q[i,j,t] will not be ready at the time it\'s needed for computing q[i,j,t+1]. In such cases, one is better off chunking the array manually. Let\'s split along the second dimension. Define a function that returns the (irange, jrange) indexes assigned to this worker:julia> @everywhere function myrange(q::SharedArray)\n           idx = indexpids(q)\n           if idx == 0 # This worker is not assigned a piece\n               return 1:0, 1:0\n           end\n           nchunks = length(procs(q))\n           splits = [round(Int, s) for s in linspace(0,size(q,2),nchunks+1)]\n           1:size(q,1), splits[idx]+1:splits[idx+1]\n       endNext, define the kernel:julia> @everywhere function advection_chunk!(q, u, irange, jrange, trange)\n           @show (irange, jrange, trange)  # display so we can see what\'s happening\n           for t in trange, j in jrange, i in irange\n               q[i,j,t+1] = q[i,j,t] + u[i,j,t]\n           end\n           q\n       endWe also define a convenience wrapper for a SharedArray implementationjulia> @everywhere advection_shared_chunk!(q, u) =\n           advection_chunk!(q, u, myrange(q)..., 1:size(q,3)-1)Now let\'s compare three different versions, one that runs in a single process:julia> advection_serial!(q, u) = advection_chunk!(q, u, 1:size(q,1), 1:size(q,2), 1:size(q,3)-1);one that uses @parallel:julia> function advection_parallel!(q, u)\n           for t = 1:size(q,3)-1\n               @sync @parallel for j = 1:size(q,2)\n                   for i = 1:size(q,1)\n                       q[i,j,t+1]= q[i,j,t] + u[i,j,t]\n                   end\n               end\n           end\n           q\n       end;and one that delegates in chunks:julia> function advection_shared!(q, u)\n           @sync begin\n               for p in procs(q)\n                   @async remotecall_wait(advection_shared_chunk!, p, q, u)\n               end\n           end\n           q\n       end;If we create SharedArrays and time these functions, we get the following results (with julia -p 4):julia> q = SharedArray{Float64,3}((500,500,500));\n\njulia> u = SharedArray{Float64,3}((500,500,500));Run the functions once to JIT-compile and @time them on the second run:julia> @time advection_serial!(q, u);\n(irange,jrange,trange) = (1:500,1:500,1:499)\n 830.220 milliseconds (216 allocations: 13820 bytes)\n\njulia> @time advection_parallel!(q, u);\n   2.495 seconds      (3999 k allocations: 289 MB, 2.09% gc time)\n\njulia> @time advection_shared!(q,u);\n        From worker 2:       (irange,jrange,trange) = (1:500,1:125,1:499)\n        From worker 4:       (irange,jrange,trange) = (1:500,251:375,1:499)\n        From worker 3:       (irange,jrange,trange) = (1:500,126:250,1:499)\n        From worker 5:       (irange,jrange,trange) = (1:500,376:500,1:499)\n 238.119 milliseconds (2264 allocations: 169 KB)The biggest advantage of advection_shared! is that it minimizes traffic among the workers, allowing each to compute for an extended time on the assigned piece."
},

{
    "location": "manual/parallel-computing/#Shared-Arrays-and-Distributed-Garbage-Collection-1",
    "page": "Parallel Computing",
    "title": "Shared Arrays and Distributed Garbage Collection",
    "category": "section",
    "text": "Like remote references, shared arrays are also dependent on garbage collection on the creating node to release references from all participating workers. Code which creates many short lived shared array objects would benefit from explicitly finalizing these objects as soon as possible. This results in both memory and file handles mapping the shared segment being released sooner."
},

{
    "location": "manual/parallel-computing/#ClusterManagers-1",
    "page": "Parallel Computing",
    "title": "ClusterManagers",
    "category": "section",
    "text": "The launching, management and networking of Julia processes into a logical cluster is done via cluster managers. A ClusterManager is responsible forlaunching worker processes in a cluster environment\nmanaging events during the lifetime of each worker\noptionally, providing data transportA Julia cluster has the following characteristics:The initial Julia process, also called the master, is special and has an id of 1.\nOnly the master process can add or remove worker processes.\nAll processes can directly communicate with each other.Connections between workers (using the in-built TCP/IP transport) is established in the following manner:addprocs() is called on the master process with a ClusterManager object.\naddprocs() calls the appropriate launch() method which spawns required number of worker processes on appropriate machines.\nEach worker starts listening on a free port and writes out its host and port information to STDOUT.\nThe cluster manager captures the STDOUT of each worker and makes it available to the master process.\nThe master process parses this information and sets up TCP/IP connections to each worker.\nEvery worker is also notified of other workers in the cluster.\nEach worker connects to all workers whose id is less than the worker\'s own id.\nIn this way a mesh network is established, wherein every worker is directly connected with every other worker.While the default transport layer uses plain TCPSocket, it is possible for a Julia cluster to provide its own transport.Julia provides two in-built cluster managers:LocalManager, used when addprocs() or addprocs(np::Integer) are called\nSSHManager, used when addprocs(hostnames::Array) is called with a list of hostnamesLocalManager is used to launch additional workers on the same host, thereby leveraging multi-core and multi-processor hardware.Thus, a minimal cluster manager would need to:be a subtype of the abstract ClusterManager\nimplement launch(), a method responsible for launching new workers\nimplement manage(), which is called at various events during a worker\'s lifetime (for example, sending an interrupt signal)addprocs(manager::FooManager) requires FooManager to implement:function launch(manager::FooManager, params::Dict, launched::Array, c::Condition)\n    [...]\nend\n\nfunction manage(manager::FooManager, id::Integer, config::WorkerConfig, op::Symbol)\n    [...]\nendAs an example let us see how the LocalManager, the manager responsible for starting workers on the same host, is implemented:struct LocalManager <: ClusterManager\n    np::Integer\nend\n\nfunction launch(manager::LocalManager, params::Dict, launched::Array, c::Condition)\n    [...]\nend\n\nfunction manage(manager::LocalManager, id::Integer, config::WorkerConfig, op::Symbol)\n    [...]\nendThe launch() method takes the following arguments:manager::ClusterManager: the cluster manager that addprocs() is called with\nparams::Dict: all the keyword arguments passed to addprocs()\nlaunched::Array: the array to append one or more WorkerConfig objects to\nc::Condition: the condition variable to be notified as and when workers are launchedThe launch() method is called asynchronously in a separate task. The termination of this task signals that all requested workers have been launched. Hence the launch() function MUST exit as soon as all the requested workers have been launched.Newly launched workers are connected to each other, and the master process, in an all-to-all manner. Specifying the command argument --worker <cookie> results in the launched processes initializing themselves as workers and connections being set up via TCP/IP sockets. Optionally, --bind-to bind_addr[:port] may also be specified to enable other workers to connect to it at the specified bind_addr and port. This is useful for multi-homed hosts.As an example of a non-TCP/IP transport, an implementation may choose to use MPI, in which case --worker must NOT be specified. Instead, newly launched workers should call init_worker(cookie) before using any of the parallel constructs.For every worker launched, the launch() method must add a WorkerConfig object (with appropriate fields initialized) to launchedmutable struct WorkerConfig\n    # Common fields relevant to all cluster managers\n    io::Nullable{IO}\n    host::Nullable{AbstractString}\n    port::Nullable{Integer}\n\n    # Used when launching additional workers at a host\n    count::Nullable{Union{Int, Symbol}}\n    exename::Nullable{AbstractString}\n    exeflags::Nullable{Cmd}\n\n    # External cluster managers can use this to store information at a per-worker level\n    # Can be a dict if multiple fields need to be stored.\n    userdata::Nullable{Any}\n\n    # SSHManager / SSH tunnel connections to workers\n    tunnel::Nullable{Bool}\n    bind_addr::Nullable{AbstractString}\n    sshflags::Nullable{Cmd}\n    max_parallel::Nullable{Integer}\n\n    connect_at::Nullable{Any}\n\n    [...]\nendMost of the fields in WorkerConfig are used by the inbuilt managers. Custom cluster managers would typically specify only io or host / port:If io is specified, it is used to read host/port information. A Julia worker prints out its bind address and port at startup. This allows Julia workers to listen on any free port available instead of requiring worker ports to be configured manually.\nIf io is not specified, host and port are used to connect.\ncount, exename and exeflags are relevant for launching additional workers from a worker. For example, a cluster manager may launch a single worker per node, and use that to launch additional workers.\ncount with an integer value n will launch a total of n workers.\ncount with a value of :auto will launch as many workers as the number of cores on that machine.\nexename is the name of the julia executable including the full path.\nexeflags should be set to the required command line arguments for new workers.\ntunnel, bind_addr, sshflags and max_parallel are used when a ssh tunnel is required to connect to the workers from the master process.\nuserdata is provided for custom cluster managers to store their own worker-specific information.manage(manager::FooManager, id::Integer, config::WorkerConfig, op::Symbol) is called at different times during the worker\'s lifetime with appropriate op values:with :register/:deregister when a worker is added / removed from the Julia worker pool.\nwith :interrupt when interrupt(workers) is called. The ClusterManager should signal the appropriate worker with an interrupt signal.\nwith :finalize for cleanup purposes."
},

{
    "location": "manual/parallel-computing/#Cluster-Managers-with-Custom-Transports-1",
    "page": "Parallel Computing",
    "title": "Cluster Managers with Custom Transports",
    "category": "section",
    "text": "Replacing the default TCP/IP all-to-all socket connections with a custom transport layer is a little more involved. Each Julia process has as many communication tasks as the workers it is connected to. For example, consider a Julia cluster of 32 processes in an all-to-all mesh network:Each Julia process thus has 31 communication tasks.\nEach task handles all incoming messages from a single remote worker in a message-processing loop.\nThe message-processing loop waits on an IO object (for example, a TCPSocket in the default implementation), reads an entire message, processes it and waits for the next one.\nSending messages to a process is done directly from any Julia task–not just communication tasks–again, via the appropriate IO object.Replacing the default transport requires the new implementation to set up connections to remote workers and to provide appropriate IO objects that the message-processing loops can wait on. The manager-specific callbacks to be implemented are:connect(manager::FooManager, pid::Integer, config::WorkerConfig)\nkill(manager::FooManager, pid::Int, config::WorkerConfig)The default implementation (which uses TCP/IP sockets) is implemented as connect(manager::ClusterManager, pid::Integer, config::WorkerConfig).connect should return a pair of IO objects, one for reading data sent from worker pid, and the other to write data that needs to be sent to worker pid. Custom cluster managers can use an in-memory BufferStream as the plumbing to proxy data between the custom, possibly non-IO transport and Julia\'s in-built parallel infrastructure.A BufferStream is an in-memory IOBuffer which behaves like an IO–it is a stream which can be handled asynchronously.Folder examples/clustermanager/0mq contains an example of using ZeroMQ to connect Julia workers in a star topology with a 0MQ broker in the middle. Note: The Julia processes are still all logically connected to each other–any worker can message any other worker directly without any awareness of 0MQ being used as the transport layer.When using custom transports:Julia workers must NOT be started with --worker. Starting with --worker will result in the newly launched workers defaulting to the TCP/IP socket transport implementation.\nFor every incoming logical connection with a worker, Base.process_messages(rd::IO, wr::IO)() must be called. This launches a new task that handles reading and writing of messages from/to the worker represented by the IO objects.\ninit_worker(cookie, manager::FooManager) MUST be called as part of worker process initialization.\nField connect_at::Any in WorkerConfig can be set by the cluster manager when launch() is called. The value of this field is passed in in all connect() callbacks. Typically, it carries information on how to connect to a worker. For example, the TCP/IP socket transport uses this field to specify the (host, port) tuple at which to connect to a worker.kill(manager, pid, config) is called to remove a worker from the cluster. On the master process, the corresponding IO objects must be closed by the implementation to ensure proper cleanup. The default implementation simply executes an exit() call on the specified remote worker.examples/clustermanager/simple is an example that shows a simple implementation using UNIX domain sockets for cluster setup."
},

{
    "location": "manual/parallel-computing/#Network-Requirements-for-LocalManager-and-SSHManager-1",
    "page": "Parallel Computing",
    "title": "Network Requirements for LocalManager and SSHManager",
    "category": "section",
    "text": "Julia clusters are designed to be executed on already secured environments on infrastructure such as local laptops, departmental clusters, or even the cloud. This section covers network security requirements for the inbuilt LocalManager and SSHManager:The master process does not listen on any port. It only connects out to the workers.\nEach worker binds to only one of the local interfaces and listens on the first free port starting from 9009.\nLocalManager, used by addprocs(N), by default binds only to the loopback interface. This means that workers started later on remote hosts (or by anyone with malicious intentions) are unable to connect to the cluster. An addprocs(4) followed by an addprocs([\"remote_host\"]) will fail. Some users may need to create a cluster comprising their local system and a few remote systems. This can be done by explicitly requesting LocalManager to bind to an external network interface via the restrict keyword argument: addprocs(4; restrict=false).\nSSHManager, used by addprocs(list_of_remote_hosts), launches workers on remote hosts via SSH. By default SSH is only used to launch Julia workers. Subsequent master-worker and worker-worker connections use plain, unencrypted TCP/IP sockets. The remote hosts must have passwordless login enabled. Additional SSH flags or credentials may be specified via keyword argument sshflags.\naddprocs(list_of_remote_hosts; tunnel=true, sshflags=<ssh keys and other flags>) is useful when we wish to use SSH connections for master-worker too. A typical scenario for this is a local laptop running the Julia REPL (i.e., the master) with the rest of the cluster on the cloud, say on Amazon EC2. In this case only port 22 needs to be opened at the remote cluster coupled with SSH client authenticated via public key infrastructure (PKI). Authentication credentials can be supplied via sshflags, for example sshflags=`-e <keyfile>`.\nNote that worker-worker connections are still plain TCP and the local security policy on the remote cluster must allow for free connections between worker nodes, at least for ports 9009 and above.\nSecuring and encrypting all worker-worker traffic (via SSH) or encrypting individual messages can be done via a custom ClusterManager."
},

{
    "location": "manual/parallel-computing/#Cluster-Cookie-1",
    "page": "Parallel Computing",
    "title": "Cluster Cookie",
    "category": "section",
    "text": "All processes in a cluster share the same cookie which, by default, is a randomly generated string on the master process:Base.cluster_cookie() returns the cookie, while Base.cluster_cookie(cookie)() sets it and returns the new cookie.\nAll connections are authenticated on both sides to ensure that only workers started by the master are allowed to connect to each other.\nThe cookie must be passed to the workers at startup via argument --worker <cookie>. Custom ClusterManagers can retrieve the cookie on the master by calling Base.cluster_cookie(). Cluster managers not using the default TCP/IP transport (and hence not specifying --worker) must call init_worker(cookie, manager) with the same cookie as on the master.Note that environments requiring higher levels of security can implement this via a custom ClusterManager. For example, cookies can be pre-shared and hence not specified as a startup argument."
},

{
    "location": "manual/parallel-computing/#Specifying-Network-Topology-(Experimental)-1",
    "page": "Parallel Computing",
    "title": "Specifying Network Topology (Experimental)",
    "category": "section",
    "text": "The keyword argument topology passed to addprocs is used to specify how the workers must be connected to each other::all_to_all, the default: all workers are connected to each other.\n:master_slave: only the driver process, i.e. pid 1, has connections to the workers.\n:custom: the launch method of the cluster manager specifies the connection topology via the fields ident and connect_idents in WorkerConfig. A worker with a cluster-manager-provided identity ident will connect to all workers specified in connect_idents.Currently, sending a message between unconnected workers results in an error. This behaviour, as with the functionality and interface, should be considered experimental in nature and may change in future releases."
},

{
    "location": "manual/parallel-computing/#Multi-Threading-(Experimental)-1",
    "page": "Parallel Computing",
    "title": "Multi-Threading (Experimental)",
    "category": "section",
    "text": "In addition to tasks, remote calls, and remote references, Julia from v0.5 forwards will natively support multi-threading. Note that this section is experimental and the interfaces may change in the future."
},

{
    "location": "manual/parallel-computing/#Setup-1",
    "page": "Parallel Computing",
    "title": "Setup",
    "category": "section",
    "text": "By default, Julia starts up with a single thread of execution. This can be verified by using the command Threads.nthreads():julia> Threads.nthreads()\n1The number of threads Julia starts up with is controlled by an environment variable called JULIA_NUM_THREADS. Now, let\'s start up Julia with 4 threads:export JULIA_NUM_THREADS=4(The above command works on bourne shells on Linux and OSX. Note that if you\'re using a C shell on these platforms, you should use the keyword set instead of export. If you\'re on Windows, start up the command line in the location of julia.exe and use set instead of export.)Let\'s verify there are 4 threads at our disposal.julia> Threads.nthreads()\n4But we are currently on the master thread. To check, we use the command Threads.threadid()julia> Threads.threadid()\n1"
},

{
    "location": "manual/parallel-computing/#The-@threads-Macro-1",
    "page": "Parallel Computing",
    "title": "The @threads Macro",
    "category": "section",
    "text": "Let\'s work a simple example using our native threads. Let us create an array of zeros:julia> a = zeros(10)\n10-element Array{Float64,1}:\n 0.0\n 0.0\n 0.0\n 0.0\n 0.0\n 0.0\n 0.0\n 0.0\n 0.0\n 0.0Let us operate on this array simultaneously using 4 threads. We\'ll have each thread write its thread ID into each location.Julia supports parallel loops using the Threads.@threads macro. This macro is affixed in front of a for loop to indicate to Julia that the loop is a multi-threaded region:julia> Threads.@threads for i = 1:10\n           a[i] = Threads.threadid()\n       endThe iteration space is split amongst the threads, after which each thread writes its thread ID to its assigned locations:julia> a\n10-element Array{Float64,1}:\n 1.0\n 1.0\n 1.0\n 2.0\n 2.0\n 2.0\n 3.0\n 3.0\n 4.0\n 4.0Note that Threads.@threads does not have an optional reduction parameter like @parallel."
},

{
    "location": "manual/parallel-computing/#@threadcall-(Experimental)-1",
    "page": "Parallel Computing",
    "title": "@threadcall (Experimental)",
    "category": "section",
    "text": "All I/O tasks, timers, REPL commands, etc are multiplexed onto a single OS thread via an event loop. A patched version of libuv (http://docs.libuv.org/en/v1.x/) provides this functionality. Yield points provide for co-operatively scheduling multiple tasks onto the same OS thread. I/O tasks and timers yield implicitly while waiting for the event to occur. Calling yield() explicitly allows for other tasks to be scheduled.Thus, a task executing a ccall effectively prevents the Julia scheduler from executing any other tasks till the call returns. This is true for all calls into external libraries. Exceptions are calls into custom C code that call back into Julia (which may then yield) or C code that calls jl_yield() (C equivalent of yield()).Note that while Julia code runs on a single thread (by default), libraries used by Julia may launch their own internal threads. For example, the BLAS library may start as many threads as there are cores on a machine.The @threadcall macro addresses scenarios where we do not want a ccall to block the main Julia event loop. It schedules a C function for execution in a separate thread. A threadpool with a default size of 4 is used for this. The size of the threadpool is controlled via environment variable UV_THREADPOOL_SIZE. While waiting for a free thread, and during function execution once a thread is available, the requesting task (on the main Julia event loop) yields to other tasks. Note that @threadcall does not return till the execution is complete. From a user point of view, it is therefore a blocking call like other Julia APIs.It is very important that the called function does not call back into Julia.@threadcall may be removed/changed in future versions of Julia.[1]: In this context, MPI refers to the MPI-1 standard. Beginning with MPI-2, the MPI standards committee introduced a new set of communication mechanisms, collectively referred to as Remote Memory Access (RMA). The motivation for adding RMA to the MPI standard was to facilitate one-sided communication patterns. For additional information on the latest MPI standard, see http://mpi-forum.org/docs."
},

{
    "location": "manual/dates/#",
    "page": "Date and DateTime",
    "title": "Date and DateTime",
    "category": "page",
    "text": ""
},

{
    "location": "manual/dates/#Date-and-DateTime-1",
    "page": "Date and DateTime",
    "title": "Date and DateTime",
    "category": "section",
    "text": "CurrentModule = Base.DatesThe Dates module provides two types for working with dates: Date and DateTime, representing day and millisecond precision, respectively; both are subtypes of the abstract TimeType. The motivation for distinct types is simple: some operations are much simpler, both in terms of code and mental reasoning, when the complexities of greater precision don\'t have to be dealt with. For example, since the Date type only resolves to the precision of a single date (i.e. no hours, minutes, or seconds), normal considerations for time zones, daylight savings/summer time, and leap seconds are unnecessary and avoided.Both Date and DateTime are basically immutable Int64 wrappers. The single instant field of either type is actually a UTInstant{P} type, which represents a continuously increasing machine timeline based on the UT second [1]. The DateTime type is not aware of time zones (naive, in Python parlance), analogous to a LocalDateTime in Java 8. Additional time zone functionality can be added through the TimeZones.jl package, which compiles the IANA time zone database. Both Date and DateTime are based on the ISO 8601 standard, which follows the proleptic Gregorian calendar. One note is that the ISO 8601 standard is particular about BC/BCE dates. In general, the last day of the BC/BCE era, 1-12-31 BC/BCE, was followed by 1-1-1 AD/CE, thus no year zero exists. The ISO standard, however, states that 1 BC/BCE is year zero, so 0000-12-31 is the day before 0001-01-01, and year -0001 (yes, negative one for the year) is 2 BC/BCE, year -0002 is 3 BC/BCE, etc.[1]: The notion of the UT second is actually quite fundamental. There are basically two different notions of time generally accepted, one based on the physical rotation of the earth (one full rotation = 1 day), the other based on the SI second (a fixed, constant value). These are radically different! Think about it, a \"UT second\", as defined relative to the rotation of the earth, may have a different absolute length depending on the day! Anyway, the fact that Date and DateTime are based on UT seconds is a simplifying, yet honest assumption so that things like leap seconds and all their complexity can be avoided. This basis of time is formally called UT or UT1. Basing types on the UT second basically means that every minute has 60 seconds and every day has 24 hours and leads to more natural calculations when working with calendar dates."
},

{
    "location": "manual/dates/#Constructors-1",
    "page": "Date and DateTime",
    "title": "Constructors",
    "category": "section",
    "text": "Date and DateTime types can be constructed by integer or Period types, by parsing, or through adjusters (more on those later):julia> DateTime(2013)\n2013-01-01T00:00:00\n\njulia> DateTime(2013,7)\n2013-07-01T00:00:00\n\njulia> DateTime(2013,7,1)\n2013-07-01T00:00:00\n\njulia> DateTime(2013,7,1,12)\n2013-07-01T12:00:00\n\njulia> DateTime(2013,7,1,12,30)\n2013-07-01T12:30:00\n\njulia> DateTime(2013,7,1,12,30,59)\n2013-07-01T12:30:59\n\njulia> DateTime(2013,7,1,12,30,59,1)\n2013-07-01T12:30:59.001\n\njulia> Date(2013)\n2013-01-01\n\njulia> Date(2013,7)\n2013-07-01\n\njulia> Date(2013,7,1)\n2013-07-01\n\njulia> Date(Dates.Year(2013),Dates.Month(7),Dates.Day(1))\n2013-07-01\n\njulia> Date(Dates.Month(7),Dates.Year(2013))\n2013-07-01Date or DateTime parsing is accomplished by the use of format strings. Format strings work by the notion of defining delimited or fixed-width \"slots\" that contain a period to parse and passing the text to parse and format string to a Date or DateTime constructor, of the form Date(\"2015-01-01\",\"y-m-d\") or DateTime(\"20150101\",\"yyyymmdd\").Delimited slots are marked by specifying the delimiter the parser should expect between two subsequent periods; so \"y-m-d\" lets the parser know that between the first and second slots in a date string like \"2014-07-16\", it should find the - character. The y, m, and d characters let the parser know which periods to parse in each slot.Fixed-width slots are specified by repeating the period character the number of times corresponding to the width with no delimiter between characters. So \"yyyymmdd\" would correspond to a date string like \"20140716\". The parser distinguishes a fixed-width slot by the absence of a delimiter, noting the transition \"yyyymm\" from one period character to the next.Support for text-form month parsing is also supported through the u and U characters, for abbreviated and full-length month names, respectively. By default, only English month names are supported, so u corresponds to \"Jan\", \"Feb\", \"Mar\", etc. And U corresponds to \"January\", \"February\", \"March\", etc. Similar to other name=>value mapping functions dayname() and monthname(), custom locales can be loaded by passing in the locale=>Dict{String,Int} mapping to the MONTHTOVALUEABBR and MONTHTOVALUE dicts for abbreviated and full-name month names, respectively.One note on parsing performance: using the Date(date_string,format_string) function is fine if only called a few times. If there are many similarly formatted date strings to parse however, it is much more efficient to first create a Dates.DateFormat, and pass it instead of a raw format string.julia> df = DateFormat(\"y-m-d\");\n\njulia> dt = Date(\"2015-01-01\",df)\n2015-01-01\n\njulia> dt2 = Date(\"2015-01-02\",df)\n2015-01-02You can also use the dateformat\"\" string macro. This macro creates the DateFormat object once when the macro is expanded and uses the same DateFormat object even if a code snippet is run multiple times.julia> for i = 1:10^5\n           Date(\"2015-01-01\", dateformat\"y-m-d\")\n       endA full suite of parsing and formatting tests and examples is available in tests/dates/io.jl."
},

{
    "location": "manual/dates/#Durations/Comparisons-1",
    "page": "Date and DateTime",
    "title": "Durations/Comparisons",
    "category": "section",
    "text": "Finding the length of time between two Date or DateTime is straightforward given their underlying representation as UTInstant{Day} and UTInstant{Millisecond}, respectively. The difference between Date is returned in the number of Day, and DateTime in the number of Millisecond. Similarly, comparing TimeType is a simple matter of comparing the underlying machine instants (which in turn compares the internal Int64 values).julia> dt = Date(2012,2,29)\n2012-02-29\n\njulia> dt2 = Date(2000,2,1)\n2000-02-01\n\njulia> dump(dt)\nDate\n  instant: Base.Dates.UTInstant{Base.Dates.Day}\n    periods: Base.Dates.Day\n      value: Int64 734562\n\njulia> dump(dt2)\nDate\n  instant: Base.Dates.UTInstant{Base.Dates.Day}\n    periods: Base.Dates.Day\n      value: Int64 730151\n\njulia> dt > dt2\ntrue\n\njulia> dt != dt2\ntrue\n\njulia> dt + dt2\nERROR: MethodError: no method matching +(::Date, ::Date)\n[...]\n\njulia> dt * dt2\nERROR: MethodError: no method matching *(::Date, ::Date)\n[...]\n\njulia> dt / dt2\nERROR: MethodError: no method matching /(::Date, ::Date)\n[...]\n\njulia> dt - dt2\n4411 days\n\njulia> dt2 - dt\n-4411 days\n\njulia> dt = DateTime(2012,2,29)\n2012-02-29T00:00:00\n\njulia> dt2 = DateTime(2000,2,1)\n2000-02-01T00:00:00\n\njulia> dt - dt2\n381110400000 milliseconds"
},

{
    "location": "manual/dates/#Accessor-Functions-1",
    "page": "Date and DateTime",
    "title": "Accessor Functions",
    "category": "section",
    "text": "Because the Date and DateTime types are stored as single Int64 values, date parts or fields can be retrieved through accessor functions. The lowercase accessors return the field as an integer:julia> t = Date(2014, 1, 31)\n2014-01-31\n\njulia> Dates.year(t)\n2014\n\njulia> Dates.month(t)\n1\n\njulia> Dates.week(t)\n5\n\njulia> Dates.day(t)\n31While propercase return the same value in the corresponding Period type:julia> Dates.Year(t)\n2014 years\n\njulia> Dates.Day(t)\n31 daysCompound methods are provided, as they provide a measure of efficiency if multiple fields are needed at the same time:julia> Dates.yearmonth(t)\n(2014, 1)\n\njulia> Dates.monthday(t)\n(1, 31)\n\njulia> Dates.yearmonthday(t)\n(2014, 1, 31)One may also access the underlying UTInstant or integer value:julia> dump(t)\nDate\n  instant: Base.Dates.UTInstant{Base.Dates.Day}\n    periods: Base.Dates.Day\n      value: Int64 735264\n\njulia> t.instant\nBase.Dates.UTInstant{Base.Dates.Day}(735264 days)\n\njulia> Dates.value(t)\n735264"
},

{
    "location": "manual/dates/#Query-Functions-1",
    "page": "Date and DateTime",
    "title": "Query Functions",
    "category": "section",
    "text": "Query functions provide calendrical information about a TimeType. They include information about the day of the week:julia> t = Date(2014, 1, 31)\n2014-01-31\n\njulia> Dates.dayofweek(t)\n5\n\njulia> Dates.dayname(t)\n\"Friday\"\n\njulia> Dates.dayofweekofmonth(t) # 5th Friday of January\n5Month of the year:julia> Dates.monthname(t)\n\"January\"\n\njulia> Dates.daysinmonth(t)\n31As well as information about the TimeType\'s year and quarter:julia> Dates.isleapyear(t)\nfalse\n\njulia> Dates.dayofyear(t)\n31\n\njulia> Dates.quarterofyear(t)\n1\n\njulia> Dates.dayofquarter(t)\n31The dayname() and monthname() methods can also take an optional locale keyword that can be used to return the name of the day or month of the year for other languages/locales. There are also versions of these functions returning the abbreviated names, namely dayabbr() and monthabbr(). First the mapping is loaded into the LOCALES variable:julia> french_months = [\"janvier\", \"février\", \"mars\", \"avril\", \"mai\", \"juin\",\n                        \"juillet\", \"août\", \"septembre\", \"octobre\", \"novembre\", \"décembre\"];\n\njulia> french_monts_abbrev = [\"janv\",\"févr\",\"mars\",\"avril\",\"mai\",\"juin\",\n                              \"juil\",\"août\",\"sept\",\"oct\",\"nov\",\"déc\"];\n\njulia> french_days = [\"lundi\",\"mardi\",\"mercredi\",\"jeudi\",\"vendredi\",\"samedi\",\"dimanche\"];\n\njulia> Dates.LOCALES[\"french\"] = Dates.DateLocale(french_months, french_monts_abbrev, french_days, [\"\"]);The above mentioned functions can then be used to perform the queries:julia> Dates.dayname(t;locale=\"french\")\n\"vendredi\"\n\njulia> Dates.monthname(t;locale=\"french\")\n\"janvier\"\n\njulia> Dates.monthabbr(t;locale=\"french\")\n\"janv\"Since the abbreviated versions of the days are not loaded, trying to use the function dayabbr() will error.julia> Dates.dayabbr(t;locale=\"french\")\nERROR: BoundsError: attempt to access 1-element Array{String,1} at index [5]\nStacktrace:\n [1] #dayabbr#6(::String, ::Function, ::Int64) at ./dates/query.jl:114\n [2] (::Base.Dates.#kw##dayabbr)(::Array{Any,1}, ::Base.Dates.#dayabbr, ::Int64) at ./<missing>:0 (repeats 2 times)"
},

{
    "location": "manual/dates/#TimeType-Period-Arithmetic-1",
    "page": "Date and DateTime",
    "title": "TimeType-Period Arithmetic",
    "category": "section",
    "text": "It\'s good practice when using any language/date framework to be familiar with how date-period arithmetic is handled as there are some tricky issues to deal with (though much less so for day-precision types).The Dates module approach tries to follow the simple principle of trying to change as little as possible when doing Period arithmetic. This approach is also often known as calendrical arithmetic or what you would probably guess if someone were to ask you the same calculation in a conversation. Why all the fuss about this? Let\'s take a classic example: add 1 month to January 31st, 2014. What\'s the answer? Javascript will say March 3 (assumes 31 days). PHP says March 2 (assumes 30 days). The fact is, there is no right answer. In the Dates module, it gives the result of February 28th. How does it figure that out? I like to think of the classic 7-7-7 gambling game in casinos.Now just imagine that instead of 7-7-7, the slots are Year-Month-Day, or in our example, 2014-01-31. When you ask to add 1 month to this date, the month slot is incremented, so now we have 2014-02-31. Then the day number is checked if it is greater than the last valid day of the new month; if it is (as in the case above), the day number is adjusted down to the last valid day (28). What are the ramifications with this approach? Go ahead and add another month to our date, 2014-02-28 + Month(1) == 2014-03-28. What? Were you expecting the last day of March? Nope, sorry, remember the 7-7-7 slots. As few slots as possible are going to change, so we first increment the month slot by 1, 2014-03-28, and boom, we\'re done because that\'s a valid date. On the other hand, if we were to add 2 months to our original date, 2014-01-31, then we end up with 2014-03-31, as expected. The other ramification of this approach is a loss in associativity when a specific ordering is forced (i.e. adding things in different orders results in different outcomes). For example:julia> (Date(2014,1,29)+Dates.Day(1)) + Dates.Month(1)\n2014-02-28\n\njulia> (Date(2014,1,29)+Dates.Month(1)) + Dates.Day(1)\n2014-03-01What\'s going on there? In the first line, we\'re adding 1 day to January 29th, which results in 2014-01-30; then we add 1 month, so we get 2014-02-30, which then adjusts down to 2014-02-28. In the second example, we add 1 month first, where we get 2014-02-29, which adjusts down to 2014-02-28, and then add 1 day, which results in 2014-03-01. One design principle that helps in this case is that, in the presence of multiple Periods, the operations will be ordered by the Periods\' types, not their value or positional order; this means Year will always be added first, then Month, then Week, etc. Hence the following does result in associativity and Just Works:julia> Date(2014,1,29) + Dates.Day(1) + Dates.Month(1)\n2014-03-01\n\njulia> Date(2014,1,29) + Dates.Month(1) + Dates.Day(1)\n2014-03-01Tricky? Perhaps. What is an innocent Dates user to do? The bottom line is to be aware that explicitly forcing a certain associativity, when dealing with months, may lead to some unexpected results, but otherwise, everything should work as expected. Thankfully, that\'s pretty much the extent of the odd cases in date-period arithmetic when dealing with time in UT (avoiding the \"joys\" of dealing with daylight savings, leap seconds, etc.).As a bonus, all period arithmetic objects work directly with ranges:julia> dr = Date(2014,1,29):Date(2014,2,3)\n2014-01-29:1 day:2014-02-03\n\njulia> collect(dr)\n6-element Array{Date,1}:\n 2014-01-29\n 2014-01-30\n 2014-01-31\n 2014-02-01\n 2014-02-02\n 2014-02-03\n\njulia> dr = Date(2014,1,29):Dates.Month(1):Date(2014,07,29)\n2014-01-29:1 month:2014-07-29\n\njulia> collect(dr)\n7-element Array{Date,1}:\n 2014-01-29\n 2014-02-28\n 2014-03-29\n 2014-04-29\n 2014-05-29\n 2014-06-29\n 2014-07-29"
},

{
    "location": "manual/dates/#Adjuster-Functions-1",
    "page": "Date and DateTime",
    "title": "Adjuster Functions",
    "category": "section",
    "text": "As convenient as date-period arithmetics are, often the kinds of calculations needed on dates take on a calendrical or temporal nature rather than a fixed number of periods. Holidays are a perfect example; most follow rules such as \"Memorial Day = Last Monday of May\", or \"Thanksgiving = 4th Thursday of November\". These kinds of temporal expressions deal with rules relative to the calendar, like first or last of the month, next Tuesday, or the first and third Wednesdays, etc.The Dates module provides the adjuster API through several convenient methods that aid in simply and succinctly expressing temporal rules. The first group of adjuster methods deal with the first and last of weeks, months, quarters, and years. They each take a single TimeType as input and return or adjust to the first or last of the desired period relative to the input.julia> Dates.firstdayofweek(Date(2014,7,16)) # Adjusts the input to the Monday of the input\'s week\n2014-07-14\n\njulia> Dates.lastdayofmonth(Date(2014,7,16)) # Adjusts to the last day of the input\'s month\n2014-07-31\n\njulia> Dates.lastdayofquarter(Date(2014,7,16)) # Adjusts to the last day of the input\'s quarter\n2014-09-30The next two higher-order methods, tonext(), and toprev(), generalize working with temporal expressions by taking a DateFunction as first argument, along with a starting TimeType. A DateFunction is just a function, usually anonymous, that takes a single TimeType as input and returns a Bool, true indicating a satisfied adjustment criterion. For example:julia> istuesday = x->Dates.dayofweek(x) == Dates.Tuesday # Returns true if the day of the week of x is Tuesday\n(::#1) (generic function with 1 method)\n\njulia> Dates.tonext(istuesday, Date(2014,7,13)) # 2014-07-13 is a Sunday\n2014-07-15\n\njulia> Dates.tonext(Date(2014,7,13), Dates.Tuesday) # Convenience method provided for day of the week adjustments\n2014-07-15This is useful with the do-block syntax for more complex temporal expressions:julia> Dates.tonext(Date(2014,7,13)) do x\n           # Return true on the 4th Thursday of November (Thanksgiving)\n           Dates.dayofweek(x) == Dates.Thursday &&\n           Dates.dayofweekofmonth(x) == 4 &&\n           Dates.month(x) == Dates.November\n       end\n2014-11-27The Base.filter() method can be used to obtain all valid dates/moments in a specified range:# Pittsburgh street cleaning; Every 2nd Tuesday from April to November\n# Date range from January 1st, 2014 to January 1st, 2015\njulia> dr = Dates.Date(2014):Dates.Date(2015);\n\njulia> filter(dr) do x\n           Dates.dayofweek(x) == Dates.Tue &&\n           Dates.April <= Dates.month(x) <= Dates.Nov &&\n           Dates.dayofweekofmonth(x) == 2\n       end\n8-element Array{Date,1}:\n 2014-04-08\n 2014-05-13\n 2014-06-10\n 2014-07-08\n 2014-08-12\n 2014-09-09\n 2014-10-14\n 2014-11-11Additional examples and tests are available in test/dates/adjusters.jl."
},

{
    "location": "manual/dates/#Period-Types-1",
    "page": "Date and DateTime",
    "title": "Period Types",
    "category": "section",
    "text": "Periods are a human view of discrete, sometimes irregular durations of time. Consider 1 month; it could represent, in days, a value of 28, 29, 30, or 31 depending on the year and month context. Or a year could represent 365 or 366 days in the case of a leap year. Period types are simple Int64 wrappers and are constructed by wrapping any Int64 convertible type, i.e. Year(1) or Month(3.0). Arithmetic between Period of the same type behave like integers, and limited Period-Real arithmetic is available.julia> y1 = Dates.Year(1)\n1 year\n\njulia> y2 = Dates.Year(2)\n2 years\n\njulia> y3 = Dates.Year(10)\n10 years\n\njulia> y1 + y2\n3 years\n\njulia> div(y3,y2)\n5\n\njulia> y3 - y2\n8 years\n\njulia> y3 % y2\n0 years\n\njulia> div(y3,3) # mirrors integer division\n3 years"
},

{
    "location": "manual/dates/#Rounding-1",
    "page": "Date and DateTime",
    "title": "Rounding",
    "category": "section",
    "text": "Date and DateTime values can be rounded to a specified resolution (e.g., 1 month or 15 minutes) with floor(), ceil(), or round():julia> floor(Date(1985, 8, 16), Dates.Month)\n1985-08-01\n\njulia> ceil(DateTime(2013, 2, 13, 0, 31, 20), Dates.Minute(15))\n2013-02-13T00:45:00\n\njulia> round(DateTime(2016, 8, 6, 20, 15), Dates.Day)\n2016-08-07T00:00:00Unlike the numeric round() method, which breaks ties toward the even number by default, the TimeTyperound() method uses the RoundNearestTiesUp rounding mode. (It\'s difficult to guess what breaking ties to nearest \"even\" TimeType would entail.) Further details on the available RoundingMode s can be found in the API reference.Rounding should generally behave as expected, but there are a few cases in which the expected behaviour is not obvious."
},

{
    "location": "manual/dates/#Rounding-Epoch-1",
    "page": "Date and DateTime",
    "title": "Rounding Epoch",
    "category": "section",
    "text": "In many cases, the resolution specified for rounding (e.g., Dates.Second(30)) divides evenly into the next largest period (in this case, Dates.Minute(1)). But rounding behaviour in cases in which this is not true may lead to confusion. What is the expected result of rounding a DateTime to the nearest 10 hours?julia> round(DateTime(2016, 7, 17, 11, 55), Dates.Hour(10))\n2016-07-17T12:00:00That may seem confusing, given that the hour (12) is not divisible by 10. The reason that 2016-07-17T12:00:00 was chosen is that it is 17,676,660 hours after 0000-01-01T00:00:00, and 17,676,660 is divisible by 10.As Julia Date and DateTime values are represented according to the ISO 8601 standard, 0000-01-01T00:00:00 was chosen as base (or \"rounding epoch\") from which to begin the count of days (and milliseconds) used in rounding calculations. (Note that this differs slightly from Julia\'s internal representation of Date s using Rata Die notation; but since the ISO 8601 standard is most visible to the end user, 0000-01-01T00:00:00 was chosen as the rounding epoch instead of the 0000-12-31T00:00:00 used internally to minimize confusion.)The only exception to the use of 0000-01-01T00:00:00 as the rounding epoch is when rounding to weeks. Rounding to the nearest week will always return a Monday (the first day of the week as specified by ISO 8601). For this reason, we use 0000-01-03T00:00:00 (the first day of the first week of year 0000, as defined by ISO 8601) as the base when rounding to a number of weeks.Here is a related case in which the expected behaviour is not necessarily obvious: What happens when we round to the nearest P(2), where P is a Period type? In some cases (specifically, when P <: Dates.TimePeriod) the answer is clear:julia> round(DateTime(2016, 7, 17, 8, 55, 30), Dates.Hour(2))\n2016-07-17T08:00:00\n\njulia> round(DateTime(2016, 7, 17, 8, 55, 30), Dates.Minute(2))\n2016-07-17T08:56:00This seems obvious, because two of each of these periods still divides evenly into the next larger order period. But in the case of two months (which still divides evenly into one year), the answer may be surprising:julia> round(DateTime(2016, 7, 17, 8, 55, 30), Dates.Month(2))\n2016-07-01T00:00:00Why round to the first day in July, even though it is month 7 (an odd number)? The key is that months are 1-indexed (the first month is assigned 1), unlike hours, minutes, seconds, and milliseconds (the first of which are assigned 0).This means that rounding a DateTime to an even multiple of seconds, minutes, hours, or years (because the ISO 8601 specification includes a year zero) will result in a DateTime with an even value in that field, while rounding a DateTime to an even multiple of months will result in the months field having an odd value. Because both months and years may contain an irregular number of days, whether rounding to an even number of days will result in an even value in the days field is uncertain.See the API reference for additional information on methods exported from the Dates module."
},

{
    "location": "manual/interacting-with-julia/#",
    "page": "Interacting With Julia",
    "title": "Interacting With Julia",
    "category": "page",
    "text": ""
},

{
    "location": "manual/interacting-with-julia/#Interacting-With-Julia-1",
    "page": "Interacting With Julia",
    "title": "Interacting With Julia",
    "category": "section",
    "text": "Julia comes with a full-featured interactive command-line REPL (read-eval-print loop) built into the julia executable. In addition to allowing quick and easy evaluation of Julia statements, it has a searchable history, tab-completion, many helpful keybindings, and dedicated help and shell modes. The REPL can be started by simply calling julia with no arguments or double-clicking on the executable:$ julia\n               _\n   _       _ _(_)_     |  A fresh approach to technical computing\n  (_)     | (_) (_)    |  Documentation: https://docs.julialang.org\n   _ _   _| |_  __ _   |  Type \"?help\" for help.\n  | | | | | | |/ _` |  |\n  | | |_| | | | (_| |  |  Version 0.6.0-dev.2493 (2017-01-31 18:53 UTC)\n _/ |\\__\'_|_|_|\\__\'_|  |  Commit c99e12c* (0 days old master)\n|__/                   |  x86_64-linux-gnu\n\njulia>To exit the interactive session, type ^D – the control key together with the d key on a blank line – or type quit() followed by the return or enter key. The REPL greets you with a banner and a julia> prompt."
},

{
    "location": "manual/interacting-with-julia/#The-different-prompt-modes-1",
    "page": "Interacting With Julia",
    "title": "The different prompt modes",
    "category": "section",
    "text": ""
},

{
    "location": "manual/interacting-with-julia/#The-Julian-mode-1",
    "page": "Interacting With Julia",
    "title": "The Julian mode",
    "category": "section",
    "text": "The REPL has four main modes of operation. The first and most common is the Julian prompt. It is the default mode of operation; each new line initially starts with julia>. It is here that you can enter Julia expressions. Hitting return or enter after a complete expression has been entered will evaluate the entry and show the result of the last expression.julia> string(1 + 2)\n\"3\"There are a number useful features unique to interactive work. In addition to showing the result, the REPL also binds the result to the variable ans. A trailing semicolon on the line can be used as a flag to suppress showing the result.julia> string(3 * 4);\n\njulia> ans\n\"12\"In Julia mode, the REPL supports something called prompt pasting. This activates when pasting text that starts with julia>  into the REPL. In that case, only expressions starting with julia>  are parsed, others are removed. This makes it is possible to paste a chunk of code that has been copied from a REPL session without having to scrub away prompts and outputs. This feature is enabled by default but can be disabled or enabled at will with Base.REPL.enable_promptpaste(::Bool). If it is enabled, you can try it out by pasting the code block above this paragraph straight into the REPL. This feature does not work on the standard Windows command prompt due to its limitation at detecting when a paste occurs."
},

{
    "location": "manual/interacting-with-julia/#Help-mode-1",
    "page": "Interacting With Julia",
    "title": "Help mode",
    "category": "section",
    "text": "When the cursor is at the beginning of the line, the prompt can be changed to a help mode by typing ?. Julia will attempt to print help or documentation for anything entered in help mode:julia> ? # upon typing ?, the prompt changes (in place) to: help?>\n\nhelp?> string\nsearch: string String stringmime Cstring Cwstring RevString readstring randstring bytestring SubString\n\n  string(xs...)\n\n  Create a string from any values using the print function.Macros, types and variables can also be queried:help?> @time\n  @time\n\n  A macro to execute an expression, printing the time it took to execute, the number of allocations,\n  and the total number of bytes its execution caused to be allocated, before returning the value of the\n  expression.\n\n  See also @timev, @timed, @elapsed, and @allocated.\n\nhelp?> AbstractString\nsearch: AbstractString AbstractSparseMatrix AbstractSparseVector AbstractSet\n\n  No documentation found.\n\n  Summary:\n\n  abstract AbstractString <: Any\n\n  Subtypes:\n\n  Base.Test.GenericString\n  DirectIndexString\n  StringHelp mode can be exited by pressing backspace at the beginning of the line."
},

{
    "location": "manual/interacting-with-julia/#man-shell-mode-1",
    "page": "Interacting With Julia",
    "title": "Shell mode",
    "category": "section",
    "text": "Just as help mode is useful for quick access to documentation, another common task is to use the system shell to execute system commands. Just as ? entered help mode when at the beginning of the line, a semicolon (;) will enter the shell mode. And it can be exited by pressing backspace at the beginning of the line.julia> ; # upon typing ;, the prompt changes (in place) to: shell>\n\nshell> echo hello\nhello"
},

{
    "location": "manual/interacting-with-julia/#Search-modes-1",
    "page": "Interacting With Julia",
    "title": "Search modes",
    "category": "section",
    "text": "In all of the above modes, the executed lines get saved to a history file, which can be searched.  To initiate an incremental search through the previous history, type ^R – the control key together with the r key. The prompt will change to (reverse-i-search)`\':, and as you type the search query will appear in the quotes. The most recent result that matches the query will dynamically update to the right of the colon as more is typed. To find an older result using the same query, simply type ^R again.Just as ^R is a reverse search, ^S is a forward search, with the prompt (i-search)`\':.  The two may be used in conjunction with each other to move through the previous or next matching results, respectively."
},

{
    "location": "manual/interacting-with-julia/#Key-bindings-1",
    "page": "Interacting With Julia",
    "title": "Key bindings",
    "category": "section",
    "text": "The Julia REPL makes great use of key bindings. Several control-key bindings were already introduced above (^D to exit, ^R and ^S for searching), but there are many more. In addition to the control-key, there are also meta-key bindings. These vary more by platform, but most terminals default to using alt- or option- held down with a key to send the meta-key (or can be configured to do so).Keybinding Description\nProgram control  \n^D Exit (when buffer is empty)\n^C Interrupt or cancel\n^L Clear console screen\nReturn/Enter, ^J New line, executing if it is complete\nmeta-Return/Enter Insert new line without executing it\n? or ; Enter help or shell mode (when at start of a line)\n^R, ^S Incremental history search, described above\nCursor movement  \nRight arrow, ^F Move right one character\nLeft arrow, ^B Move left one character\nHome, ^A Move to beginning of line\nEnd, ^E Move to end of line\n^P Change to the previous or next history entry\n^N Change to the next history entry\nUp arrow Move up one line (or to the previous history entry)\nDown arrow Move down one line (or to the next history entry)\nPage-up Change to the previous history entry that matches the text before the cursor\nPage-down Change to the next history entry that matches the text before the cursor\nmeta-F Move right one word\nmeta-B Move left one word\nEditing  \nBackspace, ^H Delete the previous character\nDelete, ^D Forward delete one character (when buffer has text)\nmeta-Backspace Delete the previous word\nmeta-D Forward delete the next word\n^W Delete previous text up to the nearest whitespace\n^K \"Kill\" to end of line, placing the text in a buffer\n^Y \"Yank\" insert the text from the kill buffer\n^T Transpose the characters about the cursor\n^Q Write a number in REPL and press ^Q to open editor at corresponding stackframe"
},

{
    "location": "manual/interacting-with-julia/#Customizing-keybindings-1",
    "page": "Interacting With Julia",
    "title": "Customizing keybindings",
    "category": "section",
    "text": "Julia\'s REPL keybindings may be fully customized to a user\'s preferences by passing a dictionary to REPL.setup_interface(). The keys of this dictionary may be characters or strings. The key \'*\' refers to the default action. Control plus character x bindings are indicated with \"^x\". Meta plus x can be written \"\\\\Mx\". The values of the custom keymap must be nothing (indicating that the input should be ignored) or functions that accept the signature (PromptState, AbstractREPL, Char). The REPL.setup_interface() function must be called before the REPL is initialized, by registering the operation with atreplinit(). For example, to bind the up and down arrow keys to move through history without prefix search, one could put the following code in .juliarc.jl:import Base: LineEdit, REPL\n\nconst mykeys = Dict{Any,Any}(\n    # Up Arrow\n    \"\\e[A\" => (s,o...)->(LineEdit.edit_move_up(s) || LineEdit.history_prev(s, LineEdit.mode(s).hist)),\n    # Down Arrow\n    \"\\e[B\" => (s,o...)->(LineEdit.edit_move_up(s) || LineEdit.history_next(s, LineEdit.mode(s).hist))\n)\n\nfunction customize_keys(repl)\n    repl.interface = REPL.setup_interface(repl; extra_repl_keymap = mykeys)\nend\n\natreplinit(customize_keys)Users should refer to base/LineEdit.jl to discover the available actions on key input."
},

{
    "location": "manual/interacting-with-julia/#Tab-completion-1",
    "page": "Interacting With Julia",
    "title": "Tab completion",
    "category": "section",
    "text": "In both the Julian and help modes of the REPL, one can enter the first few characters of a function or type and then press the tab key to get a list all matches:julia> stri[TAB]\nstride     strides     string      stringmime  strip\n\njulia> Stri[TAB]\nStridedArray    StridedMatrix    StridedVecOrMat  StridedVector    StringThe tab key can also be used to substitute LaTeX math symbols with their Unicode equivalents, and get a list of LaTeX matches as well:julia> \\pi[TAB]\njulia> π\nπ = 3.1415926535897...\n\njulia> e\\_1[TAB] = [1,0]\njulia> e₁ = [1,0]\n2-element Array{Int64,1}:\n 1\n 0\n\njulia> e\\^1[TAB] = [1 0]\njulia> e¹ = [1 0]\n1×2 Array{Int64,2}:\n 1  0\n\njulia> \\sqrt[TAB]2     # √ is equivalent to the sqrt() function\njulia> √2\n1.4142135623730951\n\njulia> \\hbar[TAB](h) = h / 2\\pi[TAB]\njulia> ħ(h) = h / 2π\nħ (generic function with 1 method)\n\njulia> \\h[TAB]\n\\hat              \\hermitconjmatrix  \\hkswarow          \\hrectangle\n\\hatapprox        \\hexagon           \\hookleftarrow     \\hrectangleblack\n\\hbar             \\hexagonblack      \\hookrightarrow    \\hslash\n\\heartsuit        \\hksearow          \\house             \\hspace\n\njulia> α=\"\\alpha[TAB]\"   # LaTeX completion also works in strings\njulia> α=\"α\"A full list of tab-completions can be found in the Unicode Input section of the manual.Completion of paths works for strings and julia\'s shell mode:julia> path=\"/[TAB]\"\n.dockerenv  .juliabox/   boot/        etc/         lib/         media/       opt/         root/        sbin/        sys/         usr/\n.dockerinit bin/         dev/         home/        lib64/       mnt/         proc/        run/         srv/         tmp/         var/\nshell> /[TAB]\n.dockerenv  .juliabox/   boot/        etc/         lib/         media/       opt/         root/        sbin/        sys/         usr/\n.dockerinit bin/         dev/         home/        lib64/       mnt/         proc/        run/         srv/         tmp/         var/Tab completion can help with investigation of the available methods matching the input arguments:julia> max([TAB] # All methods are displayed, not shown here due to size of the list\n\njulia> max([1, 2], [TAB] # All methods where `Vector{Int}` matches as first argument\nmax(x, y) in Base at operators.jl:215\nmax(a, b, c, xs...) in Base at operators.jl:281\n\njulia> max([1, 2], max(1, 2), [TAB] # All methods matching the arguments.\nmax(x, y) in Base at operators.jl:215\nmax(a, b, c, xs...) in Base at operators.jl:281Keywords are also displayed in the suggested methods, see second line after ; where limit and keep are keyword arguments:julia> split(\"1 1 1\", [TAB]\nsplit(str::AbstractString) in Base at strings/util.jl:278\nsplit{T<:AbstractString}(str::T, splitter; limit, keep) in Base at strings/util.jl:254The completion of the methods uses type inference and can therefore see if the arguments match even if the arguments are output from functions. The function needs to be type stable for the completion to be able to remove non-matching methods.Tab completion can also help completing fields:julia> Pkg.a[TAB]\nadd       availableFields for output from functions can also be completed:julia> split(\"\",\"\")[1].[TAB]\nendof  offset  stringThe completion of fields for output from functions uses type inference, and it can only suggest fields if the function is type stable."
},

{
    "location": "manual/interacting-with-julia/#Customizing-Colors-1",
    "page": "Interacting With Julia",
    "title": "Customizing Colors",
    "category": "section",
    "text": "The colors used by Julia and the REPL can be customized, as well. To change the color of the Julia prompt you can add something like the following to your .juliarc.jl file, which is to be placed inside your home directory:function customize_colors(repl)\n    repl.prompt_color = Base.text_colors[:cyan]\nend\n\natreplinit(customize_colors)The available color keys can be seen by typing Base.text_colors in the help mode of the REPL. In addition, the integers 0 to 255 can be used as color keys for terminals with 256 color support.You can also change the colors for the help and shell prompts and input and answer text by setting the appropriate field of repl in the customize_colors function above (respectively, help_color, shell_color, input_color, and answer_color). For the latter two, be sure that the envcolors field is also set to false.It is also possible to apply boldface formatting by using Base.text_colors[:bold] as a color. For instance, to print answers in boldface font, one can use the following as a .juliarc.jl:function customize_colors(repl)\n    repl.envcolors = false\n    repl.answer_color = Base.text_colors[:bold]\nend\n\natreplinit(customize_colors)You can also customize the color used to render warning and informational messages by setting the appropriate environment variables. For instance, to render error, warning, and informational messages respectively in magenta, yellow, and cyan you can add the following to your .juliarc.jl file:ENV[\"JULIA_ERROR_COLOR\"] = :magenta\nENV[\"JULIA_WARN_COLOR\"] = :yellow\nENV[\"JULIA_INFO_COLOR\"] = :cyan"
},

{
    "location": "manual/running-external-programs/#",
    "page": "Running External Programs",
    "title": "Running External Programs",
    "category": "page",
    "text": ""
},

{
    "location": "manual/running-external-programs/#Running-External-Programs-1",
    "page": "Running External Programs",
    "title": "Running External Programs",
    "category": "section",
    "text": "Julia borrows backtick notation for commands from the shell, Perl, and Ruby. However, in Julia, writingjulia> `echo hello`\n`echo hello`differs in several aspects from the behavior in various shells, Perl, or Ruby:Instead of immediately running the command, backticks create a Cmd object to represent the command. You can use this object to connect the command to others via pipes, run it, and read or write to it.\nWhen the command is run, Julia does not capture its output unless you specifically arrange for it to. Instead, the output of the command by default goes to STDOUT as it would using libc\'s system call.\nThe command is never run with a shell. Instead, Julia parses the command syntax directly, appropriately interpolating variables and splitting on words as the shell would, respecting shell quoting syntax. The command is run as julia\'s immediate child process, using fork and exec calls.Here\'s a simple example of running an external program:julia> mycommand = `echo hello`\n`echo hello`\n\njulia> typeof(mycommand)\nCmd\n\njulia> run(mycommand)\nhelloThe hello is the output of the echo command, sent to STDOUT. The run method itself returns nothing, and throws an ErrorException if the external command fails to run successfully.If you want to read the output of the external command, readstring() can be used instead:julia> a = readstring(`echo hello`)\n\"hello\\n\"\n\njulia> chomp(a) == \"hello\"\ntrueMore generally, you can use open() to read from or write to an external command.julia> open(`less`, \"w\", STDOUT) do io\n           for i = 1:3\n               println(io, i)\n           end\n       end\n1\n2\n3"
},

{
    "location": "manual/running-external-programs/#command-interpolation-1",
    "page": "Running External Programs",
    "title": "Interpolation",
    "category": "section",
    "text": "Suppose you want to do something a bit more complicated and use the name of a file in the variable file as an argument to a command. You can use $ for interpolation much as you would in a string literal (see Strings):julia> file = \"/etc/passwd\"\n\"/etc/passwd\"\n\njulia> `sort $file`\n`sort /etc/passwd`A common pitfall when running external programs via a shell is that if a file name contains characters that are special to the shell, they may cause undesirable behavior. Suppose, for example, rather than /etc/passwd, we wanted to sort the contents of the file /Volumes/External HD/data.csv. Let\'s try it:julia> file = \"/Volumes/External HD/data.csv\"\n\"/Volumes/External HD/data.csv\"\n\njulia> `sort $file`\n`sort \'/Volumes/External HD/data.csv\'`How did the file name get quoted? Julia knows that file is meant to be interpolated as a single argument, so it quotes the word for you. Actually, that is not quite accurate: the value of file is never interpreted by a shell, so there\'s no need for actual quoting; the quotes are inserted only for presentation to the user. This will even work if you interpolate a value as part of a shell word:julia> path = \"/Volumes/External HD\"\n\"/Volumes/External HD\"\n\njulia> name = \"data\"\n\"data\"\n\njulia> ext = \"csv\"\n\"csv\"\n\njulia> `sort $path/$name.$ext`\n`sort \'/Volumes/External HD/data.csv\'`As you can see, the space in the path variable is appropriately escaped. But what if you want to interpolate multiple words? In that case, just use an array (or any other iterable container):julia> files = [\"/etc/passwd\",\"/Volumes/External HD/data.csv\"]\n2-element Array{String,1}:\n \"/etc/passwd\"\n \"/Volumes/External HD/data.csv\"\n\njulia> `grep foo $files`\n`grep foo /etc/passwd \'/Volumes/External HD/data.csv\'`If you interpolate an array as part of a shell word, Julia emulates the shell\'s {a,b,c} argument generation:julia> names = [\"foo\",\"bar\",\"baz\"]\n3-element Array{String,1}:\n \"foo\"\n \"bar\"\n \"baz\"\n\njulia> `grep xylophone $names.txt`\n`grep xylophone foo.txt bar.txt baz.txt`Moreover, if you interpolate multiple arrays into the same word, the shell\'s Cartesian product generation behavior is emulated:julia> names = [\"foo\",\"bar\",\"baz\"]\n3-element Array{String,1}:\n \"foo\"\n \"bar\"\n \"baz\"\n\njulia> exts = [\"aux\",\"log\"]\n2-element Array{String,1}:\n \"aux\"\n \"log\"\n\njulia> `rm -f $names.$exts`\n`rm -f foo.aux foo.log bar.aux bar.log baz.aux baz.log`Since you can interpolate literal arrays, you can use this generative functionality without needing to create temporary array objects first:julia> `rm -rf $[\"foo\",\"bar\",\"baz\",\"qux\"].$[\"aux\",\"log\",\"pdf\"]`\n`rm -rf foo.aux foo.log foo.pdf bar.aux bar.log bar.pdf baz.aux baz.log baz.pdf qux.aux qux.log qux.pdf`"
},

{
    "location": "manual/running-external-programs/#Quoting-1",
    "page": "Running External Programs",
    "title": "Quoting",
    "category": "section",
    "text": "Inevitably, one wants to write commands that aren\'t quite so simple, and it becomes necessary to use quotes. Here\'s a simple example of a Perl one-liner at a shell prompt:sh$ perl -le \'$|=1; for (0..3) { print }\'\n0\n1\n2\n3The Perl expression needs to be in single quotes for two reasons: so that spaces don\'t break the expression into multiple shell words, and so that uses of Perl variables like $| (yes, that\'s the name of a variable in Perl), don\'t cause interpolation. In other instances, you may want to use double quotes so that interpolation does occur:sh$ first=\"A\"\nsh$ second=\"B\"\nsh$ perl -le \'$|=1; print for @ARGV\' \"1: $first\" \"2: $second\"\n1: A\n2: BIn general, the Julia backtick syntax is carefully designed so that you can just cut-and-paste shell commands as is into backticks and they will work: the escaping, quoting, and interpolation behaviors are the same as the shell\'s. The only difference is that the interpolation is integrated and aware of Julia\'s notion of what is a single string value, and what is a container for multiple values. Let\'s try the above two examples in Julia:julia> A = `perl -le \'$|=1; for (0..3) { print }\'`\n`perl -le \'$|=1; for (0..3) { print }\'`\n\njulia> run(A)\n0\n1\n2\n3\n\njulia> first = \"A\"; second = \"B\";\n\njulia> B = `perl -le \'print for @ARGV\' \"1: $first\" \"2: $second\"`\n`perl -le \'print for @ARGV\' \'1: A\' \'2: B\'`\n\njulia> run(B)\n1: A\n2: BThe results are identical, and Julia\'s interpolation behavior mimics the shell\'s with some improvements due to the fact that Julia supports first-class iterable objects while most shells use strings split on spaces for this, which introduces ambiguities. When trying to port shell commands to Julia, try cut and pasting first. Since Julia shows commands to you before running them, you can easily and safely just examine its interpretation without doing any damage."
},

{
    "location": "manual/running-external-programs/#Pipelines-1",
    "page": "Running External Programs",
    "title": "Pipelines",
    "category": "section",
    "text": "Shell metacharacters, such as |, &, and >, need to be quoted (or escaped) inside of Julia\'s backticks:julia> run(`echo hello \'|\' sort`)\nhello | sort\n\njulia> run(`echo hello \\| sort`)\nhello | sortThis expression invokes the echo command with three words as arguments: hello, |, and sort. The result is that a single line is printed: hello | sort. How, then, does one construct a pipeline? Instead of using \'|\' inside of backticks, one uses pipeline():julia> run(pipeline(`echo hello`, `sort`))\nhelloThis pipes the output of the echo command to the sort command. Of course, this isn\'t terribly interesting since there\'s only one line to sort, but we can certainly do much more interesting things:julia> run(pipeline(`cut -d: -f3 /etc/passwd`, `sort -n`, `tail -n5`))\n210\n211\n212\n213\n214This prints the highest five user IDs on a UNIX system. The cut, sort and tail commands are all spawned as immediate children of the current julia process, with no intervening shell process. Julia itself does the work to setup pipes and connect file descriptors that is normally done by the shell. Since Julia does this itself, it retains better control and can do some things that shells cannot.Julia can run multiple commands in parallel:julia> run(`echo hello` & `echo world`)\nworld\nhelloThe order of the output here is non-deterministic because the two echo processes are started nearly simultaneously, and race to make the first write to the STDOUT descriptor they share with each other and the julia parent process. Julia lets you pipe the output from both of these processes to another program:julia> run(pipeline(`echo world` & `echo hello`, `sort`))\nhello\nworldIn terms of UNIX plumbing, what\'s happening here is that a single UNIX pipe object is created and written to by both echo processes, and the other end of the pipe is read from by the sort command.IO redirection can be accomplished by passing keyword arguments stdin, stdout, and stderr to the pipeline function:pipeline(`do_work`, stdout=pipeline(`sort`, \"out.txt\"), stderr=\"errs.txt\")"
},

{
    "location": "manual/running-external-programs/#Avoiding-Deadlock-in-Pipelines-1",
    "page": "Running External Programs",
    "title": "Avoiding Deadlock in Pipelines",
    "category": "section",
    "text": "When reading and writing to both ends of a pipeline from a single process, it is important to avoid forcing the kernel to buffer all of the data.For example, when reading all of the output from a command, call readstring(out), not wait(process), since the former will actively consume all of the data written by the process, whereas the latter will attempt to store the data in the kernel\'s buffers while waiting for a reader to be connected.Another common solution is to separate the reader and writer of the pipeline into separate Tasks:writer = @async writeall(process, \"data\")\nreader = @async do_compute(readstring(process))\nwait(process)\nfetch(reader)"
},

{
    "location": "manual/running-external-programs/#Complex-Example-1",
    "page": "Running External Programs",
    "title": "Complex Example",
    "category": "section",
    "text": "The combination of a high-level programming language, a first-class command abstraction, and automatic setup of pipes between processes is a powerful one. To give some sense of the complex pipelines that can be created easily, here are some more sophisticated examples, with apologies for the excessive use of Perl one-liners:julia> prefixer(prefix, sleep) = `perl -nle \'$|=1; print \"\'$prefix\' \", $_; sleep \'$sleep\';\'`;\n\njulia> run(pipeline(`perl -le \'$|=1; for(0..9){ print; sleep 1 }\'`, prefixer(\"A\",2) & prefixer(\"B\",2)))\nA 0\nB 1\nA 2\nB 3\nA 4\nB 5\nA 6\nB 7\nA 8\nB 9This is a classic example of a single producer feeding two concurrent consumers: one perl process generates lines with the numbers 0 through 9 on them, while two parallel processes consume that output, one prefixing lines with the letter \"A\", the other with the letter \"B\". Which consumer gets the first line is non-deterministic, but once that race has been won, the lines are consumed alternately by one process and then the other. (Setting $|=1 in Perl causes each print statement to flush the STDOUT handle, which is necessary for this example to work. Otherwise all the output is buffered and printed to the pipe at once, to be read by just one consumer process.)Here is an even more complex multi-stage producer-consumer example:julia> run(pipeline(`perl -le \'$|=1; for(0..9){ print; sleep 1 }\'`,\n           prefixer(\"X\",3) & prefixer(\"Y\",3) & prefixer(\"Z\",3),\n           prefixer(\"A\",2) & prefixer(\"B\",2)))\nA X 0\nB Y 1\nA Z 2\nB X 3\nA Y 4\nB Z 5\nA X 6\nB Y 7\nA Z 8\nB X 9This example is similar to the previous one, except there are two stages of consumers, and the stages have different latency so they use a different number of parallel workers, to maintain saturated throughput.We strongly encourage you to try all these examples to see how they work."
},

{
    "location": "manual/calling-c-and-fortran-code/#",
    "page": "Calling C and Fortran Code",
    "title": "Calling C and Fortran Code",
    "category": "page",
    "text": ""
},

{
    "location": "manual/calling-c-and-fortran-code/#Calling-C-and-Fortran-Code-1",
    "page": "Calling C and Fortran Code",
    "title": "Calling C and Fortran Code",
    "category": "section",
    "text": "Though most code can be written in Julia, there are many high-quality, mature libraries for numerical computing already written in C and Fortran. To allow easy use of this existing code, Julia makes it simple and efficient to call C and Fortran functions. Julia has a \"no boilerplate\" philosophy: functions can be called directly from Julia without any \"glue\" code, code generation, or compilation – even from the interactive prompt. This is accomplished just by making an appropriate call with ccall syntax, which looks like an ordinary function call.The code to be called must be available as a shared library. Most C and Fortran libraries ship compiled as shared libraries already, but if you are compiling the code yourself using GCC (or Clang), you will need to use the -shared and -fPIC options. The machine instructions generated by Julia\'s JIT are the same as a native C call would be, so the resulting overhead is the same as calling a library function from C code. (Non-library function calls in both C and Julia can be inlined and thus may have even less overhead than calls to shared library functions. When both libraries and executables are generated by LLVM, it is possible to perform whole-program optimizations that can even optimize across this boundary, but Julia does not yet support that. In the future, however, it may do so, yielding even greater performance gains.)Shared libraries and functions are referenced by a tuple of the form (:function, \"library\") or (\"function\", \"library\") where function is the C-exported function name. library refers to the shared library name: shared libraries available in the (platform-specific) load path will be resolved by name, and if necessary a direct path may be specified.A function name may be used alone in place of the tuple (just :function or \"function\"). In this case the name is resolved within the current process. This form can be used to call C library functions, functions in the Julia runtime, or functions in an application linked to Julia.By default, Fortran compilers generate mangled names (for example, converting function names to lowercase or uppercase, often appending an underscore), and so to call a Fortran function via ccall you must pass the mangled identifier corresponding to the rule followed by your Fortran compiler.  Also, when calling a Fortran function, all inputs must be passed by reference.Finally, you can use ccall to actually generate a call to the library function. Arguments to ccall are as follows:A (:function, \"library\") pair, which must be written as a literal constant,\nOR\na function pointer (for example, from dlsym).\nReturn type (see below for mapping the declared C type to Julia)\nThis argument will be evaluated at compile-time, when the containing method is defined.\nA tuple of input types. The input types must be written as a literal tuple, not a tuple-valued variable or expression.\nThis argument will be evaluated at compile-time, when the containing method is defined.\nThe following arguments, if any, are the actual argument values passed to the function.As a complete but simple example, the following calls the clock function from the standard C library:julia> t = ccall((:clock, \"libc\"), Int32, ())\n2292761\n\njulia> t\n2292761\n\njulia> typeof(ans)\nInt32clock takes no arguments and returns an Int32. One common gotcha is that a 1-tuple must be written with a trailing comma. For example, to call the getenv function to get a pointer to the value of an environment variable, one makes a call like this:julia> path = ccall((:getenv, \"libc\"), Cstring, (Cstring,), \"SHELL\")\nCstring(@0x00007fff5fbffc45)\n\njulia> unsafe_string(path)\n\"/bin/bash\"Note that the argument type tuple must be written as (Cstring,), rather than (Cstring). This is because (Cstring) is just the expression Cstring surrounded by parentheses, rather than a 1-tuple containing Cstring:julia> (Cstring)\nCstring\n\njulia> (Cstring,)\n(Cstring,)In practice, especially when providing reusable functionality, one generally wraps ccall uses in Julia functions that set up arguments and then check for errors in whatever manner the C or Fortran function indicates them, propagating to the Julia caller as exceptions. This is especially important since C and Fortran APIs are notoriously inconsistent about how they indicate error conditions. For example, the getenv C library function is wrapped in the following Julia function, which is a simplified version of the actual definition from env.jl:function getenv(var::AbstractString)\n    val = ccall((:getenv, \"libc\"),\n                Cstring, (Cstring,), var)\n    if val == C_NULL\n        error(\"getenv: undefined variable: \", var)\n    end\n    unsafe_string(val)\nendThe C getenv function indicates an error by returning NULL, but other standard C functions indicate errors in various different ways, including by returning -1, 0, 1 and other special values. This wrapper throws an exception clearly indicating the problem if the caller tries to get a non-existent environment variable:julia> getenv(\"SHELL\")\n\"/bin/bash\"\n\njulia> getenv(\"FOOBAR\")\ngetenv: undefined variable: FOOBARHere is a slightly more complex example that discovers the local machine\'s hostname:function gethostname()\n    hostname = Vector{UInt8}(128)\n    ccall((:gethostname, \"libc\"), Int32,\n          (Ptr{UInt8}, Csize_t),\n          hostname, sizeof(hostname))\n    hostname[end] = 0; # ensure null-termination\n    return unsafe_string(pointer(hostname))\nendThis example first allocates an array of bytes, then calls the C library function gethostname to fill the array in with the hostname, takes a pointer to the hostname buffer, and converts the pointer to a Julia string, assuming that it is a NUL-terminated C string. It is common for C libraries to use this pattern of requiring the caller to allocate memory to be passed to the callee and filled in. Allocation of memory from Julia like this is generally accomplished by creating an uninitialized array and passing a pointer to its data to the C function. This is why we don\'t use the Cstring type here: as the array is uninitialized, it could contain NUL bytes. Converting to a Cstring as part of the ccall checks for contained NUL bytes and could therefore throw a conversion error."
},

{
    "location": "manual/calling-c-and-fortran-code/#Creating-C-Compatible-Julia-Function-Pointers-1",
    "page": "Calling C and Fortran Code",
    "title": "Creating C-Compatible Julia Function Pointers",
    "category": "section",
    "text": "It is possible to pass Julia functions to native C functions that accept function pointer arguments. For example, to match C prototypes of the form:typedef returntype (*functiontype)(argumenttype,...)The function cfunction() generates the C-compatible function pointer for a call to a Julia library function. Arguments to cfunction() are as follows:A Julia Function\nReturn type\nA tuple of input typesA classic example is the standard C library qsort function, declared as:void qsort(void *base, size_t nmemb, size_t size,\n           int(*compare)(const void *a, const void *b));The base argument is a pointer to an array of length nmemb, with elements of size bytes each. compare is a callback function which takes pointers to two elements a and b and returns an integer less/greater than zero if a should appear before/after b (or zero if any order is permitted). Now, suppose that we have a 1d array A of values in Julia that we want to sort using the qsort function (rather than Julia\'s built-in sort function). Before we worry about calling qsort and passing arguments, we need to write a comparison function that works for some arbitrary type T:julia> function mycompare(a::T, b::T) where T\n           return convert(Cint, a < b ? -1 : a > b ? +1 : 0)::Cint\n       end\nmycompare (generic function with 1 method)Notice that we have to be careful about the return type: qsort expects a function returning a C int, so we must be sure to return Cint via a call to convert and a typeassert.In order to pass this function to C, we obtain its address using the function cfunction:julia> const mycompare_c = cfunction(mycompare, Cint, (Ref{Cdouble}, Ref{Cdouble}));cfunction() accepts three arguments: the Julia function (mycompare), the return type (Cint), and a tuple of the argument types, in this case to sort an array of Cdouble (Float64) elements.The final call to qsort looks like this:julia> A = [1.3, -2.7, 4.4, 3.1]\n4-element Array{Float64,1}:\n  1.3\n -2.7\n  4.4\n  3.1\n\njulia> ccall(:qsort, Void, (Ptr{Cdouble}, Csize_t, Csize_t, Ptr{Void}),\n             A, length(A), sizeof(eltype(A)), mycompare_c)\n\njulia> A\n4-element Array{Float64,1}:\n -2.7\n  1.3\n  3.1\n  4.4As can be seen, A is changed to the sorted array [-2.7, 1.3, 3.1, 4.4]. Note that Julia knows how to convert an array into a Ptr{Cdouble}, how to compute the size of a type in bytes (identical to C\'s sizeof operator), and so on. For fun, try inserting a println(\"mycompare($a,$b)\") line into mycompare, which will allow you to see the comparisons that qsort is performing (and to verify that it is really calling the Julia function that you passed to it)."
},

{
    "location": "manual/calling-c-and-fortran-code/#Mapping-C-Types-to-Julia-1",
    "page": "Calling C and Fortran Code",
    "title": "Mapping C Types to Julia",
    "category": "section",
    "text": "It is critical to exactly match the declared C type with its declaration in Julia. Inconsistencies can cause code that works correctly on one system to fail or produce indeterminate results on a different system.Note that no C header files are used anywhere in the process of calling C functions: you are responsible for making sure that your Julia types and call signatures accurately reflect those in the C header file. (The Clang package can be used to auto-generate Julia code from a C header file.)"
},

{
    "location": "manual/calling-c-and-fortran-code/#Auto-conversion:-1",
    "page": "Calling C and Fortran Code",
    "title": "Auto-conversion:",
    "category": "section",
    "text": "Julia automatically inserts calls to the Base.cconvert() function to convert each argument to the specified type. For example, the following call:ccall((:foo, \"libfoo\"), Void, (Int32, Float64), x, y)will behave as if the following were written:ccall((:foo, \"libfoo\"), Void, (Int32, Float64),\n      Base.unsafe_convert(Int32, Base.cconvert(Int32, x)),\n      Base.unsafe_convert(Float64, Base.cconvert(Float64, y)))Base.cconvert() normally just calls convert(), but can be defined to return an arbitrary new object more appropriate for passing to C. For example, this is used to convert an Array of objects (e.g. strings) to an array of pointers.Base.unsafe_convert() handles conversion to Ptr types. It is considered unsafe because converting an object to a native pointer can hide the object from the garbage collector, causing it to be freed prematurely."
},

{
    "location": "manual/calling-c-and-fortran-code/#Type-Correspondences:-1",
    "page": "Calling C and Fortran Code",
    "title": "Type Correspondences:",
    "category": "section",
    "text": "First, a review of some relevant Julia type terminology:Syntax / Keyword Example Description\nmutable struct String \"Leaf Type\" :: A group of related data that includes a type-tag, is managed by the Julia GC, and is defined by object-identity. The type parameters of a leaf type must be fully defined (no TypeVars are allowed) in order for the instance to be constructed.\nabstract type Any, AbstractArray{T, N}, Complex{T} \"Super Type\" :: A super-type (not a leaf-type) that cannot be instantiated, but can be used to describe a group of types.\nT{A} Vector{Int} \"Type Parameter\" :: A specialization of a type (typically used for dispatch or storage optimization).\n  \"TypeVar\" :: The T in the type parameter declaration is referred to as a TypeVar (short for type variable).\nprimitive type Int, Float64 \"Primitive Type\" :: A type with no fields, but a size. It is stored and defined by-value.\nstruct Pair{Int, Int} \"Struct\" :: A type with all fields defined to be constant. It is defined by-value, and may be stored with a type-tag.\n Complex128 (isbits) \"Is-Bits\"   :: A primitive type, or a struct type where all fields are other isbits types. It is defined by-value, and is stored without a type-tag.\nstruct ...; end nothing \"Singleton\" :: a Leaf Type or Struct with no fields.\n(...) or tuple(...) (1, 2, 3) \"Tuple\" :: an immutable data-structure similar to an anonymous struct type, or a constant array. Represented as either an array or a struct."
},

{
    "location": "manual/calling-c-and-fortran-code/#Bits-Types:-1",
    "page": "Calling C and Fortran Code",
    "title": "Bits Types:",
    "category": "section",
    "text": "There are several special types to be aware of, as no other type can be defined to behave the same:Float32\nExactly corresponds to the float type in C (or REAL*4 in Fortran).\nFloat64\nExactly corresponds to the double type in C (or REAL*8 in Fortran).\nComplex64\nExactly corresponds to the complex float type in C (or COMPLEX*8 in Fortran).\nComplex128\nExactly corresponds to the complex double type in C (or COMPLEX*16 in Fortran).\nSigned\nExactly corresponds to the signed type annotation in C (or any INTEGER type in Fortran). Any Julia type that is not a subtype of Signed is assumed to be unsigned.Ref{T}\nBehaves like a Ptr{T} that can manage its memory via the Julia GC.Array{T,N}\nWhen an array is passed to C as a Ptr{T} argument, it is not reinterpret-cast: Julia requires that the element type of the array matches T, and the address of the first element is passed.\nTherefore, if an Array contains data in the wrong format, it will have to be explicitly converted using a call such as trunc(Int32, a).\nTo pass an array A as a pointer of a different type without converting the data beforehand (for example, to pass a Float64 array to a function that operates on uninterpreted bytes), you can declare the argument as Ptr{Void}.\nIf an array of eltype Ptr{T} is passed as a Ptr{Ptr{T}} argument, Base.cconvert() will attempt to first make a null-terminated copy of the array with each element replaced by its Base.cconvert() version. This allows, for example, passing an argv pointer array of type Vector{String} to an argument of type Ptr{Ptr{Cchar}}.On all systems we currently support, basic C/C++ value types may be translated to Julia types as follows. Every C type also has a corresponding Julia type with the same name, prefixed by C. This can help for writing portable code (and remembering that an int in C is not the same as an Int in Julia).System Independent:C name Fortran name Standard Julia Alias Julia Base Type\nunsigned char CHARACTER Cuchar UInt8\nbool (only in C++)  Cuchar UInt8\nshort INTEGER*2, LOGICAL*2 Cshort Int16\nunsigned short   Cushort UInt16\nint, BOOL (C, typical) INTEGER*4, LOGICAL*4 Cint Int32\nunsigned int   Cuint UInt32\nlong long INTEGER*8, LOGICAL*8 Clonglong Int64\nunsigned long long   Culonglong UInt64\nintmax_t   Cintmax_t Int64\nuintmax_t   Cuintmax_t UInt64\nfloat REAL*4i Cfloat Float32\ndouble REAL*8 Cdouble Float64\ncomplex float COMPLEX*8 Complex64 Complex{Float32}\ncomplex double COMPLEX*16 Complex128 Complex{Float64}\nptrdiff_t   Cptrdiff_t Int\nssize_t   Cssize_t Int\nsize_t   Csize_t UInt\nvoid     Void\nvoid and [[noreturn]] or _Noreturn     Union{}\nvoid*     Ptr{Void}\nT* (where T represents an appropriately defined type)     Ref{T}\nchar* (or char[], e.g. a string) CHARACTER*N   Cstring if NUL-terminated, or Ptr{UInt8} if not\nchar** (or *char[])     Ptr{Ptr{UInt8}}\njl_value_t* (any Julia Type)     Any\njl_value_t** (a reference to a Julia Type)     Ref{Any}\nva_arg     Not supported\n... (variadic function specification)     T... (where T is one of the above types, variadic functions of different argument types are not supported)The Cstring type is essentially a synonym for Ptr{UInt8}, except the conversion to Cstring throws an error if the Julia string contains any embedded NUL characters (which would cause the string to be silently truncated if the C routine treats NUL as the terminator).  If you are passing a char* to a C routine that does not assume NUL termination (e.g. because you pass an explicit string length), or if you know for certain that your Julia string does not contain NUL and want to skip the check, you can use Ptr{UInt8} as the argument type. Cstring can also be used as the ccall return type, but in that case it obviously does not introduce any extra checks and is only meant to improve readability of the call.System-dependent:C name Standard Julia Alias Julia Base Type\nchar Cchar Int8 (x86, x86_64), UInt8 (powerpc, arm)\nlong Clong Int (UNIX), Int32 (Windows)\nunsigned long Culong UInt (UNIX), UInt32 (Windows)\nwchar_t Cwchar_t Int32 (UNIX), UInt16 (Windows)note: Note\nWhen calling a Fortran function, all inputs must be passed by reference, so all type correspondences above should contain an additional Ptr{..} or Ref{..} wrapper around their type specification.warning: Warning\nFor string arguments (char*) the Julia type should be Cstring (if NUL- terminated data is expected) or either Ptr{Cchar} or Ptr{UInt8} otherwise (these two pointer types have the same effect), as described above, not String. Similarly, for array arguments (T[] or T*), the Julia type should again be Ptr{T}, not Vector{T}.warning: Warning\nJulia\'s Char type is 32 bits, which is not the same as the wide character type (wchar_t or wint_t) on all platforms.warning: Warning\nA return type of Union{} means the function will not return i.e. C++11 [[noreturn]] or C11 _Noreturn (e.g. jl_throw or longjmp). Do not use this for functions that return no value (void) but do return, use Void instead.note: Note\nFor wchar_t* arguments, the Julia type should be Cwstring (if the C routine expects a NUL-terminated string) or Ptr{Cwchar_t} otherwise. Note also that UTF-8 string data in Julia is internally NUL-terminated, so it can be passed to C functions expecting NUL-terminated data without making a copy (but using the Cwstring type will cause an error to be thrown if the string itself contains NUL characters).note: Note\nC functions that take an argument of the type char** can be called by using a Ptr{Ptr{UInt8}} type within Julia. For example, C functions of the form:int main(int argc, char **argv);can be called via the following Julia code:argv = [ \"a.out\", \"arg1\", \"arg2\" ]\nccall(:main, Int32, (Int32, Ptr{Ptr{UInt8}}), length(argv), argv)note: Note\nA C function declared to return Void will return the value nothing in Julia."
},

{
    "location": "manual/calling-c-and-fortran-code/#Struct-Type-correspondences-1",
    "page": "Calling C and Fortran Code",
    "title": "Struct Type correspondences",
    "category": "section",
    "text": "Composite types, aka struct in C or TYPE in Fortran90 (or STRUCTURE / RECORD in some variants of F77), can be mirrored in Julia by creating a struct definition with the same field layout.When used recursively, isbits types are stored inline. All other types are stored as a pointer to the data. When mirroring a struct used by-value inside another struct in C, it is imperative that you do not attempt to manually copy the fields over, as this will not preserve the correct field alignment. Instead, declare an isbits struct type and use that instead. Unnamed structs are not possible in the translation to Julia.Packed structs and union declarations are not supported by Julia.You can get a near approximation of a union if you know, a priori, the field that will have the greatest size (potentially including padding). When translating your fields to Julia, declare the Julia field to be only of that type.Arrays of parameters can be expressed with NTuple:in C:\nstruct B {\n    int A[3];\n};\nb_a_2 = B.A[2];\n\nin Julia:\nstruct B\n    A::NTuple{3, CInt}\nend\nb_a_2 = B.A[3]  # note the difference in indexing (1-based in Julia, 0-based in C)Arrays of unknown size (C99-compliant variable length structs specified by [] or [0]) are not directly supported. Often the best way to deal with these is to deal with the byte offsets directly. For example, if a C library declared a proper string type and returned a pointer to it:struct String {\n    int strlen;\n    char data[];\n};In Julia, we can access the parts independently to make a copy of that string:str = from_c::Ptr{Void}\nlen = unsafe_load(Ptr{Cint}(str))\nunsafe_string(str + Core.sizeof(Cint), len)"
},

{
    "location": "manual/calling-c-and-fortran-code/#Type-Parameters-1",
    "page": "Calling C and Fortran Code",
    "title": "Type Parameters",
    "category": "section",
    "text": "The type arguments to ccall are evaluated statically, when the method containing the ccall is defined. They therefore must take the form of a literal tuple, not a variable, and cannot reference local variables.This may sound like a strange restriction, but remember that since C is not a dynamic language like Julia, its functions can only accept argument types with a statically-known, fixed signature.However, while the type layout must be known statically to compute the ccall ABI, the static parameters of the function are considered to be part of this static environment. The static parameters of the function may be used as type parameters in the ccall signature, as long as they don\'t affect the layout of the type. For example, f(x::T) where {T} = ccall(:valid, Ptr{T}, (Ptr{T},), x) is valid, since Ptr is always a word-size primitive type. But, g(x::T) where {T} = ccall(:notvalid, T, (T,), x) is not valid, since the type layout of T is not known statically."
},

{
    "location": "manual/calling-c-and-fortran-code/#SIMD-Values-1",
    "page": "Calling C and Fortran Code",
    "title": "SIMD Values",
    "category": "section",
    "text": "Note: This feature is currently implemented on 64-bit x86 and AArch64 platforms only.If a C/C++ routine has an argument or return value that is a native SIMD type, the corresponding Julia type is a homogeneous tuple of VecElement that naturally maps to the SIMD type.  Specifically:The tuple must be the same size as the SIMD type. For example, a tuple representing an __m128 on x86 must have a size of 16 bytes.\nThe element type of the tuple must be an instance of VecElement{T} where T is a primitive type that is 1, 2, 4 or 8 bytes.For instance, consider this C routine that uses AVX intrinsics:#include <immintrin.h>\n\n__m256 dist( __m256 a, __m256 b ) {\n    return _mm256_sqrt_ps(_mm256_add_ps(_mm256_mul_ps(a, a),\n                                        _mm256_mul_ps(b, b)));\n}The following Julia code calls dist using ccall:const m256 = NTuple{8, VecElement{Float32}}\n\na = m256(ntuple(i -> VecElement(sin(Float32(i))), 8))\nb = m256(ntuple(i -> VecElement(cos(Float32(i))), 8))\n\nfunction call_dist(a::m256, b::m256)\n    ccall((:dist, \"libdist\"), m256, (m256, m256), a, b)\nend\n\nprintln(call_dist(a,b))The host machine must have the requisite SIMD registers.  For example, the code above will not work on hosts without AVX support."
},

{
    "location": "manual/calling-c-and-fortran-code/#Memory-Ownership-1",
    "page": "Calling C and Fortran Code",
    "title": "Memory Ownership",
    "category": "section",
    "text": "malloc/freeMemory allocation and deallocation of such objects must be handled by calls to the appropriate cleanup routines in the libraries being used, just like in any C program. Do not try to free an object received from a C library with Libc.free in Julia, as this may result in the free function being called via the wrong libc library and cause Julia to crash. The reverse (passing an object allocated in Julia to be freed by an external library) is equally invalid."
},

{
    "location": "manual/calling-c-and-fortran-code/#When-to-use-T,-Ptr{T}-and-Ref{T}-1",
    "page": "Calling C and Fortran Code",
    "title": "When to use T, Ptr{T} and Ref{T}",
    "category": "section",
    "text": "In Julia code wrapping calls to external C routines, ordinary (non-pointer) data should be declared to be of type T inside the ccall, as they are passed by value.  For C code accepting pointers, Ref{T} should generally be used for the types of input arguments, allowing the use of pointers to memory managed by either Julia or C through the implicit call to Base.cconvert().  In contrast, pointers returned by the C function called should be declared to be of output type Ptr{T}, reflecting that the memory pointed to is managed by C only. Pointers contained in C structs should be represented as fields of type Ptr{T} within the corresponding Julia struct types designed to mimic the internal structure of corresponding C structs.In Julia code wrapping calls to external Fortran routines, all input arguments should be declared as of type Ref{T}, as Fortran passes all variables by reference. The return type should either be Void for Fortran subroutines, or a T for Fortran functions returning the type T."
},

{
    "location": "manual/calling-c-and-fortran-code/#Mapping-C-Functions-to-Julia-1",
    "page": "Calling C and Fortran Code",
    "title": "Mapping C Functions to Julia",
    "category": "section",
    "text": ""
},

{
    "location": "manual/calling-c-and-fortran-code/#ccall/cfunction-argument-translation-guide-1",
    "page": "Calling C and Fortran Code",
    "title": "ccall/cfunction argument translation guide",
    "category": "section",
    "text": "For translating a C argument list to Julia:T, where T is one of the primitive types: char, int, long, short, float, double, complex, enum or any of their typedef equivalents\nT, where T is an equivalent Julia Bits Type (per the table above)\nif T is an enum, the argument type should be equivalent to Cint or Cuint\nargument value will be copied (passed by value)\nstruct T (including typedef to a struct)\nT, where T is a Julia leaf type\nargument value will be copied (passed by value)\nvoid*\ndepends on how this parameter is used, first translate this to the intended pointer type, then determine the Julia equivalent using the remaining rules in this list\nthis argument may be declared as Ptr{Void}, if it really is just an unknown pointer\njl_value_t*\nAny\nargument value must be a valid Julia object\ncurrently unsupported by cfunction()\njl_value_t**\nRef{Any}\nargument value must be a valid Julia object (or C_NULL)\ncurrently unsupported by cfunction()\nT*\nRef{T}, where T is the Julia type corresponding to T\nargument value will be copied if it is an isbits type otherwise, the value must be a valid Julia object\n(T*)(...) (e.g. a pointer to a function)\nPtr{Void} (you may need to use cfunction() explicitly to create this pointer)\n... (e.g. a vararg)\nT..., where T is the Julia type\nva_arg\nnot supported"
},

{
    "location": "manual/calling-c-and-fortran-code/#ccall/cfunction-return-type-translation-guide-1",
    "page": "Calling C and Fortran Code",
    "title": "ccall/cfunction return type translation guide",
    "category": "section",
    "text": "For translating a C return type to Julia:void\nVoid (this will return the singleton instance nothing::Void)\nT, where T is one of the primitive types: char, int, long, short, float, double, complex, enum or any of their typedef equivalents\nT, where T is an equivalent Julia Bits Type (per the table above)\nif T is an enum, the argument type should be equivalent to Cint or Cuint\nargument value will be copied (returned by-value)\nstruct T (including typedef to a struct)\nT, where T is a Julia Leaf Type\nargument value will be copied (returned by-value)\nvoid*\ndepends on how this parameter is used, first translate this to the intended pointer type, then determine the Julia equivalent using the remaining rules in this list\nthis argument may be declared as Ptr{Void}, if it really is just an unknown pointer\njl_value_t*\nAny\nargument value must be a valid Julia object\njl_value_t**\nRef{Any}\nargument value must be a valid Julia object (or C_NULL)\nT*\nIf the memory is already owned by Julia, or is an isbits type, and is known to be non-null:\nRef{T}, where T is the Julia type corresponding to T\na return type of Ref{Any} is invalid, it should either be Any (corresponding to jl_value_t*) or Ptr{Any} (corresponding to Ptr{Any})\nC MUST NOT modify the memory returned via Ref{T} if T is an isbits type\nIf the memory is owned by C:\nPtr{T}, where T is the Julia type corresponding to T\n(T*)(...) (e.g. a pointer to a function)\nPtr{Void} (you may need to use cfunction() explicitly to create this pointer)"
},

{
    "location": "manual/calling-c-and-fortran-code/#Passing-Pointers-for-Modifying-Inputs-1",
    "page": "Calling C and Fortran Code",
    "title": "Passing Pointers for Modifying Inputs",
    "category": "section",
    "text": "Because C doesn\'t support multiple return values, often C functions will take pointers to data that the function will modify. To accomplish this within a ccall, you need to first encapsulate the value inside an Ref{T} of the appropriate type. When you pass this Ref object as an argument, Julia will automatically pass a C pointer to the encapsulated data:width = Ref{Cint}(0)\nrange = Ref{Cfloat}(0)\nccall(:foo, Void, (Ref{Cint}, Ref{Cfloat}), width, range)Upon return, the contents of width and range can be retrieved (if they were changed by foo) by width[] and range[]; that is, they act like zero-dimensional arrays."
},

{
    "location": "manual/calling-c-and-fortran-code/#Special-Reference-Syntax-for-ccall-(deprecated):-1",
    "page": "Calling C and Fortran Code",
    "title": "Special Reference Syntax for ccall (deprecated):",
    "category": "section",
    "text": "The & syntax is deprecated, use the Ref{T} argument type instead.A prefix & is used on an argument to ccall to indicate that a pointer to a scalar argument should be passed instead of the scalar value itself (required for all Fortran function arguments, as noted above). The following example computes a dot product using a BLAS function.function compute_dot(DX::Vector{Float64}, DY::Vector{Float64})\n    @assert length(DX) == length(DY)\n    n = length(DX)\n    incx = incy = 1\n    product = ccall((:ddot_, \"libLAPACK\"),\n                    Float64,\n                    (Ptr{Int32}, Ptr{Float64}, Ptr{Int32}, Ptr{Float64}, Ptr{Int32}),\n                    &n, DX, &incx, DY, &incy)\n    return product\nendThe meaning of prefix & is not quite the same as in C. In particular, any changes to the referenced variables will not be visible in Julia unless the type is mutable (declared via type). However, even for immutable structs it will not cause any harm for called functions to attempt such modifications (that is, writing through the passed pointers). Moreover, & may be used with any expression, such as &0 or &f(x).When a scalar value is passed with & as an argument of type Ptr{T}, the value will first be converted to type T."
},

{
    "location": "manual/calling-c-and-fortran-code/#Some-Examples-of-C-Wrappers-1",
    "page": "Calling C and Fortran Code",
    "title": "Some Examples of C Wrappers",
    "category": "section",
    "text": "Here is a simple example of a C wrapper that returns a Ptr type:mutable struct gsl_permutation\nend\n\n# The corresponding C signature is\n#     gsl_permutation * gsl_permutation_alloc (size_t n);\nfunction permutation_alloc(n::Integer)\n    output_ptr = ccall(\n        (:gsl_permutation_alloc, :libgsl), # name of C function and library\n        Ptr{gsl_permutation},              # output type\n        (Csize_t,),                        # tuple of input types\n        n                                  # name of Julia variable to pass in\n    )\n    if output_ptr == C_NULL # Could not allocate memory\n        throw(OutOfMemoryError())\n    end\n    return output_ptr\nendThe GNU Scientific Library (here assumed to be accessible through :libgsl) defines an opaque pointer, gsl_permutation *, as the return type of the C function gsl_permutation_alloc(). As user code never has to look inside the gsl_permutation struct, the corresponding Julia wrapper simply needs a new type declaration, gsl_permutation, that has no internal fields and whose sole purpose is to be placed in the type parameter of a Ptr type.  The return type of the ccall is declared as Ptr{gsl_permutation}, since the memory allocated and pointed to by output_ptr is controlled by C (and not Julia).The input n is passed by value, and so the function\'s input signature is simply declared as (Csize_t,) without any Ref or Ptr necessary. (If the wrapper was calling a Fortran function instead, the corresponding function input signature should instead be (Ref{Csize_t},), since Fortran variables are passed by reference.) Furthermore, n can be any type that is convertable to a Csize_t integer; the ccall implicitly calls Base.cconvert(Csize_t, n).Here is a second example wrapping the corresponding destructor:# The corresponding C signature is\n#     void gsl_permutation_free (gsl_permutation * p);\nfunction permutation_free(p::Ref{gsl_permutation})\n    ccall(\n        (:gsl_permutation_free, :libgsl), # name of C function and library\n        Void,                             # output type\n        (Ref{gsl_permutation},),          # tuple of input types\n        p                                 # name of Julia variable to pass in\n    )\nendHere, the input p is declared to be of type Ref{gsl_permutation}, meaning that the memory that p points to may be managed by Julia or by C. A pointer to memory allocated by C should be of type Ptr{gsl_permutation}, but it is convertable using Base.cconvert() and therefore can be used in the same (covariant) context of the input argument to a ccall. A pointer to memory allocated by Julia must be of type Ref{gsl_permutation}, to ensure that the memory address pointed to is valid and that Julia\'s garbage collector manages the chunk of memory pointed to correctly. Therefore, the Ref{gsl_permutation} declaration allows pointers managed by C or Julia to be used.If the C wrapper never expects the user to pass pointers to memory managed by Julia, then using p::Ptr{gsl_permutation} for the method signature of the wrapper and similarly in the ccall is also acceptable.Here is a third example passing Julia arrays:# The corresponding C signature is\n#    int gsl_sf_bessel_Jn_array (int nmin, int nmax, double x,\n#                                double result_array[])\nfunction sf_bessel_Jn_array(nmin::Integer, nmax::Integer, x::Real)\n    if nmax < nmin\n        throw(DomainError())\n    end\n    result_array = Vector{Cdouble}(nmax - nmin + 1)\n    errorcode = ccall(\n        (:gsl_sf_bessel_Jn_array, :libgsl), # name of C function and library\n        Cint,                               # output type\n        (Cint, Cint, Cdouble, Ref{Cdouble}),# tuple of input types\n        nmin, nmax, x, result_array         # names of Julia variables to pass in\n    )\n    if errorcode != 0\n        error(\"GSL error code $errorcode\")\n    end\n    return result_array\nendThe C function wrapped returns an integer error code; the results of the actual evaluation of the Bessel J function populate the Julia array result_array. This variable can only be used with corresponding input type declaration Ref{Cdouble}, since its memory is allocated and managed by Julia, not C. The implicit call to Base.cconvert(Ref{Cdouble}, result_array) unpacks the Julia pointer to a Julia array data structure into a form understandable by C.Note that for this code to work correctly, result_array must be declared to be of type Ref{Cdouble} and not Ptr{Cdouble}. The memory is managed by Julia and the Ref signature alerts Julia\'s garbage collector to keep managing the memory for result_array while the ccall executes. If Ptr{Cdouble} were used instead, the ccall may still work, but Julia\'s garbage collector would not be aware that the memory declared for result_array is being used by the external C function. As a result, the code may produce a memory leak if result_array never gets freed by the garbage collector, or if the garbage collector prematurely frees result_array, the C function may end up throwing an invalid memory access exception."
},

{
    "location": "manual/calling-c-and-fortran-code/#Garbage-Collection-Safety-1",
    "page": "Calling C and Fortran Code",
    "title": "Garbage Collection Safety",
    "category": "section",
    "text": "When passing data to a ccall, it is best to avoid using the pointer() function. Instead define a convert method and pass the variables directly to the ccall. ccall automatically arranges that all of its arguments will be preserved from garbage collection until the call returns. If a C API will store a reference to memory allocated by Julia, after the ccall returns, you must arrange that the object remains visible to the garbage collector. The suggested way to handle this is to make a global variable of type Array{Ref,1} to hold these values, until the C library notifies you that it is finished with them.Whenever you have created a pointer to Julia data, you must ensure the original data exists until you are done with using the pointer. Many methods in Julia such as unsafe_load() and String() make copies of data instead of taking ownership of the buffer, so that it is safe to free (or alter) the original data without affecting Julia. A notable exception is unsafe_wrap() which, for performance reasons, shares (or can be told to take ownership of) the underlying buffer.The garbage collector does not guarantee any order of finalization. That is, if a contained a reference to b and both a and b are due for garbage collection, there is no guarantee that b would be finalized after a. If proper finalization of a depends on b being valid, it must be handled in other ways."
},

{
    "location": "manual/calling-c-and-fortran-code/#Non-constant-Function-Specifications-1",
    "page": "Calling C and Fortran Code",
    "title": "Non-constant Function Specifications",
    "category": "section",
    "text": "A (name, library) function specification must be a constant expression. However, it is possible to use computed values as function names by staging through eval as follows:@eval ccall(($(string(\"a\", \"b\")), \"lib\"), ...This expression constructs a name using string, then substitutes this name into a new ccall expression, which is then evaluated. Keep in mind that eval only operates at the top level, so within this expression local variables will not be available (unless their values are substituted with $). For this reason, eval is typically only used to form top-level definitions, for example when wrapping libraries that contain many similar functions.If your usage is more dynamic, use indirect calls as described in the next section."
},

{
    "location": "manual/calling-c-and-fortran-code/#Indirect-Calls-1",
    "page": "Calling C and Fortran Code",
    "title": "Indirect Calls",
    "category": "section",
    "text": "The first argument to ccall can also be an expression evaluated at run time. In this case, the expression must evaluate to a Ptr, which will be used as the address of the native function to call. This behavior occurs when the first ccall argument contains references to non-constants, such as local variables, function arguments, or non-constant globals.For example, you might look up the function via dlsym, then cache it in a global variable for that session. For example:macro dlsym(func, lib)\n    z, zlocal = gensym(string(func)), gensym()\n    eval(current_module(), :(global $z = C_NULL))\n    z = esc(z)\n    quote\n        let $zlocal::Ptr{Void} = $z::Ptr{Void}\n            if $zlocal == C_NULL\n                $zlocal = dlsym($(esc(lib))::Ptr{Void}, $(esc(func)))\n                global $z = $zlocal\n            end\n            $zlocal\n        end\n    end\nend\n\nmylibvar = Libdl.dlopen(\"mylib\")\nccall(@dlsym(\"myfunc\", mylibvar), Void, ())"
},

{
    "location": "manual/calling-c-and-fortran-code/#Calling-Convention-1",
    "page": "Calling C and Fortran Code",
    "title": "Calling Convention",
    "category": "section",
    "text": "The second argument to ccall can optionally be a calling convention specifier (immediately preceding return type). Without any specifier, the platform-default C calling convention is used. Other supported conventions are: stdcall, cdecl, fastcall, and thiscall. For example (from base/libc.jl) we see the same gethostnameccall as above, but with the correct signature for Windows:hn = Vector{UInt8}(256)\nerr = ccall(:gethostname, stdcall, Int32, (Ptr{UInt8}, UInt32), hn, length(hn))For more information, please see the LLVM Language Reference.There is one additional special calling convention llvmcall, which allows inserting calls to LLVM intrinsics directly. This can be especially useful when targeting unusual platforms such as GPGPUs. For example, for CUDA, we need to be able to read the thread index:ccall(\"llvm.nvvm.read.ptx.sreg.tid.x\", llvmcall, Int32, ())As with any ccall, it is essential to get the argument signature exactly correct. Also, note that there is no compatibility layer that ensures the intrinsic makes sense and works on the current target, unlike the equivalent Julia functions exposed by Core.Intrinsics."
},

{
    "location": "manual/calling-c-and-fortran-code/#Accessing-Global-Variables-1",
    "page": "Calling C and Fortran Code",
    "title": "Accessing Global Variables",
    "category": "section",
    "text": "Global variables exported by native libraries can be accessed by name using the cglobal() function. The arguments to cglobal() are a symbol specification identical to that used by ccall, and a type describing the value stored in the variable:julia> cglobal((:errno, :libc), Int32)\nPtr{Int32} @0x00007f418d0816b8The result is a pointer giving the address of the value. The value can be manipulated through this pointer using unsafe_load() and unsafe_store!()."
},

{
    "location": "manual/calling-c-and-fortran-code/#Accessing-Data-through-a-Pointer-1",
    "page": "Calling C and Fortran Code",
    "title": "Accessing Data through a Pointer",
    "category": "section",
    "text": "The following methods are described as \"unsafe\" because a bad pointer or type declaration can cause Julia to terminate abruptly.Given a Ptr{T}, the contents of type T can generally be copied from the referenced memory into a Julia object using unsafe_load(ptr, [index]). The index argument is optional (default is 1), and follows the Julia-convention of 1-based indexing. This function is intentionally similar to the behavior of getindex() and setindex!() (e.g. [] access syntax).The return value will be a new object initialized to contain a copy of the contents of the referenced memory. The referenced memory can safely be freed or released.If T is Any, then the memory is assumed to contain a reference to a Julia object (a jl_value_t*), the result will be a reference to this object, and the object will not be copied. You must be careful in this case to ensure that the object was always visible to the garbage collector (pointers do not count, but the new reference does) to ensure the memory is not prematurely freed. Note that if the object was not originally allocated by Julia, the new object will never be finalized by Julia\'s garbage collector.  If the Ptr itself is actually a jl_value_t*, it can be converted back to a Julia object reference by unsafe_pointer_to_objref(ptr). (Julia values v can be converted to jl_value_t* pointers, as Ptr{Void}, by calling pointer_from_objref(v).)The reverse operation (writing data to a Ptr{T}), can be performed using unsafe_store!(ptr, value, [index]). Currently, this is only supported for primitive types or other pointer-free (isbits) immutable struct types.Any operation that throws an error is probably currently unimplemented and should be posted as a bug so that it can be resolved.If the pointer of interest is a plain-data array (primitive type or immutable struct), the function unsafe_wrap(Array, ptr,dims,[own]) may be more useful. The final parameter should be true if Julia should \"take ownership\" of the underlying buffer and call free(ptr) when the returned Array object is finalized.  If the own parameter is omitted or false, the caller must ensure the buffer remains in existence until all access is complete.Arithmetic on the Ptr type in Julia (e.g. using +) does not behave the same as C\'s pointer arithmetic. Adding an integer to a Ptr in Julia always moves the pointer by some number of bytes, not elements. This way, the address values obtained from pointer arithmetic do not depend on the element types of pointers."
},

{
    "location": "manual/calling-c-and-fortran-code/#Thread-safety-1",
    "page": "Calling C and Fortran Code",
    "title": "Thread-safety",
    "category": "section",
    "text": "Some C libraries execute their callbacks from a different thread, and since Julia isn\'t thread-safe you\'ll need to take some extra precautions. In particular, you\'ll need to set up a two-layered system: the C callback should only schedule (via Julia\'s event loop) the execution of your \"real\" callback. To do this, create a AsyncCondition object and wait on it:cond = Base.AsyncCondition()\nwait(cond)The callback you pass to C should only execute a ccall to :uv_async_send, passing cond.handle as the argument, taking care to avoid any allocations or other interactions with the Julia runtime.Note that events may be coalesced, so multiple calls to uv_async_send may result in a single wakeup notification to the condition."
},

{
    "location": "manual/calling-c-and-fortran-code/#More-About-Callbacks-1",
    "page": "Calling C and Fortran Code",
    "title": "More About Callbacks",
    "category": "section",
    "text": "For more details on how to pass callbacks to C libraries, see this blog post."
},

{
    "location": "manual/calling-c-and-fortran-code/#C-1",
    "page": "Calling C and Fortran Code",
    "title": "C++",
    "category": "section",
    "text": "For direct C++ interfacing, see the Cxx package. For tools to create C++ bindings, see the CxxWrap package."
},

{
    "location": "manual/handling-operating-system-variation/#",
    "page": "Handling Operating System Variation",
    "title": "Handling Operating System Variation",
    "category": "page",
    "text": ""
},

{
    "location": "manual/handling-operating-system-variation/#Handling-Operating-System-Variation-1",
    "page": "Handling Operating System Variation",
    "title": "Handling Operating System Variation",
    "category": "section",
    "text": "When dealing with platform libraries, it is often necessary to provide special cases for various platforms. The variable Sys.KERNEL can be used to write these special cases. There are several functions intended to make this easier: is_unix, is_linux, is_apple, is_bsd, and is_windows. These may be used as follows:if is_windows()\n    some_complicated_thing(a)\nendNote that is_linux and is_apple are mutually exclusive subsets of is_unix. Additionally, there is a macro @static which makes it possible to use these functions to conditionally hide invalid code, as demonstrated in the following examples.Simple blocks:ccall( (@static is_windows() ? :_fopen : :fopen), ...)Complex blocks:@static if is_linux()\n    some_complicated_thing(a)\nelse\n    some_different_thing(a)\nendWhen chaining conditionals (including if/elseif/end), the @static must be repeated for each level (parentheses optional, but recommended for readability):@static is_windows() ? :a : (@static is_apple() ? :b : :c)"
},

{
    "location": "manual/environment-variables/#",
    "page": "Environment Variables",
    "title": "Environment Variables",
    "category": "page",
    "text": ""
},

{
    "location": "manual/environment-variables/#Environment-Variables-1",
    "page": "Environment Variables",
    "title": "Environment Variables",
    "category": "section",
    "text": "Julia may be configured with a number of environment variables, either in the usual way of the operating system, or in a portable way from within Julia. Suppose you want to set the environment variable JULIA_EDITOR to vim, then either type ENV[\"JULIA_EDITOR\"] = \"vim\" for instance in the REPL to make this change on a case by case basis, or add the same to the user configuration file .juliarc.jl in the user\'s home directory to have a permanent effect. The current value of the same environment variable is determined by evaluating ENV[\"JULIA_EDITOR\"].The environment variables that Julia uses generally start with JULIA. If Base.versioninfo is called with verbose equal to true, then the output will list defined environment variables relevant for Julia, including those for which JULIA appears in the name."
},

{
    "location": "manual/environment-variables/#File-locations-1",
    "page": "Environment Variables",
    "title": "File locations",
    "category": "section",
    "text": ""
},

{
    "location": "manual/environment-variables/#JULIA_HOME-1",
    "page": "Environment Variables",
    "title": "JULIA_HOME",
    "category": "section",
    "text": "The absolute path of the directory containing the Julia executable, which sets the global variable Base.JULIA_HOME. If $JULIA_HOME is not set, then Julia determines the value Base.JULIA_HOME at run-time.The executable itself is one of$JULIA_HOME/julia\n$JULIA_HOME/julia-debugby default.The global variable Base.DATAROOTDIR determines a relative path from Base.JULIA_HOME to the data directory associated with Julia. Then the path$JULIA_HOME/$DATAROOTDIR/julia/basedetermines the directory in which Julia initially searches for source files (via Base.find_source_file()).Likewise, the global variable Base.SYSCONFDIR determines a relative path to the configuration file directory. Then Julia searches for a juliarc.jl file at$JULIA_HOME/$SYSCONFDIR/julia/juliarc.jl\n$JULIA_HOME/../etc/julia/juliarc.jlby default (via Base.load_juliarc()).For example, a Linux installation with a Julia executable located at /bin/julia, a DATAROOTDIR of ../share, and a SYSCONFDIR of ../etc will have JULIA_HOME set to /bin, a source-file search path of/share/julia/baseand a global configuration search path of/etc/julia/juliarc.jl"
},

{
    "location": "manual/environment-variables/#JULIA_LOAD_PATH-1",
    "page": "Environment Variables",
    "title": "JULIA_LOAD_PATH",
    "category": "section",
    "text": "A separated list of absolute paths that are to be appended to the variable LOAD_PATH. (In Unix-like systems, the path separator is :; in Windows systems, the path separator is ;.) The LOAD_PATH variable is where Base.require and Base.load_in_path() look for code; it defaults to the absolute paths$JULIA_HOME/../local/share/julia/site/v$(VERSION.major).$(VERSION.minor)\n$JULIA_HOME/../share/julia/site/v$(VERSION.major).$(VERSION.minor)so that, e.g., version 0.6 of Julia on a Linux system with a Julia executable at /bin/julia will have a default LOAD_PATH of/local/share/julia/site/v0.6\n/share/julia/site/v0.6"
},

{
    "location": "manual/environment-variables/#JULIA_PKGDIR-1",
    "page": "Environment Variables",
    "title": "JULIA_PKGDIR",
    "category": "section",
    "text": "The path of the parent directory Pkg.Dir._pkgroot() for the version-specific Julia package repositories. If the path is relative, then it is taken with respect to the working directory. If $JULIA_PKGDIR is not set, then Pkg.Dir._pkgroot() defaults to$HOME/.juliaThen the repository location Pkg.dir for a given Julia version is$JULIA_PKGDIR/v$(VERSION.major).$(VERSION.minor)For example, for a Linux user whose home directory is /home/alice, the directory containing the package repositories would by default be/home/alice/.juliaand the package repository for version 0.6 of Julia would be/home/alice/.julia/v0.6"
},

{
    "location": "manual/environment-variables/#JULIA_HISTORY-1",
    "page": "Environment Variables",
    "title": "JULIA_HISTORY",
    "category": "section",
    "text": "The absolute path Base.REPL.find_hist_file() of the REPL\'s history file. If $JULIA_HISTORY is not set, then Base.REPL.find_hist_file() defaults to$HOME/.julia_history"
},

{
    "location": "manual/environment-variables/#JULIA_PKGRESOLVE_ACCURACY-1",
    "page": "Environment Variables",
    "title": "JULIA_PKGRESOLVE_ACCURACY",
    "category": "section",
    "text": "A positive Int that determines how much time the max-sum subroutine MaxSum.maxsum() of the package dependency resolver Base.Pkg.resolve will devote to attempting satisfying constraints before giving up: this value is by default 1, and larger values correspond to larger amounts of time.Suppose the value of $JULIA_PKGRESOLVE_ACCURACY is n. Thenthe number of pre-decimation iterations is 20*n,\nthe number of iterations between decimation steps is 10*n, and\nat decimation steps, at most one in every 20*n packages is decimated."
},

{
    "location": "manual/environment-variables/#External-applications-1",
    "page": "Environment Variables",
    "title": "External applications",
    "category": "section",
    "text": ""
},

{
    "location": "manual/environment-variables/#JULIA_SHELL-1",
    "page": "Environment Variables",
    "title": "JULIA_SHELL",
    "category": "section",
    "text": "The absolute path of the shell with which Julia should execute external commands (via Base.repl_cmd()). Defaults to the environment variable $SHELL, and falls back to /bin/sh if $SHELL is unset.note: Note\nOn Windows, this environment variable is ignored, and external commands are executed directly."
},

{
    "location": "manual/environment-variables/#JULIA_EDITOR-1",
    "page": "Environment Variables",
    "title": "JULIA_EDITOR",
    "category": "section",
    "text": "The editor returned by Base.editor() and used in, e.g., Base.edit, referring to the command of the preferred editor, for instance vim.$JULIA_EDITOR takes precedence over $VISUAL, which in turn takes precedence over $EDITOR. If none of these environment variables is set, then the editor is taken to be open on Windows and OS X, or /etc/alternatives/editor if it exists, or emacs otherwise.note: Note\n$JULIA_EDITOR is not used in the determination of the editor for Base.Pkg.edit: this function checks $VISUAL and $EDITOR alone."
},

{
    "location": "manual/environment-variables/#Parallelization-1",
    "page": "Environment Variables",
    "title": "Parallelization",
    "category": "section",
    "text": ""
},

{
    "location": "manual/environment-variables/#JULIA_CPU_CORES-1",
    "page": "Environment Variables",
    "title": "JULIA_CPU_CORES",
    "category": "section",
    "text": "Overrides the global variable Base.Sys.CPU_CORES, the number of logical CPU cores available."
},

{
    "location": "manual/environment-variables/#JULIA_WORKER_TIMEOUT-1",
    "page": "Environment Variables",
    "title": "JULIA_WORKER_TIMEOUT",
    "category": "section",
    "text": "A Float64 that sets the value of Base.worker_timeout() (default: 60.0). This function gives the number of seconds a worker process will wait for a master process to establish a connection before dying."
},

{
    "location": "manual/environment-variables/#JULIA_NUM_THREADS-1",
    "page": "Environment Variables",
    "title": "JULIA_NUM_THREADS",
    "category": "section",
    "text": "An unsigned 64-bit integer (uint64_t) that sets the maximum number of threads available to Julia. If $JULIA_NUM_THREADS exceeds the number of available physical CPU cores, then the number of threads is set to the number of cores. If $JULIA_NUM_THREADS is not positive or is not set, or if the number of CPU cores cannot be determined through system calls, then the number of threads is set to 1."
},

{
    "location": "manual/environment-variables/#JULIA_THREAD_SLEEP_THRESHOLD-1",
    "page": "Environment Variables",
    "title": "JULIA_THREAD_SLEEP_THRESHOLD",
    "category": "section",
    "text": "If set to a string that starts with the case-insensitive substring \"infinite\", then spinning threads never sleep. Otherwise, $JULIA_THREAD_SLEEP_THRESHOLD is interpreted as an unsigned 64-bit integer (uint64_t) and gives, in nanoseconds, the amount of time after which spinning threads should sleep."
},

{
    "location": "manual/environment-variables/#JULIA_EXCLUSIVE-1",
    "page": "Environment Variables",
    "title": "JULIA_EXCLUSIVE",
    "category": "section",
    "text": "If set to anything besides 0, then Julia\'s thread policy is consistent with running on a dedicated machine: the master thread is on proc 0, and threads are affinitized. Otherwise, Julia lets the operating system handle thread policy."
},

{
    "location": "manual/environment-variables/#REPL-formatting-1",
    "page": "Environment Variables",
    "title": "REPL formatting",
    "category": "section",
    "text": "Environment variables that determine how REPL output should be formatted at the terminal. Generally, these variables should be set to ANSI terminal escape sequences. Julia provides a high-level interface with much of the same functionality: see the section on Interacting With Julia."
},

{
    "location": "manual/environment-variables/#JULIA_ERROR_COLOR-1",
    "page": "Environment Variables",
    "title": "JULIA_ERROR_COLOR",
    "category": "section",
    "text": "The formatting Base.error_color() (default: light red, \"\\033[91m\") that errors should have at the terminal."
},

{
    "location": "manual/environment-variables/#JULIA_WARN_COLOR-1",
    "page": "Environment Variables",
    "title": "JULIA_WARN_COLOR",
    "category": "section",
    "text": "The formatting Base.warn_color() (default: yellow, \"\\033[93m\") that warnings should have at the terminal."
},

{
    "location": "manual/environment-variables/#JULIA_INFO_COLOR-1",
    "page": "Environment Variables",
    "title": "JULIA_INFO_COLOR",
    "category": "section",
    "text": "The formatting Base.info_color() (default: cyan, \"\\033[36m\") that info should have at the terminal."
},

{
    "location": "manual/environment-variables/#JULIA_INPUT_COLOR-1",
    "page": "Environment Variables",
    "title": "JULIA_INPUT_COLOR",
    "category": "section",
    "text": "The formatting Base.input_color() (default: normal, \"\\033[0m\") that input should have at the terminal."
},

{
    "location": "manual/environment-variables/#JULIA_ANSWER_COLOR-1",
    "page": "Environment Variables",
    "title": "JULIA_ANSWER_COLOR",
    "category": "section",
    "text": "The formatting Base.answer_color() (default: normal, \"\\033[0m\") that output should have at the terminal."
},

{
    "location": "manual/environment-variables/#JULIA_STACKFRAME_LINEINFO_COLOR-1",
    "page": "Environment Variables",
    "title": "JULIA_STACKFRAME_LINEINFO_COLOR",
    "category": "section",
    "text": "The formatting Base.stackframe_lineinfo_color() (default: bold, \"\\033[1m\") that line info should have during a stack trace at the terminal."
},

{
    "location": "manual/environment-variables/#JULIA_STACKFRAME_FUNCTION_COLOR-1",
    "page": "Environment Variables",
    "title": "JULIA_STACKFRAME_FUNCTION_COLOR",
    "category": "section",
    "text": "The formatting Base.stackframe_function_color() (default: bold, \"\\033[1m\") that function calls should have during a stack trace at the terminal."
},

{
    "location": "manual/environment-variables/#Debugging-and-profiling-1",
    "page": "Environment Variables",
    "title": "Debugging and profiling",
    "category": "section",
    "text": ""
},

{
    "location": "manual/environment-variables/#JULIA_GC_ALLOC_POOL,-JULIA_GC_ALLOC_OTHER,-JULIA_GC_ALLOC_PRINT-1",
    "page": "Environment Variables",
    "title": "JULIA_GC_ALLOC_POOL, JULIA_GC_ALLOC_OTHER, JULIA_GC_ALLOC_PRINT",
    "category": "section",
    "text": "If set, these environment variables take strings that optionally start with the character \'r\', followed by a string interpolation of a colon-separated list of three signed 64-bit integers (int64_t). This triple of integers a:b:c represents the arithmetic sequence a, a + b, a + 2*b, ... c.If it\'s the nth time that jl_gc_pool_alloc() has been called, and n   belongs to the arithmetic sequence represented by $JULIA_GC_ALLOC_POOL,   then garbage collection is forced.\nIf it\'s the nth time that maybe_collect() has been called, and n belongs   to the arithmetic sequence represented by $JULIA_GC_ALLOC_OTHER, then garbage   collection is forced.\nIf it\'s the nth time that jl_gc_collect() has been called, and n belongs   to the arithmetic sequence represented by $JULIA_GC_ALLOC_PRINT, then counts   for the number of calls to jl_gc_pool_alloc() and maybe_collect() are   printed.If the value of the environment variable begins with the character \'r\', then the interval between garbage collection events is randomized.note: Note\nThese environment variables only have an effect if Julia was compiled with garbage-collection debugging (that is, if WITH_GC_DEBUG_ENV is set to 1 in the build configuration)."
},

{
    "location": "manual/environment-variables/#JULIA_GC_NO_GENERATIONAL-1",
    "page": "Environment Variables",
    "title": "JULIA_GC_NO_GENERATIONAL",
    "category": "section",
    "text": "If set to anything besides 0, then the Julia garbage collector never performs \"quick sweeps\" of memory.note: Note\nThis environment variable only has an effect if Julia was compiled with garbage-collection debugging (that is, if WITH_GC_DEBUG_ENV is set to 1 in the build configuration)."
},

{
    "location": "manual/environment-variables/#JULIA_GC_WAIT_FOR_DEBUGGER-1",
    "page": "Environment Variables",
    "title": "JULIA_GC_WAIT_FOR_DEBUGGER",
    "category": "section",
    "text": "If set to anything besides 0, then the Julia garbage collector will wait for a debugger to attach instead of aborting whenever there\'s a critical error.note: Note\nThis environment variable only has an effect if Julia was compiled with garbage-collection debugging (that is, if WITH_GC_DEBUG_ENV is set to 1 in the build configuration)."
},

{
    "location": "manual/environment-variables/#ENABLE_JITPROFILING-1",
    "page": "Environment Variables",
    "title": "ENABLE_JITPROFILING",
    "category": "section",
    "text": "If set to anything besides 0, then the compiler will create and register an event listener for just-in-time (JIT) profiling.note: Note\nThis environment variable only has an effect if Julia was compiled with JIT profiling support, using eitherIntel\'s VTune™ Amplifier   (USE_INTEL_JITEVENTS set to 1 in the build configuration), or\nOProfile (USE_OPROFILE_JITEVENTS set to 1   in the build configuration)."
},

{
    "location": "manual/environment-variables/#JULIA_LLVM_ARGS-1",
    "page": "Environment Variables",
    "title": "JULIA_LLVM_ARGS",
    "category": "section",
    "text": "Arguments to be passed to the LLVM backend.note: Note\nThis environment variable has an effect only if Julia was compiled with JL_DEBUG_BUILD set — in particular, the julia-debug executable is always compiled with this build variable."
},

{
    "location": "manual/environment-variables/#JULIA_DEBUG_LOADING-1",
    "page": "Environment Variables",
    "title": "JULIA_DEBUG_LOADING",
    "category": "section",
    "text": "If set, then Julia prints detailed information about the cache in the loading process of Base.require."
},

{
    "location": "manual/embedding/#",
    "page": "Embedding Julia",
    "title": "Embedding Julia",
    "category": "page",
    "text": ""
},

{
    "location": "manual/embedding/#Embedding-Julia-1",
    "page": "Embedding Julia",
    "title": "Embedding Julia",
    "category": "section",
    "text": "As we have seen in Calling C and Fortran Code, Julia has a simple and efficient way to call functions written in C. But there are situations where the opposite is needed: calling Julia function from C code. This can be used to integrate Julia code into a larger C/C++ project, without the need to rewrite everything in C/C++. Julia has a C API to make this possible. As almost all programming languages have some way to call C functions, the Julia C API can also be used to build further language bridges (e.g. calling Julia from Python or C#)."
},

{
    "location": "manual/embedding/#High-Level-Embedding-1",
    "page": "Embedding Julia",
    "title": "High-Level Embedding",
    "category": "section",
    "text": "We start with a simple C program that initializes Julia and calls some Julia code:#include <julia.h>\n\nint main(int argc, char *argv[])\n{\n    /* required: setup the Julia context */\n    jl_init();\n\n    /* run Julia commands */\n    jl_eval_string(\"print(sqrt(2.0))\");\n\n    /* strongly recommended: notify Julia that the\n         program is about to terminate. this allows\n         Julia time to cleanup pending write requests\n         and run all finalizers\n    */\n    jl_atexit_hook(0);\n    return 0;\n}In order to build this program you have to put the path to the Julia header into the include path and link against libjulia. For instance, when Julia is installed to $JULIA_DIR, one can compile the above test program test.c with gcc using:gcc -o test -fPIC -I$JULIA_DIR/include/julia -L$JULIA_DIR/lib test.c -ljulia $JULIA_DIR/lib/julia/libstdc++.so.6Then if the environment variable JULIA_HOME is set to $JULIA_DIR/bin, the output test program can be executed.Alternatively, look at the embedding.c program in the Julia source tree in the examples/ folder. The file ui/repl.c program is another simple example of how to set jl_options options while linking against libjulia.The first thing that has to be done before calling any other Julia C function is to initialize Julia. This is done by calling jl_init, which tries to automatically determine Julia\'s install location. If you need to specify a custom location, or specify which system image to load, use jl_init_with_image instead.The second statement in the test program evaluates a Julia statement using a call to jl_eval_string.Before the program terminates, it is strongly recommended to call jl_atexit_hook.  The above example program calls this before returning from main.note: Note\nCurrently, dynamically linking with the libjulia shared library requires passing the RTLD_GLOBAL option. In Python, this looks like:>>> julia=CDLL(\'./libjulia.dylib\',RTLD_GLOBAL)\n>>> julia.jl_init.argtypes = []\n>>> julia.jl_init()\n250593296note: Note\nIf the julia program needs to access symbols from the main executable, it may be necessary to add -Wl,--export-dynamic linker flag at compile time on Linux in addition to the ones generated by julia-config.jl described below. This is not necessary when compiling a shared library."
},

{
    "location": "manual/embedding/#Using-julia-config-to-automatically-determine-build-parameters-1",
    "page": "Embedding Julia",
    "title": "Using julia-config to automatically determine build parameters",
    "category": "section",
    "text": "The script julia-config.jl was created to aid in determining what build parameters are required by a program that uses embedded Julia.  This script uses the build parameters and system configuration of the particular Julia distribution it is invoked by to export the necessary compiler flags for an embedding program to interact with that distribution.  This script is located in the Julia shared data directory."
},

{
    "location": "manual/embedding/#Example-1",
    "page": "Embedding Julia",
    "title": "Example",
    "category": "section",
    "text": "#include <julia.h>\n\nint main(int argc, char *argv[])\n{\n    jl_init();\n    (void)jl_eval_string(\"println(sqrt(2.0))\");\n    jl_atexit_hook(0);\n    return 0;\n}"
},

{
    "location": "manual/embedding/#On-the-command-line-1",
    "page": "Embedding Julia",
    "title": "On the command line",
    "category": "section",
    "text": "A simple use of this script is from the command line.  Assuming that julia-config.jl is located in /usr/local/julia/share/julia, it can be invoked on the command line directly and takes any combination of 3 flags:/usr/local/julia/share/julia/julia-config.jl\nUsage: julia-config [--cflags|--ldflags|--ldlibs]If the above example source is saved in the file embed_example.c, then the following command will compile it into a running program on Linux and Windows (MSYS2 environment), or if on OS/X, then substitute clang for gcc.:/usr/local/julia/share/julia/julia-config.jl --cflags --ldflags --ldlibs | xargs gcc embed_example.c"
},

{
    "location": "manual/embedding/#Use-in-Makefiles-1",
    "page": "Embedding Julia",
    "title": "Use in Makefiles",
    "category": "section",
    "text": "But in general, embedding projects will be more complicated than the above, and so the following allows general makefile support as well – assuming GNU make because of the use of the shell macro expansions.  Additionally, though many times julia-config.jl may be found in the directory /usr/local, this is not necessarily the case, but Julia can be used to locate julia-config.jl too, and the makefile can be used to take advantage of that.  The above example is extended to use a Makefile:JL_SHARE = $(shell julia -e \'print(joinpath(JULIA_HOME,Base.DATAROOTDIR,\"julia\"))\')\nCFLAGS   += $(shell $(JL_SHARE)/julia-config.jl --cflags)\nCXXFLAGS += $(shell $(JL_SHARE)/julia-config.jl --cflags)\nLDFLAGS  += $(shell $(JL_SHARE)/julia-config.jl --ldflags)\nLDLIBS   += $(shell $(JL_SHARE)/julia-config.jl --ldlibs)\n\nall: embed_exampleNow the build command is simply make."
},

{
    "location": "manual/embedding/#Converting-Types-1",
    "page": "Embedding Julia",
    "title": "Converting Types",
    "category": "section",
    "text": "Real applications will not just need to execute expressions, but also return their values to the host program. jl_eval_string returns a jl_value_t*, which is a pointer to a heap-allocated Julia object. Storing simple data types like Float64 in this way is called boxing, and extracting the stored primitive data is called unboxing. Our improved sample program that calculates the square root of 2 in Julia and reads back the result in C looks as follows:jl_value_t *ret = jl_eval_string(\"sqrt(2.0)\");\n\nif (jl_typeis(ret, jl_float64_type)) {\n    double ret_unboxed = jl_unbox_float64(ret);\n    printf(\"sqrt(2.0) in C: %e \\n\", ret_unboxed);\n}\nelse {\n    printf(\"ERROR: unexpected return type from sqrt(::Float64)\\n\");\n}In order to check whether ret is of a specific Julia type, we can use the jl_isa, jl_typeis, or jl_is_... functions. By typing typeof(sqrt(2.0)) into the Julia shell we can see that the return type is Float64 (double in C). To convert the boxed Julia value into a C double the jl_unbox_float64 function is used in the above code snippet.Corresponding jl_box_... functions are used to convert the other way:jl_value_t *a = jl_box_float64(3.0);\njl_value_t *b = jl_box_float32(3.0f);\njl_value_t *c = jl_box_int32(3);As we will see next, boxing is required to call Julia functions with specific arguments."
},

{
    "location": "manual/embedding/#Calling-Julia-Functions-1",
    "page": "Embedding Julia",
    "title": "Calling Julia Functions",
    "category": "section",
    "text": "While jl_eval_string allows C to obtain the result of a Julia expression, it does not allow passing arguments computed in C to Julia. For this you will need to invoke Julia functions directly, using jl_call:jl_function_t *func = jl_get_function(jl_base_module, \"sqrt\");\njl_value_t *argument = jl_box_float64(2.0);\njl_value_t *ret = jl_call1(func, argument);In the first step, a handle to the Julia function sqrt is retrieved by calling jl_get_function. The first argument passed to jl_get_function is a pointer to the Base module in which sqrt is defined. Then, the double value is boxed using jl_box_float64. Finally, in the last step, the function is called using jl_call1. jl_call0, jl_call2, and jl_call3 functions also exist, to conveniently handle different numbers of arguments. To pass more arguments, use jl_call:jl_value_t *jl_call(jl_function_t *f, jl_value_t **args, int32_t nargs)Its second argument args is an array of jl_value_t* arguments and nargs is the number of arguments."
},

{
    "location": "manual/embedding/#Memory-Management-1",
    "page": "Embedding Julia",
    "title": "Memory Management",
    "category": "section",
    "text": "As we have seen, Julia objects are represented in C as pointers. This raises the question of who is responsible for freeing these objects.Typically, Julia objects are freed by a garbage collector (GC), but the GC does not automatically know that we are holding a reference to a Julia value from C. This means the GC can free objects out from under you, rendering pointers invalid.The GC can only run when Julia objects are allocated. Calls like jl_box_float64 perform allocation, and allocation might also happen at any point in running Julia code. However, it is generally safe to use pointers in between jl_... calls. But in order to make sure that values can survive jl_... calls, we have to tell Julia that we hold a reference to a Julia value. This can be done using the JL_GC_PUSH macros:jl_value_t *ret = jl_eval_string(\"sqrt(2.0)\");\nJL_GC_PUSH1(&ret);\n// Do something with ret\nJL_GC_POP();The JL_GC_POP call releases the references established by the previous JL_GC_PUSH. Note that JL_GC_PUSH  is working on the stack, so it must be exactly paired with a JL_GC_POP before the stack frame is destroyed.Several Julia values can be pushed at once using the JL_GC_PUSH2 , JL_GC_PUSH3 , and JL_GC_PUSH4 macros. To push an array of Julia values one can use the  JL_GC_PUSHARGS macro, which can be used as follows:jl_value_t **args;\nJL_GC_PUSHARGS(args, 2); // args can now hold 2 `jl_value_t*` objects\nargs[0] = some_value;\nargs[1] = some_other_value;\n// Do something with args (e.g. call jl_... functions)\nJL_GC_POP();The garbage collector also operates under the assumption that it is aware of every old-generation object pointing to a young-generation one. Any time a pointer is updated breaking that assumption, it must be signaled to the collector with the jl_gc_wb (write barrier) function like so:jl_value_t *parent = some_old_value, *child = some_young_value;\n((some_specific_type*)parent)->field = child;\njl_gc_wb(parent, child);It is in general impossible to predict which values will be old at runtime, so the write barrier must be inserted after all explicit stores. One notable exception is if the parent object was just allocated and garbage collection was not run since then. Remember that most jl_... functions can sometimes invoke garbage collection.The write barrier is also necessary for arrays of pointers when updating their data directly. For example:jl_array_t *some_array = ...; // e.g. a Vector{Any}\nvoid **data = (void**)jl_array_data(some_array);\njl_value_t *some_value = ...;\ndata[0] = some_value;\njl_gc_wb(some_array, some_value);"
},

{
    "location": "manual/embedding/#Manipulating-the-Garbage-Collector-1",
    "page": "Embedding Julia",
    "title": "Manipulating the Garbage Collector",
    "category": "section",
    "text": "There are some functions to control the GC. In normal use cases, these should not be necessary.Function Description\njl_gc_collect() Force a GC run\njl_gc_enable(0) Disable the GC, return previous state as int\njl_gc_enable(1) Enable the GC,  return previous state as int\njl_gc_is_enabled() Return current state as int"
},

{
    "location": "manual/embedding/#Working-with-Arrays-1",
    "page": "Embedding Julia",
    "title": "Working with Arrays",
    "category": "section",
    "text": "Julia and C can share array data without copying. The next example will show how this works.Julia arrays are represented in C by the datatype jl_array_t*. Basically, jl_array_t is a struct that contains:Information about the datatype\nA pointer to the data block\nInformation about the sizes of the arrayTo keep things simple, we start with a 1D array. Creating an array containing Float64 elements of length 10 is done by:jl_value_t* array_type = jl_apply_array_type(jl_float64_type, 1);\njl_array_t* x          = jl_alloc_array_1d(array_type, 10);Alternatively, if you have already allocated the array you can generate a thin wrapper around its data:double *existingArray = (double*)malloc(sizeof(double)*10);\njl_array_t *x = jl_ptr_to_array_1d(array_type, existingArray, 10, 0);The last argument is a boolean indicating whether Julia should take ownership of the data. If this argument is non-zero, the GC will call free on the data pointer when the array is no longer referenced.In order to access the data of x, we can use jl_array_data:double *xData = (double*)jl_array_data(x);Now we can fill the array:for(size_t i=0; i<jl_array_len(x); i++)\n    xData[i] = i;Now let us call a Julia function that performs an in-place operation on x:jl_function_t *func = jl_get_function(jl_base_module, \"reverse!\");\njl_call1(func, (jl_value_t*)x);By printing the array, one can verify that the elements of x are now reversed."
},

{
    "location": "manual/embedding/#Accessing-Returned-Arrays-1",
    "page": "Embedding Julia",
    "title": "Accessing Returned Arrays",
    "category": "section",
    "text": "If a Julia function returns an array, the return value of jl_eval_string and jl_call can be cast to a jl_array_t*:jl_function_t *func  = jl_get_function(jl_base_module, \"reverse\");\njl_array_t *y = (jl_array_t*)jl_call1(func, (jl_value_t*)x);Now the content of y can be accessed as before using jl_array_data. As always, be sure to keep a reference to the array while it is in use."
},

{
    "location": "manual/embedding/#Multidimensional-Arrays-1",
    "page": "Embedding Julia",
    "title": "Multidimensional Arrays",
    "category": "section",
    "text": "Julia\'s multidimensional arrays are stored in memory in column-major order. Here is some code that creates a 2D array and accesses its properties:// Create 2D array of float64 type\njl_value_t *array_type = jl_apply_array_type(jl_float64_type, 2);\njl_array_t *x  = jl_alloc_array_2d(array_type, 10, 5);\n\n// Get array pointer\ndouble *p = (double*)jl_array_data(x);\n// Get number of dimensions\nint ndims = jl_array_ndims(x);\n// Get the size of the i-th dim\nsize_t size0 = jl_array_dim(x,0);\nsize_t size1 = jl_array_dim(x,1);\n\n// Fill array with data\nfor(size_t i=0; i<size1; i++)\n    for(size_t j=0; j<size0; j++)\n        p[j + size0*i] = i + j;Notice that while Julia arrays use 1-based indexing, the C API uses 0-based indexing (for example in calling jl_array_dim) in order to read as idiomatic C code."
},

{
    "location": "manual/embedding/#Exceptions-1",
    "page": "Embedding Julia",
    "title": "Exceptions",
    "category": "section",
    "text": "Julia code can throw exceptions. For example, consider:jl_eval_string(\"this_function_does_not_exist()\");This call will appear to do nothing. However, it is possible to check whether an exception was thrown:if (jl_exception_occurred())\n    printf(\"%s \\n\", jl_typeof_str(jl_exception_occurred()));If you are using the Julia C API from a language that supports exceptions (e.g. Python, C#, C++), it makes sense to wrap each call into libjulia with a function that checks whether an exception was thrown, and then rethrows the exception in the host language."
},

{
    "location": "manual/embedding/#Throwing-Julia-Exceptions-1",
    "page": "Embedding Julia",
    "title": "Throwing Julia Exceptions",
    "category": "section",
    "text": "When writing Julia callable functions, it might be necessary to validate arguments and throw exceptions to indicate errors. A typical type check looks like:if (!jl_typeis(val, jl_float64_type)) {\n    jl_type_error(function_name, (jl_value_t*)jl_float64_type, val);\n}General exceptions can be raised using the functions:void jl_error(const char *str);\nvoid jl_errorf(const char *fmt, ...);jl_error takes a C string, and jl_errorf is called like printf:jl_errorf(\"argument x = %d is too large\", x);where in this example x is assumed to be an integer."
},

{
    "location": "manual/packages/#",
    "page": "Packages",
    "title": "Packages",
    "category": "page",
    "text": ""
},

{
    "location": "manual/packages/#Packages-1",
    "page": "Packages",
    "title": "Packages",
    "category": "section",
    "text": "Julia has a built-in package manager for installing add-on functionality written in Julia. It can also install external libraries using your operating system\'s standard system for doing so, or by compiling from source. The list of registered Julia packages can be found at http://pkg.julialang.org. All package manager commands are found in the Pkg module, included in Julia\'s Base install.First we\'ll go over the mechanics of the Pkg family of commands and then we\'ll provide some guidance on how to get your package registered. Be sure to read the section below on package naming conventions, tagging versions and the importance of a REQUIRE file for when you\'re ready to add your code to the curated METADATA repository."
},

{
    "location": "manual/packages/#Package-Status-1",
    "page": "Packages",
    "title": "Package Status",
    "category": "section",
    "text": "The Pkg.status() function prints out a summary of the state of packages you have installed. Initially, you\'ll have no packages installed:julia> Pkg.status()\nINFO: Initializing package repository /Users/stefan/.julia/v0.6\nINFO: Cloning METADATA from git://github.com/JuliaLang/METADATA.jl\nNo packages installed.Your package directory is automatically initialized the first time you run a Pkg command that expects it to exist – which includes Pkg.status(). Here\'s an example non-trivial set of required and additional packages:julia> Pkg.status()\nRequired packages:\n - Distributions                 0.2.8\n - SHA                           0.3.2\nAdditional packages:\n - NumericExtensions             0.2.17\n - Stats                         0.2.6These packages are all on registered versions, managed by Pkg. Packages can be in more complicated states, indicated by annotations to the right of the installed package version; we will explain these states and annotations as we encounter them. For programmatic usage, Pkg.installed() returns a dictionary, mapping installed package names to the version of that package which is installed:julia> Pkg.installed()\nDict{String,VersionNumber} with 4 entries:\n\"Distributions\"     => v\"0.2.8\"\n\"Stats\"             => v\"0.2.6\"\n\"SHA\"               => v\"0.3.2\"\n\"NumericExtensions\" => v\"0.2.17\""
},

{
    "location": "manual/packages/#Adding-and-Removing-Packages-1",
    "page": "Packages",
    "title": "Adding and Removing Packages",
    "category": "section",
    "text": "Julia\'s package manager is a little unusual in that it is declarative rather than imperative. This means that you tell it what you want and it figures out what versions to install (or remove) to satisfy those requirements optimally – and minimally. So rather than installing a package, you just add it to the list of requirements and then \"resolve\" what needs to be installed. In particular, this means that if some package had been installed because it was needed by a previous version of something you wanted, and a newer version doesn\'t have that requirement anymore, updating will actually remove that package.Your package requirements are in the file ~/.julia/v0.6/REQUIRE. You can edit this file by hand and then call Pkg.resolve() to install, upgrade or remove packages to optimally satisfy the requirements, or you can do Pkg.edit(), which will open REQUIRE in your editor (configured via the EDITOR or VISUAL environment variables), and then automatically call Pkg.resolve() afterwards if necessary. If you only want to add or remove the requirement for a single package, you can also use the non-interactive Pkg.add() and Pkg.rm() commands, which add or remove a single requirement to REQUIRE and then call Pkg.resolve().You can add a package to the list of requirements with the Pkg.add() function, and the package and all the packages that it depends on will be installed:julia> Pkg.status()\nNo packages installed.\n\njulia> Pkg.add(\"Distributions\")\nINFO: Cloning cache of Distributions from git://github.com/JuliaStats/Distributions.jl.git\nINFO: Cloning cache of NumericExtensions from git://github.com/lindahua/NumericExtensions.jl.git\nINFO: Cloning cache of Stats from git://github.com/JuliaStats/Stats.jl.git\nINFO: Installing Distributions v0.2.7\nINFO: Installing NumericExtensions v0.2.17\nINFO: Installing Stats v0.2.6\nINFO: REQUIRE updated.\n\njulia> Pkg.status()\nRequired packages:\n - Distributions                 0.2.7\nAdditional packages:\n - NumericExtensions             0.2.17\n - Stats                         0.2.6What this is doing is first adding Distributions to your ~/.julia/v0.6/REQUIRE file:$ cat ~/.julia/v0.6/REQUIRE\nDistributionsIt then runs Pkg.resolve() using these new requirements, which leads to the conclusion that the Distributions package should be installed since it is required but not installed. As stated before, you can accomplish the same thing by editing your ~/.julia/v0.6/REQUIRE file by hand and then running Pkg.resolve() yourself:$ echo SHA >> ~/.julia/v0.6/REQUIRE\n\njulia> Pkg.resolve()\nINFO: Cloning cache of SHA from git://github.com/staticfloat/SHA.jl.git\nINFO: Installing SHA v0.3.2\n\njulia> Pkg.status()\nRequired packages:\n - Distributions                 0.2.7\n - SHA                           0.3.2\nAdditional packages:\n - NumericExtensions             0.2.17\n - Stats                         0.2.6This is functionally equivalent to calling Pkg.add(\"SHA\"), except that Pkg.add() doesn\'t change REQUIRE until after installation has completed, so if there are problems, REQUIRE will be left as it was before calling Pkg.add(). The format of the REQUIRE file is described in Requirements Specification; it allows, among other things, requiring specific ranges of versions of packages.When you decide that you don\'t want to have a package around any more, you can use Pkg.rm() to remove the requirement for it from the REQUIRE file:julia> Pkg.rm(\"Distributions\")\nINFO: Removing Distributions v0.2.7\nINFO: Removing Stats v0.2.6\nINFO: Removing NumericExtensions v0.2.17\nINFO: REQUIRE updated.\n\njulia> Pkg.status()\nRequired packages:\n - SHA                           0.3.2\n\njulia> Pkg.rm(\"SHA\")\nINFO: Removing SHA v0.3.2\nINFO: REQUIRE updated.\n\njulia> Pkg.status()\nNo packages installed.Once again, this is equivalent to editing the REQUIRE file to remove the line with each package name on it then running Pkg.resolve() to update the set of installed packages to match. While Pkg.add() and Pkg.rm() are convenient for adding and removing requirements for a single package, when you want to add or remove multiple packages, you can call Pkg.edit() to manually change the contents of REQUIRE and then update your packages accordingly. Pkg.edit() does not roll back the contents of REQUIRE if Pkg.resolve() fails – rather, you have to run Pkg.edit() again to fix the files contents yourself.Because the package manager uses libgit2 internally to manage the package git repositories, users may run into protocol issues (if behind a firewall, for example), when running Pkg.add(). By default, all GitHub-hosted packages wil be accessed via \'https\'; this default can be modified by calling Pkg.setprotocol!(). The following command can be run from the command line in order to tell git to use \'https\' instead of the \'git\' protocol when cloning all repositories, wherever they are hosted:git config --global url.\"https://\".insteadOf git://However, this change will be system-wide and thus the use of Pkg.setprotocol!() is preferable.note: Note\nThe package manager functions also accept the .jl suffix on package names, though the suffix is stripped internally. For example:Pkg.add(\"Distributions.jl\")\nPkg.rm(\"Distributions.jl\")"
},

{
    "location": "manual/packages/#Offline-Installation-of-Packages-1",
    "page": "Packages",
    "title": "Offline Installation of Packages",
    "category": "section",
    "text": "For machines with no Internet connection, packages may be installed by copying the package root directory (given by Pkg.dir()) from a machine with the same operating system and environment.Pkg.add() does the following within the package root directory:Adds the name of the package to REQUIRE.\nDownloads the package to .cache, then copies the package to the package root directory.\nRecursively performs step 2 against all the packages listed in the package\'s REQUIRE file.\nRuns Pkg.build()warning: Warning\nCopying installed packages from a different machine is brittle for packages requiring binary external dependencies. Such packages may break due to differences in operating system versions, build environments, and/or absolute path dependencies."
},

{
    "location": "manual/packages/#Installing-Unregistered-Packages-1",
    "page": "Packages",
    "title": "Installing Unregistered Packages",
    "category": "section",
    "text": "Julia packages are simply git repositories, clonable via any of the protocols that git supports, and containing Julia code that follows certain layout conventions. Official Julia packages are registered in the METADATA.jl repository, available at a well-known location [1]. The Pkg.add() and Pkg.rm() commands in the previous section interact with registered packages, but the package manager can install and work with unregistered packages too. To install an unregistered package, use Pkg.clone(url), where url is a git URL from which the package can be cloned:julia> Pkg.clone(\"git://example.com/path/to/Package.jl.git\")\nINFO: Cloning Package from git://example.com/path/to/Package.jl.git\nCloning into \'Package\'...\nremote: Counting objects: 22, done.\nremote: Compressing objects: 100% (10/10), done.\nremote: Total 22 (delta 8), reused 22 (delta 8)\nReceiving objects: 100% (22/22), 2.64 KiB, done.\nResolving deltas: 100% (8/8), done.By convention, Julia repository names end with .jl (the additional .git indicates a \"bare\" git repository), which keeps them from colliding with repositories for other languages, and also makes Julia packages easy to find in search engines. When packages are installed in your .julia/v0.6 directory, however, the extension is redundant so we leave it off.If unregistered packages contain a REQUIRE file at the top of their source tree, that file will be used to determine which registered packages the unregistered package depends on, and they will automatically be installed. Unregistered packages participate in the same version resolution logic as registered packages, so installed package versions will be adjusted as necessary to satisfy the requirements of both registered and unregistered packages.[1]: The official set of packages is at https://github.com/JuliaLang/METADATA.jl, but individuals and organizations can easily use a different metadata repository. This allows control which packages are available for automatic installation. One can allow only audited and approved package versions, and make private packages or forks available. See Custom METADATA Repository for details."
},

{
    "location": "manual/packages/#Updating-Packages-1",
    "page": "Packages",
    "title": "Updating Packages",
    "category": "section",
    "text": "When package developers publish new registered versions of packages that you\'re using, you will, of course, want the new shiny versions. To get the latest and greatest versions of all your packages, just do Pkg.update():julia> Pkg.update()\nINFO: Updating METADATA...\nINFO: Computing changes...\nINFO: Upgrading Distributions: v0.2.8 => v0.2.10\nINFO: Upgrading Stats: v0.2.7 => v0.2.8The first step of updating packages is to pull new changes to ~/.julia/v0.6/METADATA and see if any new registered package versions have been published. After this, Pkg.update() attempts to update packages that are checked out on a branch and not dirty (i.e. no changes have been made to files tracked by git) by pulling changes from the package\'s upstream repository. Upstream changes will only be applied if no merging or rebasing is necessary – i.e. if the branch can be \"fast-forwarded\". If the branch cannot be fast-forwarded, it is assumed that you\'re working on it and will update the repository yourself.Finally, the update process recomputes an optimal set of package versions to have installed to satisfy your top-level requirements and the requirements of \"fixed\" packages. A package is considered fixed if it is one of the following:Unregistered: the package is not in METADATA – you installed it with Pkg.clone().\nChecked out: the package repo is on a development branch.\nDirty: changes have been made to files in the repo.If any of these are the case, the package manager cannot freely change the installed version of the package, so its requirements must be satisfied by whatever other package versions it picks. The combination of top-level requirements in ~/.julia/v0.6/REQUIRE and the requirement of fixed packages are used to determine what should be installed.You can also update only a subset of the installed packages, by providing arguments to the Pkg.update function. In that case, only the packages provided as arguments and their dependencies will be updated:julia> Pkg.update(\"Example\")\nINFO: Updating METADATA...\nINFO: Computing changes...\nINFO: Upgrading Example: v0.4.0 => 0.4.1This partial update process still computes the new set of package versions according to top-level requirements and \"fixed\" packages, but it additionally considers all other packages except those explicitly provided, and their dependencies, as fixed."
},

{
    "location": "manual/packages/#Checkout,-Pin-and-Free-1",
    "page": "Packages",
    "title": "Checkout, Pin and Free",
    "category": "section",
    "text": "You may want to use the master version of a package rather than one of its registered versions. There might be fixes or functionality on master that you need that aren\'t yet published in any registered versions, or you may be a developer of the package and need to make changes on master or some other development branch. In such cases, you can do Pkg.checkout(pkg) to checkout the master branch of pkg or Pkg.checkout(pkg,branch) to checkout some other branch:julia> Pkg.add(\"Distributions\")\nINFO: Installing Distributions v0.2.9\nINFO: Installing NumericExtensions v0.2.17\nINFO: Installing Stats v0.2.7\nINFO: REQUIRE updated.\n\njulia> Pkg.status()\nRequired packages:\n - Distributions                 0.2.9\nAdditional packages:\n - NumericExtensions             0.2.17\n - Stats                         0.2.7\n\njulia> Pkg.checkout(\"Distributions\")\nINFO: Checking out Distributions master...\nINFO: No packages to install, update or remove.\n\njulia> Pkg.status()\nRequired packages:\n - Distributions                 0.2.9+             master\nAdditional packages:\n - NumericExtensions             0.2.17\n - Stats                         0.2.7Immediately after installing Distributions with Pkg.add() it is on the current most recent registered version – 0.2.9 at the time of writing this. Then after running Pkg.checkout(\"Distributions\"), you can see from the output of Pkg.status() that Distributions is on an unregistered version greater than 0.2.9, indicated by the \"pseudo-version\" number 0.2.9+.When you checkout an unregistered version of a package, the copy of the REQUIRE file in the package repo takes precedence over any requirements registered in METADATA, so it is important that developers keep this file accurate and up-to-date, reflecting the actual requirements of the current version of the package. If the REQUIRE file in the package repo is incorrect or missing, dependencies may be removed when the package is checked out. This file is also used to populate newly published versions of the package if you use the API that Pkg provides for this (described below).When you decide that you no longer want to have a package checked out on a branch, you can \"free\" it back to the control of the package manager with Pkg.free(pkg):julia> Pkg.free(\"Distributions\")\nINFO: Freeing Distributions...\nINFO: No packages to install, update or remove.\n\njulia> Pkg.status()\nRequired packages:\n - Distributions                 0.2.9\nAdditional packages:\n - NumericExtensions             0.2.17\n - Stats                         0.2.7After this, since the package is on a registered version and not on a branch, its version will be updated as new registered versions of the package are published.If you want to pin a package at a specific version so that calling Pkg.update() won\'t change the version the package is on, you can use the Pkg.pin() function:julia> Pkg.pin(\"Stats\")\nINFO: Creating Stats branch pinned.47c198b1.tmp\n\njulia> Pkg.status()\nRequired packages:\n - Distributions                 0.2.9\nAdditional packages:\n - NumericExtensions             0.2.17\n - Stats                         0.2.7              pinned.47c198b1.tmpAfter this, the Stats package will remain pinned at version 0.2.7 – or more specifically, at commit 47c198b1, but since versions are permanently associated a given git hash, this is the same thing. Pkg.pin() works by creating a throw-away branch for the commit you want to pin the package at and then checking that branch out. By default, it pins a package at the current commit, but you can choose a different version by passing a second argument:julia> Pkg.pin(\"Stats\",v\"0.2.5\")\nINFO: Creating Stats branch pinned.1fd0983b.tmp\nINFO: No packages to install, update or remove.\n\njulia> Pkg.status()\nRequired packages:\n - Distributions                 0.2.9\nAdditional packages:\n - NumericExtensions             0.2.17\n - Stats                         0.2.5              pinned.1fd0983b.tmpNow the Stats package is pinned at commit 1fd0983b, which corresponds to version 0.2.5. When you decide to \"unpin\" a package and let the package manager update it again, you can use Pkg.free() like you would to move off of any branch:julia> Pkg.free(\"Stats\")\nINFO: Freeing Stats...\nINFO: No packages to install, update or remove.\n\njulia> Pkg.status()\nRequired packages:\n - Distributions                 0.2.9\nAdditional packages:\n - NumericExtensions             0.2.17\n - Stats                         0.2.7After this, the Stats package is managed by the package manager again, and future calls to Pkg.update() will upgrade it to newer versions when they are published. The throw-away pinned.1fd0983b.tmp branch remains in your local Stats repo, but since git branches are extremely lightweight, this doesn\'t really matter; if you feel like cleaning them up, you can go into the repo and delete those branches [2].[2]: Packages that aren\'t on branches will also be marked as dirty if you make changes in the repo, but that\'s a less common thing to do."
},

{
    "location": "manual/packages/#Custom-METADATA-Repository-1",
    "page": "Packages",
    "title": "Custom METADATA Repository",
    "category": "section",
    "text": "By default, Julia assumes you will be using the official METADATA.jl repository for downloading and installing packages. You can also provide a different metadata repository location. A common approach is to keep your metadata-v2 branch up to date with the Julia official branch and add another branch with your custom packages. You can initialize your local metadata repository using that custom location and branch and then periodically rebase your custom branch with the official metadata-v2 branch. In order to use a custom repository and branch, issue the following command:julia> Pkg.init(\"https://me.example.com/METADATA.jl.git\", \"branch\")The branch argument is optional and defaults to metadata-v2. Once initialized, a file named META_BRANCH in your ~/.julia/vX.Y/ path will track the branch that your METADATA repository was initialized with. If you want to change branches, you will need to either modify the META_BRANCH file directly (be careful!) or remove the vX.Y directory and re-initialize your METADATA repository using the Pkg.init command."
},

{
    "location": "manual/packages/#Package-Development-1",
    "page": "Packages",
    "title": "Package Development",
    "category": "section",
    "text": "Julia\'s package manager is designed so that when you have a package installed, you are already in a position to look at its source code and full development history. You are also able to make changes to packages, commit them using git, and easily contribute fixes and enhancements upstream. Similarly, the system is designed so that if you want to create a new package, the simplest way to do so is within the infrastructure provided by the package manager."
},

{
    "location": "manual/packages/#man-initial-setup-1",
    "page": "Packages",
    "title": "Initial Setup",
    "category": "section",
    "text": "Since packages are git repositories, before doing any package development you should setup the following standard global git configuration settings:$ git config --global user.name \"FULL NAME\"\n$ git config --global user.email \"EMAIL\"where FULL NAME is your actual full name (spaces are allowed between the double quotes) and EMAIL is your actual email address. Although it isn\'t necessary to use GitHub to create or publish Julia packages, most Julia packages as of writing this are hosted on GitHub and the package manager knows how to format origin URLs correctly and otherwise work with the service smoothly. We recommend that you create a free account on GitHub and then do:$ git config --global github.user \"USERNAME\"where USERNAME is your actual GitHub user name. Once you do this, the package manager knows your GitHub user name and can configure things accordingly. You should also upload your public SSH key to GitHub and set up an SSH agent on your development machine so that you can push changes with minimal hassle. In the future, we will make this system extensible and support other common git hosting options like BitBucket and allow developers to choose their favorite. Since the package development functions has been moved to the PkgDev package, you need to run Pkg.add(\"PkgDev\"); import PkgDev to access the functions starting with PkgDev. in the document below."
},

{
    "location": "manual/packages/#Making-changes-to-an-existing-package-1",
    "page": "Packages",
    "title": "Making changes to an existing package",
    "category": "section",
    "text": ""
},

{
    "location": "manual/packages/#Documentation-changes-1",
    "page": "Packages",
    "title": "Documentation changes",
    "category": "section",
    "text": "If you want to improve the online documentation of a package, the easiest approach (at least for small changes) is to use GitHub\'s online editing functionality. First, navigate to the repository\'s GitHub \"home page,\" find the file (e.g., README.md) within the repository\'s folder structure, and click on it. You\'ll see the contents displayed, along with a small \"pencil\" icon in the upper right hand corner. Clicking that icon opens the file in edit mode. Make your changes, write a brief summary describing the changes you want to make (this is your commit message), and then hit \"Propose file change.\" Your changes will be submitted for consideration by the package owner(s) and collaborators.For larger documentation changes–and especially ones that you expect to have to update in response to feedback–you might find it easier to use the procedure for code changes described below."
},

{
    "location": "manual/packages/#Code-changes-1",
    "page": "Packages",
    "title": "Code changes",
    "category": "section",
    "text": ""
},

{
    "location": "manual/packages/#Executive-summary-1",
    "page": "Packages",
    "title": "Executive summary",
    "category": "section",
    "text": "Here we assume you\'ve already set up git on your local machine and have a GitHub account (see above). Let\'s imagine you\'re fixing a bug in the Images package:Pkg.checkout(\"Images\")           # check out the master branch\n<here, make sure your bug is still a bug and hasn\'t been fixed already>\ncd(Pkg.dir(\"Images\"))\n;git checkout -b myfixes         # create a branch for your changes\n<edit code>                      # be sure to add a test for your bug\nPkg.test(\"Images\")               # make sure everything works now\n;git commit -a -m \"Fix foo by calling bar\"   # write a descriptive message\nusing PkgDev\nPkgDev.submit(\"Images\")The last line will present you with a link to submit a pull request to incorporate your changes."
},

{
    "location": "manual/packages/#Detailed-description-1",
    "page": "Packages",
    "title": "Detailed description",
    "category": "section",
    "text": "If you want to fix a bug or add new functionality, you want to be able to test your changes before you submit them for consideration. You also need to have an easy way to update your proposal in response to the package owner\'s feedback. Consequently, in this case the strategy is to work locally on your own machine; once you are satisfied with your changes, you submit them for consideration.  This process is called a pull request because you are asking to \"pull\" your changes into the project\'s main repository. Because the online repository can\'t see the code on your private machine, you first push your changes to a publicly-visible location, your own online fork of the package (hosted on your own personal GitHub account).Let\'s assume you already have the Foo package installed. In the description below, anything starting with Pkg. or PkgDev. is meant to be typed at the Julia prompt; anything starting with git is meant to be typed in julia\'s shell mode (or using the shell that comes with your operating system). Within Julia, you can combine these two modes:julia> cd(Pkg.dir(\"Foo\"))          # go to Foo\'s folder\n\nshell> git command arguments...    # command will apply to FooNow suppose you\'re ready to make some changes to Foo. While there are several possible approaches, here is one that is widely used:From the Julia prompt, type Pkg.checkout(\"Foo\"). This ensures you\'re running the latest code (the master branch), rather than just whatever \"official release\" version you have installed. (If you\'re planning to fix a bug, at this point it\'s a good idea to check again whether the bug has already been fixed by someone else. If it has, you can request that a new official release be tagged so that the fix gets distributed to the rest of the community.) If you receive an error Foo is dirty, bailing, see Dirty packages below.\nCreate a branch for your changes: navigate to the package folder (the one that Julia reports from Pkg.dir(\"Foo\")) and (in shell mode) create a new branch using git checkout -b <newbranch>, where <newbranch> might be some descriptive name (e.g., fixbar). By creating a branch, you ensure that you can easily go back and forth between your new work and the current master branch (see https://git-scm.com/book/en/v2/Git-Branching-Branches-in-a-Nutshell).\nIf you forget to do this step until after you\'ve already made some changes, don\'t worry: see more detail about branching below.\nMake your changes. Whether it\'s fixing a bug or adding new functionality, in most cases your change should include updates to both the src/ and test/ folders. If you\'re fixing a bug, add your minimal example demonstrating the bug (on the current code) to the test suite; by contributing a test for the bug, you ensure that the bug won\'t accidentally reappear at some later time due to other changes. If you\'re adding new functionality, creating tests demonstrates to the package owner that you\'ve made sure your code works as intended.\nRun the package\'s tests and make sure they pass. There are several ways to run the tests:\nFrom Julia, run Pkg.test(\"Foo\"): this will run your tests in a separate (new) julia process.\nFrom Julia, include(\"runtests.jl\") from the package\'s test/ folder (it\'s possible the file has a different name, look for one that runs all the tests): this allows you to run the tests repeatedly in the same session without reloading all the package code; for packages that take a while to load, this can be much faster. With this approach, you do have to do some extra work to make changes in the package code.\nFrom the shell, run julia ../test/runtests.jl from within the package\'s src/ folder.\nCommit your changes: see https://git-scm.com/book/en/v2/Git-Basics-Recording-Changes-to-the-Repository.\nSubmit your changes: From the Julia prompt, type PkgDev.submit(\"Foo\"). This will push your changes to your GitHub fork, creating it if it doesn\'t already exist. (If you encounter an error, make sure you\'ve set up your SSH keys.) Julia will then give you a hyperlink; open that link, edit the message, and then click \"submit.\" At that point, the package owner will be notified of your changes and may initiate discussion. (If you are comfortable with git, you can also do these steps manually from the shell.)\nThe package owner may suggest additional improvements. To respond to those suggestions, you can easily update the pull request (this only works for changes that have not already been merged; for merged pull requests, make new changes by starting a new branch):\nIf you\'ve changed branches in the meantime, make sure you go back to the same branch with git checkout fixbar (from shell mode) or Pkg.checkout(\"Foo\", \"fixbar\") (from the Julia prompt).\nAs above, make your changes, run the tests, and commit your changes.\nFrom the shell, type git push.  This will add your new commit(s) to the same pull request; you should see them appear automatically on the page holding the discussion of your pull request.\nOne potential type of change the owner may request is that you squash your commits. See Squashing below."
},

{
    "location": "manual/packages/#Dirty-packages-1",
    "page": "Packages",
    "title": "Dirty packages",
    "category": "section",
    "text": "If you can\'t change branches because the package manager complains that your package is dirty, it means you have some changes that have not been committed. From the shell, use git diff to see what these changes are; you can either discard them (git checkout changedfile.jl) or commit them before switching branches.  If you can\'t easily resolve the problems manually, as a last resort you can delete the entire \"Foo\" folder and reinstall a fresh copy with Pkg.add(\"Foo\"). Naturally, this deletes any changes you\'ve made."
},

{
    "location": "manual/packages/#man-branch-post-hoc-1",
    "page": "Packages",
    "title": "Making a branch post hoc",
    "category": "section",
    "text": "Especially for newcomers to git, one often forgets to create a new branch until after some changes have already been made. If you haven\'t yet staged or committed your changes, you can create a new branch with git checkout -b <newbranch> just as usual–git will kindly show you that some files have been modified and create the new branch for you. Your changes have not yet been committed to this new branch, so the normal work rules still apply.However, if you\'ve already made a commit to master but wish to go back to the official master (called origin/master), use the following procedure:Create a new branch. This branch will hold your changes.\nMake sure everything is committed to this branch.\ngit checkout master. If this fails, do not proceed further until you have resolved the problems, or you may lose your changes.\nResetmaster (your current branch) back to an earlier state with git reset --hard origin/master (see https://git-scm.com/blog/2011/07/11/reset.html).This requires a bit more familiarity with git, so it\'s much better to get in the habit of creating a branch at the outset."
},

{
    "location": "manual/packages/#man-squashing-and-rebasing-1",
    "page": "Packages",
    "title": "Squashing and rebasing",
    "category": "section",
    "text": "Depending on the tastes of the package owner (s)he may ask you to \"squash\" your commits. This is especially likely if your change is quite simple but your commit history looks like this:WIP: add new 1-line whizbang function (currently breaks package)\nFinish whizbang function\nFix typo in variable name\nOops, don\'t forget to supply default argument\nSplit into two 1-line functions\nRats, forgot to export the second function\n...This gets into the territory of more advanced git usage, and you\'re encouraged to do some reading (https://git-scm.com/book/en/v2/Git-Branching-Rebasing).  However, a brief summary of the procedure is as follows:To protect yourself from error, start from your fixbar branch and create a new branch with git checkout -b fixbar_backup.  Since you started from fixbar, this will be a copy. Now go back to the one you intend to modify with git checkout fixbar.\nFrom the shell, type git rebase -i origin/master.\nTo combine commits, change pick to squash (for additional options, consult other sources). Save the file and close the editor window.\nEdit the combined commit message.If the rebase goes badly, you can go back to the beginning to try again like this:git checkout fixbar\ngit reset --hard fixbar_backupNow let\'s assume you\'ve rebased successfully. Since your fixbar repository has now diverged from the one in your GitHub fork, you\'re going to have to do a force push:To make it easy to refer to your GitHub fork, create a \"handle\" for it with git remote add myfork https://github.com/myaccount/Foo.jl.git, where the URL comes from the \"clone URL\" on your GitHub fork\'s page.\nForce-push to your fork with git push myfork +fixbar. The + indicates that this should replace the fixbar branch found at myfork."
},

{
    "location": "manual/packages/#Creating-a-new-Package-1",
    "page": "Packages",
    "title": "Creating a new Package",
    "category": "section",
    "text": ""
},

{
    "location": "manual/packages/#REQUIRE-speaks-for-itself-1",
    "page": "Packages",
    "title": "REQUIRE speaks for itself",
    "category": "section",
    "text": "You should have a REQUIRE file in your package repository, with a bare minimum directive of what Julia version you expect your users to be running for the package to work. Putting a floor on what Julia version your package supports is done by simply adding julia 0.x in this file. While this line is partly informational, it also has the consequence of whether Pkg.update() will update code found in .julia version directories. It will not update code found in version directories beneath the floor of what\'s specified in your REQUIRE.As the development version 0.y matures, you may find yourself using it more frequently, and wanting your package to support it. Be warned, the development branch of Julia is the land of breakage, and you can expect things to break. When you go about fixing whatever broke your package in the development 0.y branch, you will likely find that you just broke your package on the stable version.There is a mechanism found in the Compat package that will enable you to support both the stable version and breaking changes found in the development version. Should you decide to use this solution, you will need to add Compat to your REQUIRE file. In this case, you will still have julia 0.x in your REQUIRE. The x is the floor version of what your package supports.You might also have no interest in supporting the development version of Julia. Just as you can add a floor to the version you expect your users to be on, you can set an upper bound. In this case, you would put julia 0.x 0.y- in your REQUIRE file. The - at the end of the version number means pre-release versions of that specific version from the very first commit. By setting it as the ceiling, you mean the code supports everything up to but not including the ceiling version.Another scenario is that you are writing the bulk of the code for your package with Julia 0.y and do not want to support the current stable version of Julia. If you choose to do this, simply add julia 0.y- to your REQUIRE. Just remember to change the julia 0.y- to julia 0.y in your REQUIRE file once 0.y is officially released. If you don\'t edit the dash cruft you are suggesting that you support both the development and stable versions of the same version number! That would be madness. See the Requirements Specification for the full format of REQUIRE.Lastly, in many cases you may need extra packages for testing. Additional packages which are only required for tests should be specified in the test/REQUIRE file. This REQUIRE file has the same specification as the standard REQUIRE file."
},

{
    "location": "manual/packages/#Guidelines-for-naming-a-package-1",
    "page": "Packages",
    "title": "Guidelines for naming a package",
    "category": "section",
    "text": "Package names should be sensible to most Julia users, even to those who are not domain experts. When you submit your package to METADATA, you can expect a little back and forth about the package name with collaborators, especially if it\'s ambiguous or can be confused with something other than what it is. During this bike-shedding, it\'s not uncommon to get a range of different name suggestions. These are only suggestions though, with the intent being to keep a tidy namespace in the curated METADATA repository. Since this repository belongs to the entire community, there will likely be a few collaborators who care about your package name. Here are some guidelines to follow in naming your package:Avoid jargon. In particular, avoid acronyms unless there is minimal possibility of confusion.\nIt\'s ok to say USA if you\'re talking about the USA.\nIt\'s not ok to say PMA, even if you\'re talking about positive mental attitude.\nAvoid using Julia in your package name.\nIt is usually clear from context and to your users that the package is a Julia package.\nHaving Julia in the name can imply that the package is connected to, or endorsed by, contributors to the Julia language itself.\nPackages that provide most of their functionality in association with a new type should have pluralized names.\nDataFrames provides the DataFrame type.\nBloomFilters provides the BloomFilter type.\nIn contrast, JuliaParser provides no new type, but instead new functionality in the JuliaParser.parse() function.\nErr on the side of clarity, even if clarity seems long-winded to you.\nRandomMatrices is a less ambiguous name than RndMat or RMT, even though the latter are shorter.\nA less systematic name may suit a package that implements one of several possible approaches to its domain.\nJulia does not have a single comprehensive plotting package. Instead, Gadfly, PyPlot, Winston and other packages each implement a unique approach based on a particular design philosophy.\nIn contrast, SortingAlgorithms provides a consistent interface to use many well-established sorting algorithms.\nPackages that wrap external libraries or programs should be named after those libraries or programs.\nCPLEX.jl wraps the CPLEX library, which can be identified easily in a web search.\nMATLAB.jl provides an interface to call the MATLAB engine from within Julia."
},

{
    "location": "manual/packages/#Generating-the-package-1",
    "page": "Packages",
    "title": "Generating the package",
    "category": "section",
    "text": "Suppose you want to create a new Julia package called FooBar. To get started, do PkgDev.generate(pkg,license) where pkg is the new package name and license is the name of a license that the package generator knows about:julia> PkgDev.generate(\"FooBar\",\"MIT\")\nINFO: Initializing FooBar repo: /Users/stefan/.julia/v0.6/FooBar\nINFO: Origin: git://github.com/StefanKarpinski/FooBar.jl.git\nINFO: Generating LICENSE.md\nINFO: Generating README.md\nINFO: Generating src/FooBar.jl\nINFO: Generating test/runtests.jl\nINFO: Generating REQUIRE\nINFO: Generating .travis.yml\nINFO: Generating appveyor.yml\nINFO: Generating .gitignore\nINFO: Committing FooBar generated filesThis creates the directory ~/.julia/v0.6/FooBar, initializes it as a git repository, generates a bunch of files that all packages should have, and commits them to the repository:$ cd ~/.julia/v0.6/FooBar && git show --stat\n\ncommit 84b8e266dae6de30ab9703150b3bf771ec7b6285\nAuthor: Stefan Karpinski <stefan@karpinski.org>\nDate:   Wed Oct 16 17:57:58 2013 -0400\n\n    FooBar.jl generated files.\n\n        license: MIT\n        authors: Stefan Karpinski\n        years:   2013\n        user:    StefanKarpinski\n\n    Julia Version 0.3.0-prerelease+3217 [5fcfb13*]\n\n .gitignore       |  2 ++\n .travis.yml      | 13 +++++++++++++\n LICENSE.md       | 22 +++++++++++++++++++++++\n README.md        |  3 +++\n REQUIRE          |  1 +\n appveyor.yml     | 34 ++++++++++++++++++++++++++++++++++\n src/FooBar.jl    |  5 +++++\n test/runtests.jl |  5 +++++\n 8 files changed, 85 insertions(+)At the moment, the package manager knows about the MIT \"Expat\" License, indicated by \"MIT\", the Simplified BSD License, indicated by \"BSD\", and version 2.0 of the Apache Software License, indicated by \"ASL\". If you want to use a different license, you can ask us to add it to the package generator, or just pick one of these three and then modify the ~/.julia/v0.6/PACKAGE/LICENSE.md file after it has been generated.If you created a GitHub account and configured git to know about it, PkgDev.generate() will set an appropriate origin URL for you. It will also automatically generate a .travis.yml file for using the Travis automated testing service, and an appveyor.yml file for using AppVeyor. You will have to enable testing on the Travis and AppVeyor websites for your package repository, but once you\'ve done that, it will already have working tests. Of course, all the default testing does is verify that using FooBar in Julia works."
},

{
    "location": "manual/packages/#Loading-Static-Non-Julia-Files-1",
    "page": "Packages",
    "title": "Loading Static Non-Julia Files",
    "category": "section",
    "text": "If your package code needs to load static files which are not Julia code, e.g. an external library or data files, and are located within the package directory, use the @__DIR__ macro to determine the directory of the current source file. For example if FooBar/src/FooBar.jl needs to load FooBar/data/foo.csv, use the following code:datapath = joinpath(@__DIR__, \"..\", \"data\")\nfoo = readcsv(joinpath(datapath, \"foo.csv\"))"
},

{
    "location": "manual/packages/#Making-Your-Package-Available-1",
    "page": "Packages",
    "title": "Making Your Package Available",
    "category": "section",
    "text": "Once you\'ve made some commits and you\'re happy with how FooBar is working, you may want to get some other people to try it out. First you\'ll need to create the remote repository and push your code to it; we don\'t yet automatically do this for you, but we will in the future and it\'s not too hard to figure out [3]. Once you\'ve done this, letting people try out your code is as simple as sending them the URL of the published repo – in this case:git://github.com/StefanKarpinski/FooBar.jl.gitFor your package, it will be your GitHub user name and the name of your package, but you get the idea. People you send this URL to can use Pkg.clone() to install the package and try it out:julia> Pkg.clone(\"git://github.com/StefanKarpinski/FooBar.jl.git\")\nINFO: Cloning FooBar from git@github.com:StefanKarpinski/FooBar.jl.git[3]: Installing and using GitHub\'s \"hub\" tool is highly recommended. It allows you to do things like run hub create in the package repo and have it automatically created via GitHub\'s API."
},

{
    "location": "manual/packages/#Tagging-and-Publishing-Your-Package-1",
    "page": "Packages",
    "title": "Tagging and Publishing Your Package",
    "category": "section",
    "text": "tip: Tip\nIf you are hosting your package on GitHub, you can use the attobot integration to handle package registration, tagging and publishing.Once you\'ve decided that FooBar is ready to be registered as an official package, you can add it to your local copy of METADATA using PkgDev.register():julia> PkgDev.register(\"FooBar\")\nINFO: Registering FooBar at git://github.com/StefanKarpinski/FooBar.jl.git\nINFO: Committing METADATA for FooBarThis creates a commit in the ~/.julia/v0.6/METADATA repo:$ cd ~/.julia/v0.6/METADATA && git show\n\ncommit 9f71f4becb05cadacb983c54a72eed744e5c019d\nAuthor: Stefan Karpinski <stefan@karpinski.org>\nDate:   Wed Oct 16 18:46:02 2013 -0400\n\n    Register FooBar\n\ndiff --git a/FooBar/url b/FooBar/url\nnew file mode 100644\nindex 0000000..30e525e\n--- /dev/null\n+++ b/FooBar/url\n@@ -0,0 +1 @@\n+git://github.com/StefanKarpinski/FooBar.jl.gitThis commit is only locally visible, however. To make it visible to the Julia community, you need to merge your local METADATA upstream into the official repo. The PkgDev.publish() command will fork the METADATA repository on GitHub, push your changes to your fork, and open a pull request:julia> PkgDev.publish()\nINFO: Validating METADATA\nINFO: No new package versions to publish\nINFO: Submitting METADATA changes\nINFO: Forking JuliaLang/METADATA.jl to StefanKarpinski\nINFO: Pushing changes as branch pull-request/ef45f54b\nINFO: To create a pull-request open:\n\n  https://github.com/StefanKarpinski/METADATA.jl/compare/pull-request/ef45f54btip: Tip\nIf PkgDev.publish() fails with error:ERROR: key not found: \"token\"then you may have encountered an issue from using the GitHub API on multiple systems. The solution is to delete the \"Julia Package Manager\" personal access token from your Github account and try again.Other failures may require you to circumvent PkgDev.publish() by creating a pull request on GitHub. See: Publishing METADATA manually below.Once the package URL for FooBar is registered in the official METADATA repo, people know where to clone the package from, but there still aren\'t any registered versions available. You can tag and register it with the PkgDev.tag() command:julia> PkgDev.tag(\"FooBar\")\nINFO: Tagging FooBar v0.0.1\nINFO: Committing METADATA for FooBarThis tags v0.0.1 in the FooBar repo:$ cd ~/.julia/v0.6/FooBar && git tag\nv0.0.1It also creates a new version entry in your local METADATA repo for FooBar:$ cd ~/.julia/v0.6/FooBar && git show\ncommit de77ee4dc0689b12c5e8b574aef7f70e8b311b0e\nAuthor: Stefan Karpinski <stefan@karpinski.org>\nDate:   Wed Oct 16 23:06:18 2013 -0400\n\n    Tag FooBar v0.0.1\n\ndiff --git a/FooBar/versions/0.0.1/sha1 b/FooBar/versions/0.0.1/sha1\nnew file mode 100644\nindex 0000000..c1cb1c1\n--- /dev/null\n+++ b/FooBar/versions/0.0.1/sha1\n@@ -0,0 +1 @@\n+84b8e266dae6de30ab9703150b3bf771ec7b6285The PkgDev.tag() command takes an optional second argument that is either an explicit version number object like v\"0.0.1\" or one of the symbols :patch, :minor or :major. These increment the patch, minor or major version number of your package intelligently.Adding a tagged version of your package will expedite the official registration into METADATA.jl by collaborators. It is strongly recommended that you complete this process, regardless if your package is completely ready for an official release.As a general rule, packages should be tagged 0.0.1 first. Since Julia itself hasn\'t achieved 1.0 status, it\'s best to be conservative in your package\'s tagged versions.As with PkgDev.register(), these changes to METADATA aren\'t available to anyone else until they\'ve been included upstream. Again, use the PkgDev.publish() command, which first makes sure that individual package repos have been tagged, pushes them if they haven\'t already been, and then opens a pull request to METADATA:julia> PkgDev.publish()\nINFO: Validating METADATA\nINFO: Pushing FooBar permanent tags: v0.0.1\nINFO: Submitting METADATA changes\nINFO: Forking JuliaLang/METADATA.jl to StefanKarpinski\nINFO: Pushing changes as branch pull-request/3ef4f5c4\nINFO: To create a pull-request open:\n\n  https://github.com/StefanKarpinski/METADATA.jl/compare/pull-request/3ef4f5c4"
},

{
    "location": "manual/packages/#Publishing-METADATA-manually-1",
    "page": "Packages",
    "title": "Publishing METADATA manually",
    "category": "section",
    "text": "If PkgDev.publish() fails you can follow these instructions to manually publish your package.By \"forking\" the main METADATA repository, you can create a personal copy (of METADATA.jl) under your GitHub account. Once that copy exists, you can push your local changes to your copy (just like any other GitHub project).Create a fork of METADATA.jl.\nAdd your fork as a remote repository for the METADATA repository on your local computer (in the terminal where USERNAME is your github username):\ncd ~/.julia/v0.6/METADATA\ngit remote add USERNAME https://github.com/USERNAME/METADATA.jl.git\nPush your changes to your fork:\ngit push USERNAME metadata-v2\nIf all of that works, then go back to the GitHub page for your fork, and click the \"pull request\" link."
},

{
    "location": "manual/packages/#Fixing-Package-Requirements-1",
    "page": "Packages",
    "title": "Fixing Package Requirements",
    "category": "section",
    "text": "If you need to fix the registered requirements of an already-published package version, you can do so just by editing the metadata for that version, which will still have the same commit hash – the hash associated with a version is permanent:$ cd ~/.julia/v0.6/METADATA/FooBar/versions/0.0.1 && cat requires\njulia 0.3-\n$ vi requiresSince the commit hash stays the same, the contents of the REQUIRE file that will be checked out in the repo will not match the requirements in METADATA after such a change; this is unavoidable. When you fix the requirements in METADATA for a previous version of a package, however, you should also fix the REQUIRE file in the current version of the package."
},

{
    "location": "manual/packages/#Requirements-Specification-1",
    "page": "Packages",
    "title": "Requirements Specification",
    "category": "section",
    "text": "The ~/.julia/v0.6/REQUIRE file, the REQUIRE file inside packages, and the METADATA package requires files use a simple line-based format to express the ranges of package versions which need to be installed. Package REQUIRE and METADATA requires files should also include the range of versions of julia the package is expected to work with. Additionally, packages can include a test/REQUIRE file to specify additional packages which are only required for testing.Here\'s how these files are parsed and interpreted.Everything after a # mark is stripped from each line as a comment.\nIf nothing but whitespace is left, the line is ignored.\nIf there are non-whitespace characters remaining, the line is a requirement and the is split on whitespace into words.The simplest possible requirement is just the name of a package name on a line by itself:DistributionsThis requirement is satisfied by any version of the Distributions package. The package name can be followed by zero or more version numbers in ascending order, indicating acceptable intervals of versions of that package. One version opens an interval, while the next closes it, and the next opens a new interval, and so on; if an odd number of version numbers are given, then arbitrarily large versions will satisfy; if an even number of version numbers are given, the last one is an upper limit on acceptable version numbers. For example, the line:Distributions 0.1is satisfied by any version of Distributions greater than or equal to 0.1.0. Suffixing a version with - allows any pre-release versions as well. For example:Distributions 0.1-is satisfied by pre-release versions such as 0.1-dev or 0.1-rc1, or by any version greater than or equal to 0.1.0.This requirement entry:Distributions 0.1 0.2.5is satisfied by versions from 0.1.0 up to, but not including 0.2.5. If you want to indicate that any 0.1.x version will do, you will want to write:Distributions 0.1 0.2-If you want to start accepting versions after 0.2.7, you can write:Distributions 0.1 0.2- 0.2.7If a requirement line has leading words that begin with @, it is a system-dependent requirement. If your system matches these system conditionals, the requirement is included, if not, the requirement is ignored. For example:@osx Homebrewwill require the Homebrew package only on systems where the operating system is OS X. The system conditions that are currently supported are (hierarchically):@unix\n@linux\n@bsd\n@osx\n@windowsThe @unix condition is satisfied on all UNIX systems, including Linux and BSD. Negated system conditionals are also supported by adding a ! after the leading @. Examples:@!windows\n@unix @!osxThe first condition applies to any system but Windows and the second condition applies to any UNIX system besides OS X.Runtime checks for the current version of Julia can be made using the built-in VERSION variable, which is of type VersionNumber. Such code is occasionally necessary to keep track of new or deprecated functionality between various releases of Julia. Examples of runtime checks:VERSION < v\"0.3-\" #exclude all pre-release versions of 0.3\n\nv\"0.2-\" <= VERSION < v\"0.3-\" #get all 0.2 versions, including pre-releases, up to the above\n\nv\"0.2\" <= VERSION < v\"0.3-\" #To get only stable 0.2 versions (Note v\"0.2\" == v\"0.2.0\")\n\nVERSION >= v\"0.2.1\" #get at least version 0.2.1See the section on version number literals for a more complete description."
},

{
    "location": "manual/profile/#",
    "page": "Profiling",
    "title": "Profiling",
    "category": "page",
    "text": ""
},

{
    "location": "manual/profile/#Profiling-1",
    "page": "Profiling",
    "title": "Profiling",
    "category": "section",
    "text": "The Profile module provides tools to help developers improve the performance of their code. When used, it takes measurements on running code, and produces output that helps you understand how much time is spent on individual line(s). The most common usage is to identify \"bottlenecks\" as targets for optimization.Profile implements what is known as a \"sampling\" or statistical profiler.  It works by periodically taking a backtrace during the execution of any task. Each backtrace captures the currently-running function and line number, plus the complete chain of function calls that led to this line, and hence is a \"snapshot\" of the current state of execution.If much of your run time is spent executing a particular line of code, this line will show up frequently in the set of all backtraces. In other words, the \"cost\" of a given line–or really, the cost of the sequence of function calls up to and including this line–is proportional to how often it appears in the set of all backtraces.A sampling profiler does not provide complete line-by-line coverage, because the backtraces occur at intervals (by default, 1 ms on Unix systems and 10 ms on Windows, although the actual scheduling is subject to operating system load). Moreover, as discussed further below, because samples are collected at a sparse subset of all execution points, the data collected by a sampling profiler is subject to statistical noise.Despite these limitations, sampling profilers have substantial strengths:You do not have to make any modifications to your code to take timing measurements (in contrast to the alternative instrumenting profiler).\nIt can profile into Julia\'s core code and even (optionally) into C and Fortran libraries.\nBy running \"infrequently\" there is very little performance overhead; while profiling, your code can run at nearly native speed.For these reasons, it\'s recommended that you try using the built-in sampling profiler before considering any alternatives."
},

{
    "location": "manual/profile/#Basic-usage-1",
    "page": "Profiling",
    "title": "Basic usage",
    "category": "section",
    "text": "Let\'s work with a simple test case:julia> function myfunc()\n           A = rand(200, 200, 400)\n           maximum(A)\n       endIt\'s a good idea to first run the code you intend to profile at least once (unless you want to profile Julia\'s JIT-compiler):julia> myfunc() # run once to force compilationNow we\'re ready to profile this function:julia> @profile myfunc()To see the profiling results, there is a graphical browser available, but here we\'ll use the text-based display that comes with the standard library:julia> Profile.print()\n80 ./event.jl:73; (::Base.REPL.##1#2{Base.REPL.REPLBackend})()\n 80 ./REPL.jl:97; macro expansion\n  80 ./REPL.jl:66; eval_user_input(::Any, ::Base.REPL.REPLBackend)\n   80 ./boot.jl:235; eval(::Module, ::Any)\n    80 ./<missing>:?; anonymous\n     80 ./profile.jl:23; macro expansion\n      52 ./REPL[1]:2; myfunc()\n       38 ./random.jl:431; rand!(::MersenneTwister, ::Array{Float64,3}, ::Int64, ::Type{B...\n        38 ./dSFMT.jl:84; dsfmt_fill_array_close_open!(::Base.dSFMT.DSFMT_state, ::Ptr{F...\n       14 ./random.jl:278; rand\n        14 ./random.jl:277; rand\n         14 ./random.jl:366; rand\n          14 ./random.jl:369; rand\n      28 ./REPL[1]:3; myfunc()\n       28 ./reduce.jl:270; _mapreduce(::Base.#identity, ::Base.#scalarmax, ::IndexLinear,...\n        3  ./reduce.jl:426; mapreduce_impl(::Base.#identity, ::Base.#scalarmax, ::Array{F...\n        25 ./reduce.jl:428; mapreduce_impl(::Base.#identity, ::Base.#scalarmax, ::Array{F...Each line of this display represents a particular spot (line number) in the code. Indentation is used to indicate the nested sequence of function calls, with more-indented lines being deeper in the sequence of calls. In each line, the first \"field\" is the number of backtraces (samples) taken at this line or in any functions executed by this line. The second field is the file name and line number and the third field is the function name. Note that the specific line numbers may change as Julia\'s code changes; if you want to follow along, it\'s best to run this example yourself.In this example, we can see that the top level function called is in the file event.jl. This is the function that runs the REPL when you launch Julia. If you examine line 97 of REPL.jl, you\'ll see this is where the function eval_user_input() is called. This is the function that evaluates what you type at the REPL, and since we\'re working interactively these functions were invoked when we entered @profile myfunc(). The next line reflects actions taken in the @profile macro.The first line shows that 80 backtraces were taken at line 73 of event.jl, but it\'s not that this line was \"expensive\" on its own: the third line reveals that all 80 of these backtraces were actually triggered inside its call to eval_user_input, and so on. To find out which operations are actually taking the time, we need to look deeper in the call chain.The first \"important\" line in this output is this one:52 ./REPL[1]:2; myfunc()REPL refers to the fact that we defined myfunc in the REPL, rather than putting it in a file; if we had used a file, this would show the file name. The [1] shows that the function myfunc was the first expression evaluated in this REPL session. Line 2 of myfunc() contains the call to rand, and there were 52 (out of 80) backtraces that occurred at this line. Below that, you can see a call to dsfmt_fill_array_close_open! inside dSFMT.jl.A little further down, you see:28 ./REPL[1]:3; myfunc()Line 3 of myfunc contains the call to maximum, and there were 28 (out of 80) backtraces taken here. Below that, you can see the specific places in base/reduce.jl that carry out the time-consuming operations in the maximum function for this type of input data.Overall, we can tentatively conclude that generating the random numbers is approximately twice as expensive as finding the maximum element. We could increase our confidence in this result by collecting more samples:julia> @profile (for i = 1:100; myfunc(); end)\n\njulia> Profile.print()\n[....]\n 3821 ./REPL[1]:2; myfunc()\n  3511 ./random.jl:431; rand!(::MersenneTwister, ::Array{Float64,3}, ::Int64, ::Type...\n   3511 ./dSFMT.jl:84; dsfmt_fill_array_close_open!(::Base.dSFMT.DSFMT_state, ::Ptr...\n  310  ./random.jl:278; rand\n   [....]\n 2893 ./REPL[1]:3; myfunc()\n  2893 ./reduce.jl:270; _mapreduce(::Base.#identity, ::Base.#scalarmax, ::IndexLinea...\n   [....]In general, if you have N samples collected at a line, you can expect an uncertainty on the order of sqrt(N) (barring other sources of noise, like how busy the computer is with other tasks). The major exception to this rule is garbage collection, which runs infrequently but tends to be quite expensive. (Since Julia\'s garbage collector is written in C, such events can be detected using the C=true output mode described below, or by using ProfileView.jl.)This illustrates the default \"tree\" dump; an alternative is the \"flat\" dump, which accumulates counts independent of their nesting:julia> Profile.print(format=:flat)\n Count File          Line Function\n  6714 ./<missing>     -1 anonymous\n  6714 ./REPL.jl       66 eval_user_input(::Any, ::Base.REPL.REPLBackend)\n  6714 ./REPL.jl       97 macro expansion\n  3821 ./REPL[1]        2 myfunc()\n  2893 ./REPL[1]        3 myfunc()\n  6714 ./REPL[7]        1 macro expansion\n  6714 ./boot.jl      235 eval(::Module, ::Any)\n  3511 ./dSFMT.jl      84 dsfmt_fill_array_close_open!(::Base.dSFMT.DSFMT_s...\n  6714 ./event.jl      73 (::Base.REPL.##1#2{Base.REPL.REPLBackend})()\n  6714 ./profile.jl    23 macro expansion\n  3511 ./random.jl    431 rand!(::MersenneTwister, ::Array{Float64,3}, ::In...\n   310 ./random.jl    277 rand\n   310 ./random.jl    278 rand\n   310 ./random.jl    366 rand\n   310 ./random.jl    369 rand\n  2893 ./reduce.jl    270 _mapreduce(::Base.#identity, ::Base.#scalarmax, :...\n     5 ./reduce.jl    420 mapreduce_impl(::Base.#identity, ::Base.#scalarma...\n   253 ./reduce.jl    426 mapreduce_impl(::Base.#identity, ::Base.#scalarma...\n  2592 ./reduce.jl    428 mapreduce_impl(::Base.#identity, ::Base.#scalarma...\n    43 ./reduce.jl    429 mapreduce_impl(::Base.#identity, ::Base.#scalarma...If your code has recursion, one potentially-confusing point is that a line in a \"child\" function can accumulate more counts than there are total backtraces. Consider the following function definitions:dumbsum(n::Integer) = n == 1 ? 1 : 1 + dumbsum(n-1)\ndumbsum3() = dumbsum(3)If you were to profile dumbsum3, and a backtrace was taken while it was executing dumbsum(1), the backtrace would look like this:dumbsum3\n    dumbsum(3)\n        dumbsum(2)\n            dumbsum(1)Consequently, this child function gets 3 counts, even though the parent only gets one. The \"tree\" representation makes this much clearer, and for this reason (among others) is probably the most useful way to view the results."
},

{
    "location": "manual/profile/#Accumulation-and-clearing-1",
    "page": "Profiling",
    "title": "Accumulation and clearing",
    "category": "section",
    "text": "Results from @profile accumulate in a buffer; if you run multiple pieces of code under @profile, then Profile.print() will show you the combined results. This can be very useful, but sometimes you want to start fresh; you can do so with Profile.clear()."
},

{
    "location": "manual/profile/#Options-for-controlling-the-display-of-profile-results-1",
    "page": "Profiling",
    "title": "Options for controlling the display of profile results",
    "category": "section",
    "text": "Profile.print() has more options than we\'ve described so far. Let\'s see the full declaration:function print(io::IO = STDOUT, data = fetch(); kwargs...)Let\'s first discuss the two positional arguments, and later the keyword arguments:io – Allows you to save the results to a buffer, e.g. a file, but the default is to print to STDOUT (the console).\ndata – Contains the data you want to analyze; by default that is obtained from Profile.fetch(), which pulls out the backtraces from a pre-allocated buffer. For example, if you want to profile the profiler, you could say:\ndata = copy(Profile.fetch())\nProfile.clear()\n@profile Profile.print(STDOUT, data) # Prints the previous results\nProfile.print()                      # Prints results from Profile.print()The keyword arguments can be any combination of:format – Introduced above, determines whether backtraces are printed  with (default, :tree) or without (:flat) indentation indicating tree  structure.\nC – If true, backtraces from C and Fortran code are shown (normally they are excluded). Try running the introductory example with Profile.print(C = true). This can be extremely helpful in deciding whether it\'s Julia code or C code that is causing a bottleneck; setting C = true also improves the interpretability of the nesting, at the cost of longer profile dumps.\ncombine – Some lines of code contain multiple operations; for example, s += A[i] contains both an array reference (A[i]) and a sum operation. These correspond to different lines in the generated machine code, and hence there may be two or more different addresses captured during backtraces on this line. combine = true lumps them together, and is probably what you typically want, but you can generate an output separately for each unique instruction pointer with combine = false.\nmaxdepth – Limits frames at a depth higher than maxdepth in the :tree format.\nsortedby – Controls the order in :flat format. :filefuncline (default) sorts by the source line, whereas :count sorts in order of number of collected samples.\nnoisefloor – Limits frames that are below the heuristic noise floor of the sample (only applies to format :tree). A suggested value to try for this is 2.0 (the default is 0). This parameter hides samples for which n <= noisefloor * √N, where n is the number of samples on this line, and N is the number of samples for the callee.\nmincount – Limits frames with less than mincount occurrences.File/function names are sometimes truncated (with ...), and indentation is truncated with a +n at the beginning, where n is the number of extra spaces that would have been inserted, had there been room. If you want a complete profile of deeply-nested code, often a good idea is to save to a file using a wide displaysize in an IOContext:open(\"/tmp/prof.txt\", \"w\") do s\n    Profile.print(IOContext(s, :displaysize => (24, 500)))\nend"
},

{
    "location": "manual/profile/#Configuration-1",
    "page": "Profiling",
    "title": "Configuration",
    "category": "section",
    "text": "@profile just accumulates backtraces, and the analysis happens when you call Profile.print(). For a long-running computation, it\'s entirely possible that the pre-allocated buffer for storing backtraces will be filled. If that happens, the backtraces stop but your computation continues. As a consequence, you may miss some important profiling data (you will get a warning when that happens).You can obtain and configure the relevant parameters this way:Profile.init() # returns the current settings\nProfile.init(n = 10^7, delay = 0.01)n is the total number of instruction pointers you can store, with a default value of 10^6. If your typical backtrace is 20 instruction pointers, then you can collect 50000 backtraces, which suggests a statistical uncertainty of less than 1%. This may be good enough for most applications.Consequently, you are more likely to need to modify delay, expressed in seconds, which sets the amount of time that Julia gets between snapshots to perform the requested computations. A very long-running job might not need frequent backtraces. The default setting is delay = 0.001. Of course, you can decrease the delay as well as increase it; however, the overhead of profiling grows once the delay becomes similar to the amount of time needed to take a backtrace (~30 microseconds on the author\'s laptop)."
},

{
    "location": "manual/profile/#Memory-allocation-analysis-1",
    "page": "Profiling",
    "title": "Memory allocation analysis",
    "category": "section",
    "text": "One of the most common techniques to improve performance is to reduce memory allocation. The total amount of allocation can be measured with @time and @allocated, and specific lines triggering allocation can often be inferred from profiling via the cost of garbage collection that these lines incur. However, sometimes it is more efficient to directly measure the amount of memory allocated by each line of code.To measure allocation line-by-line, start Julia with the --track-allocation=<setting> command-line option, for which you can choose none (the default, do not measure allocation), user (measure memory allocation everywhere except Julia\'s core code), or all (measure memory allocation at each line of Julia code). Allocation gets measured for each line of compiled code. When you quit Julia, the cumulative results are written to text files with .mem appended after the file name, residing in the same directory as the source file. Each line lists the total number of bytes allocated. The Coverage package contains some elementary analysis tools, for example to sort the lines in order of number of bytes allocated.In interpreting the results, there are a few important details. Under the user setting, the first line of any function directly called from the REPL will exhibit allocation due to events that happen in the REPL code itself. More significantly, JIT-compilation also adds to allocation counts, because much of Julia\'s compiler is written in Julia (and compilation usually requires memory allocation). The recommended procedure is to force compilation by executing all the commands you want to analyze, then call Profile.clear_malloc_data() to reset all allocation counters.  Finally, execute the desired commands and quit Julia to trigger the generation of the .mem files."
},

{
    "location": "manual/stacktraces/#",
    "page": "Stack Traces",
    "title": "Stack Traces",
    "category": "page",
    "text": ""
},

{
    "location": "manual/stacktraces/#Stack-Traces-1",
    "page": "Stack Traces",
    "title": "Stack Traces",
    "category": "section",
    "text": "The StackTraces module provides simple stack traces that are both human readable and easy to use programmatically."
},

{
    "location": "manual/stacktraces/#Viewing-a-stack-trace-1",
    "page": "Stack Traces",
    "title": "Viewing a stack trace",
    "category": "section",
    "text": "The primary function used to obtain a stack trace is stacktrace():julia> stacktrace()\n4-element Array{StackFrame,1}:\n eval(::Module, ::Any) at boot.jl:236\n eval_user_input(::Any, ::Base.REPL.REPLBackend) at REPL.jl:66\n macro expansion at REPL.jl:97 [inlined]\n (::Base.REPL.##1#2{Base.REPL.REPLBackend})() at event.jl:73Calling stacktrace() returns a vector of StackFrame s. For ease of use, the alias StackTrace can be used in place of Vector{StackFrame}. (Examples with [...] indicate that output may vary depending on how the code is run.)julia> example() = stacktrace()\nexample (generic function with 1 method)\n\njulia> example()\n5-element Array{StackFrame,1}:\n example() at REPL[1]:1\n eval(::Module, ::Any) at boot.jl:236\n[...]\n\njulia> @noinline child() = stacktrace()\nchild (generic function with 1 method)\n\njulia> @noinline parent() = child()\nparent (generic function with 1 method)\n\njulia> grandparent() = parent()\ngrandparent (generic function with 1 method)\n\njulia> grandparent()\n7-element Array{StackFrame,1}:\n child() at REPL[3]:1\n parent() at REPL[4]:1\n grandparent() at REPL[5]:1\n[...]Note that when calling stacktrace() you\'ll typically see a frame with eval(...) at boot.jl. When calling stacktrace() from the REPL you\'ll also have a few extra frames in the stack from REPL.jl, usually looking something like this:julia> example() = stacktrace()\nexample (generic function with 1 method)\n\njulia> example()\n5-element Array{StackFrame,1}:\n example() at REPL[1]:1\n eval(::Module, ::Any) at boot.jl:236\n eval_user_input(::Any, ::Base.REPL.REPLBackend) at REPL.jl:66\n macro expansion at REPL.jl:97 [inlined]\n (::Base.REPL.##1#2{Base.REPL.REPLBackend})() at event.jl:73"
},

{
    "location": "manual/stacktraces/#Extracting-useful-information-1",
    "page": "Stack Traces",
    "title": "Extracting useful information",
    "category": "section",
    "text": "Each StackFrame contains the function name, file name, line number, lambda info, a flag indicating whether the frame has been inlined, a flag indicating whether it is a C function (by default C functions do not appear in the stack trace), and an integer representation of the pointer returned by backtrace():julia> top_frame = stacktrace()[1]\neval(::Module, ::Any) at boot.jl:236\n\njulia> top_frame.func\n:eval\n\njulia> top_frame.file\nSymbol(\"./boot.jl\")\n\njulia> top_frame.line\n236\n\njulia> top_frame.linfo\nNullable{Core.MethodInstance}(MethodInstance for eval(::Module, ::Any))\n\njulia> top_frame.inlined\nfalse\n\njulia> top_frame.from_c\nfalsejulia> top_frame.pointer\n0x00007f390d152a59This makes stack trace information available programmatically for logging, error handling, and more."
},

{
    "location": "manual/stacktraces/#Error-handling-1",
    "page": "Stack Traces",
    "title": "Error handling",
    "category": "section",
    "text": "While having easy access to information about the current state of the callstack can be helpful in many places, the most obvious application is in error handling and debugging.julia> @noinline bad_function() = undeclared_variable\nbad_function (generic function with 1 method)\n\njulia> @noinline example() = try\n           bad_function()\n       catch\n           stacktrace()\n       end\nexample (generic function with 1 method)\n\njulia> example()\n5-element Array{StackFrame,1}:\n example() at REPL[2]:4\n eval(::Module, ::Any) at boot.jl:236\n[...]You may notice that in the example above the first stack frame points points at line 4, where stacktrace() is called, rather than line 2, where bad_function is called, and bad_function\'s frame is missing entirely. This is understandable, given that stacktrace() is called from the context of the catch. While in this example it\'s fairly easy to find the actual source of the error, in complex cases tracking down the source of the error becomes nontrivial.This can be remedied by calling catch_stacktrace() instead of stacktrace(). Instead of returning callstack information for the current context, catch_stacktrace() returns stack information for the context of the most recent exception:julia> @noinline bad_function() = undeclared_variable\nbad_function (generic function with 1 method)\n\njulia> @noinline example() = try\n           bad_function()\n       catch\n           catch_stacktrace()\n       end\nexample (generic function with 1 method)\n\njulia> example()\n6-element Array{StackFrame,1}:\n bad_function() at REPL[1]:1\n example() at REPL[2]:2\n[...]Notice that the stack trace now indicates the appropriate line number and the missing frame.julia> @noinline child() = error(\"Whoops!\")\nchild (generic function with 1 method)\n\njulia> @noinline parent() = child()\nparent (generic function with 1 method)\n\njulia> @noinline function grandparent()\n           try\n               parent()\n           catch err\n               println(\"ERROR: \", err.msg)\n               catch_stacktrace()\n           end\n       end\ngrandparent (generic function with 1 method)\n\njulia> grandparent()\nERROR: Whoops!\n7-element Array{StackFrame,1}:\n child() at REPL[1]:1\n parent() at REPL[2]:1\n grandparent() at REPL[3]:3\n[...]"
},

{
    "location": "manual/stacktraces/#Comparison-with-[backtrace()](@ref)-1",
    "page": "Stack Traces",
    "title": "Comparison with backtrace()",
    "category": "section",
    "text": "A call to backtrace() returns a vector of Ptr{Void}, which may then be passed into stacktrace() for translation:julia> trace = backtrace()\n21-element Array{Ptr{Void},1}:\n Ptr{Void} @0x00007f10049d5b2f\n Ptr{Void} @0x00007f0ffeb4d29c\n Ptr{Void} @0x00007f0ffeb4d2a9\n Ptr{Void} @0x00007f1004993fe7\n Ptr{Void} @0x00007f10049a92be\n Ptr{Void} @0x00007f10049a823a\n Ptr{Void} @0x00007f10049a9fb0\n Ptr{Void} @0x00007f10049aa718\n Ptr{Void} @0x00007f10049c0d5e\n Ptr{Void} @0x00007f10049a3286\n Ptr{Void} @0x00007f0ffe9ba3ba\n Ptr{Void} @0x00007f0ffe9ba3d0\n Ptr{Void} @0x00007f1004993fe7\n Ptr{Void} @0x00007f0ded34583d\n Ptr{Void} @0x00007f0ded345a87\n Ptr{Void} @0x00007f1004993fe7\n Ptr{Void} @0x00007f0ded34308f\n Ptr{Void} @0x00007f0ded343320\n Ptr{Void} @0x00007f1004993fe7\n Ptr{Void} @0x00007f10049aeb67\n Ptr{Void} @0x0000000000000000\n\njulia> stacktrace(trace)\n5-element Array{StackFrame,1}:\n backtrace() at error.jl:46\n eval(::Module, ::Any) at boot.jl:236\n eval_user_input(::Any, ::Base.REPL.REPLBackend) at REPL.jl:66\n macro expansion at REPL.jl:97 [inlined]\n (::Base.REPL.##1#2{Base.REPL.REPLBackend})() at event.jl:73Notice that the vector returned by backtrace() had 21 pointers, while the vector returned by stacktrace() only has 5. This is because, by default, stacktrace() removes any lower-level C functions from the stack. If you want to include stack frames from C calls, you can do it like this:julia> stacktrace(trace, true)\n27-element Array{StackFrame,1}:\n jl_backtrace_from_here at stackwalk.c:103\n backtrace() at error.jl:46\n backtrace() at sys.so:?\n jl_call_method_internal at julia_internal.h:248 [inlined]\n jl_apply_generic at gf.c:2215\n do_call at interpreter.c:75\n eval at interpreter.c:215\n eval_body at interpreter.c:519\n jl_interpret_toplevel_thunk at interpreter.c:664\n jl_toplevel_eval_flex at toplevel.c:592\n jl_toplevel_eval_in at builtins.c:614\n eval(::Module, ::Any) at boot.jl:236\n eval(::Module, ::Any) at sys.so:?\n jl_call_method_internal at julia_internal.h:248 [inlined]\n jl_apply_generic at gf.c:2215\n eval_user_input(::Any, ::Base.REPL.REPLBackend) at REPL.jl:66\n ip:0x7f1c707f1846\n jl_call_method_internal at julia_internal.h:248 [inlined]\n jl_apply_generic at gf.c:2215\n macro expansion at REPL.jl:97 [inlined]\n (::Base.REPL.##1#2{Base.REPL.REPLBackend})() at event.jl:73\n ip:0x7f1c707ea1ef\n jl_call_method_internal at julia_internal.h:248 [inlined]\n jl_apply_generic at gf.c:2215\n jl_apply at julia.h:1411 [inlined]\n start_task at task.c:261\n ip:0xffffffffffffffffIndividual pointers returned by backtrace() can be translated into StackFrame s by passing them into StackTraces.lookup():julia> pointer = backtrace()[1];\n\njulia> frame = StackTraces.lookup(pointer)\n1-element Array{StackFrame,1}:\n jl_backtrace_from_here at stackwalk.c:103\n\njulia> println(\"The top frame is from $(frame[1].func)!\")\nThe top frame is from jl_backtrace_from_here!"
},

{
    "location": "manual/performance-tips/#",
    "page": "Performance Tips",
    "title": "Performance Tips",
    "category": "page",
    "text": ""
},

{
    "location": "manual/performance-tips/#man-performance-tips-1",
    "page": "Performance Tips",
    "title": "Performance Tips",
    "category": "section",
    "text": "In the following sections, we briefly go through a few techniques that can help make your Julia code run as fast as possible."
},

{
    "location": "manual/performance-tips/#Avoid-global-variables-1",
    "page": "Performance Tips",
    "title": "Avoid global variables",
    "category": "section",
    "text": "A global variable might have its value, and therefore its type, change at any point. This makes it difficult for the compiler to optimize code using global variables. Variables should be local, or passed as arguments to functions, whenever possible.Any code that is performance critical or being benchmarked should be inside a function.We find that global names are frequently constants, and declaring them as such greatly improves performance:const DEFAULT_VAL = 0Uses of non-constant globals can be optimized by annotating their types at the point of use:global x\ny = f(x::Int + 1)Writing functions is better style. It leads to more reusable code and clarifies what steps are being done, and what their inputs and outputs are.note: Note\nAll code in the REPL is evaluated in global scope, so a variable defined and assigned at toplevel will be a global variable.In the following REPL session:julia> x = 1.0is equivalent to:julia> global x = 1.0so all the performance issues discussed previously apply."
},

{
    "location": "manual/performance-tips/#Measure-performance-with-[@time](@ref)-and-pay-attention-to-memory-allocation-1",
    "page": "Performance Tips",
    "title": "Measure performance with @time and pay attention to memory allocation",
    "category": "section",
    "text": "A useful tool for measuring performance is the @time macro. The following example illustrates good working style:julia> function f(n)\n           s = 0\n           for i = 1:n\n               s += i/2\n           end\n           s\n       end\nf (generic function with 1 method)\n\njulia> @time f(1)\n  0.012686 seconds (2.09 k allocations: 103.421 KiB)\n0.5\n\njulia> @time f(10^6)\n  0.021061 seconds (3.00 M allocations: 45.777 MiB, 11.69% gc time)\n2.5000025e11On the first call (@time f(1)), f gets compiled.  (If you\'ve not yet used @time in this session, it will also compile functions needed for timing.)  You should not take the results of this run seriously. For the second run, note that in addition to reporting the time, it also indicated that a large amount of memory was allocated. This is the single biggest advantage of @time vs. functions like tic() and toc(), which only report time.Unexpected memory allocation is almost always a sign of some problem with your code, usually a problem with type-stability. Consequently, in addition to the allocation itself, it\'s very likely that the code generated for your function is far from optimal. Take such indications seriously and follow the advice below.For more serious benchmarking, consider the BenchmarkTools.jl package which evaluates the function multiple times in order to reduce noise.As a teaser, an improved version of this function allocates no memory (the allocation reported below is due to running the @time macro in global scope) and has an order of magnitude faster execution after the first call:julia> @time f_improved(1)\n  0.007008 seconds (1.32 k allocations: 63.640 KiB)\n0.5\n\njulia> @time f_improved(10^6)\n  0.002997 seconds (6 allocations: 192 bytes)\n2.5000025e11Below you\'ll learn how to spot the problem with f and how to fix it.In some situations, your function may need to allocate memory as part of its operation, and this can complicate the simple picture above. In such cases, consider using one of the tools below to diagnose problems, or write a version of your function that separates allocation from its algorithmic aspects (see Pre-allocating outputs)."
},

{
    "location": "manual/performance-tips/#tools-1",
    "page": "Performance Tips",
    "title": "Tools",
    "category": "section",
    "text": "Julia and its package ecosystem includes tools that may help you diagnose problems and improve the performance of your code:Profiling allows you to measure the performance of your running code and identify lines that serve as bottlenecks.  For complex projects, the ProfileView package can help you visualize your profiling results.\nUnexpectedly-large memory allocations–as reported by @time, @allocated, or the profiler (through calls to the garbage-collection routines)–hint that there might be issues with your code.  If you don\'t see another reason for the allocations, suspect a type problem.  You can also start Julia with the --track-allocation=user option and examine the resulting *.mem files to see information about where those allocations occur.  See Memory allocation analysis.\n@code_warntype generates a representation of your code that can be helpful in finding expressions that result in type uncertainty. See @code_warntype below.\nThe Lint package can also warn you of certain types of programming errors."
},

{
    "location": "manual/performance-tips/#Avoid-containers-with-abstract-type-parameters-1",
    "page": "Performance Tips",
    "title": "Avoid containers with abstract type parameters",
    "category": "section",
    "text": "When working with parameterized types, including arrays, it is best to avoid parameterizing with abstract types where possible.Consider the following:a = Real[]    # typeof(a) = Array{Real,1}\nif (f = rand()) < .8\n    push!(a, f)\nendBecause a is a an array of abstract type Real, it must be able to hold any Real value.  Since Real objects can be of arbitrary size and structure, a must be represented as an array of pointers to individually allocated Real objects. Because f will always be a Float64, we should instead, use:a = Float64[] # typeof(a) = Array{Float64,1}which will create a contiguous block of 64-bit floating-point values that can be manipulated efficiently.See also the discussion under Parametric Types."
},

{
    "location": "manual/performance-tips/#Type-declarations-1",
    "page": "Performance Tips",
    "title": "Type declarations",
    "category": "section",
    "text": "In many languages with optional type declarations, adding declarations is the principal way to make code run faster. This is not the case in Julia. In Julia, the compiler generally knows the types of all function arguments, local variables, and expressions. However, there are a few specific instances where declarations are helpful."
},

{
    "location": "manual/performance-tips/#Avoid-fields-with-abstract-type-1",
    "page": "Performance Tips",
    "title": "Avoid fields with abstract type",
    "category": "section",
    "text": "Types can be declared without specifying the types of their fields:julia> struct MyAmbiguousType\n           a\n       endThis allows a to be of any type. This can often be useful, but it does have a downside: for objects of type MyAmbiguousType, the compiler will not be able to generate high-performance code.  The reason is that the compiler uses the types of objects, not their values, to determine how to build code. Unfortunately, very little can be inferred about an object of type MyAmbiguousType:julia> b = MyAmbiguousType(\"Hello\")\nMyAmbiguousType(\"Hello\")\n\njulia> c = MyAmbiguousType(17)\nMyAmbiguousType(17)\n\njulia> typeof(b)\nMyAmbiguousType\n\njulia> typeof(c)\nMyAmbiguousTypeb and c have the same type, yet their underlying representation of data in memory is very different. Even if you stored just numeric values in field a, the fact that the memory representation of a UInt8 differs from a Float64 also means that the CPU needs to handle them using two different kinds of instructions. Since the required information is not available in the type, such decisions have to be made at run-time. This slows performance.You can do better by declaring the type of a. Here, we are focused on the case where a might be any one of several types, in which case the natural solution is to use parameters. For example:julia> mutable struct MyType{T<:AbstractFloat}\n           a::T\n       endThis is a better choice thanjulia> mutable struct MyStillAmbiguousType\n           a::AbstractFloat\n       endbecause the first version specifies the type of a from the type of the wrapper object.  For example:julia> m = MyType(3.2)\nMyType{Float64}(3.2)\n\njulia> t = MyStillAmbiguousType(3.2)\nMyStillAmbiguousType(3.2)\n\njulia> typeof(m)\nMyType{Float64}\n\njulia> typeof(t)\nMyStillAmbiguousTypeThe type of field a can be readily determined from the type of m, but not from the type of t.  Indeed, in t it\'s possible to change the type of field a:julia> typeof(t.a)\nFloat64\n\njulia> t.a = 4.5f0\n4.5f0\n\njulia> typeof(t.a)\nFloat32In contrast, once m is constructed, the type of m.a cannot change:julia> m.a = 4.5f0\n4.5f0\n\njulia> typeof(m.a)\nFloat64The fact that the type of m.a is known from m\'s type–coupled with the fact that its type cannot change mid-function–allows the compiler to generate highly-optimized code for objects like m but not for objects like t.Of course, all of this is true only if we construct m with a concrete type.  We can break this by explicitly constructing it with an abstract type:julia> m = MyType{AbstractFloat}(3.2)\nMyType{AbstractFloat}(3.2)\n\njulia> typeof(m.a)\nFloat64\n\njulia> m.a = 4.5f0\n4.5f0\n\njulia> typeof(m.a)\nFloat32For all practical purposes, such objects behave identically to those of MyStillAmbiguousType.It\'s quite instructive to compare the sheer amount code generated for a simple functionfunc(m::MyType) = m.a+1usingcode_llvm(func,Tuple{MyType{Float64}})\ncode_llvm(func,Tuple{MyType{AbstractFloat}})\ncode_llvm(func,Tuple{MyType})For reasons of length the results are not shown here, but you may wish to try this yourself. Because the type is fully-specified in the first case, the compiler doesn\'t need to generate any code to resolve the type at run-time. This results in shorter and faster code."
},

{
    "location": "manual/performance-tips/#Avoid-fields-with-abstract-containers-1",
    "page": "Performance Tips",
    "title": "Avoid fields with abstract containers",
    "category": "section",
    "text": "The same best practices also work for container types:julia> mutable struct MySimpleContainer{A<:AbstractVector}\n           a::A\n       end\n\njulia> mutable struct MyAmbiguousContainer{T}\n           a::AbstractVector{T}\n       endFor example:julia> c = MySimpleContainer(1:3);\n\njulia> typeof(c)\nMySimpleContainer{UnitRange{Int64}}\n\njulia> c = MySimpleContainer([1:3;]);\n\njulia> typeof(c)\nMySimpleContainer{Array{Int64,1}}\n\njulia> b = MyAmbiguousContainer(1:3);\n\njulia> typeof(b)\nMyAmbiguousContainer{Int64}\n\njulia> b = MyAmbiguousContainer([1:3;]);\n\njulia> typeof(b)\nMyAmbiguousContainer{Int64}For MySimpleContainer, the object is fully-specified by its type and parameters, so the compiler can generate optimized functions. In most instances, this will probably suffice.While the compiler can now do its job perfectly well, there are cases where you might wish that your code could do different things depending on the element type of a.  Usually the best way to achieve this is to wrap your specific operation (here, foo) in a separate function:julia> function sumfoo(c::MySimpleContainer)\n           s = 0\n           for x in c.a\n               s += foo(x)\n           end\n           s\n       end\nsumfoo (generic function with 1 method)\n\njulia> foo(x::Integer) = x\nfoo (generic function with 1 method)\n\njulia> foo(x::AbstractFloat) = round(x)\nfoo (generic function with 2 methods)This keeps things simple, while allowing the compiler to generate optimized code in all cases.However, there are cases where you may need to declare different versions of the outer function for different element types of a. You could do it like this:function myfun(c::MySimpleContainer{Vector{T}}) where T<:AbstractFloat\n    ...\nend\nfunction myfun(c::MySimpleContainer{Vector{T}}) where T<:Integer\n    ...\nendThis works fine for Vector{T}, but we\'d also have to write explicit versions for UnitRange{T} or other abstract types. To prevent such tedium, you can use two parameters in the declaration of MyContainer:julia> mutable struct MyContainer{T, A<:AbstractVector}\n           a::A\n       end\n\njulia> MyContainer(v::AbstractVector) = MyContainer{eltype(v), typeof(v)}(v)\nMyContainer\n\njulia> b = MyContainer(1:5);\n\njulia> typeof(b)\nMyContainer{Int64,UnitRange{Int64}}Note the somewhat surprising fact that T doesn\'t appear in the declaration of field a, a point that we\'ll return to in a moment. With this approach, one can write functions such as:julia> function myfunc(c::MyContainer{<:Integer, <:AbstractArray})\n           return c.a[1]+1\n       end\nmyfunc (generic function with 1 method)\n\njulia> function myfunc(c::MyContainer{<:AbstractFloat})\n           return c.a[1]+2\n       end\nmyfunc (generic function with 2 methods)\n\njulia> function myfunc(c::MyContainer{T,Vector{T}}) where T<:Integer\n           return c.a[1]+3\n       end\nmyfunc (generic function with 3 methods)note: Note\nBecause we can only define MyContainer for A<:AbstractArray, and any unspecified parameters are arbitrary, the first function above could have been written more succinctly as function myfunc{T<:Integer}(c::MyContainer{T})julia> myfunc(MyContainer(1:3))\n2\n\njulia> myfunc(MyContainer(1.0:3))\n3.0\n\njulia> myfunc(MyContainer([1:3;]))\n4As you can see, with this approach it\'s possible to specialize on both the element type T and the array type A.However, there\'s one remaining hole: we haven\'t enforced that A has element type T, so it\'s perfectly possible to construct an object like this:julia> b = MyContainer{Int64, UnitRange{Float64}}(UnitRange(1.3, 5.0));\n\njulia> typeof(b)\nMyContainer{Int64,UnitRange{Float64}}To prevent this, we can add an inner constructor:julia> mutable struct MyBetterContainer{T<:Real, A<:AbstractVector}\n           a::A\n           MyBetterContainer{T,A}(v::AbstractVector{T}) where {T,A} = new(v)\n       end\n\njulia> MyBetterContainer(v::AbstractVector) = MyBetterContainer{eltype(v),typeof(v)}(v)\nMyBetterContainer\n\njulia> b = MyBetterContainer(UnitRange(1.3, 5.0));\n\njulia> typeof(b)\nMyBetterContainer{Float64,UnitRange{Float64}}\n\njulia> b = MyBetterContainer{Int64, UnitRange{Float64}}(UnitRange(1.3, 5.0));\nERROR: MethodError: Cannot `convert` an object of type UnitRange{Float64} to an object of type MyBetterContainer{Int64,UnitRange{Float64}}\n[...]The inner constructor requires that the element type of A be T."
},

{
    "location": "manual/performance-tips/#Annotate-values-taken-from-untyped-locations-1",
    "page": "Performance Tips",
    "title": "Annotate values taken from untyped locations",
    "category": "section",
    "text": "It is often convenient to work with data structures that may contain values of any type (arrays of type Array{Any}). But, if you\'re using one of these structures and happen to know the type of an element, it helps to share this knowledge with the compiler:function foo(a::Array{Any,1})\n    x = a[1]::Int32\n    b = x+1\n    ...\nendHere, we happened to know that the first element of a would be an Int32. Making an annotation like this has the added benefit that it will raise a run-time error if the value is not of the expected type, potentially catching certain bugs earlier."
},

{
    "location": "manual/performance-tips/#Declare-types-of-keyword-arguments-1",
    "page": "Performance Tips",
    "title": "Declare types of keyword arguments",
    "category": "section",
    "text": "Keyword arguments can have declared types:function with_keyword(x; name::Int = 1)\n    ...\nendFunctions are specialized on the types of keyword arguments, so these declarations will not affect performance of code inside the function. However, they will reduce the overhead of calls to the function that include keyword arguments.Functions with keyword arguments have near-zero overhead for call sites that pass only positional arguments.Passing dynamic lists of keyword arguments, as in f(x; keywords...), can be slow and should be avoided in performance-sensitive code."
},

{
    "location": "manual/performance-tips/#Break-functions-into-multiple-definitions-1",
    "page": "Performance Tips",
    "title": "Break functions into multiple definitions",
    "category": "section",
    "text": "Writing a function as many small definitions allows the compiler to directly call the most applicable code, or even inline it.Here is an example of a \"compound function\" that should really be written as multiple definitions:function norm(A)\n    if isa(A, Vector)\n        return sqrt(real(dot(A,A)))\n    elseif isa(A, Matrix)\n        return maximum(svd(A)[2])\n    else\n        error(\"norm: invalid argument\")\n    end\nendThis can be written more concisely and efficiently as:norm(x::Vector) = sqrt(real(dot(x,x)))\nnorm(A::Matrix) = maximum(svd(A)[2])"
},

{
    "location": "manual/performance-tips/#Write-\"type-stable\"-functions-1",
    "page": "Performance Tips",
    "title": "Write \"type-stable\" functions",
    "category": "section",
    "text": "When possible, it helps to ensure that a function always returns a value of the same type. Consider the following definition:pos(x) = x < 0 ? 0 : xAlthough this seems innocent enough, the problem is that 0 is an integer (of type Int) and x might be of any type. Thus, depending on the value of x, this function might return a value of either of two types. This behavior is allowed, and may be desirable in some cases. But it can easily be fixed as follows:pos(x) = x < 0 ? zero(x) : xThere is also a one() function, and a more general oftype(x, y) function, which returns y converted to the type of x."
},

{
    "location": "manual/performance-tips/#Avoid-changing-the-type-of-a-variable-1",
    "page": "Performance Tips",
    "title": "Avoid changing the type of a variable",
    "category": "section",
    "text": "An analogous \"type-stability\" problem exists for variables used repeatedly within a function:function foo()\n    x = 1\n    for i = 1:10\n        x = x/bar()\n    end\n    return x\nendLocal variable x starts as an integer, and after one loop iteration becomes a floating-point number (the result of / operator). This makes it more difficult for the compiler to optimize the body of the loop. There are several possible fixes:Initialize x with x = 1.0\nDeclare the type of x: x::Float64 = 1\nUse an explicit conversion: x = oneunit(T)\nInitialize with the first loop iteration, to x = 1/bar(), then loop for i = 2:10"
},

{
    "location": "manual/performance-tips/#kernal-functions-1",
    "page": "Performance Tips",
    "title": "Separate kernel functions (aka, function barriers)",
    "category": "section",
    "text": "Many functions follow a pattern of performing some set-up work, and then running many iterations to perform a core computation. Where possible, it is a good idea to put these core computations in separate functions. For example, the following contrived function returns an array of a randomly-chosen type:DocTestSetup = quote\n    srand(1234)\nendjulia> function strange_twos(n)\n           a = Vector{rand(Bool) ? Int64 : Float64}(n)\n           for i = 1:n\n               a[i] = 2\n           end\n           return a\n       end\nstrange_twos (generic function with 1 method)\n\njulia> strange_twos(3)\n3-element Array{Float64,1}:\n 2.0\n 2.0\n 2.0This should be written as:julia> function fill_twos!(a)\n           for i=1:length(a)\n               a[i] = 2\n           end\n       end\nfill_twos! (generic function with 1 method)\n\njulia> function strange_twos(n)\n           a = Array{rand(Bool) ? Int64 : Float64}(n)\n           fill_twos!(a)\n           return a\n       end\nstrange_twos (generic function with 1 method)\n\njulia> strange_twos(3)\n3-element Array{Float64,1}:\n 2.0\n 2.0\n 2.0Julia\'s compiler specializes code for argument types at function boundaries, so in the original implementation it does not know the type of a during the loop (since it is chosen randomly). Therefore the second version is generally faster since the inner loop can be recompiled as part of fill_twos! for different types of a.The second form is also often better style and can lead to more code reuse.This pattern is used in several places in the standard library. For example, see hvcat_fill in abstractarray.jl, or the fill! function, which we could have used instead of writing our own fill_twos!.Functions like strange_twos occur when dealing with data of uncertain type, for example data loaded from an input file that might contain either integers, floats, strings, or something else."
},

{
    "location": "manual/performance-tips/#Types-with-values-as-parameters-1",
    "page": "Performance Tips",
    "title": "Types with values-as-parameters",
    "category": "section",
    "text": "Let\'s say you want to create an N-dimensional array that has size 3 along each axis.  Such arrays can be created like this:julia> A = fill(5.0, (3, 3))\n3×3 Array{Float64,2}:\n 5.0  5.0  5.0\n 5.0  5.0  5.0\n 5.0  5.0  5.0This approach works very well: the compiler can figure out that A is an Array{Float64,2} because it knows the type of the fill value (5.0::Float64) and the dimensionality ((3, 3)::NTuple{2,Int}). This implies that the compiler can generate very efficient code for any future usage of A in the same function.But now let\'s say you want to write a function that creates a 3×3×... array in arbitrary dimensions; you might be tempted to write a functionjulia> function array3(fillval, N)\n           fill(fillval, ntuple(d->3, N))\n       end\narray3 (generic function with 1 method)\n\njulia> array3(5.0, 2)\n3×3 Array{Float64,2}:\n 5.0  5.0  5.0\n 5.0  5.0  5.0\n 5.0  5.0  5.0This works, but (as you can verify for yourself using @code_warntype array3(5.0, 2)) the problem is that the output type cannot be inferred: the argument N is a value of type Int, and type-inference does not (and cannot) predict its value in advance. This means that code using the output of this function has to be conservative, checking the type on each access of A; such code will be very slow.Now, one very good way to solve such problems is by using the function-barrier technique. However, in some cases you might want to eliminate the type-instability altogether.  In such cases, one approach is to pass the dimensionality as a parameter, for example through Val{T} (see \"Value types\"):julia> function array3(fillval, ::Type{Val{N}}) where N\n           fill(fillval, ntuple(d->3, Val{N}))\n       end\narray3 (generic function with 1 method)\n\njulia> array3(5.0, Val{2})\n3×3 Array{Float64,2}:\n 5.0  5.0  5.0\n 5.0  5.0  5.0\n 5.0  5.0  5.0Julia has a specialized version of ntuple that accepts a Val{::Int} as the second parameter; by passing N as a type-parameter, you make its \"value\" known to the compiler. Consequently, this version of array3 allows the compiler to predict the return type.However, making use of such techniques can be surprisingly subtle. For example, it would be of no help if you called array3 from a function like this:function call_array3(fillval, n)\n    A = array3(fillval, Val{n})\nendHere, you\'ve created the same problem all over again: the compiler can\'t guess the type of n, so it doesn\'t know the type of Val{n}.  Attempting to use Val, but doing so incorrectly, can easily make performance worse in many situations.  (Only in situations where you\'re effectively combining Val with the function-barrier trick, to make the kernel function more efficient, should code like the above be used.)An example of correct usage of Val would be:function filter3(A::AbstractArray{T,N}) where {T,N}\n    kernel = array3(1, Val{N})\n    filter(A, kernel)\nendIn this example, N is passed as a parameter, so its \"value\" is known to the compiler.  Essentially, Val{T} works only when T is either hard-coded (Val{3}) or already specified in the type-domain."
},

{
    "location": "manual/performance-tips/#The-dangers-of-abusing-multiple-dispatch-(aka,-more-on-types-with-values-as-parameters)-1",
    "page": "Performance Tips",
    "title": "The dangers of abusing multiple dispatch (aka, more on types with values-as-parameters)",
    "category": "section",
    "text": "Once one learns to appreciate multiple dispatch, there\'s an understandable tendency to go crazy and try to use it for everything. For example, you might imagine using it to store information, e.g.struct Car{Make,Model}\n    year::Int\n    ...more fields...\nendand then dispatch on objects like Car{:Honda,:Accord}(year, args...).This might be worthwhile when the following are true:You require CPU-intensive processing on each Car, and it becomes vastly more efficient if you know the Make and Model at compile time.\nYou have homogenous lists of the same type of Car to process, so that you can store them all in an Array{Car{:Honda,:Accord},N}.When the latter holds, a function processing such a homogenous array can be productively specialized: Julia knows the type of each element in advance (all objects in the container have the same concrete type), so Julia can \"look up\" the correct method calls when the function is being compiled (obviating the need to check at run-time) and thereby emit efficient code for processing the whole list.When these do not hold, then it\'s likely that you\'ll get no benefit; worse, the resulting \"combinatorial explosion of types\" will be counterproductive.  If items[i+1] has a different type than item[i], Julia has to look up the type at run-time, search for the appropriate method in method tables, decide (via type intersection) which one matches, determine whether it has been JIT-compiled yet (and do so if not), and then make the call. In essence, you\'re asking the full type- system and JIT-compilation machinery to basically execute the equivalent of a switch statement or dictionary lookup in your own code.Some run-time benchmarks comparing (1) type dispatch, (2) dictionary lookup, and (3) a \"switch\" statement can be found on the mailing list.Perhaps even worse than the run-time impact is the compile-time impact: Julia will compile specialized functions for each different Car{Make, Model}; if you have hundreds or thousands of such types, then every function that accepts such an object as a parameter (from a custom get_year function you might write yourself, to the generic push! function in the standard library) will have hundreds or thousands of variants compiled for it.  Each of these increases the size of the cache of compiled code, the length of internal lists of methods, etc.  Excess enthusiasm for values-as-parameters can easily waste enormous resources."
},

{
    "location": "manual/performance-tips/#Access-arrays-in-memory-order,-along-columns-1",
    "page": "Performance Tips",
    "title": "Access arrays in memory order, along columns",
    "category": "section",
    "text": "Multidimensional arrays in Julia are stored in column-major order. This means that arrays are stacked one column at a time. This can be verified using the vec function or the syntax [:] as shown below (notice that the array is ordered [1 3 2 4], not [1 2 3 4]):julia> x = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> x[:]\n4-element Array{Int64,1}:\n 1\n 3\n 2\n 4This convention for ordering arrays is common in many languages like Fortran, Matlab, and R (to name a few). The alternative to column-major ordering is row-major ordering, which is the convention adopted by C and Python (numpy) among other languages. Remembering the ordering of arrays can have significant performance effects when looping over arrays. A rule of thumb to keep in mind is that with column-major arrays, the first index changes most rapidly. Essentially this means that looping will be faster if the inner-most loop index is the first to appear in a slice expression.Consider the following contrived example. Imagine we wanted to write a function that accepts a Vector and returns a square Matrix with either the rows or the columns filled with copies of the input vector. Assume that it is not important whether rows or columns are filled with these copies (perhaps the rest of the code can be easily adapted accordingly). We could conceivably do this in at least four ways (in addition to the recommended call to the built-in repmat()):function copy_cols(x::Vector{T}) where T\n    n = size(x, 1)\n    out = Array{T}(n, n)\n    for i = 1:n\n        out[:, i] = x\n    end\n    out\nend\n\nfunction copy_rows(x::Vector{T}) where T\n    n = size(x, 1)\n    out = Array{T}(n, n)\n    for i = 1:n\n        out[i, :] = x\n    end\n    out\nend\n\nfunction copy_col_row(x::Vector{T}) where T\n    n = size(x, 1)\n    out = Array{T}(n, n)\n    for col = 1:n, row = 1:n\n        out[row, col] = x[row]\n    end\n    out\nend\n\nfunction copy_row_col(x::Vector{T}) where T\n    n = size(x, 1)\n    out = Array{T}(n, n)\n    for row = 1:n, col = 1:n\n        out[row, col] = x[col]\n    end\n    out\nendNow we will time each of these functions using the same random 10000 by 1 input vector:julia> x = randn(10000);\n\njulia> fmt(f) = println(rpad(string(f)*\": \", 14, \' \'), @elapsed f(x))\n\njulia> map(fmt, Any[copy_cols, copy_rows, copy_col_row, copy_row_col]);\ncopy_cols:    0.331706323\ncopy_rows:    1.799009911\ncopy_col_row: 0.415630047\ncopy_row_col: 1.721531501Notice that copy_cols is much faster than copy_rows. This is expected because copy_cols respects the column-based memory layout of the Matrix and fills it one column at a time. Additionally, copy_col_row is much faster than copy_row_col because it follows our rule of thumb that the first element to appear in a slice expression should be coupled with the inner-most loop."
},

{
    "location": "manual/performance-tips/#Pre-allocating-outputs-1",
    "page": "Performance Tips",
    "title": "Pre-allocating outputs",
    "category": "section",
    "text": "If your function returns an Array or some other complex type, it may have to allocate memory.  Unfortunately, oftentimes allocation and its converse, garbage collection, are substantial bottlenecks.Sometimes you can circumvent the need to allocate memory on each function call by preallocating the output.  As a trivial example, comparefunction xinc(x)\n    return [x, x+1, x+2]\nend\n\nfunction loopinc()\n    y = 0\n    for i = 1:10^7\n        ret = xinc(i)\n        y += ret[2]\n    end\n    y\nendwithfunction xinc!(ret::AbstractVector{T}, x::T) where T\n    ret[1] = x\n    ret[2] = x+1\n    ret[3] = x+2\n    nothing\nend\n\nfunction loopinc_prealloc()\n    ret = Array{Int}(3)\n    y = 0\n    for i = 1:10^7\n        xinc!(ret, i)\n        y += ret[2]\n    end\n    y\nendTiming results:julia> @time loopinc()\n  0.529894 seconds (40.00 M allocations: 1.490 GiB, 12.14% gc time)\n50000015000000\n\njulia> @time loopinc_prealloc()\n  0.030850 seconds (6 allocations: 288 bytes)\n50000015000000Preallocation has other advantages, for example by allowing the caller to control the \"output\" type from an algorithm.  In the example above, we could have passed a SubArray rather than an Array, had we so desired.Taken to its extreme, pre-allocation can make your code uglier, so performance measurements and some judgment may be required. However, for \"vectorized\" (element-wise) functions, the convenient syntax x .= f.(y) can be used for in-place operations with fused loops and no temporary arrays (see the dot syntax for vectorizing functions)."
},

{
    "location": "manual/performance-tips/#More-dots:-Fuse-vectorized-operations-1",
    "page": "Performance Tips",
    "title": "More dots: Fuse vectorized operations",
    "category": "section",
    "text": "Julia has a special dot syntax that converts any scalar function into a \"vectorized\" function call, and any operator into a \"vectorized\" operator, with the special property that nested \"dot calls\" are fusing: they are combined at the syntax level into a single loop, without allocating temporary arrays. If you use .= and similar assignment operators, the result can also be stored in-place in a pre-allocated array (see above).In a linear-algebra context, this means that even though operations like vector + vector and vector * scalar are defined, it can be advantageous to instead use vector .+ vector and vector .* scalar because the resulting loops can be fused with surrounding computations. For example, consider the two functions:f(x) = 3x.^2 + 4x + 7x.^3\n\nfdot(x) = @. 3x^2 + 4x + 7x^3 # equivalent to 3 .* x.^2 .+ 4 .* x .+ 7 .* x.^3Both f and fdot compute the same thing.  However, fdot (defined with the help of the @. macro) is significantly faster when applied to an array:julia> x = rand(10^6);\n\njulia> @time f(x);\n  0.010986 seconds (18 allocations: 53.406 MiB, 11.45% gc time)\n\njulia> @time fdot(x);\n  0.003470 seconds (6 allocations: 7.630 MiB)\n\njulia> @time f.(x);\n  0.003297 seconds (30 allocations: 7.631 MiB)That is, fdot(x) is three times faster and allocates 1/7 the memory of f(x), because each * and + operation in f(x) allocates a new temporary array and executes in a separate loop. (Of course, if you just do f.(x) then it is as fast as fdot(x) in this example, but in many contexts it is more convenient to just sprinkle some dots in your expressions rather than defining a separate function for each vectorized operation.)"
},

{
    "location": "manual/performance-tips/#Consider-using-views-for-slices-1",
    "page": "Performance Tips",
    "title": "Consider using views for slices",
    "category": "section",
    "text": "In Julia, an array \"slice\" expression like array[1:5, :] creates a copy of that data (except on the left-hand side of an assignment, where array[1:5, :] = ... assigns in-place to that portion of array). If you are doing many operations on the slice, this can be good for performance because it is more efficient to work with a smaller contiguous copy than it would be to index into the original array. On the other hand, if you are just doing a few simple operations on the slice, the cost of the allocation and copy operations can be substantial.An alternative is to create a \"view\" of the array, which is an array object (a SubArray) that actually references the data of the original array in-place, without making a copy.  (If you write to a view, it modifies the original array\'s data as well.) This can be done for individual slices by calling view(), or more simply for a whole expression or block of code by putting @views in front of that expression.  For example:julia> fcopy(x) = sum(x[2:end-1])\n\njulia> @views fview(x) = sum(x[2:end-1])\n\njulia> x = rand(10^6);\n\njulia> @time fcopy(x);\n  0.003051 seconds (7 allocations: 7.630 MB)\n\njulia> @time fview(x);\n  0.001020 seconds (6 allocations: 224 bytes)Notice both the 3× speedup and the decreased memory allocation of the fview version of the function."
},

{
    "location": "manual/performance-tips/#Avoid-string-interpolation-for-I/O-1",
    "page": "Performance Tips",
    "title": "Avoid string interpolation for I/O",
    "category": "section",
    "text": "When writing data to a file (or other I/O device), forming extra intermediate strings is a source of overhead. Instead of:println(file, \"$a $b\")use:println(file, a, \" \", b)The first version of the code forms a string, then writes it to the file, while the second version writes values directly to the file. Also notice that in some cases string interpolation can be harder to read. Consider:println(file, \"$(f(a))$(f(b))\")versus:println(file, f(a), f(b))"
},

{
    "location": "manual/performance-tips/#Optimize-network-I/O-during-parallel-execution-1",
    "page": "Performance Tips",
    "title": "Optimize network I/O during parallel execution",
    "category": "section",
    "text": "When executing a remote function in parallel:responses = Vector{Any}(nworkers())\n@sync begin\n    for (idx, pid) in enumerate(workers())\n        @async responses[idx] = remotecall_fetch(pid, foo, args...)\n    end\nendis faster than:refs = Vector{Any}(nworkers())\nfor (idx, pid) in enumerate(workers())\n    refs[idx] = @spawnat pid foo(args...)\nend\nresponses = [fetch(r) for r in refs]The former results in a single network round-trip to every worker, while the latter results in two network calls - first by the @spawnat and the second due to the fetch (or even a wait). The fetch/wait is also being executed serially resulting in an overall poorer performance."
},

{
    "location": "manual/performance-tips/#Fix-deprecation-warnings-1",
    "page": "Performance Tips",
    "title": "Fix deprecation warnings",
    "category": "section",
    "text": "A deprecated function internally performs a lookup in order to print a relevant warning only once. This extra lookup can cause a significant slowdown, so all uses of deprecated functions should be modified as suggested by the warnings."
},

{
    "location": "manual/performance-tips/#Tweaks-1",
    "page": "Performance Tips",
    "title": "Tweaks",
    "category": "section",
    "text": "These are some minor points that might help in tight inner loops.Avoid unnecessary arrays. For example, instead of sum([x,y,z]) use x+y+z.\nUse abs2(z) instead of abs(z)^2 for complex z. In general, try to rewrite code to use abs2() instead of abs() for complex arguments.\nUse div(x,y) for truncating division of integers instead of trunc(x/y), fld(x,y) instead of floor(x/y), and cld(x,y) instead of ceil(x/y)."
},

{
    "location": "manual/performance-tips/#Performance-Annotations-1",
    "page": "Performance Tips",
    "title": "Performance Annotations",
    "category": "section",
    "text": "Sometimes you can enable better optimization by promising certain program properties.Use @inbounds to eliminate array bounds checking within expressions. Be certain before doing this. If the subscripts are ever out of bounds, you may suffer crashes or silent corruption.\nUse @fastmath to allow floating point optimizations that are correct for real numbers, but lead to differences for IEEE numbers. Be careful when doing this, as this may change numerical results. This corresponds to the -ffast-math option of clang.\nWrite @simd in front of for loops that are amenable to vectorization. This feature is experimental and could change or disappear in future versions of Julia.Note: While @simd needs to be placed directly in front of a loop, both @inbounds and @fastmath can be applied to several statements at once, e.g. using begin ... end, or even to a whole function.Here is an example with both @inbounds and @simd markup:function inner(x, y)\n    s = zero(eltype(x))\n    for i=1:length(x)\n        @inbounds s += x[i]*y[i]\n    end\n    s\nend\n\nfunction innersimd(x, y)\n    s = zero(eltype(x))\n    @simd for i=1:length(x)\n        @inbounds s += x[i]*y[i]\n    end\n    s\nend\n\nfunction timeit(n, reps)\n    x = rand(Float32,n)\n    y = rand(Float32,n)\n    s = zero(Float64)\n    time = @elapsed for j in 1:reps\n        s+=inner(x,y)\n    end\n    println(\"GFlop/sec        = \",2.0*n*reps/time*1E-9)\n    time = @elapsed for j in 1:reps\n        s+=innersimd(x,y)\n    end\n    println(\"GFlop/sec (SIMD) = \",2.0*n*reps/time*1E-9)\nend\n\ntimeit(1000,1000)On a computer with a 2.4GHz Intel Core i5 processor, this produces:GFlop/sec        = 1.9467069505224963\nGFlop/sec (SIMD) = 17.578554163920018(GFlop/sec measures the performance, and larger numbers are better.) The range for a @simd for loop should be a one-dimensional range. A variable used for accumulating, such as s in the example, is called a reduction variable. By using @simd, you are asserting several properties of the loop:It is safe to execute iterations in arbitrary or overlapping order, with special consideration for reduction variables.\nFloating-point operations on reduction variables can be reordered, possibly causing different results than without @simd.\nNo iteration ever waits on another iteration to make forward progress.A loop containing break, continue, or @goto will cause a compile-time error.Using @simd merely gives the compiler license to vectorize. Whether it actually does so depends on the compiler. To actually benefit from the current implementation, your loop should have the following additional properties:The loop must be an innermost loop.\nThe loop body must be straight-line code. This is why @inbounds is currently needed for all array accesses. The compiler can sometimes turn short &&, ||, and ?: expressions into straight-line code, if it is safe to evaluate all operands unconditionally. Consider using ifelse() instead of ?: in the loop if it is safe to do so.\nAccesses must have a stride pattern and cannot be \"gathers\" (random-index reads) or \"scatters\" (random-index writes).\nThe stride should be unit stride.\nIn some simple cases, for example with 2-3 arrays accessed in a loop, the LLVM auto-vectorization may kick in automatically, leading to no further speedup with @simd.Here is an example with all three kinds of markup. This program first calculates the finite difference of a one-dimensional array, and then evaluates the L2-norm of the result:function init!(u)\n    n = length(u)\n    dx = 1.0 / (n-1)\n    @fastmath @inbounds @simd for i in 1:n\n        u[i] = sin(2pi*dx*i)\n    end\nend\n\nfunction deriv!(u, du)\n    n = length(u)\n    dx = 1.0 / (n-1)\n    @fastmath @inbounds du[1] = (u[2] - u[1]) / dx\n    @fastmath @inbounds @simd for i in 2:n-1\n        du[i] = (u[i+1] - u[i-1]) / (2*dx)\n    end\n    @fastmath @inbounds du[n] = (u[n] - u[n-1]) / dx\nend\n\nfunction norm(u)\n    n = length(u)\n    T = eltype(u)\n    s = zero(T)\n    @fastmath @inbounds @simd for i in 1:n\n        s += u[i]^2\n    end\n    @fastmath @inbounds return sqrt(s/n)\nend\n\nfunction main()\n    n = 2000\n    u = Array{Float64}(n)\n    init!(u)\n    du = similar(u)\n\n    deriv!(u, du)\n    nu = norm(du)\n\n    @time for i in 1:10^6\n        deriv!(u, du)\n        nu = norm(du)\n    end\n\n    println(nu)\nend\n\nmain()On a computer with a 2.7 GHz Intel Core i7 processor, this produces:$ julia wave.jl;\nelapsed time: 1.207814709 seconds (0 bytes allocated)\n\n$ julia --math-mode=ieee wave.jl;\nelapsed time: 4.487083643 seconds (0 bytes allocated)Here, the option --math-mode=ieee disables the @fastmath macro, so that we can compare results.In this case, the speedup due to @fastmath is a factor of about 3.7. This is unusually large – in general, the speedup will be smaller. (In this particular example, the working set of the benchmark is small enough to fit into the L1 cache of the processor, so that memory access latency does not play a role, and computing time is dominated by CPU usage. In many real world programs this is not the case.) Also, in this case this optimization does not change the result – in general, the result will be slightly different. In some cases, especially for numerically unstable algorithms, the result can be very different.The annotation @fastmath re-arranges floating point expressions, e.g. changing the order of evaluation, or assuming that certain special cases (inf, nan) cannot occur. In this case (and on this particular computer), the main difference is that the expression 1 / (2*dx) in the function deriv is hoisted out of the loop (i.e. calculated outside the loop), as if one had written idx = 1 / (2*dx). In the loop, the expression ... / (2*dx) then becomes ... * idx, which is much faster to evaluate. Of course, both the actual optimization that is applied by the compiler as well as the resulting speedup depend very much on the hardware. You can examine the change in generated code by using Julia\'s code_native() function."
},

{
    "location": "manual/performance-tips/#Treat-Subnormal-Numbers-as-Zeros-1",
    "page": "Performance Tips",
    "title": "Treat Subnormal Numbers as Zeros",
    "category": "section",
    "text": "Subnormal numbers, formerly called denormal numbers, are useful in many contexts, but incur a performance penalty on some hardware. A call set_zero_subnormals(true) grants permission for floating-point operations to treat subnormal inputs or outputs as zeros, which may improve performance on some hardware. A call set_zero_subnormals(false) enforces strict IEEE behavior for subnormal numbers.Below is an example where subnormals noticeably impact performance on some hardware:function timestep(b::Vector{T}, a::Vector{T}, Δt::T) where T\n    @assert length(a)==length(b)\n    n = length(b)\n    b[1] = 1                            # Boundary condition\n    for i=2:n-1\n        b[i] = a[i] + (a[i-1] - T(2)*a[i] + a[i+1]) * Δt\n    end\n    b[n] = 0                            # Boundary condition\nend\n\nfunction heatflow(a::Vector{T}, nstep::Integer) where T\n    b = similar(a)\n    for t=1:div(nstep,2)                # Assume nstep is even\n        timestep(b,a,T(0.1))\n        timestep(a,b,T(0.1))\n    end\nend\n\nheatflow(zeros(Float32,10),2)           # Force compilation\nfor trial=1:6\n    a = zeros(Float32,1000)\n    set_zero_subnormals(iseven(trial))  # Odd trials use strict IEEE arithmetic\n    @time heatflow(a,1000)\nendThis example generates many subnormal numbers because the values in a become an exponentially decreasing curve, which slowly flattens out over time.Treating subnormals as zeros should be used with caution, because doing so breaks some identities, such as x-y == 0 implies x == y:julia> x = 3f-38; y = 2f-38;\n\njulia> set_zero_subnormals(true); (x - y, x == y)\n(0.0f0, false)\n\njulia> set_zero_subnormals(false); (x - y, x == y)\n(1.0000001f-38, false)In some applications, an alternative to zeroing subnormal numbers is to inject a tiny bit of noise.  For example, instead of initializing a with zeros, initialize it with:a = rand(Float32,1000) * 1.f-9"
},

{
    "location": "manual/performance-tips/#man-code-warntype-1",
    "page": "Performance Tips",
    "title": "@code_warntype",
    "category": "section",
    "text": "The macro @code_warntype (or its function variant code_warntype()) can sometimes be helpful in diagnosing type-related problems. Here\'s an example:pos(x) = x < 0 ? 0 : x\n\nfunction f(x)\n    y = pos(x)\n    sin(y*x+1)\nend\n\njulia> @code_warntype f(3.2)\nVariables:\n  #self#::#f\n  x::Float64\n  y::UNION{FLOAT64,INT64}\n  fy::Float64\n  #temp#@_5::UNION{FLOAT64,INT64}\n  #temp#@_6::Core.MethodInstance\n  #temp#@_7::Float64\n\nBody:\n  begin\n      $(Expr(:inbounds, false))\n      # meta: location REPL[1] pos 1\n      # meta: location float.jl < 487\n      fy::Float64 = (Core.typeassert)((Base.sitofp)(Float64,0)::Float64,Float64)::Float64\n      # meta: pop location\n      unless (Base.or_int)((Base.lt_float)(x::Float64,fy::Float64)::Bool,(Base.and_int)((Base.and_int)((Base.eq_float)(x::Float64,fy::Float64)::Bool,(Base.lt_float)(fy::Float64,9.223372036854776e18)::Bool)::Bool,(Base.slt_int)((Base.fptosi)(Int64,fy::Float64)::Int64,0)::Bool)::Bool)::Bool goto 9\n      #temp#@_5::UNION{FLOAT64,INT64} = 0\n      goto 11\n      9:\n      #temp#@_5::UNION{FLOAT64,INT64} = x::Float64\n      11:\n      # meta: pop location\n      $(Expr(:inbounds, :pop))\n      y::UNION{FLOAT64,INT64} = #temp#@_5::UNION{FLOAT64,INT64} # line 3:\n      unless (y::UNION{FLOAT64,INT64} isa Int64)::ANY goto 19\n      #temp#@_6::Core.MethodInstance = MethodInstance for *(::Int64, ::Float64)\n      goto 28\n      19:\n      unless (y::UNION{FLOAT64,INT64} isa Float64)::ANY goto 23\n      #temp#@_6::Core.MethodInstance = MethodInstance for *(::Float64, ::Float64)\n      goto 28\n      23:\n      goto 25\n      25:\n      #temp#@_7::Float64 = (y::UNION{FLOAT64,INT64} * x::Float64)::Float64\n      goto 30\n      28:\n      #temp#@_7::Float64 = $(Expr(:invoke, :(#temp#@_6), :(Main.*), :(y), :(x)))\n      30:\n      return $(Expr(:invoke, MethodInstance for sin(::Float64), :(Main.sin), :((Base.add_float)(#temp#@_7,(Base.sitofp)(Float64,1)::Float64)::Float64)))\n  end::Float64Interpreting the output of @code_warntype, like that of its cousins @code_lowered, @code_typed, @code_llvm, and @code_native, takes a little practice. Your code is being presented in form that has been partially digested on its way to generating compiled machine code.  Most of the expressions are annotated by a type, indicated by the ::T (where T might be Float64, for example). The most important characteristic of @code_warntype is that non-concrete types are displayed in red; in the above example, such output is shown in all-caps.The top part of the output summarizes the type information for the different variables internal to the function. You can see that y, one of the variables you created, is a Union{Int64,Float64}, due to the type-instability of pos.  There is another variable, _var4, which you can see also has the same type.The next lines represent the body of f. The lines starting with a number followed by a colon (1:, 2:) are labels, and represent targets for jumps (via goto) in your code.  Looking at the body, you can see that pos has been inlined into f–everything before 2: comes from code defined in pos.Starting at 2:, the variable y is defined, and again annotated as a Union type.  Next, we see that the compiler created the temporary variable _var1 to hold the result of y*x. Because a Float64 times either an Int64 or Float64 yields a Float64, all type-instability ends here. The net result is that f(x::Float64) will not be type-unstable in its output, even if some of the intermediate computations are type-unstable.How you use this information is up to you. Obviously, it would be far and away best to fix pos to be type-stable: if you did so, all of the variables in f would be concrete, and its performance would be optimal.  However, there are circumstances where this kind of ephemeral type instability might not matter too much: for example, if pos is never used in isolation, the fact that f\'s output is type-stable (for Float64 inputs) will shield later code from the propagating effects of type instability.  This is particularly relevant in cases where fixing the type instability is difficult or impossible: for example, currently it\'s not possible to infer the return type of an anonymous function.  In such cases, the tips above (e.g., adding type annotations and/or breaking up functions) are your best tools to contain the \"damage\" from type instability.The following examples may help you interpret expressions marked as containing non-leaf types:Function body ending in end::Union{T1,T2})\nInterpretation: function with unstable return type\nSuggestion: make the return value type-stable, even if you have to annotate it\nf(x::T)::Union{T1,T2}\nInterpretation: call to a type-unstable function\nSuggestion: fix the function, or if necessary annotate the return value\n(top(arrayref))(A::Array{Any,1},1)::Any\nInterpretation: accessing elements of poorly-typed arrays\nSuggestion: use arrays with better-defined types, or if necessary annotate the type of individual element accesses\n(top(getfield))(A::ArrayContainer{Float64},:data)::Array{Float64,N}\nInterpretation: getting a field that is of non-leaf type. In this case, ArrayContainer had a field data::Array{T}. But Array needs the dimension N, too, to be a concrete type.\nSuggestion: use concrete types like Array{T,3} or Array{T,N}, where N is now a parameter of ArrayContainer"
},

{
    "location": "manual/workflow-tips/#",
    "page": "Workflow Tips",
    "title": "Workflow Tips",
    "category": "page",
    "text": ""
},

{
    "location": "manual/workflow-tips/#man-workflow-tips-1",
    "page": "Workflow Tips",
    "title": "Workflow Tips",
    "category": "section",
    "text": "Here are some tips for working with Julia efficiently."
},

{
    "location": "manual/workflow-tips/#REPL-based-workflow-1",
    "page": "Workflow Tips",
    "title": "REPL-based workflow",
    "category": "section",
    "text": "As already elaborated in Interacting With Julia, Julia\'s REPL provides rich functionality that facilitates an efficient interactive workflow. Here are some tips that might further enhance your experience at the command line."
},

{
    "location": "manual/workflow-tips/#A-basic-editor/REPL-workflow-1",
    "page": "Workflow Tips",
    "title": "A basic editor/REPL workflow",
    "category": "section",
    "text": "The most basic Julia workflows involve using a text editor in conjunction with the julia command line. A common pattern includes the following elements:Put code under development in a temporary module. Create a file, say Tmp.jl, and include within it\nmodule Tmp\n\n<your definitions here>\n\nend\nPut your test code in another file. Create another file, say tst.jl, which begins with\nimport Tmp\nand includes tests for the contents of Tmp. The value of using import versus using is that you can call reload(\"Tmp\") instead of having to restart the REPL when your definitions change. Of course, the cost is the need to prepend Tmp. to uses of names defined in your module. (You can lower that cost by keeping your module name short.)\nAlternatively, you can wrap the contents of your test file in a module, as\nmodule Tst\n    using Tmp\n\n    <scratch work>\n\nend\nThe advantage is that you can now do using Tmp in your test code and can therefore avoid prepending Tmp. everywhere. The disadvantage is that code can no longer be selectively copied to the REPL without some tweaking.\nLather. Rinse. Repeat. Explore ideas at the julia command prompt. Save good ideas in tst.jl. Occasionally restart the REPL, issuing\nreload(\"Tmp\")\ninclude(\"tst.jl\")"
},

{
    "location": "manual/workflow-tips/#Simplify-initialization-1",
    "page": "Workflow Tips",
    "title": "Simplify initialization",
    "category": "section",
    "text": "To simplify restarting the REPL, put project-specific initialization code in a file, say _init.jl, which you can run on startup by issuing the command:julia -L _init.jlIf you further add the following to your .juliarc.jl fileisfile(\"_init.jl\") && include(joinpath(pwd(), \"_init.jl\"))then calling julia from that directory will run the initialization code without the additional command line argument."
},

{
    "location": "manual/workflow-tips/#Browser-based-workflow-1",
    "page": "Workflow Tips",
    "title": "Browser-based workflow",
    "category": "section",
    "text": "It is also possible to interact with a Julia REPL in the browser via IJulia. See the package home for details."
},

{
    "location": "manual/style-guide/#",
    "page": "Style Guide",
    "title": "Style Guide",
    "category": "page",
    "text": ""
},

{
    "location": "manual/style-guide/#Style-Guide-1",
    "page": "Style Guide",
    "title": "Style Guide",
    "category": "section",
    "text": "The following sections explain a few aspects of idiomatic Julia coding style. None of these rules are absolute; they are only suggestions to help familiarize you with the language and to help you choose among alternative designs."
},

{
    "location": "manual/style-guide/#Write-functions,-not-just-scripts-1",
    "page": "Style Guide",
    "title": "Write functions, not just scripts",
    "category": "section",
    "text": "Writing code as a series of steps at the top level is a quick way to get started solving a problem, but you should try to divide a program into functions as soon as possible. Functions are more reusable and testable, and clarify what steps are being done and what their inputs and outputs are. Furthermore, code inside functions tends to run much faster than top level code, due to how Julia\'s compiler works.It is also worth emphasizing that functions should take arguments, instead of operating directly on global variables (aside from constants like pi)."
},

{
    "location": "manual/style-guide/#Avoid-writing-overly-specific-types-1",
    "page": "Style Guide",
    "title": "Avoid writing overly-specific types",
    "category": "section",
    "text": "Code should be as generic as possible. Instead of writing:convert(Complex{Float64}, x)it\'s better to use available generic functions:complex(float(x))The second version will convert x to an appropriate type, instead of always the same type.This style point is especially relevant to function arguments. For example, don\'t declare an argument to be of type Int or Int32 if it really could be any integer, expressed with the abstract type Integer. In fact, in many cases you can omit the argument type altogether, unless it is needed to disambiguate from other method definitions, since a MethodError will be thrown anyway if a type is passed that does not support any of the requisite operations. (This is known as duck typing.)For example, consider the following definitions of a function addone that returns one plus its argument:addone(x::Int) = x + 1                 # works only for Int\naddone(x::Integer) = x + oneunit(x)    # any integer type\naddone(x::Number) = x + oneunit(x)     # any numeric type\naddone(x) = x + oneunit(x)             # any type supporting + and oneunitThe last definition of addone handles any type supporting oneunit (which returns 1 in the same type as x, which avoids unwanted type promotion) and the + function with those arguments. The key thing to realize is that there is no performance penalty to defining only the general addone(x) = x + oneunit(x), because Julia will automatically compile specialized versions as needed. For example, the first time you call addone(12), Julia will automatically compile a specialized addone function for x::Int arguments, with the call to oneunit replaced by its inlined value 1. Therefore, the first three definitions of addone above are completely redundant with the fourth definition."
},

{
    "location": "manual/style-guide/#Handle-excess-argument-diversity-in-the-caller-1",
    "page": "Style Guide",
    "title": "Handle excess argument diversity in the caller",
    "category": "section",
    "text": "Instead of:function foo(x, y)\n    x = Int(x); y = Int(y)\n    ...\nend\nfoo(x, y)use:function foo(x::Int, y::Int)\n    ...\nend\nfoo(Int(x), Int(y))This is better style because foo does not really accept numbers of all types; it really needs Int s.One issue here is that if a function inherently requires integers, it might be better to force the caller to decide how non-integers should be converted (e.g. floor or ceiling). Another issue is that declaring more specific types leaves more \"space\" for future method definitions."
},

{
    "location": "manual/style-guide/#Append-!-to-names-of-functions-that-modify-their-arguments-1",
    "page": "Style Guide",
    "title": "Append ! to names of functions that modify their arguments",
    "category": "section",
    "text": "Instead of:function double(a::AbstractArray{<:Number})\n    for i = 1:endof(a)\n        a[i] *= 2\n    end\n    return a\nenduse:function double!(a::AbstractArray{<:Number})\n    for i = 1:endof(a)\n        a[i] *= 2\n    end\n    return a\nendThe Julia standard library uses this convention throughout and contains examples of functions with both copying and modifying forms (e.g., sort() and sort!()), and others which are just modifying (e.g., push!(), pop!(), splice!()).  It is typical for such functions to also return the modified array for convenience."
},

{
    "location": "manual/style-guide/#Avoid-strange-type-Unions-1",
    "page": "Style Guide",
    "title": "Avoid strange type Unions",
    "category": "section",
    "text": "Types such as Union{Function,AbstractString} are often a sign that some design could be cleaner."
},

{
    "location": "manual/style-guide/#Avoid-type-Unions-in-fields-1",
    "page": "Style Guide",
    "title": "Avoid type Unions in fields",
    "category": "section",
    "text": "When creating a type such as:mutable struct MyType\n    ...\n    x::Union{Void,T}\nendask whether the option for x to be nothing (of type Void) is really necessary. Here are some alternatives to consider:Find a safe default value to initialize x with\nIntroduce another type that lacks x\nIf there are many fields like x, store them in a dictionary\nDetermine whether there is a simple rule for when x is nothing. For example, often the field will start as nothing but get initialized at some well-defined point. In that case, consider leaving it undefined at first.\nIf x really needs to hold no value at some times, define it as ::Nullable{T} instead, as this guarantees type-stability in the code accessing this field (see Nullable types)."
},

{
    "location": "manual/style-guide/#Avoid-elaborate-container-types-1",
    "page": "Style Guide",
    "title": "Avoid elaborate container types",
    "category": "section",
    "text": "It is usually not much help to construct arrays like the following:a = Array{Union{Int,AbstractString,Tuple,Array}}(n)In this case Array{Any}(n) is better. It is also more helpful to the compiler to annotate specific uses (e.g. a[i]::Int) than to try to pack many alternatives into one type."
},

{
    "location": "manual/style-guide/#Use-naming-conventions-consistent-with-Julia\'s-base/-1",
    "page": "Style Guide",
    "title": "Use naming conventions consistent with Julia\'s base/",
    "category": "section",
    "text": "modules and type names use capitalization and camel case: module SparseArrays, struct UnitRange.\nfunctions are lowercase (maximum(), convert()) and, when readable, with multiple words squashed together (isequal(), haskey()). When necessary, use underscores as word separators. Underscores are also used to indicate a combination of concepts (remotecall_fetch() as a more efficient implementation of fetch(remotecall(...))) or as modifiers (sum_kbn()).\nconciseness is valued, but avoid abbreviation (indexin() rather than indxin()) as it becomes difficult to remember whether and how particular words are abbreviated.If a function name requires multiple words, consider whether it might represent more than one concept and might be better split into pieces."
},

{
    "location": "manual/style-guide/#Don\'t-overuse-try-catch-1",
    "page": "Style Guide",
    "title": "Don\'t overuse try-catch",
    "category": "section",
    "text": "It is better to avoid errors than to rely on catching them."
},

{
    "location": "manual/style-guide/#Don\'t-parenthesize-conditions-1",
    "page": "Style Guide",
    "title": "Don\'t parenthesize conditions",
    "category": "section",
    "text": "Julia doesn\'t require parens around conditions in if and while. Write:if a == binstead of:if (a == b)"
},

{
    "location": "manual/style-guide/#Don\'t-overuse-...-1",
    "page": "Style Guide",
    "title": "Don\'t overuse ...",
    "category": "section",
    "text": "Splicing function arguments can be addictive. Instead of [a..., b...], use simply [a; b], which already concatenates arrays. collect(a) is better than [a...], but since a is already iterable it is often even better to leave it alone, and not convert it to an array."
},

{
    "location": "manual/style-guide/#Don\'t-use-unnecessary-static-parameters-1",
    "page": "Style Guide",
    "title": "Don\'t use unnecessary static parameters",
    "category": "section",
    "text": "A function signature:foo(x::T) where {T<:Real} = ...should be written as:foo(x::Real) = ...instead, especially if T is not used in the function body. Even if T is used, it can be replaced with typeof(x) if convenient. There is no performance difference. Note that this is not a general caution against static parameters, just against uses where they are not needed.Note also that container types, specifically may need type parameters in function calls. See the FAQ Avoid fields with abstract containers for more information."
},

{
    "location": "manual/style-guide/#Avoid-confusion-about-whether-something-is-an-instance-or-a-type-1",
    "page": "Style Guide",
    "title": "Avoid confusion about whether something is an instance or a type",
    "category": "section",
    "text": "Sets of definitions like the following are confusing:foo(::Type{MyType}) = ...\nfoo(::MyType) = foo(MyType)Decide whether the concept in question will be written as MyType or MyType(), and stick to it.The preferred style is to use instances by default, and only add methods involving Type{MyType} later if they become necessary to solve some problem.If a type is effectively an enumeration, it should be defined as a single (ideally immutable struct or primitive) type, with the enumeration values being instances of it. Constructors and conversions can check whether values are valid. This design is preferred over making the enumeration an abstract type, with the \"values\" as subtypes."
},

{
    "location": "manual/style-guide/#Don\'t-overuse-macros-1",
    "page": "Style Guide",
    "title": "Don\'t overuse macros",
    "category": "section",
    "text": "Be aware of when a macro could really be a function instead.Calling eval() inside a macro is a particularly dangerous warning sign; it means the macro will only work when called at the top level. If such a macro is written as a function instead, it will naturally have access to the run-time values it needs."
},

{
    "location": "manual/style-guide/#Don\'t-expose-unsafe-operations-at-the-interface-level-1",
    "page": "Style Guide",
    "title": "Don\'t expose unsafe operations at the interface level",
    "category": "section",
    "text": "If you have a type that uses a native pointer:mutable struct NativeType\n    p::Ptr{UInt8}\n    ...\nenddon\'t write definitions like the following:getindex(x::NativeType, i) = unsafe_load(x.p, i)The problem is that users of this type can write x[i] without realizing that the operation is unsafe, and then be susceptible to memory bugs.Such a function should either check the operation to ensure it is safe, or have unsafe somewhere in its name to alert callers."
},

{
    "location": "manual/style-guide/#Don\'t-overload-methods-of-base-container-types-1",
    "page": "Style Guide",
    "title": "Don\'t overload methods of base container types",
    "category": "section",
    "text": "It is possible to write definitions like the following:show(io::IO, v::Vector{MyType}) = ...This would provide custom showing of vectors with a specific new element type. While tempting, this should be avoided. The trouble is that users will expect a well-known type like Vector() to behave in a certain way, and overly customizing its behavior can make it harder to work with."
},

{
    "location": "manual/style-guide/#Avoid-type-piracy-1",
    "page": "Style Guide",
    "title": "Avoid type piracy",
    "category": "section",
    "text": "\"Type piracy\" refers to the practice of extending or redefining methods in Base or other packages on types that you have not defined. In some cases, you can get away with type piracy with little ill effect. In extreme cases, however, you can even crash Julia (e.g. if your method extension or redefinition causes invalid input to be passed to a ccall). Type piracy can complicate reasoning about code, and may introduce incompatibilities that are hard to predict and diagnose.As an example, suppose you wanted to define multiplication on symbols in a module:module A\nimport Base.*\n*(x::Symbol, y::Symbol) = Symbol(x,y)\nendThe problem is that now any other module that uses Base.* will also see this definition. Since Symbol is defined in Base and is used by other modules, this can change the behavior of unrelated code unexpectedly. There are several alternatives here, including using a different function name, or wrapping the Symbols in another type that you define.Sometimes, coupled packages may engage in type piracy to separate features from definitions, especially when the packages were designed by collaborating authors, and when the definitions are reusable. For example, one package might provide some types useful for working with colors; another package could define methods for those types that enable conversions between color spaces. Another example might be a package that acts as a thin wrapper for some C code, which another package might then pirate to implement a higher-level, Julia-friendly API."
},

{
    "location": "manual/style-guide/#Be-careful-with-type-equality-1",
    "page": "Style Guide",
    "title": "Be careful with type equality",
    "category": "section",
    "text": "You generally want to use isa() and <: (issubtype()) for testing types, not ==. Checking types for exact equality typically only makes sense when comparing to a known concrete type (e.g. T == Float64), or if you really, really know what you\'re doing."
},

{
    "location": "manual/style-guide/#Do-not-write-x-f(x)-1",
    "page": "Style Guide",
    "title": "Do not write x->f(x)",
    "category": "section",
    "text": "Since higher-order functions are often called with anonymous functions, it is easy to conclude that this is desirable or even necessary. But any function can be passed directly, without being \"wrapped\" in an anonymous function. Instead of writing map(x->f(x), a), write map(f, a)."
},

{
    "location": "manual/style-guide/#Avoid-using-floats-for-numeric-literals-in-generic-code-when-possible-1",
    "page": "Style Guide",
    "title": "Avoid using floats for numeric literals in generic code when possible",
    "category": "section",
    "text": "If you write generic code which handles numbers, and which can be expected to run with many different numeric type arguments, try using literals of a numeric type that will affect the arguments as little as possible through promotion.For example,julia> f(x) = 2.0 * x\nf (generic function with 1 method)\n\njulia> f(1//2)\n1.0\n\njulia> f(1/2)\n1.0\n\njulia> f(1)\n2.0whilejulia> g(x) = 2 * x\ng (generic function with 1 method)\n\njulia> g(1//2)\n1//1\n\njulia> g(1/2)\n1.0\n\njulia> g(1)\n2As you can see, the second version, where we used an Int literal, preserved the type of the input argument, while the first didn\'t. This is because e.g. promote_type(Int, Float64) == Float64, and promotion happens with the multiplication. Similarly, Rational literals are less type disruptive than Float64 literals, but more disruptive than Ints:julia> h(x) = 2//1 * x\nh (generic function with 1 method)\n\njulia> h(1//2)\n1//1\n\njulia> h(1/2)\n1.0\n\njulia> h(1)\n2//1Thus, use Int literals when possible, with Rational{Int} for literal non-integer numbers, in order to make it easier to use your code."
},

{
    "location": "manual/faq/#",
    "page": "Frequently Asked Questions",
    "title": "Frequently Asked Questions",
    "category": "page",
    "text": ""
},

{
    "location": "manual/faq/#Frequently-Asked-Questions-1",
    "page": "Frequently Asked Questions",
    "title": "Frequently Asked Questions",
    "category": "section",
    "text": ""
},

{
    "location": "manual/faq/#Sessions-and-the-REPL-1",
    "page": "Frequently Asked Questions",
    "title": "Sessions and the REPL",
    "category": "section",
    "text": ""
},

{
    "location": "manual/faq/#How-do-I-delete-an-object-in-memory?-1",
    "page": "Frequently Asked Questions",
    "title": "How do I delete an object in memory?",
    "category": "section",
    "text": "Julia does not have an analog of MATLAB\'s clear function; once a name is defined in a Julia session (technically, in module Main), it is always present.If memory usage is your concern, you can always replace objects with ones that consume less memory.  For example, if A is a gigabyte-sized array that you no longer need, you can free the memory with A = 0.  The memory will be released the next time the garbage collector runs; you can force this to happen with gc()."
},

{
    "location": "manual/faq/#How-can-I-modify-the-declaration-of-a-type-in-my-session?-1",
    "page": "Frequently Asked Questions",
    "title": "How can I modify the declaration of a type in my session?",
    "category": "section",
    "text": "Perhaps you\'ve defined a type and then realize you need to add a new field.  If you try this at the REPL, you get the error:ERROR: invalid redefinition of constant MyTypeTypes in module Main cannot be redefined.While this can be inconvenient when you are developing new code, there\'s an excellent workaround.  Modules can be replaced by redefining them, and so if you wrap all your new code inside a module you can redefine types and constants.  You can\'t import the type names into Main and then expect to be able to redefine them there, but you can use the module name to resolve the scope.  In other words, while developing you might use a workflow something like this:include(\"mynewcode.jl\")              # this defines a module MyModule\nobj1 = MyModule.ObjConstructor(a, b)\nobj2 = MyModule.somefunction(obj1)\n# Got an error. Change something in \"mynewcode.jl\"\ninclude(\"mynewcode.jl\")              # reload the module\nobj1 = MyModule.ObjConstructor(a, b) # old objects are no longer valid, must reconstruct\nobj2 = MyModule.somefunction(obj1)   # this time it worked!\nobj3 = MyModule.someotherfunction(obj2, c)\n..."
},

{
    "location": "manual/faq/#Functions-1",
    "page": "Frequently Asked Questions",
    "title": "Functions",
    "category": "section",
    "text": ""
},

{
    "location": "manual/faq/#I-passed-an-argument-x-to-a-function,-modified-it-inside-that-function,-but-on-the-outside,-1",
    "page": "Frequently Asked Questions",
    "title": "I passed an argument x to a function, modified it inside that function, but on the outside,",
    "category": "section",
    "text": "the variable x is still unchanged. Why?Suppose you call a function like this:julia> x = 10\n10\n\njulia> function change_value!(y)\n           y = 17\n       end\nchange_value! (generic function with 1 method)\n\njulia> change_value!(x)\n17\n\njulia> x # x is unchanged!\n10In Julia, the binding of a variable x cannot be changed by passing x as an argument to a function. When calling change_value!(x) in the above example, y is a newly created variable, bound initially to the value of x, i.e. 10; then y is rebound to the constant 17, while the variable x of the outer scope is left untouched.But here is a thing you should pay attention to: suppose x is bound to an object of type Array (or any other mutable type). From within the function, you cannot \"unbind\" x from this Array, but you can change its content. For example:julia> x = [1,2,3]\n3-element Array{Int64,1}:\n 1\n 2\n 3\n\njulia> function change_array!(A)\n           A[1] = 5\n       end\nchange_array! (generic function with 1 method)\n\njulia> change_array!(x)\n5\n\njulia> x\n3-element Array{Int64,1}:\n 5\n 2\n 3Here we created a function change_array!(), that assigns 5 to the first element of the passed array (bound to x at the call site, and bound to A within the function). Notice that, after the function call, x is still bound to the same array, but the content of that array changed: the variables A and x were distinct bindings refering to the same mutable Array object."
},

{
    "location": "manual/faq/#Can-I-use-using-or-import-inside-a-function?-1",
    "page": "Frequently Asked Questions",
    "title": "Can I use using or import inside a function?",
    "category": "section",
    "text": "No, you are not allowed to have a using or import statement inside a function.  If you want to import a module but only use its symbols inside a specific function or set of functions, you have two options:Use import:\nimport Foo\nfunction bar(...)\n    # ... refer to Foo symbols via Foo.baz ...\nend\nThis loads the module Foo and defines a variable Foo that refers to the module, but does not import any of the other symbols from the module into the current namespace.  You refer to the Foo symbols by their qualified names Foo.bar etc.\nWrap your function in a module:\nmodule Bar\nexport bar\nusing Foo\nfunction bar(...)\n    # ... refer to Foo.baz as simply baz ....\nend\nend\nusing Bar\nThis imports all the symbols from Foo, but only inside the module Bar."
},

{
    "location": "manual/faq/#What-does-the-...-operator-do?-1",
    "page": "Frequently Asked Questions",
    "title": "What does the ... operator do?",
    "category": "section",
    "text": ""
},

{
    "location": "manual/faq/#The-two-uses-of-the-...-operator:-slurping-and-splatting-1",
    "page": "Frequently Asked Questions",
    "title": "The two uses of the ... operator: slurping and splatting",
    "category": "section",
    "text": "Many newcomers to Julia find the use of ... operator confusing. Part of what makes the ... operator confusing is that it means two different things depending on context."
},

{
    "location": "manual/faq/#...-combines-many-arguments-into-one-argument-in-function-definitions-1",
    "page": "Frequently Asked Questions",
    "title": "... combines many arguments into one argument in function definitions",
    "category": "section",
    "text": "In the context of function definitions, the ... operator is used to combine many different arguments into a single argument. This use of ... for combining many different arguments into a single argument is called slurping:julia> function printargs(args...)\n           @printf(\"%s\\n\", typeof(args))\n           for (i, arg) in enumerate(args)\n               @printf(\"Arg %d = %s\\n\", i, arg)\n           end\n       end\nprintargs (generic function with 1 method)\n\njulia> printargs(1, 2, 3)\nTuple{Int64,Int64,Int64}\nArg 1 = 1\nArg 2 = 2\nArg 3 = 3If Julia were a language that made more liberal use of ASCII characters, the slurping operator might have been written as <-... instead of ...."
},

{
    "location": "manual/faq/#...-splits-one-argument-into-many-different-arguments-in-function-calls-1",
    "page": "Frequently Asked Questions",
    "title": "... splits one argument into many different arguments in function calls",
    "category": "section",
    "text": "In contrast to the use of the ... operator to denote slurping many different arguments into one argument when defining a function, the ... operator is also used to cause a single function argument to be split apart into many different arguments when used in the context of a function call. This use of ... is called splatting:julia> function threeargs(a, b, c)\n           @printf(\"a = %s::%s\\n\", a, typeof(a))\n           @printf(\"b = %s::%s\\n\", b, typeof(b))\n           @printf(\"c = %s::%s\\n\", c, typeof(c))\n       end\nthreeargs (generic function with 1 method)\n\njulia> vec = [1, 2, 3]\n3-element Array{Int64,1}:\n 1\n 2\n 3\n\njulia> threeargs(vec...)\na = 1::Int64\nb = 2::Int64\nc = 3::Int64If Julia were a language that made more liberal use of ASCII characters, the splatting operator might have been written as ...-> instead of ...."
},

{
    "location": "manual/faq/#Types,-type-declarations,-and-constructors-1",
    "page": "Frequently Asked Questions",
    "title": "Types, type declarations, and constructors",
    "category": "section",
    "text": ""
},

{
    "location": "manual/faq/#man-type-stability-1",
    "page": "Frequently Asked Questions",
    "title": "What does \"type-stable\" mean?",
    "category": "section",
    "text": "It means that the type of the output is predictable from the types of the inputs.  In particular, it means that the type of the output cannot vary depending on the values of the inputs. The following code is not type-stable:julia> function unstable(flag::Bool)\n           if flag\n               return 1\n           else\n               return 1.0\n           end\n       end\nunstable (generic function with 1 method)It returns either an Int or a Float64 depending on the value of its argument. Since Julia can\'t predict the return type of this function at compile-time, any computation that uses it will have to guard against both types possibly occurring, making generation of fast machine code difficult."
},

{
    "location": "manual/faq/#faq-domain-errors-1",
    "page": "Frequently Asked Questions",
    "title": "Why does Julia give a DomainError for certain seemingly-sensible operations?",
    "category": "section",
    "text": "Certain operations make mathematical sense but result in errors:julia> sqrt(-2.0)\nERROR: DomainError:\nsqrt will only return a complex result if called with a complex argument. Try sqrt(complex(x)).\nStacktrace:\n [1] sqrt(::Float64) at ./math.jl:425\n\njulia> 2^-5\nERROR: DomainError:\nCannot raise an integer x to a negative power -n.\nMake x a float by adding a zero decimal (e.g. 2.0^-n instead of 2^-n), or write 1/x^n, float(x)^-n, or (x//1)^-n.\nStacktrace:\n [1] power_by_squaring(::Int64, ::Int64) at ./intfuncs.jl:173\n [2] literal_pow(::Base.#^, ::Int64, ::Type{Val{-5}}) at ./intfuncs.jl:208This behavior is an inconvenient consequence of the requirement for type-stability.  In the case of sqrt(), most users want sqrt(2.0) to give a real number, and would be unhappy if it produced the complex number 1.4142135623730951 + 0.0im.  One could write the sqrt() function to switch to a complex-valued output only when passed a negative number (which is what sqrt() does in some other languages), but then the result would not be type-stable and the sqrt() function would have poor performance.In these and other cases, you can get the result you want by choosing an input type that conveys your willingness to accept an output type in which the result can be represented:julia> sqrt(-2.0+0im)\n0.0 + 1.4142135623730951im\n\njulia> 2.0^-5\n0.03125"
},

{
    "location": "manual/faq/#Why-does-Julia-use-native-machine-integer-arithmetic?-1",
    "page": "Frequently Asked Questions",
    "title": "Why does Julia use native machine integer arithmetic?",
    "category": "section",
    "text": "Julia uses machine arithmetic for integer computations. This means that the range of Int values is bounded and wraps around at either end so that adding, subtracting and multiplying integers can overflow or underflow, leading to some results that can be unsettling at first:julia> typemax(Int)\n9223372036854775807\n\njulia> ans+1\n-9223372036854775808\n\njulia> -ans\n-9223372036854775808\n\njulia> 2*ans\n0Clearly, this is far from the way mathematical integers behave, and you might think it less than ideal for a high-level programming language to expose this to the user. For numerical work where efficiency and transparency are at a premium, however, the alternatives are worse.One alternative to consider would be to check each integer operation for overflow and promote results to bigger integer types such as Int128 or BigInt in the case of overflow. Unfortunately, this introduces major overhead on every integer operation (think incrementing a loop counter) – it requires emitting code to perform run-time overflow checks after arithmetic instructions and branches to handle potential overflows. Worse still, this would cause every computation involving integers to be type-unstable. As we mentioned above, type-stability is crucial for effective generation of efficient code. If you can\'t count on the results of integer operations being integers, it\'s impossible to generate fast, simple code the way C and Fortran compilers do.A variation on this approach, which avoids the appearance of type instability is to merge the Int and BigInt types into a single hybrid integer type, that internally changes representation when a result no longer fits into the size of a machine integer. While this superficially avoids type-instability at the level of Julia code, it just sweeps the problem under the rug by foisting all of the same difficulties onto the C code implementing this hybrid integer type. This approach can be made to work and can even be made quite fast in many cases, but has several drawbacks. One problem is that the in-memory representation of integers and arrays of integers no longer match the natural representation used by C, Fortran and other languages with native machine integers. Thus, to interoperate with those languages, we would ultimately need to introduce native integer types anyway. Any unbounded representation of integers cannot have a fixed number of bits, and thus cannot be stored inline in an array with fixed-size slots – large integer values will always require separate heap-allocated storage. And of course, no matter how clever a hybrid integer implementation one uses, there are always performance traps – situations where performance degrades unexpectedly. Complex representation, lack of interoperability with C and Fortran, the inability to represent integer arrays without additional heap storage, and unpredictable performance characteristics make even the cleverest hybrid integer implementations a poor choice for high-performance numerical work.An alternative to using hybrid integers or promoting to BigInts is to use saturating integer arithmetic, where adding to the largest integer value leaves it unchanged and likewise for subtracting from the smallest integer value. This is precisely what Matlab™ does:>> int64(9223372036854775807)\n\nans =\n\n  9223372036854775807\n\n>> int64(9223372036854775807) + 1\n\nans =\n\n  9223372036854775807\n\n>> int64(-9223372036854775808)\n\nans =\n\n -9223372036854775808\n\n>> int64(-9223372036854775808) - 1\n\nans =\n\n -9223372036854775808At first blush, this seems reasonable enough since 9223372036854775807 is much closer to 9223372036854775808 than -9223372036854775808 is and integers are still represented with a fixed size in a natural way that is compatible with C and Fortran. Saturated integer arithmetic, however, is deeply problematic. The first and most obvious issue is that this is not the way machine integer arithmetic works, so implementing saturated operations requires emitting instructions after each machine integer operation to check for underflow or overflow and replace the result with typemin(Int) or typemax(Int) as appropriate. This alone expands each integer operation from a single, fast instruction into half a dozen instructions, probably including branches. Ouch. But it gets worse – saturating integer arithmetic isn\'t associative. Consider this Matlab computation:>> n = int64(2)^62\n4611686018427387904\n\n>> n + (n - 1)\n9223372036854775807\n\n>> (n + n) - 1\n9223372036854775806This makes it hard to write many basic integer algorithms since a lot of common techniques depend on the fact that machine addition with overflow is associative. Consider finding the midpoint between integer values lo and hi in Julia using the expression (lo + hi) >>> 1:julia> n = 2^62\n4611686018427387904\n\njulia> (n + 2n) >>> 1\n6917529027641081856See? No problem. That\'s the correct midpoint between 2^62 and 2^63, despite the fact that n + 2n is -4611686018427387904. Now try it in Matlab:>> (n + 2*n)/2\n\nans =\n\n  4611686018427387904Oops. Adding a >>> operator to Matlab wouldn\'t help, because saturation that occurs when adding n and 2n has already destroyed the information necessary to compute the correct midpoint.Not only is lack of associativity unfortunate for programmers who cannot rely it for techniques like this, but it also defeats almost anything compilers might want to do to optimize integer arithmetic. For example, since Julia integers use normal machine integer arithmetic, LLVM is free to aggressively optimize simple little functions like f(k) = 5k-1. The machine code for this function is just this:julia> code_native(f, Tuple{Int})\n  .text\nFilename: none\n  pushq %rbp\n  movq  %rsp, %rbp\nSource line: 1\n  leaq  -1(%rdi,%rdi,4), %rax\n  popq  %rbp\n  retq\n  nopl  (%rax,%rax)The actual body of the function is a single leaq instruction, which computes the integer multiply and add at once. This is even more beneficial when f gets inlined into another function:julia> function g(k, n)\n           for i = 1:n\n               k = f(k)\n           end\n           return k\n       end\ng (generic function with 1 methods)\n\njulia> code_native(g, Tuple{Int,Int})\n  .text\nFilename: none\n  pushq %rbp\n  movq  %rsp, %rbp\nSource line: 2\n  testq %rsi, %rsi\n  jle L26\n  nopl  (%rax)\nSource line: 3\nL16:\n  leaq  -1(%rdi,%rdi,4), %rdi\nSource line: 2\n  decq  %rsi\n  jne L16\nSource line: 5\nL26:\n  movq  %rdi, %rax\n  popq  %rbp\n  retq\n  nopSince the call to f gets inlined, the loop body ends up being just a single leaq instruction. Next, consider what happens if we make the number of loop iterations fixed:julia> function g(k)\n           for i = 1:10\n               k = f(k)\n           end\n           return k\n       end\ng (generic function with 2 methods)\n\njulia> code_native(g,(Int,))\n  .text\nFilename: none\n  pushq %rbp\n  movq  %rsp, %rbp\nSource line: 3\n  imulq $9765625, %rdi, %rax    # imm = 0x9502F9\n  addq  $-2441406, %rax         # imm = 0xFFDABF42\nSource line: 5\n  popq  %rbp\n  retq\n  nopw  %cs:(%rax,%rax)Because the compiler knows that integer addition and multiplication are associative and that multiplication distributes over addition – neither of which is true of saturating arithmetic – it can optimize the entire loop down to just a multiply and an add. Saturated arithmetic completely defeats this kind of optimization since associativity and distributivity can fail at each loop iteration, causing different outcomes depending on which iteration the failure occurs in. The compiler can unroll the loop, but it cannot algebraically reduce multiple operations into fewer equivalent operations.The most reasonable alternative to having integer arithmetic silently overflow is to do checked arithmetic everywhere, raising errors when adds, subtracts, and multiplies overflow, producing values that are not value-correct. In this blog post, Dan Luu analyzes this and finds that rather than the trivial cost that this approach should in theory have, it ends up having a substantial cost due to compilers (LLVM and GCC) not gracefully optimizing around the added overflow checks. If this improves in the future, we could consider defaulting to checked integer arithmetic in Julia, but for now, we have to live with the possibility of overflow."
},

{
    "location": "manual/faq/#What-are-the-possible-causes-of-an-UndefVarError-during-remote-execution?-1",
    "page": "Frequently Asked Questions",
    "title": "What are the possible causes of an UndefVarError during remote execution?",
    "category": "section",
    "text": "As the error states, an immediate cause of an UndefVarError on a remote node is that a binding by that name does not exist. Let us explore some of the possible causes.julia> module Foo\n           foo() = remotecall_fetch(x->x, 2, \"Hello\")\n       end\n\njulia> Foo.foo()\nERROR: On worker 2:\nUndefVarError: Foo not defined\n[...]The closure x->x carries a reference to Foo, and since Foo is unavailable on node 2, an UndefVarError is thrown.Globals under modules other than Main are not serialized by value to the remote node. Only a reference is sent. Functions which create global bindings (except under Main) may cause an UndefVarError to be thrown later.julia> @everywhere module Foo\n           function foo()\n               global gvar = \"Hello\"\n               remotecall_fetch(()->gvar, 2)\n           end\n       end\n\njulia> Foo.foo()\nERROR: On worker 2:\nUndefVarError: gvar not defined\n[...]In the above example, @everywhere module Foo defined Foo on all nodes. However the call to Foo.foo() created a new global binding gvar on the local node, but this was not found on node 2 resulting in an UndefVarError error.Note that this does not apply to globals created under module Main. Globals under module Main are serialized and new bindings created under Main on the remote node.julia> gvar_self = \"Node1\"\n\"Node1\"\n\njulia> remotecall_fetch(()->gvar_self, 2)\n\"Node1\"\n\njulia> remotecall_fetch(whos, 2)\n	From worker 2:	                          Base  41762 KB     Module\n	From worker 2:	                          Core  27337 KB     Module\n	From worker 2:	                           Foo   2477 bytes  Module\n	From worker 2:	                          Main  46191 KB     Module\n	From worker 2:	                     gvar_self     13 bytes  StringThis does not apply to function or type declarations. However, anonymous functions bound to global variables are serialized as can be seen below.julia> bar() = 1\nbar (generic function with 1 method)\n\njulia> remotecall_fetch(bar, 2)\nERROR: On worker 2:\nUndefVarError: #bar not defined\n[...]\n\njulia> anon_bar  = ()->1\n(::#21) (generic function with 1 method)\n\njulia> remotecall_fetch(anon_bar, 2)\n1"
},

{
    "location": "manual/faq/#Packages-and-Modules-1",
    "page": "Frequently Asked Questions",
    "title": "Packages and Modules",
    "category": "section",
    "text": ""
},

{
    "location": "manual/faq/#What-is-the-difference-between-\"using\"-and-\"importall\"?-1",
    "page": "Frequently Asked Questions",
    "title": "What is the difference between \"using\" and \"importall\"?",
    "category": "section",
    "text": "There is only one difference, and on the surface (syntax-wise) it may seem very minor. The difference between using and importall is that with using you need to say function Foo.bar(.. to extend module Foo\'s function bar with a new method, but with importall or import Foo.bar, you only need to say function bar(... and it automatically extends module Foo\'s function bar.If you use importall, then function Foo.bar(... and function bar(... become equivalent. If you use using, then they are different.The reason this is important enough to have been given separate syntax is that you don\'t want to accidentally extend a function that you didn\'t know existed, because that could easily cause a bug. This is most likely to happen with a method that takes a common type like a string or integer, because both you and the other module could define a method to handle such a common type. If you use importall, then you\'ll replace the other module\'s implementation of bar(s::AbstractString) with your new implementation, which could easily do something completely different (and break all/many future usages of the other functions in module Foo that depend on calling bar)."
},

{
    "location": "manual/faq/#Nothingness-and-missing-values-1",
    "page": "Frequently Asked Questions",
    "title": "Nothingness and missing values",
    "category": "section",
    "text": ""
},

{
    "location": "manual/faq/#How-does-\"null\"-or-\"nothingness\"-work-in-Julia?-1",
    "page": "Frequently Asked Questions",
    "title": "How does \"null\" or \"nothingness\" work in Julia?",
    "category": "section",
    "text": "Unlike many languages (for example, C and Java), Julia does not have a \"null\" value. When a reference (variable, object field, or array element) is uninitialized, accessing it will immediately throw an error. This situation can be detected using the isdefined function.Some functions are used only for their side effects, and do not need to return a value. In these cases, the convention is to return the value nothing, which is just a singleton object of type Void. This is an ordinary type with no fields; there is nothing special about it except for this convention, and that the REPL does not print anything for it. Some language constructs that would not otherwise have a value also yield nothing, for example if false; end.For situations where a value exists only sometimes (for example, missing statistical data), it is best to use the Nullable{T} type, which allows specifying the type of a missing value.The empty tuple (()) is another form of nothingness. But, it should not really be thought of as nothing but rather a tuple of zero values.In code written for Julia prior to version 0.4 you may occasionally see None, which is quite different. It is the empty (or \"bottom\") type, a type with no values and no subtypes (except itself). This is now written as Union{} (an empty union type). You will generally not need to use this type."
},

{
    "location": "manual/faq/#Memory-1",
    "page": "Frequently Asked Questions",
    "title": "Memory",
    "category": "section",
    "text": ""
},

{
    "location": "manual/faq/#Why-does-x-y-allocate-memory-when-x-and-y-are-arrays?-1",
    "page": "Frequently Asked Questions",
    "title": "Why does x += y allocate memory when x and y are arrays?",
    "category": "section",
    "text": "In Julia, x += y gets replaced during parsing by x = x + y. For arrays, this has the consequence that, rather than storing the result in the same location in memory as x, it allocates a new array to store the result.While this behavior might surprise some, the choice is deliberate. The main reason is the presence of immutable objects within Julia, which cannot change their value once created.  Indeed, a number is an immutable object; the statements x = 5; x += 1 do not modify the meaning of 5, they modify the value bound to x. For an immutable, the only way to change the value is to reassign it.To amplify a bit further, consider the following function:function power_by_squaring(x, n::Int)\n    ispow2(n) || error(\"This implementation only works for powers of 2\")\n    while n >= 2\n        x *= x\n        n >>= 1\n    end\n    x\nendAfter a call like x = 5; y = power_by_squaring(x, 4), you would get the expected result: x == 5 && y == 625.  However, now suppose that *=, when used with matrices, instead mutated the left hand side.  There would be two problems:For general square matrices, A = A*B cannot be implemented without temporary storage: A[1,1] gets computed and stored on the left hand side before you\'re done using it on the right hand side.\nSuppose you were willing to allocate a temporary for the computation (which would eliminate most of the point of making *= work in-place); if you took advantage of the mutability of x, then this function would behave differently for mutable vs. immutable inputs. In particular, for immutable x, after the call you\'d have (in general) y != x, but for mutable x you\'d have y == x.Because supporting generic programming is deemed more important than potential performance optimizations that can be achieved by other means (e.g., using explicit loops), operators like += and *= work by rebinding new values."
},

{
    "location": "manual/faq/#Asynchronous-IO-and-concurrent-synchronous-writes-1",
    "page": "Frequently Asked Questions",
    "title": "Asynchronous IO and concurrent synchronous writes",
    "category": "section",
    "text": ""
},

{
    "location": "manual/faq/#Why-do-concurrent-writes-to-the-same-stream-result-in-inter-mixed-output?-1",
    "page": "Frequently Asked Questions",
    "title": "Why do concurrent writes to the same stream result in inter-mixed output?",
    "category": "section",
    "text": "While the streaming I/O API is synchronous, the underlying implementation is fully asynchronous.Consider the printed output from the following:julia> @sync for i in 1:3\n           @async write(STDOUT, string(i), \" Foo \", \" Bar \")\n       end\n123 Foo  Foo  Foo  Bar  Bar  BarThis is happening because, while the write call is synchronous, the writing of each argument yields to other tasks while waiting for that part of the I/O to complete.print and println \"lock\" the stream during a call. Consequently changing write to println in the above example results in:julia> @sync for i in 1:3\n           @async println(STDOUT, string(i), \" Foo \", \" Bar \")\n       end\n1 Foo  Bar\n2 Foo  Bar\n3 Foo  BarYou can lock your writes with a ReentrantLock like this:julia> l = ReentrantLock()\nReentrantLock(Nullable{Task}(), Condition(Any[]), 0)\n\njulia> @sync for i in 1:3\n           @async begin\n               lock(l)\n               try\n                   write(STDOUT, string(i), \" Foo \", \" Bar \")\n               finally\n                   unlock(l)\n               end\n           end\n       end\n1 Foo  Bar 2 Foo  Bar 3 Foo  Bar"
},

{
    "location": "manual/faq/#Julia-Releases-1",
    "page": "Frequently Asked Questions",
    "title": "Julia Releases",
    "category": "section",
    "text": ""
},

{
    "location": "manual/faq/#Do-I-want-to-use-a-release,-beta,-or-nightly-version-of-Julia?-1",
    "page": "Frequently Asked Questions",
    "title": "Do I want to use a release, beta, or nightly version of Julia?",
    "category": "section",
    "text": "You may prefer the release version of Julia if you are looking for a stable code base. Releases generally occur every 6 months, giving you a stable platform for writing code.You may prefer the beta version of Julia if you don\'t mind being slightly behind the latest bugfixes and changes, but find the slightly faster rate of changes more appealing. Additionally, these binaries are tested before they are published to ensure they are fully functional.You may prefer the nightly version of Julia if you want to take advantage of the latest updates to the language, and don\'t mind if the version available today occasionally doesn\'t actually work.Finally, you may also consider building Julia from source for yourself. This option is mainly for those individuals who are comfortable at the command line, or interested in learning. If this describes you, you may also be interested in reading our guidelines for contributing.Links to each of these download types can be found on the download page at https://julialang.org/downloads/. Note that not all versions of Julia are available for all platforms."
},

{
    "location": "manual/faq/#When-are-deprecated-functions-removed?-1",
    "page": "Frequently Asked Questions",
    "title": "When are deprecated functions removed?",
    "category": "section",
    "text": "Deprecated functions are removed after the subsequent release. For example, functions marked as deprecated in the 0.1 release will not be available starting with the 0.2 release."
},

{
    "location": "manual/noteworthy-differences/#",
    "page": "Noteworthy Differences from other Languages",
    "title": "Noteworthy Differences from other Languages",
    "category": "page",
    "text": ""
},

{
    "location": "manual/noteworthy-differences/#Noteworthy-Differences-from-other-Languages-1",
    "page": "Noteworthy Differences from other Languages",
    "title": "Noteworthy Differences from other Languages",
    "category": "section",
    "text": ""
},

{
    "location": "manual/noteworthy-differences/#Noteworthy-differences-from-MATLAB-1",
    "page": "Noteworthy Differences from other Languages",
    "title": "Noteworthy differences from MATLAB",
    "category": "section",
    "text": "Although MATLAB users may find Julia\'s syntax familiar, Julia is not a MATLAB clone. There are major syntactic and functional differences. The following are some noteworthy differences that may trip up Julia users accustomed to MATLAB:Julia arrays are indexed with square brackets, A[i,j].\nJulia arrays are assigned by reference. After A=B, changing elements of B will modify A as well.\nJulia values are passed and assigned by reference. If a function modifies an array, the changes will be visible in the caller.\nJulia does not automatically grow arrays in an assignment statement. Whereas in MATLAB a(4) = 3.2 can create the array a = [0 0 0 3.2] and a(5) = 7 can grow it into a = [0 0 0 3.2 7], the corresponding Julia statement a[5] = 7 throws an error if the length of a is less than 5 or if this statement is the first use of the identifier a. Julia has push!() and append!(), which grow Vectors much more efficiently than MATLAB\'s a(end+1) = val.\nThe imaginary unit sqrt(-1) is represented in Julia as im, not i or j as in MATLAB.\nIn Julia, literal numbers without a decimal point (such as 42) create integers instead of floating point numbers. Arbitrarily large integer literals are supported. As a result, some operations such as 2^-1 will throw a domain error as the result is not an integer (see the FAQ entry on domain errors for details).\nIn Julia, multiple values are returned and assigned as tuples, e.g. (a, b) = (1, 2) or a, b = 1, 2. MATLAB\'s nargout, which is often used in MATLAB to do optional work based on the number of returned values, does not exist in Julia. Instead, users can use optional and keyword arguments to achieve similar capabilities.\nJulia has true one-dimensional arrays. Column vectors are of size N, not Nx1. For example, rand(N) makes a 1-dimensional array.\nIn Julia, [x,y,z] will always construct a 3-element array containing x, y and z.\nTo concatenate in the first (\"vertical\") dimension use either vcat(x,y,z) or separate with semicolons ([x; y; z]).\nTo concatenate in the second (\"horizontal\") dimension use either hcat(x,y,z) or separate with spaces ([x y z]).\nTo construct block matrices (concatenating in the first two dimensions), use either hvcat() or combine spaces and semicolons ([a b; c d]).\nIn Julia, a:b and a:b:c construct Range objects. To construct a full vector like in MATLAB, use collect(a:b). Generally, there is no need to call collect though. Range will act like a normal array in most cases but is more efficient because it lazily computes its values. This pattern of creating specialized objects instead of full arrays is used frequently, and is also seen in functions such as linspace, or with iterators such as enumerate, and zip. The special objects can mostly be used as if they were normal arrays.\nFunctions in Julia return values from their last expression or the return keyword instead of listing the names of variables to return in the function definition (see The return Keyword for details).\nA Julia script may contain any number of functions, and all definitions will be externally visible when the file is loaded. Function definitions can be loaded from files outside the current working directory.\nIn Julia, reductions such as sum(), prod(), and max() are performed over every element of an array when called with a single argument, as in sum(A), even if A has more than one dimension.\nIn Julia, functions such as sort() that operate column-wise by default (sort(A) is equivalent to sort(A,1)) do not have special behavior for 1xN arrays; the argument is returned unmodified since it still performs sort(A,1). To sort a 1xN matrix like a vector, use sort(A,2).\nIn Julia, if A is a 2-dimensional array, fft(A) computes a 2D FFT. In particular, it is not equivalent to fft(A,1), which computes a 1D FFT acting column-wise.\nIn Julia, parentheses must be used to call a function with zero arguments, like in tic() and toc().\nJulia discourages the used of semicolons to end statements. The results of statements are not automatically printed (except at the interactive prompt), and lines of code do not need to end with semicolons. println() or @printf() can be used to print specific output.\nIn Julia, if A and B are arrays, logical comparison operations like A == B do not return an array of booleans. Instead, use A .== B, and similarly for the other boolean operators like <, > and =.\nIn Julia, the operators &, |, and ⊻ (xor) perform the bitwise operations equivalent to and, or, and xor respectively in MATLAB, and have precedence similar to Python\'s bitwise operators (unlike C). They can operate on scalars or element-wise across arrays and can be used to combine logical arrays, but note the difference in order of operations: parentheses may be required (e.g., to select elements of A equal to 1 or 2 use (A .== 1) | (A .== 2)).\nIn Julia, the elements of a collection can be passed as arguments to a function using the splat operator ..., as in xs=[1,2]; f(xs...).\nJulia\'s svd() returns singular values as a vector instead of as a dense diagonal matrix.\nIn Julia, ... is not used to continue lines of code. Instead, incomplete expressions automatically continue onto the next line.\nIn both Julia and MATLAB, the variable ans is set to the value of the last expression issued in an interactive session. In Julia, unlike MATLAB, ans is not set when Julia code is run in non-interactive mode.\nJulia\'s types do not support dynamically adding fields at runtime, unlike MATLAB\'s classes. Instead, use a Dict.\nIn Julia each module has its own global scope/namespace, whereas in MATLAB there is just one global scope.\nIn MATLAB, an idiomatic way to remove unwanted values is to use logical indexing, like in the expression x(x>3) or in the statement x(x>3) = [] to modify x in-place. In contrast, Julia provides the higher order functions filter() and filter!(), allowing users to write filter(z->z>3, x) and filter!(z->z>3, x) as alternatives to the corresponding transliterations x[x.>3] and x = x[x.>3]. Using filter!() reduces the use of temporary arrays.\nThe analogue of extracting (or \"dereferencing\") all elements of a cell array, e.g. in vertcat(A{:}) in MATLAB, is written using the splat operator in Julia, e.g. as vcat(A...)."
},

{
    "location": "manual/noteworthy-differences/#Noteworthy-differences-from-R-1",
    "page": "Noteworthy Differences from other Languages",
    "title": "Noteworthy differences from R",
    "category": "section",
    "text": "One of Julia\'s goals is to provide an effective language for data analysis and statistical programming. For users coming to Julia from R, these are some noteworthy differences:Julia\'s single quotes enclose characters, not strings.\nJulia can create substrings by indexing into strings. In R, strings must be converted into character vectors before creating substrings.\nIn Julia, like Python but unlike R, strings can be created with triple quotes \"\"\" ... \"\"\". This syntax is convenient for constructing strings that contain line breaks.\nIn Julia, varargs are specified using the splat operator ..., which always follows the name of a specific variable, unlike R, for which ... can occur in isolation.\nIn Julia, modulus is mod(a, b), not a %% b. % in Julia is the remainder operator.\nIn Julia, not all data structures support logical indexing. Furthermore, logical indexing in Julia is supported only with vectors of length equal to the object being indexed. For example:\nIn R, c(1, 2, 3, 4)[c(TRUE, FALSE)] is equivalent to c(1, 3).\nIn R, c(1, 2, 3, 4)[c(TRUE, FALSE, TRUE, FALSE)] is equivalent to c(1, 3).\nIn Julia, [1, 2, 3, 4][[true, false]] throws a BoundsError.\nIn Julia, [1, 2, 3, 4][[true, false, true, false]] produces [1, 3].\nLike many languages, Julia does not always allow operations on vectors of different lengths, unlike R where the vectors only need to share a common index range.  For example, c(1, 2, 3, 4) + c(1, 2) is valid R but the equivalent [1, 2, 3, 4] + [1, 2] will throw an error in Julia.\nJulia\'s map() takes the function first, then its arguments, unlike lapply(<structure>, function, ...) in R. Similarly Julia\'s equivalent of apply(X, MARGIN, FUN, ...) in R is mapslices() where the function is the first argument.\nMultivariate apply in R, e.g. mapply(choose, 11:13, 1:3), can be written as broadcast(binomial, 11:13, 1:3) in Julia. Equivalently Julia offers a shorter dot syntax for vectorizing functions binomial.(11:13, 1:3).\nJulia uses end to denote the end of conditional blocks, like if, loop blocks, like while/ for, and functions. In lieu of the one-line if ( cond ) statement, Julia allows statements of the form if cond; statement; end, cond && statement and !cond || statement. Assignment statements in the latter two syntaxes must be explicitly wrapped in parentheses, e.g. cond && (x = value).\nIn Julia, <-, <<- and -> are not assignment operators.\nJulia\'s -> creates an anonymous function, like Python.\nJulia constructs vectors using brackets. Julia\'s [1, 2, 3] is the equivalent of R\'s c(1, 2, 3).\nJulia\'s * operator can perform matrix multiplication, unlike in R. If A and B are matrices, then A * B denotes a matrix multiplication in Julia, equivalent to R\'s A %*% B. In R, this same notation would perform an element-wise (Hadamard) product. To get the element-wise multiplication operation, you need to write A .* B in Julia.\nJulia performs matrix transposition using the .\' operator and conjugated transposition using the \' operator. Julia\'s A.\' is therefore equivalent to R\'s t(A).\nJulia does not require parentheses when writing if statements or for/while loops: use for i in [1, 2, 3] instead of for (i in c(1, 2, 3)) and if i == 1 instead of if (i == 1).\nJulia does not treat the numbers 0 and 1 as Booleans. You cannot write if (1) in Julia, because if statements accept only booleans. Instead, you can write if true, if Bool(1), or if 1==1.\nJulia does not provide nrow and ncol. Instead, use size(M, 1) for nrow(M) and size(M, 2) for ncol(M).\nJulia is careful to distinguish scalars, vectors and matrices.  In R, 1 and c(1) are the same. In Julia, they cannot be used interchangeably.\nJulia\'s diag and diagm are not like R\'s.\nJulia cannot assign to the results of function calls on the left hand side of an assignment operation: you cannot write diag(M) = ones(n).\nJulia discourages populating the main namespace with functions. Most statistical functionality for Julia is found in packages under the JuliaStats organization. For example:\nFunctions pertaining to probability distributions are provided by the Distributions package.\nThe DataFrames package provides data frames.\nGeneralized linear models are provided by the GLM package.\nJulia provides tuples and real hash tables, but not R-style lists. When returning multiple items, you should typically use a tuple: instead of list(a = 1, b = 2), use (1, 2).\nJulia encourages users to write their own types, which are easier to use than S3 or S4 objects in R. Julia\'s multiple dispatch system means that table(x::TypeA) and table(x::TypeB) act like R\'s table.TypeA(x) and table.TypeB(x).\nIn Julia, values are passed and assigned by reference. If a function modifies an array, the changes will be visible in the caller. This is very different from R and allows new functions to operate on large data structures much more efficiently.\nIn Julia, vectors and matrices are concatenated using hcat(), vcat() and hvcat(), not c, rbind and cbind like in R.\nIn Julia, a range like a:b is not shorthand for a vector like in R, but is a specialized Range that is used for iteration without high memory overhead. To convert a range into a vector, use collect(a:b).\nJulia\'s max() and min() are the equivalent of pmax and pmin respectively in R, but both arguments need to have the same dimensions.  While maximum() and minimum() replace max and min in R, there are important differences.\nJulia\'s sum(), prod(), maximum(), and minimum() are different from their counterparts in R. They all accept one or two arguments. The first argument is an iterable collection such as an array.  If there is a second argument, then this argument indicates the dimensions, over which the operation is carried out.  For instance, let A=[[1 2],[3 4]] in Julia and B=rbind(c(1,2),c(3,4)) be the same matrix in R.  Then sum(A) gives the same result as sum(B), but sum(A, 1) is a row vector containing the sum over each column and sum(A, 2) is a column vector containing the sum over each row.  This contrasts to the behavior of R, where sum(B,1)=11 and sum(B,2)=12.  If the second argument is a vector, then it specifies all the dimensions over which the sum is performed, e.g., sum(A,[1,2])=10.  It should be noted that there is no error checking regarding the second argument.\nJulia has several functions that can mutate their arguments. For example, it has both sort() and sort!().\nIn R, performance requires vectorization. In Julia, almost the opposite is true: the best performing code is often achieved by using devectorized loops.\nJulia is eagerly evaluated and does not support R-style lazy evaluation. For most users, this means that there are very few unquoted expressions or column names.\nJulia does not support the NULL type.\nJulia lacks the equivalent of R\'s assign or get.\nIn Julia, return does not require parentheses.\nIn R, an idiomatic way to remove unwanted values is to use logical indexing, like in the expression x[x>3] or in the statement x = x[x>3] to modify x in-place. In contrast, Julia provides the higher order functions filter() and filter!(), allowing users to write filter(z->z>3, x) and filter!(z->z>3, x) as alternatives to the corresponding transliterations x[x.>3] and x = x[x.>3]. Using filter!() reduces the use of temporary arrays."
},

{
    "location": "manual/noteworthy-differences/#Noteworthy-differences-from-Python-1",
    "page": "Noteworthy Differences from other Languages",
    "title": "Noteworthy differences from Python",
    "category": "section",
    "text": "Julia requires end to end a block. Unlike Python, Julia has no pass keyword.\nIn Julia, indexing of arrays, strings, etc. is 1-based not 0-based.\nJulia\'s slice indexing includes the last element, unlike in Python. a[2:3] in Julia is a[1:3] in Python.\nJulia does not support negative indexes. In particular, the last element of a list or array is indexed with end in Julia, not -1 as in Python.\nJulia\'s for, if, while, etc. blocks are terminated by the end keyword. Indentation level is not significant as it is in Python.\nJulia has no line continuation syntax: if, at the end of a line, the input so far is a complete expression, it is considered done; otherwise the input continues. One way to force an expression to continue is to wrap it in parentheses.\nJulia arrays are column major (Fortran ordered) whereas NumPy arrays are row major (C-ordered) by default. To get optimal performance when looping over arrays, the order of the loops should be reversed in Julia relative to NumPy (see relevant section of Performance Tips).\nJulia\'s updating operators (e.g. +=, -=, ...) are not in-place whereas NumPy\'s are. This means A = ones(4); B = A; B += 3 doesn\'t change values in A, it rather rebinds the name B to the result of the right- hand side B = B + 3, which is a new array. Use B[:] += 3, explicit loops, or InplaceOps.jl.\nJulia evaluates default values of function arguments every time the method is invoked, unlike in Python where the default values are evaluated only once when the function is defined. For example, the function f(x=rand()) = x returns a new random number every time it is invoked without argument. On the other hand, the function g(x=[1,2]) = push!(x,3) returns [1,2,3] every time it is called as g().\nIn Julia % is the remainder operator, whereas in Python it is the modulus."
},

{
    "location": "manual/noteworthy-differences/#Noteworthy-differences-from-C/C-1",
    "page": "Noteworthy Differences from other Languages",
    "title": "Noteworthy differences from C/C++",
    "category": "section",
    "text": "Julia arrays are indexed with square brackets, and can have more than one dimension A[i,j]. This syntax is not just syntactic sugar for a reference to a pointer or address as in C/C++. See the Julia documentation for the syntax for array construction (it has changed between versions).\nIn Julia, indexing of arrays, strings, etc. is 1-based not 0-based.\nJulia arrays are assigned by reference. After A=B, changing elements of B will modify A as well. Updating operators like += do not operate in-place, they are equivalent to A = A + B which rebinds the left-hand side to the result of the right-hand side expression.\nJulia arrays are column major (Fortran ordered) whereas C/C++ arrays are row major ordered by default. To get optimal performance when looping over arrays, the order of the loops should be reversed in Julia relative to C/C++ (see relevant section of Performance Tips).\nJulia values are passed and assigned by reference. If a function modifies an array, the changes will be visible in the caller.\nIn Julia, whitespace is significant, unlike C/C++, so care must be taken when adding/removing whitespace from a Julia program.\nIn Julia, literal numbers without a decimal point (such as 42) create signed integers, of type Int, but literals too large to fit in the machine word size will automatically be promoted to a larger size type, such as Int64 (if Int is Int32), Int128, or the arbitrarily large BigInt type. There are no numeric literal suffixes, such as L, LL, U, UL, ULL to indicate unsigned and/or signed vs. unsigned. Decimal literals are always signed, and hexadecimal literals (which start with 0x like C/C++), are unsigned. Hexadecimal literals also, unlike C/C++/Java and unlike decimal literals in Julia, have a type based on the length of the literal, including leading 0s. For example, 0x0 and 0x00 have type UInt8, 0x000 and 0x0000 have type UInt16, then literals with 5 to 8 hex digits have type UInt32, 9 to 16 hex digits type UInt64 and 17 to 32 hex digits type UInt128. This needs to be taken into account when defining hexadecimal masks, for example ~0xf == 0xf0 is very different from ~0x000f == 0xfff0. 64 bit Float64 and 32 bit Float32 bit literals are expressed as 1.0 and 1.0f0 respectively. Floating point literals are rounded (and not promoted to the BigFloat type) if they can not be exactly represented.  Floating point literals are closer in behavior to C/C++. Octal (prefixed with 0o) and binary (prefixed with 0b) literals are also treated as unsigned.\nString literals can be delimited with either \"  or \"\"\", \"\"\" delimited literals can contain \" characters without quoting it like \"\\\"\" String literals can have values of other variables or expressions interpolated into them, indicated by $variablename or $(expression), which evaluates the variable name or the expression in the context of the function.\n// indicates a Rational number, and not a single-line comment (which is # in Julia)\n#= indicates the start of a multiline comment, and =# ends it.\nFunctions in Julia return values from their last expression(s) or the return keyword.  Multiple values can be returned from functions and assigned as tuples, e.g. (a, b) = myfunction() or a, b = myfunction(), instead of having to pass pointers to values as one would have to do in C/C++ (i.e. a = myfunction(&b).\nJulia does not require the use of semicolons to end statements. The results of expressions are not automatically printed (except at the interactive prompt, i.e. the REPL), and lines of code do not need to end with semicolons. println() or @printf() can be used to print specific output. In the REPL, ; can be used to suppress output. ; also has a different meaning within [ ], something to watch out for. ; can be used to separate expressions on a single line, but are not strictly necessary in many cases, and are more an aid to readability.\nIn Julia, the operator ⊻ (xor) performs the bitwise XOR operation, i.e. ^ in C/C++.  Also, the bitwise operators do not have the same precedence as C/++, so parenthesis may be required.\nJulia\'s ^ is exponentiation (pow), not bitwise XOR as in C/C++ (use ⊻, or xor, in Julia)\nJulia has two right-shift operators, >> and >>>.  >>> performs an arithmetic shift, >> always performs a logical shift, unlike C/C++, where the meaning of >> depends on the type of the value being shifted.\nJulia\'s -> creates an anonymous function, it does not access a member via a pointer.\nJulia does not require parentheses when writing if statements or for/while loops: use for i in [1, 2, 3] instead of for (int i=1; i <= 3; i++) and if i == 1 instead of if (i == 1).\nJulia does not treat the numbers 0 and 1 as Booleans. You cannot write if (1) in Julia, because if statements accept only booleans. Instead, you can write if true, if Bool(1), or if 1==1.\nJulia uses end to denote the end of conditional blocks, like if, loop blocks, like while/ for, and functions. In lieu of the one-line if ( cond ) statement, Julia allows statements of the form if cond; statement; end, cond && statement and !cond || statement. Assignment statements in the latter two syntaxes must be explicitly wrapped in parentheses, e.g. cond && (x = value), because of the operator precedence.\nJulia has no line continuation syntax: if, at the end of a line, the input so far is a complete expression, it is considered done; otherwise the input continues. One way to force an expression to continue is to wrap it in parentheses.\nJulia macros operate on parsed expressions, rather than the text of the program, which allows them to perform sophisticated transformations of Julia code. Macro names start with the @ character, and have both a function-like syntax, @mymacro(arg1, arg2, arg3), and a statement-like syntax, @mymacro arg1 arg2 arg3. The forms are interchangable; the function-like form is particularly useful if the macro appears within another expression, and is often clearest. The statement-like form is often used to annotate blocks, as in the parallel for construct: @parallel for i in 1:n; #= body =#; end. Where the end of the macro construct may be unclear, use the function-like form.\nJulia now has an enumeration type, expressed using the macro @enum(name, value1, value2, ...) For example: @enum(Fruit, banana=1, apple, pear)\nBy convention, functions that modify their arguments have a ! at the end of the name, for example push!.\nIn C++, by default, you have static dispatch, i.e. you need to annotate a function as virtual, in order to have dynamic dispatch. On the other hand, in Julia every method is \"virtual\" (although it\'s more general than that since methods are dispatched on every argument type, not only this, using the most-specific-declaration rule)."
},

{
    "location": "manual/unicode-input/#",
    "page": "Unicode Input",
    "title": "Unicode Input",
    "category": "page",
    "text": ""
},

{
    "location": "manual/unicode-input/#Unicode-Input-1",
    "page": "Unicode Input",
    "title": "Unicode Input",
    "category": "section",
    "text": "The following table lists Unicode characters that can be entered via tab completion of LaTeX-like abbreviations in the Julia REPL (and in various other editing environments).  You can also get information on how to type a symbol by entering it in the REPL help, i.e. by typing ? and then entering the symbol in the REPL (e.g., by copy-paste from somewhere you saw the symbol).warning: Warning\nThis table may appear to contain missing characters in the second column, or even show characters that are inconsistent with the characters as they are rendered in the Julia REPL. In these cases, users are strongly advised to check their choice of fonts in their browser and REPL environment, as there are known issues with glyphs in many fonts.#\n# Generate a table containing all LaTeX and Emoji tab completions available in the REPL.\n#\n\nfunction tab_completions(symbols...)\n    completions = Dict{String, Vector{String}}()\n    for each in symbols, (k, v) in each\n        completions[v] = push!(get!(completions, v, String[]), k)\n    end\n    return completions\nend\n\nfunction unicode_data()\n    file = normpath(JULIA_HOME, \"..\", \"..\", \"doc\", \"UnicodeData.txt\")\n    names = Dict{UInt32, String}()\n    open(file) do unidata\n        for line in readlines(unidata)\n            id, name, desc = split(line, \";\")[[1, 2, 11]]\n            codepoint = parse(UInt32, \"0x$id\")\n            names[codepoint] = titlecase(lowercase(name == \"\" ? desc : desc == \"\" ? name : \"$name / $desc\"))\n        end\n    end\n    return names\nend\n\n# Prepend a dotted circle (\'◌\' i.e. \'\\u25CC\') to combining characters\nfunction fix_combining_chars(char)\n    cat = Base.UTF8proc.category_code(char)\n    return string(cat == 6 || cat == 8 ? \"◌\" : \"\", char)\nend\n\n\nfunction table_entries(completions, unicode_dict)\n    entries = [[\n        \"Code point(s)\", \"Character(s)\",\n        \"Tab completion sequence(s)\", \"Unicode name(s)\"\n    ]]\n    for (chars, inputs) in sort!(collect(completions), by = first)\n        code_points, unicode_names, characters = String[], String[], String[]\n        for char in chars\n            push!(code_points, \"U+$(uppercase(hex(char, 5)))\")\n            push!(unicode_names, get(unicode_dict, UInt32(char), \"(No Unicode name)\"))\n            push!(characters, isempty(characters) ? fix_combining_chars(char) : \"$char\")\n        end\n        push!(entries, [\n            join(code_points, \" + \"), join(characters),\n            join(inputs, \", \"), join(unicode_names, \" + \")\n        ])\n    end\n    return Markdown.Table(entries, [:l, :l, :l, :l])\nend\n\ntable_entries(\n    tab_completions(\n        Base.REPLCompletions.latex_symbols,\n        Base.REPLCompletions.emoji_symbols\n    ),\n    unicode_data()\n)"
},

{
    "location": "stdlib/base/#",
    "page": "Essentials",
    "title": "Essentials",
    "category": "page",
    "text": ""
},

{
    "location": "stdlib/base/#Essentials-1",
    "page": "Essentials",
    "title": "Essentials",
    "category": "section",
    "text": ""
},

{
    "location": "stdlib/base/#Introduction-1",
    "page": "Essentials",
    "title": "Introduction",
    "category": "section",
    "text": "The Julia standard library contains a range of functions and macros appropriate for performing scientific and numerical computing, but is also as broad as those of many general purpose programming languages.  Additional functionality is available from a growing collection of available packages. Functions are grouped by topic below.Some general notes:Except for functions in built-in modules (Pkg, Collections, Test and Profile), all functions documented here are directly available for use in programs.\nTo use module functions, use import Module to import the module, and Module.fn(x) to use the functions.\nAlternatively, using Module will import all exported Module functions into the current namespace.\nBy convention, function names ending with an exclamation point (!) modify their arguments. Some functions have both modifying (e.g., sort!) and non-modifying (sort) versions."
},

{
    "location": "stdlib/base/#Base.exit",
    "page": "Essentials",
    "title": "Base.exit",
    "category": "function",
    "text": "exit([code])\n\nQuit (or control-D at the prompt). The default exit code is zero, indicating that the processes completed successfully.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.quit",
    "page": "Essentials",
    "title": "Base.quit",
    "category": "function",
    "text": "quit()\n\nQuit the program indicating that the processes completed successfully. This function calls exit(0) (see exit).\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.atexit",
    "page": "Essentials",
    "title": "Base.atexit",
    "category": "function",
    "text": "atexit(f)\n\nRegister a zero-argument function f() to be called at process exit. atexit() hooks are called in last in first out (LIFO) order and run before object finalizers.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.atreplinit",
    "page": "Essentials",
    "title": "Base.atreplinit",
    "category": "function",
    "text": "atreplinit(f)\n\nRegister a one-argument function to be called before the REPL interface is initialized in interactive sessions; this is useful to customize the interface. The argument of f is the REPL object. This function should be called from within the .juliarc.jl initialization file.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.isinteractive",
    "page": "Essentials",
    "title": "Base.isinteractive",
    "category": "function",
    "text": "isinteractive() -> Bool\n\nDetermine whether Julia is running an interactive session.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.whos",
    "page": "Essentials",
    "title": "Base.whos",
    "category": "function",
    "text": "whos(io::IO=STDOUT, m::Module=current_module(), pattern::Regex=r\"\")\n\nPrint information about exported global variables in a module, optionally restricted to those matching pattern.\n\nThe memory consumption estimate is an approximate lower bound on the size of the internal structure of the object.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.summarysize",
    "page": "Essentials",
    "title": "Base.summarysize",
    "category": "function",
    "text": "Base.summarysize(obj; exclude=Union{...}, chargeall=Union{...}) -> Int\n\nCompute the amount of memory used by all unique objects reachable from the argument.\n\nKeyword Arguments\n\nexclude: specifies the types of objects to exclude from the traversal.\nchargeall: specifies the types of objects to always charge the size of all of their fields, even if those fields would normally be excluded.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.edit-Tuple{AbstractString,Integer}",
    "page": "Essentials",
    "title": "Base.edit",
    "category": "method",
    "text": "edit(path::AbstractString, line::Integer=0)\n\nEdit a file or directory optionally providing a line number to edit the file at. Returns to the julia prompt when you quit the editor. The editor can be changed by setting JULIA_EDITOR, VISUAL or EDITOR as an environment variable.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.edit-Tuple{Any}",
    "page": "Essentials",
    "title": "Base.edit",
    "category": "method",
    "text": "edit(function, [types])\n\nEdit the definition of a function, optionally specifying a tuple of types to indicate which method to edit. The editor can be changed by setting JULIA_EDITOR, VISUAL or EDITOR as an environment variable.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.@edit",
    "page": "Essentials",
    "title": "Base.@edit",
    "category": "macro",
    "text": "@edit\n\nEvaluates the arguments to the function or macro call, determines their types, and calls the edit function on the resulting expression.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.less-Tuple{AbstractString}",
    "page": "Essentials",
    "title": "Base.less",
    "category": "method",
    "text": "less(file::AbstractString, [line::Integer])\n\nShow a file using the default pager, optionally providing a starting line number. Returns to the julia prompt when you quit the pager.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.less-Tuple{Any}",
    "page": "Essentials",
    "title": "Base.less",
    "category": "method",
    "text": "less(function, [types])\n\nShow the definition of a function using the default pager, optionally specifying a tuple of types to indicate which method to see.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.@less",
    "page": "Essentials",
    "title": "Base.@less",
    "category": "macro",
    "text": "@less\n\nEvaluates the arguments to the function or macro call, determines their types, and calls the less function on the resulting expression.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.clipboard-Tuple{Any}",
    "page": "Essentials",
    "title": "Base.clipboard",
    "category": "method",
    "text": "clipboard(x)\n\nSend a printed form of x to the operating system clipboard (\"copy\").\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.clipboard-Tuple{}",
    "page": "Essentials",
    "title": "Base.clipboard",
    "category": "method",
    "text": "clipboard() -> AbstractString\n\nReturn a string with the contents of the operating system clipboard (\"paste\").\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.reload",
    "page": "Essentials",
    "title": "Base.reload",
    "category": "function",
    "text": "reload(name::AbstractString)\n\nForce reloading of a package, even if it has been loaded before. This is intended for use during package development as code is modified.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.require",
    "page": "Essentials",
    "title": "Base.require",
    "category": "function",
    "text": "require(module::Symbol)\n\nThis function is part of the implementation of using / import, if a module is not already defined in Main. It can also be called directly to force reloading a module, regardless of whether it has been loaded before (for example, when interactively developing libraries).\n\nLoads a source file, in the context of the Main module, on every active node, searching standard locations for files. require is considered a top-level operation, so it sets the current include path but does not use it to search for files (see help for include). This function is typically used to load library code, and is implicitly called by using to load packages.\n\nWhen searching for files, require first looks for package code under Pkg.dir(), then tries paths in the global array LOAD_PATH. require is case-sensitive on all platforms, including those with case-insensitive filesystems like macOS and Windows.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.compilecache",
    "page": "Essentials",
    "title": "Base.compilecache",
    "category": "function",
    "text": "Base.compilecache(module::String)\n\nCreates a precompiled cache file for a module and all of its dependencies. This can be used to reduce package load times. Cache files are stored in LOAD_CACHE_PATH[1], which defaults to ~/.julia/lib/VERSION. See Module initialization and precompilation for important notes.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.__precompile__",
    "page": "Essentials",
    "title": "Base.__precompile__",
    "category": "function",
    "text": "__precompile__(isprecompilable::Bool=true)\n\nSpecify whether the file calling this function is precompilable. If isprecompilable is true, then __precompile__ throws an exception when the file is loaded by using/import/require unless the file is being precompiled, and in a module file it causes the module to be automatically precompiled when it is imported. Typically, __precompile__() should occur before the module declaration in the file, or better yet VERSION >= v\"0.4\" && __precompile__() in order to be backward-compatible with Julia 0.3.\n\nIf a module or file is not safely precompilable, it should call __precompile__(false) in order to throw an error if Julia attempts to precompile it.\n\n__precompile__() should not be used in a module unless all of its dependencies are also using __precompile__(). Failure to do so can result in a runtime error when loading the module.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.include",
    "page": "Essentials",
    "title": "Base.include",
    "category": "function",
    "text": "include(path::AbstractString)\n\nEvaluate the contents of the input source file in the current context. Returns the result of the last evaluated expression of the input file. During including, a task-local include path is set to the directory containing the file. Nested calls to include will search relative to that path. All paths refer to files on node 1 when running in parallel, and files will be fetched from node 1. This function is typically used to load source interactively, or to combine files in packages that are broken into multiple source files.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.include_string",
    "page": "Essentials",
    "title": "Base.include_string",
    "category": "function",
    "text": "include_string(code::AbstractString, filename::AbstractString=\"string\")\n\nLike include, except reads code from the given string rather than from a file. Since there is no file path involved, no path processing or fetching from node 1 is done.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.include_dependency",
    "page": "Essentials",
    "title": "Base.include_dependency",
    "category": "function",
    "text": "include_dependency(path::AbstractString)\n\nIn a module, declare that the file specified by path (relative or absolute) is a dependency for precompilation; that is, the module will need to be recompiled if this file changes.\n\nThis is only needed if your module depends on a file that is not used via include. It has no effect outside of compilation.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.Docs.apropos",
    "page": "Essentials",
    "title": "Base.Docs.apropos",
    "category": "function",
    "text": "apropos(string)\n\nSearch through all documentation for a string, ignoring case.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.which-Tuple{Any,Any}",
    "page": "Essentials",
    "title": "Base.which",
    "category": "method",
    "text": "which(f, types)\n\nReturns the method of f (a Method object) that would be called for arguments of the given types.\n\nIf types is an abstract type, then the method that would be called by invoke is returned.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.which-Tuple{Symbol}",
    "page": "Essentials",
    "title": "Base.which",
    "category": "method",
    "text": "which(symbol)\n\nReturn the module in which the binding for the variable referenced by symbol was created.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.@which",
    "page": "Essentials",
    "title": "Base.@which",
    "category": "macro",
    "text": "@which\n\nApplied to a function or macro call, it evaluates the arguments to the specified call, and returns the Method object for the method that would be called for those arguments. Applied to a variable, it returns the module in which the variable was bound. It calls out to the which function.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.methods",
    "page": "Essentials",
    "title": "Base.methods",
    "category": "function",
    "text": "methods(f, [types])\n\nReturns the method table for f.\n\nIf types is specified, returns an array of methods whose types match.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.methodswith",
    "page": "Essentials",
    "title": "Base.methodswith",
    "category": "function",
    "text": "methodswith(typ[, module or function][, showparents::Bool=false])\n\nReturn an array of methods with an argument of type typ.\n\nThe optional second argument restricts the search to a particular module or function (the default is all modules, starting from Main).\n\nIf optional showparents is true, also return arguments with a parent type of typ, excluding type Any.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.@show",
    "page": "Essentials",
    "title": "Base.@show",
    "category": "macro",
    "text": "@show\n\nShow an expression and result, returning the result.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.versioninfo",
    "page": "Essentials",
    "title": "Base.versioninfo",
    "category": "function",
    "text": "versioninfo(io::IO=STDOUT, verbose::Bool=false)\n\nPrint information about the version of Julia in use. If the verbose argument is true, detailed system information is shown as well.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.workspace",
    "page": "Essentials",
    "title": "Base.workspace",
    "category": "function",
    "text": "workspace()\n\nReplace the top-level module (Main) with a new one, providing a clean workspace. The previous Main module is made available as LastMain. A previously-loaded package can be accessed using a statement such as using LastMain.Package.\n\nThis function should only be used interactively.\n\n\n\n"
},

{
    "location": "stdlib/base/#ans",
    "page": "Essentials",
    "title": "ans",
    "category": "keyword",
    "text": "ans\n\nA variable referring to the last computed value, automatically set at the interactive prompt.\n\n\n\n"
},

{
    "location": "stdlib/base/#Getting-Around-1",
    "page": "Essentials",
    "title": "Getting Around",
    "category": "section",
    "text": "Base.exit\nBase.quit\nBase.atexit\nBase.atreplinit\nBase.isinteractive\nBase.whos\nBase.summarysize\nBase.edit(::AbstractString, ::Integer)\nBase.edit(::Any)\nBase.@edit\nBase.less(::AbstractString)\nBase.less(::Any)\nBase.@less\nBase.clipboard(::Any)\nBase.clipboard()\nBase.reload\nBase.require\nBase.compilecache\nBase.__precompile__\nBase.include\nBase.include_string\nBase.include_dependency\nBase.Docs.apropos\nBase.which(::Any, ::Any)\nBase.which(::Symbol)\nBase.@which\nBase.methods\nBase.methodswith\nBase.@show\nBase.versioninfo\nBase.workspace\nans"
},

{
    "location": "stdlib/base/#Core.:===",
    "page": "Essentials",
    "title": "Core.:===",
    "category": "function",
    "text": "===(x,y) -> Bool\n≡(x,y) -> Bool\n\nDetermine whether x and y are identical, in the sense that no program could distinguish them. Compares mutable objects by address in memory, and compares immutable objects (such as numbers) by contents at the bit level. This function is sometimes called egal.\n\njulia> a = [1, 2]; b = [1, 2];\n\njulia> a == b\ntrue\n\njulia> a === b\nfalse\n\njulia> a === a\ntrue\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.isa",
    "page": "Essentials",
    "title": "Core.isa",
    "category": "function",
    "text": "isa(x, type) -> Bool\n\nDetermine whether x is of the given type. Can also be used as an infix operator, e.g. x isa type.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.isequal-Tuple{Any,Any}",
    "page": "Essentials",
    "title": "Base.isequal",
    "category": "method",
    "text": "isequal(x, y)\n\nSimilar to ==, except treats all floating-point NaN values as equal to each other, and treats -0.0 as unequal to 0.0. The default implementation of isequal calls ==, so if you have a type that doesn\'t have these floating-point subtleties then you probably only need to define ==.\n\nisequal is the comparison function used by hash tables (Dict). isequal(x,y) must imply that hash(x) == hash(y).\n\nThis typically means that if you define your own == function then you must define a corresponding hash (and vice versa). Collections typically implement isequal by calling isequal recursively on all contents.\n\nScalar types generally do not need to implement isequal separate from ==, unless they represent floating-point numbers amenable to a more efficient implementation than that provided as a generic fallback (based on isnan, signbit, and ==).\n\njulia> isequal([1., NaN], [1., NaN])\ntrue\n\njulia> [1., NaN] == [1., NaN]\nfalse\n\njulia> 0.0 == -0.0\ntrue\n\njulia> isequal(0.0, -0.0)\nfalse\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.isequal-Tuple{Nullable,Nullable}",
    "page": "Essentials",
    "title": "Base.isequal",
    "category": "method",
    "text": "isequal(x, y)\n\nSimilar to ==, except treats all floating-point NaN values as equal to each other, and treats -0.0 as unequal to 0.0. The default implementation of isequal calls ==, so if you have a type that doesn\'t have these floating-point subtleties then you probably only need to define ==.\n\nisequal is the comparison function used by hash tables (Dict). isequal(x,y) must imply that hash(x) == hash(y).\n\nThis typically means that if you define your own == function then you must define a corresponding hash (and vice versa). Collections typically implement isequal by calling isequal recursively on all contents.\n\nScalar types generally do not need to implement isequal separate from ==, unless they represent floating-point numbers amenable to a more efficient implementation than that provided as a generic fallback (based on isnan, signbit, and ==).\n\njulia> isequal([1., NaN], [1., NaN])\ntrue\n\njulia> [1., NaN] == [1., NaN]\nfalse\n\njulia> 0.0 == -0.0\ntrue\n\njulia> isequal(0.0, -0.0)\nfalse\n\n\n\nisequal(x::Nullable, y::Nullable)\n\nIf neither x nor y is null, compare them according to their values (i.e. isequal(get(x), get(y))). Else, return true if both arguments are null, and false if one is null but not the other: nulls are considered equal.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.isless",
    "page": "Essentials",
    "title": "Base.isless",
    "category": "function",
    "text": "isless(x, y)\n\nTest whether x is less than y, according to a canonical total order. Values that are normally unordered, such as NaN, are ordered in an arbitrary but consistent fashion. This is the default comparison used by sort. Non-numeric types with a canonical total order should implement this function. Numeric types only need to implement it if they have special values such as NaN.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.isless-Tuple{Nullable,Nullable}",
    "page": "Essentials",
    "title": "Base.isless",
    "category": "method",
    "text": "isless(x::Nullable, y::Nullable)\n\nIf neither x nor y is null, compare them according to their values (i.e. isless(get(x), get(y))). Else, return true if only y is null, and false otherwise: nulls are always considered greater than non-nulls, but not greater than another null.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.ifelse",
    "page": "Essentials",
    "title": "Base.ifelse",
    "category": "function",
    "text": "ifelse(condition::Bool, x, y)\n\nReturn x if condition is true, otherwise return y. This differs from ? or if in that it is an ordinary function, so all the arguments are evaluated first. In some cases, using ifelse instead of an if statement can eliminate the branch in generated code and provide higher performance in tight loops.\n\njulia> ifelse(1 > 2, 1, 2)\n2\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.lexcmp",
    "page": "Essentials",
    "title": "Base.lexcmp",
    "category": "function",
    "text": "lexcmp(x, y)\n\nCompare x and y lexicographically and return -1, 0, or 1 depending on whether x is less than, equal to, or greater than y, respectively. This function should be defined for lexicographically comparable types, and lexless will call lexcmp by default.\n\njulia> lexcmp(\"abc\", \"abd\")\n-1\n\njulia> lexcmp(\"abc\", \"abc\")\n0\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.lexless",
    "page": "Essentials",
    "title": "Base.lexless",
    "category": "function",
    "text": "lexless(x, y)\n\nDetermine whether x is lexicographically less than y.\n\njulia> lexless(\"abc\", \"abd\")\ntrue\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.typeof",
    "page": "Essentials",
    "title": "Core.typeof",
    "category": "function",
    "text": "typeof(x)\n\nGet the concrete type of x.\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.tuple",
    "page": "Essentials",
    "title": "Core.tuple",
    "category": "function",
    "text": "tuple(xs...)\n\nConstruct a tuple of the given objects.\n\nExample\n\njulia> tuple(1, \'a\', pi)\n(1, \'a\', π = 3.1415926535897...)\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.ntuple",
    "page": "Essentials",
    "title": "Base.ntuple",
    "category": "function",
    "text": "ntuple(f::Function, n::Integer)\n\nCreate a tuple of length n, computing each element as f(i), where i is the index of the element.\n\njulia> ntuple(i -> 2*i, 4)\n(2, 4, 6, 8)\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.object_id",
    "page": "Essentials",
    "title": "Base.object_id",
    "category": "function",
    "text": "object_id(x)\n\nGet a hash value for x based on object identity. object_id(x)==object_id(y) if x === y.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.hash",
    "page": "Essentials",
    "title": "Base.hash",
    "category": "function",
    "text": "hash(x[, h::UInt])\n\nCompute an integer hash code such that isequal(x,y) implies hash(x)==hash(y). The optional second argument h is a hash code to be mixed with the result.\n\nNew types should implement the 2-argument form, typically by calling the 2-argument hash method recursively in order to mix hashes of the contents with each other (and with h). Typically, any type that implements hash should also implement its own == (hence isequal) to guarantee the property mentioned above.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.finalizer",
    "page": "Essentials",
    "title": "Base.finalizer",
    "category": "function",
    "text": "finalizer(x, f)\n\nRegister a function f(x) to be called when there are no program-accessible references to x. The type of x must be a mutable struct, otherwise the behavior of this function is unpredictable.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.finalize",
    "page": "Essentials",
    "title": "Base.finalize",
    "category": "function",
    "text": "finalize(x)\n\nImmediately run finalizers registered for object x.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.copy",
    "page": "Essentials",
    "title": "Base.copy",
    "category": "function",
    "text": "copy(x)\n\nCreate a shallow copy of x: the outer structure is copied, but not all internal values. For example, copying an array produces a new array with identically-same elements as the original.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.deepcopy",
    "page": "Essentials",
    "title": "Base.deepcopy",
    "category": "function",
    "text": "deepcopy(x)\n\nCreate a deep copy of x: everything is copied recursively, resulting in a fully independent object. For example, deep-copying an array produces a new array whose elements are deep copies of the original elements. Calling deepcopy on an object should generally have the same effect as serializing and then deserializing it.\n\nAs a special case, functions can only be actually deep-copied if they are anonymous, otherwise they are just copied. The difference is only relevant in the case of closures, i.e. functions which may contain hidden internal references.\n\nWhile it isn\'t normally necessary, user-defined types can override the default deepcopy behavior by defining a specialized version of the function deepcopy_internal(x::T, dict::ObjectIdDict) (which shouldn\'t otherwise be used), where T is the type to be specialized for, and dict keeps track of objects copied so far within the recursion. Within the definition, deepcopy_internal should be used in place of deepcopy, and the dict variable should be updated as appropriate before returning.\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.isdefined",
    "page": "Essentials",
    "title": "Core.isdefined",
    "category": "function",
    "text": "isdefined([m::Module,] s::Symbol)\nisdefined(object, s::Symbol)\nisdefined(object, index::Int)\n\nTests whether an assignable location is defined. The arguments can be a module and a symbol or a composite object and field name (as a symbol) or index. With a single symbol argument, tests whether a global variable with that name is defined in current_module().\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.convert",
    "page": "Essentials",
    "title": "Base.convert",
    "category": "function",
    "text": "convert(T, x)\n\nConvert x to a value of type T.\n\nIf T is an Integer type, an InexactError will be raised if x is not representable by T, for example if x is not integer-valued, or is outside the range supported by T.\n\nExamples\n\njulia> convert(Int, 3.0)\n3\n\njulia> convert(Int, 3.5)\nERROR: InexactError()\nStacktrace:\n [1] convert(::Type{Int64}, ::Float64) at ./float.jl:679\n\nIf T is a AbstractFloat or Rational type, then it will return the closest value to x representable by T.\n\njulia> x = 1/3\n0.3333333333333333\n\njulia> convert(Float32, x)\n0.33333334f0\n\njulia> convert(Rational{Int32}, x)\n1//3\n\njulia> convert(Rational{Int64}, x)\n6004799503160661//18014398509481984\n\nIf T is a collection type and x a collection, the result of convert(T, x) may alias x.\n\njulia> x = Int[1,2,3];\n\njulia> y = convert(Vector{Int}, x);\n\njulia> y === x\ntrue\n\nSimilarly, if T is a composite type and x a related instance, the result of convert(T, x) may alias part or all of x.\n\njulia> x = speye(5);\n\njulia> typeof(x)\nSparseMatrixCSC{Float64,Int64}\n\njulia> y = convert(SparseMatrixCSC{Float64,Int64}, x);\n\njulia> z = convert(SparseMatrixCSC{Float32,Int64}, y);\n\njulia> y === x\ntrue\n\njulia> z === x\nfalse\n\njulia> z.colptr === x.colptr\ntrue\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.promote",
    "page": "Essentials",
    "title": "Base.promote",
    "category": "function",
    "text": "promote(xs...)\n\nConvert all arguments to their common promotion type (if any), and return them all (as a tuple).\n\nExample\n\njulia> promote(Int8(1), Float16(4.5), Float32(4.1))\n(1.0f0, 4.5f0, 4.1f0)\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.oftype",
    "page": "Essentials",
    "title": "Base.oftype",
    "category": "function",
    "text": "oftype(x, y)\n\nConvert y to the type of x (convert(typeof(x), y)).\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.widen",
    "page": "Essentials",
    "title": "Base.widen",
    "category": "function",
    "text": "widen(x)\n\nIf x is a type, return a \"larger\" type (for numeric types, this will be a type with at least as much range and precision as the argument, and usually more). Otherwise x is converted to widen(typeof(x)).\n\nExamples\n\njulia> widen(Int32)\nInt64\n\njulia> widen(1.5f0)\n1.5\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.identity",
    "page": "Essentials",
    "title": "Base.identity",
    "category": "function",
    "text": "identity(x)\n\nThe identity function. Returns its argument.\n\njulia> identity(\"Well, what did you expect?\")\n\"Well, what did you expect?\"\n\n\n\n"
},

{
    "location": "stdlib/base/#All-Objects-1",
    "page": "Essentials",
    "title": "All Objects",
    "category": "section",
    "text": "Core.:(===)\nCore.isa\nBase.isequal(::Any, ::Any)\nBase.isequal(::Nullable, ::Nullable)\nBase.isless\nBase.isless(::Nullable, ::Nullable)\nBase.ifelse\nBase.lexcmp\nBase.lexless\nCore.typeof\nCore.tuple\nBase.ntuple\nBase.object_id\nBase.hash\nBase.finalizer\nBase.finalize\nBase.copy\nBase.deepcopy\nCore.isdefined\nBase.convert\nBase.promote\nBase.oftype\nBase.widen\nBase.identity"
},

{
    "location": "stdlib/base/#Base.supertype",
    "page": "Essentials",
    "title": "Base.supertype",
    "category": "function",
    "text": "supertype(T::DataType)\n\nReturn the supertype of DataType T.\n\njulia> supertype(Int32)\nSigned\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.issubtype",
    "page": "Essentials",
    "title": "Core.issubtype",
    "category": "function",
    "text": "issubtype(type1, type2)\n\nReturn true if and only if all values of type1 are also of type2. Can also be written using the <: infix operator as type1 <: type2.\n\nExamples\n\njulia> issubtype(Int8, Int32)\nfalse\n\njulia> Int8 <: Integer\ntrue\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.:<:",
    "page": "Essentials",
    "title": "Base.:<:",
    "category": "function",
    "text": "<:(T1, T2)\n\nSubtype operator, equivalent to issubtype(T1, T2).\n\njulia> Float64 <: AbstractFloat\ntrue\n\njulia> Vector{Int} <: AbstractArray\ntrue\n\njulia> Matrix{Float64} <: Matrix{AbstractFloat}\nfalse\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.:>:",
    "page": "Essentials",
    "title": "Base.:>:",
    "category": "function",
    "text": ">:(T1, T2)\n\nSupertype operator, equivalent to issubtype(T2, T1).\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.subtypes",
    "page": "Essentials",
    "title": "Base.subtypes",
    "category": "function",
    "text": "subtypes(T::DataType)\n\nReturn a list of immediate subtypes of DataType T. Note that all currently loaded subtypes are included, including those not visible in the current module.\n\njulia> subtypes(Integer)\n4-element Array{Union{DataType, UnionAll},1}:\n BigInt\n Bool\n Signed\n Unsigned\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.typemin",
    "page": "Essentials",
    "title": "Base.typemin",
    "category": "function",
    "text": "typemin(T)\n\nThe lowest value representable by the given (real) numeric DataType T.\n\nExamples\n\njulia> typemin(Float16)\n-Inf16\n\njulia> typemin(Float32)\n-Inf32\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.typemax",
    "page": "Essentials",
    "title": "Base.typemax",
    "category": "function",
    "text": "typemax(T)\n\nThe highest value representable by the given (real) numeric DataType.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.realmin",
    "page": "Essentials",
    "title": "Base.realmin",
    "category": "function",
    "text": "realmin(T)\n\nThe smallest in absolute value non-subnormal value representable by the given floating-point DataType T.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.realmax",
    "page": "Essentials",
    "title": "Base.realmax",
    "category": "function",
    "text": "realmax(T)\n\nThe highest finite value representable by the given floating-point DataType T.\n\nExamples\n\njulia> realmax(Float16)\nFloat16(6.55e4)\n\njulia> realmax(Float32)\n3.4028235f38\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.maxintfloat",
    "page": "Essentials",
    "title": "Base.maxintfloat",
    "category": "function",
    "text": "maxintfloat(T)\n\nThe largest integer losslessly representable by the given floating-point DataType T.\n\n\n\nmaxintfloat(T, S)\n\nThe largest integer losslessly representable by the given floating-point DataType T that also does not exceed the maximum integer representable by the integer DataType S.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.sizeof-Tuple{Type}",
    "page": "Essentials",
    "title": "Base.sizeof",
    "category": "method",
    "text": "sizeof(T)\n\nSize, in bytes, of the canonical binary representation of the given DataType T, if any.\n\nExamples\n\njulia> sizeof(Float32)\n4\n\njulia> sizeof(Complex128)\n16\n\nIf T does not have a specific size, an error is thrown.\n\njulia> sizeof(Base.LinAlg.LU)\nERROR: argument is an abstract type; size is indeterminate\nStacktrace:\n [1] sizeof(::Type{T} where T) at ./essentials.jl:159\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.eps-Tuple{Type{#s27} where #s27<:AbstractFloat}",
    "page": "Essentials",
    "title": "Base.eps",
    "category": "method",
    "text": "eps(::Type{T}) where T<:AbstractFloat\neps()\n\nReturns the machine epsilon of the floating point type T (T = Float64 by default). This is defined as the gap between 1 and the next largest value representable by T, and is equivalent to eps(one(T)).\n\njulia> eps()\n2.220446049250313e-16\n\njulia> eps(Float32)\n1.1920929f-7\n\njulia> 1.0 + eps()\n1.0000000000000002\n\njulia> 1.0 + eps()/2\n1.0\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.eps-Tuple{AbstractFloat}",
    "page": "Essentials",
    "title": "Base.eps",
    "category": "method",
    "text": "eps(x::AbstractFloat)\n\nReturns the unit in last place (ulp) of x. This is the distance between consecutive representable floating point values at x. In most cases, if the distance on either side of x is different, then the larger of the two is taken, that is\n\neps(x) == max(x-prevfloat(x), nextfloat(x)-x)\n\nThe exceptions to this rule are the smallest and largest finite values (e.g. nextfloat(-Inf) and prevfloat(Inf) for Float64), which round to the smaller of the values.\n\nThe rationale for this behavior is that eps bounds the floating point rounding error. Under the default RoundNearest rounding mode, if y is a real number and x is the nearest floating point number to y, then\n\ny-x leq operatornameeps(x)2\n\njulia> eps(1.0)\n2.220446049250313e-16\n\njulia> eps(prevfloat(2.0))\n2.220446049250313e-16\n\njulia> eps(2.0)\n4.440892098500626e-16\n\njulia> x = prevfloat(Inf)      # largest finite Float64\n1.7976931348623157e308\n\njulia> x + eps(x)/2            # rounds up\nInf\n\njulia> x + prevfloat(eps(x)/2) # rounds down\n1.7976931348623157e308\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.promote_type",
    "page": "Essentials",
    "title": "Base.promote_type",
    "category": "function",
    "text": "promote_type(type1, type2)\n\nDetermine a type big enough to hold values of each argument type without loss, whenever possible. In some cases, where no type exists to which both types can be promoted losslessly, some loss is tolerated; for example, promote_type(Int64, Float64) returns Float64 even though strictly, not all Int64 values can be represented exactly as Float64 values.\n\njulia> promote_type(Int64, Float64)\nFloat64\n\njulia> promote_type(Int32, Int64)\nInt64\n\njulia> promote_type(Float32, BigInt)\nBigFloat\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.promote_rule",
    "page": "Essentials",
    "title": "Base.promote_rule",
    "category": "function",
    "text": "promote_rule(type1, type2)\n\nSpecifies what type should be used by promote when given values of types type1 and type2. This function should not be called directly, but should have definitions added to it for new types as appropriate.\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.getfield",
    "page": "Essentials",
    "title": "Core.getfield",
    "category": "function",
    "text": "getfield(value, name::Symbol)\n\nExtract a named field from a value of composite type. The syntax a.b calls getfield(a, :b).\n\nExample\n\njulia> a = 1//2\n1//2\n\njulia> getfield(a, :num)\n1\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.setfield!",
    "page": "Essentials",
    "title": "Core.setfield!",
    "category": "function",
    "text": "setfield!(value, name::Symbol, x)\n\nAssign x to a named field in value of composite type. The syntax a.b = c calls setfield!(a, :b, c).\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.fieldoffset",
    "page": "Essentials",
    "title": "Base.fieldoffset",
    "category": "function",
    "text": "fieldoffset(type, i)\n\nThe byte offset of field i of a type relative to the data start. For example, we could use it in the following manner to summarize information about a struct:\n\njulia> structinfo(T) = [(fieldoffset(T,i), fieldname(T,i), fieldtype(T,i)) for i = 1:nfields(T)];\n\njulia> structinfo(Base.Filesystem.StatStruct)\n12-element Array{Tuple{UInt64,Symbol,DataType},1}:\n (0x0000000000000000, :device, UInt64)\n (0x0000000000000008, :inode, UInt64)\n (0x0000000000000010, :mode, UInt64)\n (0x0000000000000018, :nlink, Int64)\n (0x0000000000000020, :uid, UInt64)\n (0x0000000000000028, :gid, UInt64)\n (0x0000000000000030, :rdev, UInt64)\n (0x0000000000000038, :size, Int64)\n (0x0000000000000040, :blksize, Int64)\n (0x0000000000000048, :blocks, Int64)\n (0x0000000000000050, :mtime, Float64)\n (0x0000000000000058, :ctime, Float64)\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.fieldtype",
    "page": "Essentials",
    "title": "Core.fieldtype",
    "category": "function",
    "text": "fieldtype(T, name::Symbol | index::Int)\n\nDetermine the declared type of a field (specified by name or index) in a composite DataType T.\n\njulia> struct Foo\n           x::Int64\n           y::String\n       end\n\njulia> fieldtype(Foo, :x)\nInt64\n\njulia> fieldtype(Foo, 2)\nString\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.isimmutable",
    "page": "Essentials",
    "title": "Base.isimmutable",
    "category": "function",
    "text": "isimmutable(v)\n\nReturn true iff value v is immutable.  See Mutable Composite Types for a discussion of immutability. Note that this function works on values, so if you give it a type, it will tell you that a value of DataType is mutable.\n\njulia> isimmutable(1)\ntrue\n\njulia> isimmutable([1,2])\nfalse\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.isbits",
    "page": "Essentials",
    "title": "Base.isbits",
    "category": "function",
    "text": "isbits(T)\n\nReturn true if T is a \"plain data\" type, meaning it is immutable and contains no references to other values. Typical examples are numeric types such as UInt8, Float64, and Complex{Float64}.\n\njulia> isbits(Complex{Float64})\ntrue\n\njulia> isbits(Complex)\nfalse\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.isleaftype",
    "page": "Essentials",
    "title": "Base.isleaftype",
    "category": "function",
    "text": "isleaftype(T)\n\nDetermine whether T\'s only subtypes are itself and Union{}. This means T is a concrete type that can have instances.\n\njulia> isleaftype(Complex)\nfalse\n\njulia> isleaftype(Complex{Float32})\ntrue\n\njulia> isleaftype(Vector{Complex})\ntrue\n\njulia> isleaftype(Vector{Complex{Float32}})\ntrue\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.typejoin",
    "page": "Essentials",
    "title": "Base.typejoin",
    "category": "function",
    "text": "typejoin(T, S)\n\nCompute a type that contains both T and S.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.typeintersect",
    "page": "Essentials",
    "title": "Base.typeintersect",
    "category": "function",
    "text": "typeintersect(T, S)\n\nCompute a type that contains the intersection of T and S. Usually this will be the smallest such type or one close to it.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.Val",
    "page": "Essentials",
    "title": "Base.Val",
    "category": "type",
    "text": "Val{c}\n\nCreate a \"value type\" out of c, which must be an isbits value. The intent of this construct is to be able to dispatch on constants, e.g., f(Val{false}) allows you to dispatch directly (at compile-time) to an implementation f(::Type{Val{false}}), without having to test the boolean value at runtime.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.Enums.@enum",
    "page": "Essentials",
    "title": "Base.Enums.@enum",
    "category": "macro",
    "text": "@enum EnumName[::BaseType] value1[=x] value2[=y]\n\nCreate an Enum{BaseType} subtype with name EnumName and enum member values of value1 and value2 with optional assigned values of x and y, respectively. EnumName can be used just like other types and enum member values as regular values, such as\n\njulia> @enum Fruit apple=1 orange=2 kiwi=3\n\njulia> f(x::Fruit) = \"I\'m a Fruit with value: $(Int(x))\"\nf (generic function with 1 method)\n\njulia> f(apple)\n\"I\'m a Fruit with value: 1\"\n\nBaseType, which defaults to Int32, must be a primitive subtype of Integer. Member values can be converted between the enum type and BaseType. read and write perform these conversions automatically.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.instances",
    "page": "Essentials",
    "title": "Base.instances",
    "category": "function",
    "text": "instances(T::Type)\n\nReturn a collection of all instances of the given type, if applicable. Mostly used for enumerated types (see @enum).\n\njulia> @enum Color red blue green\n\njulia> instances(Color)\n(red::Color = 0, blue::Color = 1, green::Color = 2)\n\n\n\n"
},

{
    "location": "stdlib/base/#Types-1",
    "page": "Essentials",
    "title": "Types",
    "category": "section",
    "text": "Base.supertype\nCore.issubtype\nBase.:(<:)\nBase.:(>:)\nBase.subtypes\nBase.typemin\nBase.typemax\nBase.realmin\nBase.realmax\nBase.maxintfloat\nBase.sizeof(::Type)\nBase.eps(::Type{<:AbstractFloat})\nBase.eps(::AbstractFloat)\nBase.promote_type\nBase.promote_rule\nCore.getfield\nCore.setfield!\nBase.fieldoffset\nCore.fieldtype\nBase.isimmutable\nBase.isbits\nBase.isleaftype\nBase.typejoin\nBase.typeintersect\nBase.Val\nBase.Enums.@enum\nBase.instances"
},

{
    "location": "stdlib/base/#Core.Function",
    "page": "Essentials",
    "title": "Core.Function",
    "category": "type",
    "text": "Function\n\nAbstract type of all functions.\n\njulia> isa(+, Function)\ntrue\n\njulia> typeof(sin)\nBase.#sin\n\njulia> ans <: Function\ntrue\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.method_exists",
    "page": "Essentials",
    "title": "Base.method_exists",
    "category": "function",
    "text": "method_exists(f, Tuple type, world=typemax(UInt)) -> Bool\n\nDetermine whether the given generic function has a method matching the given Tuple of argument types with the upper bound of world age given by world.\n\njulia> method_exists(length, Tuple{Array})\ntrue\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.applicable",
    "page": "Essentials",
    "title": "Core.applicable",
    "category": "function",
    "text": "applicable(f, args...) -> Bool\n\nDetermine whether the given generic function has a method applicable to the given arguments.\n\nExamples\n\njulia> function f(x, y)\n           x + y\n       end;\n\njulia> applicable(f, 1)\nfalse\n\njulia> applicable(f, 1, 2)\ntrue\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.invoke",
    "page": "Essentials",
    "title": "Core.invoke",
    "category": "function",
    "text": "invoke(f, types <: Tuple, args...)\n\nInvoke a method for the given generic function matching the specified types, on the specified arguments. The arguments must be compatible with the specified types. This allows invoking a method other than the most specific matching method, which is useful when the behavior of a more general definition is explicitly needed (often as part of the implementation of a more specific method of the same function).\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.invokelatest",
    "page": "Essentials",
    "title": "Base.invokelatest",
    "category": "function",
    "text": "invokelatest(f, args...)\n\nCalls f(args...), but guarantees that the most recent method of f will be executed.   This is useful in specialized circumstances, e.g. long-running event loops or callback functions that may call obsolete versions of a function f. (The drawback is that invokelatest is somewhat slower than calling f directly, and the type of the result cannot be inferred by the compiler.)\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.:|>",
    "page": "Essentials",
    "title": "Base.:|>",
    "category": "function",
    "text": "|>(x, f)\n\nApplies a function to the preceding argument. This allows for easy function chaining.\n\njulia> [1:5;] |> x->x.^2 |> sum |> inv\n0.01818181818181818\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.:∘",
    "page": "Essentials",
    "title": "Base.:∘",
    "category": "function",
    "text": "f ∘ g\n\nCompose functions: i.e. (f ∘ g)(args...) means f(g(args...)). The ∘ symbol can be entered in the Julia REPL (and most editors, appropriately configured) by typing \\circ<tab>. Example:\n\njulia> map(uppercase∘hex, 250:255)\n6-element Array{String,1}:\n \"FA\"\n \"FB\"\n \"FC\"\n \"FD\"\n \"FE\"\n \"FF\"\n\n\n\n"
},

{
    "location": "stdlib/base/#Generic-Functions-1",
    "page": "Essentials",
    "title": "Generic Functions",
    "category": "section",
    "text": "Core.Function\nBase.method_exists\nCore.applicable\nCore.invoke\nBase.invokelatest\nBase.:(|>)\nBase.:(∘)"
},

{
    "location": "stdlib/base/#Core.eval",
    "page": "Essentials",
    "title": "Core.eval",
    "category": "function",
    "text": "eval([m::Module], expr::Expr)\n\nEvaluate an expression in the given module and return the result. Every Module (except those defined with baremodule) has its own 1-argument definition of eval, which evaluates expressions in that module.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.@eval",
    "page": "Essentials",
    "title": "Base.@eval",
    "category": "macro",
    "text": "@eval [mod,] ex\n\nEvaluate an expression with values interpolated into it using eval. If two arguments are provided, the first is the module to evaluate in.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.evalfile",
    "page": "Essentials",
    "title": "Base.evalfile",
    "category": "function",
    "text": "evalfile(path::AbstractString, args::Vector{String}=String[])\n\nLoad the file using include, evaluate all expressions, and return the value of the last one.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.esc",
    "page": "Essentials",
    "title": "Base.esc",
    "category": "function",
    "text": "esc(e::ANY)\n\nOnly valid in the context of an Expr returned from a macro. Prevents the macro hygiene pass from turning embedded variables into gensym variables. See the Macros section of the Metaprogramming chapter of the manual for more details and examples.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.@inbounds",
    "page": "Essentials",
    "title": "Base.@inbounds",
    "category": "macro",
    "text": "@inbounds(blk)\n\nEliminates array bounds checking within expressions.\n\nIn the example below the bound check of array A is skipped to improve performance.\n\nfunction sum(A::AbstractArray)\n    r = zero(eltype(A))\n    for i = 1:length(A)\n        @inbounds r += A[i]\n    end\n    return r\nend\n\nwarning: Warning\nUsing @inbounds may return incorrect results/crashes/corruption for out-of-bounds indices. The user is responsible for checking it manually.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.@inline",
    "page": "Essentials",
    "title": "Base.@inline",
    "category": "macro",
    "text": "@inline\n\nGive a hint to the compiler that this function is worth inlining.\n\nSmall functions typically do not need the @inline annotation, as the compiler does it automatically. By using @inline on bigger functions, an extra nudge can be given to the compiler to inline it. This is shown in the following example:\n\n@inline function bigfunction(x)\n    #=\n        Function Definition\n    =#\nend\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.@noinline",
    "page": "Essentials",
    "title": "Base.@noinline",
    "category": "macro",
    "text": "@noinline\n\nPrevents the compiler from inlining a function.\n\nSmall functions are typically inlined automatically. By using @noinline on small functions, auto-inlining can be prevented. This is shown in the following example:\n\n@noinline function smallfunction(x)\n    #=\n        Function Definition\n    =#\nend\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.gensym",
    "page": "Essentials",
    "title": "Base.gensym",
    "category": "function",
    "text": "gensym([tag])\n\nGenerates a symbol which will not conflict with other variable names.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.@gensym",
    "page": "Essentials",
    "title": "Base.@gensym",
    "category": "macro",
    "text": "@gensym\n\nGenerates a gensym symbol for a variable. For example, @gensym x y is transformed into x = gensym(\"x\"); y = gensym(\"y\").\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.@polly",
    "page": "Essentials",
    "title": "Base.@polly",
    "category": "macro",
    "text": "@polly\n\nTells the compiler to apply the polyhedral optimizer Polly to a function.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.parse-Tuple{Any,Any}",
    "page": "Essentials",
    "title": "Base.parse",
    "category": "method",
    "text": "parse(str, start; greedy=true, raise=true)\n\nParse the expression string and return an expression (which could later be passed to eval for execution). start is the index of the first character to start parsing. If greedy is true (default), parse will try to consume as much input as it can; otherwise, it will stop as soon as it has parsed a valid expression. Incomplete but otherwise syntactically valid expressions will return Expr(:incomplete, \"(error message)\"). If raise is true (default), syntax errors other than incomplete expressions will raise an error. If raise is false, parse will return an expression that will raise an error upon evaluation.\n\njulia> parse(\"x = 3, y = 5\", 7)\n(:(y = 5), 13)\n\njulia> parse(\"x = 3, y = 5\", 5)\n(:((3, y) = 5), 13)\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.parse-Tuple{Any}",
    "page": "Essentials",
    "title": "Base.parse",
    "category": "method",
    "text": "parse(str; raise=true)\n\nParse the expression string greedily, returning a single expression. An error is thrown if there are additional characters after the first expression. If raise is true (default), syntax errors will raise an error; otherwise, parse will return an expression that will raise an error upon evaluation.\n\njulia> parse(\"x = 3\")\n:(x = 3)\n\njulia> parse(\"x = \")\n:($(Expr(:incomplete, \"incomplete: premature end of input\")))\n\njulia> parse(\"1.0.2\")\nERROR: ParseError(\"invalid numeric constant \\\"1.0.\\\"\")\nStacktrace:\n[...]\n\njulia> parse(\"1.0.2\"; raise = false)\n:($(Expr(:error, \"invalid numeric constant \\\"1.0.\\\"\")))\n\n\n\n"
},

{
    "location": "stdlib/base/#Syntax-1",
    "page": "Essentials",
    "title": "Syntax",
    "category": "section",
    "text": "Core.eval\nBase.@eval\nBase.evalfile\nBase.esc\nBase.@inbounds\nBase.@inline\nBase.@noinline\nBase.gensym\nBase.@gensym\nBase.@polly\nBase.parse(::Any, ::Any)\nBase.parse(::Any)"
},

{
    "location": "stdlib/base/#Base.Nullable",
    "page": "Essentials",
    "title": "Base.Nullable",
    "category": "type",
    "text": "Nullable(x, hasvalue::Bool=true)\n\nWrap value x in an object of type Nullable, which indicates whether a value is present. Nullable(x) yields a non-empty wrapper and Nullable{T}() yields an empty instance of a wrapper that might contain a value of type T.\n\nNullable(x, false) yields Nullable{typeof(x)}() with x stored in the result\'s value field.\n\nExamples\n\njulia> Nullable(1)\nNullable{Int64}(1)\n\njulia> Nullable{Int64}()\nNullable{Int64}()\n\njulia> Nullable(1, false)\nNullable{Int64}()\n\njulia> dump(Nullable(1, false))\nNullable{Int64}\n  hasvalue: Bool false\n  value: Int64 1\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.get-Tuple{Nullable,Any}",
    "page": "Essentials",
    "title": "Base.get",
    "category": "method",
    "text": "get(x::Nullable[, y])\n\nAttempt to access the value of x. Returns the value if it is present; otherwise, returns y if provided, or throws a NullException if not.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.isnull",
    "page": "Essentials",
    "title": "Base.isnull",
    "category": "function",
    "text": "isnull(x)\n\nReturn whether or not x is null for Nullable x; return false for all other x.\n\nExamples\n\njulia> x = Nullable(1, false)\nNullable{Int64}()\n\njulia> isnull(x)\ntrue\n\njulia> x = Nullable(1, true)\nNullable{Int64}(1)\n\njulia> isnull(x)\nfalse\n\njulia> x = 1\n1\n\njulia> isnull(x)\nfalse\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.unsafe_get",
    "page": "Essentials",
    "title": "Base.unsafe_get",
    "category": "function",
    "text": "unsafe_get(x)\n\nReturn the value of x for Nullable x; return x for all other x.\n\nThis method does not check whether or not x is null before attempting to access the value of x for x::Nullable (hence \"unsafe\").\n\njulia> x = Nullable(1)\nNullable{Int64}(1)\n\njulia> unsafe_get(x)\n1\n\njulia> x = Nullable{String}()\nNullable{String}()\n\njulia> unsafe_get(x)\nERROR: UndefRefError: access to undefined reference\nStacktrace:\n [1] unsafe_get(::Nullable{String}) at ./nullable.jl:125\n\njulia> x = 1\n1\n\njulia> unsafe_get(x)\n1\n\n\n\n"
},

{
    "location": "stdlib/base/#Nullables-1",
    "page": "Essentials",
    "title": "Nullables",
    "category": "section",
    "text": "Base.Nullable\nBase.get(::Nullable, ::Any)\nBase.isnull\nBase.unsafe_get"
},

{
    "location": "stdlib/base/#Base.run",
    "page": "Essentials",
    "title": "Base.run",
    "category": "function",
    "text": "run(command, args...)\n\nRun a command object, constructed with backticks. Throws an error if anything goes wrong, including the process exiting with a non-zero status.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.spawn",
    "page": "Essentials",
    "title": "Base.spawn",
    "category": "function",
    "text": "spawn(command)\n\nRun a command object asynchronously, returning the resulting Process object.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.DevNull",
    "page": "Essentials",
    "title": "Base.DevNull",
    "category": "constant",
    "text": "DevNull\n\nUsed in a stream redirect to discard all data written to it. Essentially equivalent to /dev/null on Unix or NUL on Windows. Usage:\n\nrun(pipeline(`cat test.txt`, DevNull))\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.success",
    "page": "Essentials",
    "title": "Base.success",
    "category": "function",
    "text": "success(command)\n\nRun a command object, constructed with backticks, and tell whether it was successful (exited with a code of 0). An exception is raised if the process cannot be started.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.process_running",
    "page": "Essentials",
    "title": "Base.process_running",
    "category": "function",
    "text": "process_running(p::Process)\n\nDetermine whether a process is currently running.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.process_exited",
    "page": "Essentials",
    "title": "Base.process_exited",
    "category": "function",
    "text": "process_exited(p::Process)\n\nDetermine whether a process has exited.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.kill-Tuple{Base.Process,Integer}",
    "page": "Essentials",
    "title": "Base.kill",
    "category": "method",
    "text": "kill(p::Process, signum=SIGTERM)\n\nSend a signal to a process. The default is to terminate the process.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.Sys.set_process_title",
    "page": "Essentials",
    "title": "Base.Sys.set_process_title",
    "category": "function",
    "text": "Sys.set_process_title(title::AbstractString)\n\nSet the process title. No-op on some operating systems.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.Sys.get_process_title",
    "page": "Essentials",
    "title": "Base.Sys.get_process_title",
    "category": "function",
    "text": "Sys.get_process_title()\n\nGet the process title. On some systems, will always return an empty string.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.readandwrite",
    "page": "Essentials",
    "title": "Base.readandwrite",
    "category": "function",
    "text": "readandwrite(command)\n\nStarts running a command asynchronously, and returns a tuple (stdout,stdin,process) of the output stream and input stream of the process, and the process object itself.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.ignorestatus",
    "page": "Essentials",
    "title": "Base.ignorestatus",
    "category": "function",
    "text": "ignorestatus(command)\n\nMark a command object so that running it will not throw an error if the result code is non-zero.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.detach",
    "page": "Essentials",
    "title": "Base.detach",
    "category": "function",
    "text": "detach(command)\n\nMark a command object so that it will be run in a new process group, allowing it to outlive the julia process, and not have Ctrl-C interrupts passed to it.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.Cmd",
    "page": "Essentials",
    "title": "Base.Cmd",
    "category": "type",
    "text": "Cmd(cmd::Cmd; ignorestatus, detach, windows_verbatim, windows_hide, env, dir)\n\nConstruct a new Cmd object, representing an external program and arguments, from cmd, while changing the settings of the optional keyword arguments:\n\nignorestatus::Bool: If true (defaults to false), then the Cmd will not throw an error if the return code is nonzero.\ndetach::Bool: If true (defaults to false), then the Cmd will be run in a new process group, allowing it to outlive the julia process and not have Ctrl-C passed to it.\nwindows_verbatim::Bool: If true (defaults to false), then on Windows the Cmd will send a command-line string to the process with no quoting or escaping of arguments, even arguments containing spaces. (On Windows, arguments are sent to a program as a single \"command-line\" string, and programs are responsible for parsing it into arguments. By default, empty arguments and arguments with spaces or tabs are quoted with double quotes \" in the command line, and \\ or \" are preceded by backslashes. windows_verbatim=true is useful for launching programs that parse their command line in nonstandard ways.) Has no effect on non-Windows systems.\nwindows_hide::Bool: If true (defaults to false), then on Windows no new console window is displayed when the Cmd is executed. This has no effect if a console is already open or on non-Windows systems.\nenv: Set environment variables to use when running the Cmd. env is either a dictionary mapping strings to strings, an array of strings of the form \"var=val\", an array or tuple of \"var\"=>val pairs, or nothing. In order to modify (rather than replace) the existing environment, create env by copy(ENV) and then set env[\"var\"]=val as desired.\ndir::AbstractString: Specify a working directory for the command (instead of the current directory).\n\nFor any keywords that are not specified, the current settings from cmd are used. Normally, to create a Cmd object in the first place, one uses backticks, e.g.\n\nCmd(`echo \"Hello world\"`, ignorestatus=true, detach=false)\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.setenv",
    "page": "Essentials",
    "title": "Base.setenv",
    "category": "function",
    "text": "setenv(command::Cmd, env; dir=\"\")\n\nSet environment variables to use when running the given command. env is either a dictionary mapping strings to strings, an array of strings of the form \"var=val\", or zero or more \"var\"=>val pair arguments. In order to modify (rather than replace) the existing environment, create env by copy(ENV) and then setting env[\"var\"]=val as desired, or use withenv.\n\nThe dir keyword argument can be used to specify a working directory for the command.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.withenv",
    "page": "Essentials",
    "title": "Base.withenv",
    "category": "function",
    "text": "withenv(f::Function, kv::Pair...)\n\nExecute f() in an environment that is temporarily modified (not replaced as in setenv) by zero or more \"var\"=>val arguments kv. withenv is generally used via the withenv(kv...) do ... end syntax. A value of nothing can be used to temporarily unset an environment variable (if it is set). When withenv returns, the original environment has been restored.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.pipeline-Tuple{Any,Any,Any,Vararg{Any,N} where N}",
    "page": "Essentials",
    "title": "Base.pipeline",
    "category": "method",
    "text": "pipeline(from, to, ...)\n\nCreate a pipeline from a data source to a destination. The source and destination can be commands, I/O streams, strings, or results of other pipeline calls. At least one argument must be a command. Strings refer to filenames. When called with more than two arguments, they are chained together from left to right. For example pipeline(a,b,c) is equivalent to pipeline(pipeline(a,b),c). This provides a more concise way to specify multi-stage pipelines.\n\nExamples:\n\nrun(pipeline(`ls`, `grep xyz`))\nrun(pipeline(`ls`, \"out.txt\"))\nrun(pipeline(\"out.txt\", `grep xyz`))\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.pipeline-Tuple{Base.AbstractCmd}",
    "page": "Essentials",
    "title": "Base.pipeline",
    "category": "method",
    "text": "pipeline(command; stdin, stdout, stderr, append=false)\n\nRedirect I/O to or from the given command. Keyword arguments specify which of the command\'s streams should be redirected. append controls whether file output appends to the file. This is a more general version of the 2-argument pipeline function. pipeline(from, to) is equivalent to pipeline(from, stdout=to) when from is a command, and to pipeline(to, stdin=from) when from is another kind of data source.\n\nExamples:\n\nrun(pipeline(`dothings`, stdout=\"out.txt\", stderr=\"errs.txt\"))\nrun(pipeline(`update`, stdout=\"log.txt\", append=true))\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.Libc.gethostname",
    "page": "Essentials",
    "title": "Base.Libc.gethostname",
    "category": "function",
    "text": "gethostname() -> AbstractString\n\nGet the local machine\'s host name.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.getipaddr",
    "page": "Essentials",
    "title": "Base.getipaddr",
    "category": "function",
    "text": "getipaddr() -> IPAddr\n\nGet the IP address of the local machine.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.Libc.getpid",
    "page": "Essentials",
    "title": "Base.Libc.getpid",
    "category": "function",
    "text": "getpid() -> Int32\n\nGet Julia\'s process ID.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.Libc.time-Tuple{}",
    "page": "Essentials",
    "title": "Base.Libc.time",
    "category": "method",
    "text": "time()\n\nGet the system time in seconds since the epoch, with fairly high (typically, microsecond) resolution.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.time_ns",
    "page": "Essentials",
    "title": "Base.time_ns",
    "category": "function",
    "text": "time_ns()\n\nGet the time in nanoseconds. The time corresponding to 0 is undefined, and wraps every 5.8 years.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.tic",
    "page": "Essentials",
    "title": "Base.tic",
    "category": "function",
    "text": "tic()\n\nSet a timer to be read by the next call to toc or toq. The macro call @time expr can also be used to time evaluation.\n\njulia> tic()\n0x0000c45bc7abac95\n\njulia> sleep(0.3)\n\njulia> toc()\nelapsed time: 0.302745944 seconds\n0.302745944\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.toc",
    "page": "Essentials",
    "title": "Base.toc",
    "category": "function",
    "text": "toc()\n\nPrint and return the time elapsed since the last tic. The macro call @time expr can also be used to time evaluation.\n\njulia> tic()\n0x0000c45bc7abac95\n\njulia> sleep(0.3)\n\njulia> toc()\nelapsed time: 0.302745944 seconds\n0.302745944\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.toq",
    "page": "Essentials",
    "title": "Base.toq",
    "category": "function",
    "text": "toq()\n\nReturn, but do not print, the time elapsed since the last tic. The macro calls @timed expr and @elapsed expr also return evaluation time.\n\njulia> tic()\n0x0000c46477a9675d\n\njulia> sleep(0.3)\n\njulia> toq()\n0.302251004\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.@time",
    "page": "Essentials",
    "title": "Base.@time",
    "category": "macro",
    "text": "@time\n\nA macro to execute an expression, printing the time it took to execute, the number of allocations, and the total number of bytes its execution caused to be allocated, before returning the value of the expression.\n\nSee also @timev, @timed, @elapsed, and @allocated.\n\njulia> @time rand(10^6);\n  0.001525 seconds (7 allocations: 7.630 MiB)\n\njulia> @time begin\n           sleep(0.3)\n           1+1\n       end\n  0.301395 seconds (8 allocations: 336 bytes)\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.@timev",
    "page": "Essentials",
    "title": "Base.@timev",
    "category": "macro",
    "text": "@timev\n\nThis is a verbose version of the @time macro. It first prints the same information as @time, then any non-zero memory allocation counters, and then returns the value of the expression.\n\nSee also @time, @timed, @elapsed, and @allocated.\n\njulia> @timev rand(10^6);\n  0.001006 seconds (7 allocations: 7.630 MiB)\nelapsed time (ns): 1005567\nbytes allocated:   8000256\npool allocs:       6\nmalloc() calls:    1\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.@timed",
    "page": "Essentials",
    "title": "Base.@timed",
    "category": "macro",
    "text": "@timed\n\nA macro to execute an expression, and return the value of the expression, elapsed time, total bytes allocated, garbage collection time, and an object with various memory allocation counters.\n\nSee also @time, @timev, @elapsed, and @allocated.\n\njulia> val, t, bytes, gctime, memallocs = @timed rand(10^6);\n\njulia> t\n0.006634834\n\njulia> bytes\n8000256\n\njulia> gctime\n0.0055765\n\njulia> fieldnames(typeof(memallocs))\n9-element Array{Symbol,1}:\n :allocd\n :malloc\n :realloc\n :poolalloc\n :bigalloc\n :freecall\n :total_time\n :pause\n :full_sweep\n\njulia> memallocs.total_time\n5576500\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.@elapsed",
    "page": "Essentials",
    "title": "Base.@elapsed",
    "category": "macro",
    "text": "@elapsed\n\nA macro to evaluate an expression, discarding the resulting value, instead returning the number of seconds it took to execute as a floating-point number.\n\nSee also @time, @timev, @timed, and @allocated.\n\njulia> @elapsed sleep(0.3)\n0.301391426\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.@allocated",
    "page": "Essentials",
    "title": "Base.@allocated",
    "category": "macro",
    "text": "@allocated\n\nA macro to evaluate an expression, discarding the resulting value, instead returning the total number of bytes allocated during evaluation of the expression. Note: the expression is evaluated inside a local function, instead of the current context, in order to eliminate the effects of compilation, however, there still may be some allocations due to JIT compilation. This also makes the results inconsistent with the @time macros, which do not try to adjust for the effects of compilation.\n\nSee also @time, @timev, @timed, and @elapsed.\n\njulia> @allocated rand(10^6)\n8000080\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.EnvHash",
    "page": "Essentials",
    "title": "Base.EnvHash",
    "category": "type",
    "text": "EnvHash() -> EnvHash\n\nA singleton of this type provides a hash table interface to environment variables.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.ENV",
    "page": "Essentials",
    "title": "Base.ENV",
    "category": "constant",
    "text": "ENV\n\nReference to the singleton EnvHash, providing a dictionary interface to system environment variables.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.is_unix",
    "page": "Essentials",
    "title": "Base.is_unix",
    "category": "function",
    "text": "is_unix([os])\n\nPredicate for testing if the OS provides a Unix-like interface. See documentation in Handling Operating System Variation.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.is_apple",
    "page": "Essentials",
    "title": "Base.is_apple",
    "category": "function",
    "text": "is_apple([os])\n\nPredicate for testing if the OS is a derivative of Apple Macintosh OS X or Darwin. See documentation in Handling Operating System Variation.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.is_linux",
    "page": "Essentials",
    "title": "Base.is_linux",
    "category": "function",
    "text": "is_linux([os])\n\nPredicate for testing if the OS is a derivative of Linux. See documentation in Handling Operating System Variation.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.is_bsd",
    "page": "Essentials",
    "title": "Base.is_bsd",
    "category": "function",
    "text": "is_bsd([os])\n\nPredicate for testing if the OS is a derivative of BSD. See documentation in Handling Operating System Variation.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.is_windows",
    "page": "Essentials",
    "title": "Base.is_windows",
    "category": "function",
    "text": "is_windows([os])\n\nPredicate for testing if the OS is a derivative of Microsoft Windows NT. See documentation in Handling Operating System Variation.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.Sys.windows_version",
    "page": "Essentials",
    "title": "Base.Sys.windows_version",
    "category": "function",
    "text": "Sys.windows_version()\n\nReturns the version number for the Windows NT Kernel as a (major, minor) pair, or (0, 0) if this is not running on Windows.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.@static",
    "page": "Essentials",
    "title": "Base.@static",
    "category": "macro",
    "text": "@static\n\nPartially evaluates an expression at parse time.\n\nFor example, @static is_windows() ? foo : bar will evaluate is_windows() and insert either foo or bar into the expression. This is useful in cases where a construct would be invalid on other platforms, such as a ccall to a non-existent function. @static if is_apple() foo end and @static foo <&&,||> bar are also valid syntax.\n\n\n\n"
},

{
    "location": "stdlib/base/#System-1",
    "page": "Essentials",
    "title": "System",
    "category": "section",
    "text": "Base.run\nBase.spawn\nBase.DevNull\nBase.success\nBase.process_running\nBase.process_exited\nBase.kill(::Base.Process, ::Integer)\nBase.Sys.set_process_title\nBase.Sys.get_process_title\nBase.readandwrite\nBase.ignorestatus\nBase.detach\nBase.Cmd\nBase.setenv\nBase.withenv\nBase.pipeline(::Any, ::Any, ::Any, ::Any...)\nBase.pipeline(::Base.AbstractCmd)\nBase.Libc.gethostname\nBase.getipaddr\nBase.Libc.getpid\nBase.Libc.time()\nBase.time_ns\nBase.tic\nBase.toc\nBase.toq\nBase.@time\nBase.@timev\nBase.@timed\nBase.@elapsed\nBase.@allocated\nBase.EnvHash\nBase.ENV\nBase.is_unix\nBase.is_apple\nBase.is_linux\nBase.is_bsd\nBase.is_windows\nBase.Sys.windows_version\nBase.@static"
},

{
    "location": "stdlib/base/#Base.error",
    "page": "Essentials",
    "title": "Base.error",
    "category": "function",
    "text": "error(message::AbstractString)\n\nRaise an ErrorException with the given message.\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.throw",
    "page": "Essentials",
    "title": "Core.throw",
    "category": "function",
    "text": "throw(e)\n\nThrow an object as an exception.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.rethrow",
    "page": "Essentials",
    "title": "Base.rethrow",
    "category": "function",
    "text": "rethrow([e])\n\nThrow an object without changing the current exception backtrace. The default argument is the current exception (if called within a catch block).\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.backtrace",
    "page": "Essentials",
    "title": "Base.backtrace",
    "category": "function",
    "text": "backtrace()\n\nGet a backtrace object for the current program point.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.catch_backtrace",
    "page": "Essentials",
    "title": "Base.catch_backtrace",
    "category": "function",
    "text": "catch_backtrace()\n\nGet the backtrace of the current exception, for use within catch blocks.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.assert",
    "page": "Essentials",
    "title": "Base.assert",
    "category": "function",
    "text": "assert(cond)\n\nThrow an AssertionError if cond is false. Also available as the macro @assert expr.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.@assert",
    "page": "Essentials",
    "title": "Base.@assert",
    "category": "macro",
    "text": "@assert cond [text]\n\nThrow an AssertionError if cond is false. Preferred syntax for writing assertions. Message text is optionally displayed upon assertion failure.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.ArgumentError",
    "page": "Essentials",
    "title": "Base.ArgumentError",
    "category": "type",
    "text": "ArgumentError(msg)\n\nThe parameters to a function call do not match a valid signature. Argument msg is a descriptive error string.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.AssertionError",
    "page": "Essentials",
    "title": "Base.AssertionError",
    "category": "type",
    "text": "AssertionError([msg])\n\nThe asserted condition did not evaluate to true. Optional argument msg is a descriptive error string.\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.BoundsError",
    "page": "Essentials",
    "title": "Core.BoundsError",
    "category": "type",
    "text": "BoundsError([a],[i])\n\nAn indexing operation into an array, a, tried to access an out-of-bounds element, i.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.DimensionMismatch",
    "page": "Essentials",
    "title": "Base.DimensionMismatch",
    "category": "type",
    "text": "DimensionMismatch([msg])\n\nThe objects called do not have matching dimensionality. Optional argument msg is a descriptive error string.\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.DivideError",
    "page": "Essentials",
    "title": "Core.DivideError",
    "category": "type",
    "text": "DivideError()\n\nInteger division was attempted with a denominator value of 0.\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.DomainError",
    "page": "Essentials",
    "title": "Core.DomainError",
    "category": "type",
    "text": "DomainError()\n\nThe arguments to a function or constructor are outside the valid domain.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.EOFError",
    "page": "Essentials",
    "title": "Base.EOFError",
    "category": "type",
    "text": "EOFError()\n\nNo more data was available to read from a file or stream.\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.ErrorException",
    "page": "Essentials",
    "title": "Core.ErrorException",
    "category": "type",
    "text": "ErrorException(msg)\n\nGeneric error type. The error message, in the .msg field, may provide more specific details.\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.InexactError",
    "page": "Essentials",
    "title": "Core.InexactError",
    "category": "type",
    "text": "InexactError()\n\nType conversion cannot be done exactly.\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.InterruptException",
    "page": "Essentials",
    "title": "Core.InterruptException",
    "category": "type",
    "text": "InterruptException()\n\nThe process was stopped by a terminal interrupt (CTRL+C).\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.KeyError",
    "page": "Essentials",
    "title": "Base.KeyError",
    "category": "type",
    "text": "KeyError(key)\n\nAn indexing operation into an Associative (Dict) or Set like object tried to access or delete a non-existent element.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.LoadError",
    "page": "Essentials",
    "title": "Base.LoadError",
    "category": "type",
    "text": "LoadError(file::AbstractString, line::Int, error)\n\nAn error occurred while includeing, requireing, or using a file. The error specifics should be available in the .error field.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.MethodError",
    "page": "Essentials",
    "title": "Base.MethodError",
    "category": "type",
    "text": "MethodError(f, args)\n\nA method with the required type signature does not exist in the given generic function. Alternatively, there is no unique most-specific method.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.NullException",
    "page": "Essentials",
    "title": "Base.NullException",
    "category": "type",
    "text": "NullException()\n\nAn attempted access to a Nullable with no defined value.\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.OutOfMemoryError",
    "page": "Essentials",
    "title": "Core.OutOfMemoryError",
    "category": "type",
    "text": "OutOfMemoryError()\n\nAn operation allocated too much memory for either the system or the garbage collector to handle properly.\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.ReadOnlyMemoryError",
    "page": "Essentials",
    "title": "Core.ReadOnlyMemoryError",
    "category": "type",
    "text": "ReadOnlyMemoryError()\n\nAn operation tried to write to memory that is read-only.\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.OverflowError",
    "page": "Essentials",
    "title": "Core.OverflowError",
    "category": "type",
    "text": "OverflowError()\n\nThe result of an expression is too large for the specified type and will cause a wraparound.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.ParseError",
    "page": "Essentials",
    "title": "Base.ParseError",
    "category": "type",
    "text": "ParseError(msg)\n\nThe expression passed to the parse function could not be interpreted as a valid Julia expression.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.Distributed.ProcessExitedException",
    "page": "Essentials",
    "title": "Base.Distributed.ProcessExitedException",
    "category": "type",
    "text": "ProcessExitedException()\n\nAfter a client Julia process has exited, further attempts to reference the dead child will throw this exception.\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.StackOverflowError",
    "page": "Essentials",
    "title": "Core.StackOverflowError",
    "category": "type",
    "text": "StackOverflowError()\n\nThe function call grew beyond the size of the call stack. This usually happens when a call recurses infinitely.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.SystemError",
    "page": "Essentials",
    "title": "Base.SystemError",
    "category": "type",
    "text": "SystemError(prefix::AbstractString, [errno::Int32])\n\nA system call failed with an error code (in the errno global variable).\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.TypeError",
    "page": "Essentials",
    "title": "Core.TypeError",
    "category": "type",
    "text": "TypeError(func::Symbol, context::AbstractString, expected::Type, got)\n\nA type assertion failure, or calling an intrinsic function with an incorrect argument type.\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.UndefRefError",
    "page": "Essentials",
    "title": "Core.UndefRefError",
    "category": "type",
    "text": "UndefRefError()\n\nThe item or field is not defined for the given object.\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.UndefVarError",
    "page": "Essentials",
    "title": "Core.UndefVarError",
    "category": "type",
    "text": "UndefVarError(var::Symbol)\n\nA symbol in the current scope is not defined.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.InitError",
    "page": "Essentials",
    "title": "Base.InitError",
    "category": "type",
    "text": "InitError(mod::Symbol, error)\n\nAn error occurred when running a module\'s __init__ function. The actual error thrown is available in the .error field.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.retry",
    "page": "Essentials",
    "title": "Base.retry",
    "category": "function",
    "text": "retry(f::Function;  delays=ExponentialBackOff(), check=nothing) -> Function\n\nReturns an anonymous function that calls function f.  If an exception arises, f is repeatedly called again, each time check returns true, after waiting the number of seconds specified in delays.  check should input delays\'s current state and the Exception.\n\nExamples\n\nretry(f, delays=fill(5.0, 3))\nretry(f, delays=rand(5:10, 2))\nretry(f, delays=Base.ExponentialBackOff(n=3, first_delay=5, max_delay=1000))\nretry(http_get, check=(s,e)->e.status == \"503\")(url)\nretry(read, check=(s,e)->isa(e, UVError))(io, 128; all=false)\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.ExponentialBackOff",
    "page": "Essentials",
    "title": "Base.ExponentialBackOff",
    "category": "type",
    "text": "ExponentialBackOff(; n=1, first_delay=0.05, max_delay=10.0, factor=5.0, jitter=0.1)\n\nA Float64 iterator of length n whose elements exponentially increase at a rate in the interval factor * (1 ± jitter).  The first element is first_delay and all elements are clamped to max_delay.\n\n\n\n"
},

{
    "location": "stdlib/base/#Errors-1",
    "page": "Essentials",
    "title": "Errors",
    "category": "section",
    "text": "Base.error\nCore.throw\nBase.rethrow\nBase.backtrace\nBase.catch_backtrace\nBase.assert\nBase.@assert\nBase.ArgumentError\nBase.AssertionError\nCore.BoundsError\nBase.DimensionMismatch\nCore.DivideError\nCore.DomainError\nBase.EOFError\nCore.ErrorException\nCore.InexactError\nCore.InterruptException\nBase.KeyError\nBase.LoadError\nBase.MethodError\nBase.NullException\nCore.OutOfMemoryError\nCore.ReadOnlyMemoryError\nCore.OverflowError\nBase.ParseError\nBase.ProcessExitedException\nCore.StackOverflowError\nBase.SystemError\nCore.TypeError\nCore.UndefRefError\nCore.UndefVarError\nBase.InitError\nBase.retry\nBase.ExponentialBackOff"
},

{
    "location": "stdlib/base/#Base.Timer-Tuple{Function,Real,Real}",
    "page": "Essentials",
    "title": "Base.Timer",
    "category": "method",
    "text": "Timer(callback::Function, delay, repeat=0)\n\nCreate a timer to call the given callback function. The callback is passed one argument, the timer object itself. The callback will be invoked after the specified initial delay, and then repeating with the given repeat interval. If repeat is 0, the timer is only triggered once. Times are in seconds. A timer is stopped and has its resources freed by calling close on it.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.Timer",
    "page": "Essentials",
    "title": "Base.Timer",
    "category": "type",
    "text": "Timer(delay, repeat=0)\n\nCreate a timer that wakes up tasks waiting for it (by calling wait on the timer object) at a specified interval.  Times are in seconds.  Waiting tasks are woken with an error when the timer is closed (by close. Use isopen to check whether a timer is still active.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.AsyncCondition",
    "page": "Essentials",
    "title": "Base.AsyncCondition",
    "category": "type",
    "text": "AsyncCondition()\n\nCreate a async condition that wakes up tasks waiting for it (by calling wait on the object) when notified from C by a call to uv_async_send. Waiting tasks are woken with an error when the object is closed (by close. Use isopen to check whether it is still active.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.AsyncCondition-Tuple{Function}",
    "page": "Essentials",
    "title": "Base.AsyncCondition",
    "category": "method",
    "text": "AsyncCondition(callback::Function)\n\nCreate a async condition that calls the given callback function. The callback is passed one argument, the async condition object itself.\n\n\n\n"
},

{
    "location": "stdlib/base/#Events-1",
    "page": "Essentials",
    "title": "Events",
    "category": "section",
    "text": "Base.Timer(::Function, ::Real, ::Real)\nBase.Timer\nBase.AsyncCondition\nBase.AsyncCondition(::Function)"
},

{
    "location": "stdlib/base/#Base.module_name",
    "page": "Essentials",
    "title": "Base.module_name",
    "category": "function",
    "text": "module_name(m::Module) -> Symbol\n\nGet the name of a Module as a Symbol.\n\njulia> module_name(Base.LinAlg)\n:LinAlg\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.module_parent",
    "page": "Essentials",
    "title": "Base.module_parent",
    "category": "function",
    "text": "module_parent(m::Module) -> Module\n\nGet a module\'s enclosing Module. Main is its own parent, as is LastMain after workspace().\n\njulia> module_parent(Main)\nMain\n\njulia> module_parent(Base.LinAlg.BLAS)\nBase.LinAlg\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.current_module",
    "page": "Essentials",
    "title": "Base.current_module",
    "category": "function",
    "text": "current_module() -> Module\n\nGet the dynamically current Module, which is the Module code is currently being read from. In general, this is not the same as the module containing the call to this function.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.fullname",
    "page": "Essentials",
    "title": "Base.fullname",
    "category": "function",
    "text": "fullname(m::Module)\n\nGet the fully-qualified name of a module as a tuple of symbols. For example,\n\njulia> fullname(Base.Pkg)\n(:Base, :Pkg)\n\njulia> fullname(Main)\n()\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.names",
    "page": "Essentials",
    "title": "Base.names",
    "category": "function",
    "text": "names(x::Module, all::Bool=false, imported::Bool=false)\n\nGet an array of the names exported by a Module, excluding deprecated names. If all is true, then the list also includes non-exported names defined in the module, deprecated names, and compiler-generated names. If imported is true, then names explicitly imported from other modules are also included.\n\nAs a special case, all names defined in Main are considered \"exported\", since it is not idiomatic to explicitly export names from Main.\n\n\n\n"
},

{
    "location": "stdlib/base/#Core.nfields",
    "page": "Essentials",
    "title": "Core.nfields",
    "category": "function",
    "text": "nfields(x::DataType) -> Int\n\nGet the number of fields of a DataType.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.fieldnames",
    "page": "Essentials",
    "title": "Base.fieldnames",
    "category": "function",
    "text": "fieldnames(x::DataType)\n\nGet an array of the fields of a DataType.\n\njulia> fieldnames(Hermitian)\n2-element Array{Symbol,1}:\n :data\n :uplo\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.fieldname",
    "page": "Essentials",
    "title": "Base.fieldname",
    "category": "function",
    "text": "fieldname(x::DataType, i::Integer)\n\nGet the name of field i of a DataType.\n\njulia> fieldname(SparseMatrixCSC,1)\n:m\n\njulia> fieldname(SparseMatrixCSC,5)\n:nzval\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.datatype_module",
    "page": "Essentials",
    "title": "Base.datatype_module",
    "category": "function",
    "text": "Base.datatype_module(t::DataType) -> Module\n\nDetermine the module containing the definition of a DataType.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.datatype_name",
    "page": "Essentials",
    "title": "Base.datatype_name",
    "category": "function",
    "text": "Base.datatype_name(t) -> Symbol\n\nGet the name of a (potentially UnionAll-wrapped) DataType (without its parent module) as a symbol.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.isconst",
    "page": "Essentials",
    "title": "Base.isconst",
    "category": "function",
    "text": "isconst([m::Module], s::Symbol) -> Bool\n\nDetermine whether a global is declared const in a given Module. The default Module argument is current_module().\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.function_name",
    "page": "Essentials",
    "title": "Base.function_name",
    "category": "function",
    "text": "Base.function_name(f::Function) -> Symbol\n\nGet the name of a generic Function as a symbol, or :anonymous.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.function_module-Tuple{Function}",
    "page": "Essentials",
    "title": "Base.function_module",
    "category": "method",
    "text": "Base.function_module(f::Function) -> Module\n\nDetermine the module containing the (first) definition of a generic function.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.function_module-Tuple{Any,Any}",
    "page": "Essentials",
    "title": "Base.function_module",
    "category": "method",
    "text": "Base.function_module(f::Function, types) -> Module\n\nDetermine the module containing a given definition of a generic function.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.functionloc-Tuple{Any,Any}",
    "page": "Essentials",
    "title": "Base.functionloc",
    "category": "method",
    "text": "functionloc(f::Function, types)\n\nReturns a tuple (filename,line) giving the location of a generic Function definition.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.functionloc-Tuple{Method}",
    "page": "Essentials",
    "title": "Base.functionloc",
    "category": "method",
    "text": "functionloc(m::Method)\n\nReturns a tuple (filename,line) giving the location of a Method definition.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.@functionloc",
    "page": "Essentials",
    "title": "Base.@functionloc",
    "category": "macro",
    "text": "@functionloc\n\nApplied to a function or macro call, it evaluates the arguments to the specified call, and returns a tuple (filename,line) giving the location for the method that would be called for those arguments. It calls out to the functionloc function.\n\n\n\n"
},

{
    "location": "stdlib/base/#Reflection-1",
    "page": "Essentials",
    "title": "Reflection",
    "category": "section",
    "text": "Base.module_name\nBase.module_parent\nBase.current_module\nBase.fullname\nBase.names\nCore.nfields\nBase.fieldnames\nBase.fieldname\nBase.datatype_module\nBase.datatype_name\nBase.isconst\nBase.function_name\nBase.function_module(::Function)\nBase.function_module(::Any, ::Any)\nBase.functionloc(::Any, ::Any)\nBase.functionloc(::Method)\nBase.@functionloc"
},

{
    "location": "stdlib/base/#Base.gc",
    "page": "Essentials",
    "title": "Base.gc",
    "category": "function",
    "text": "gc()\n\nPerform garbage collection. This should not generally be used.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.gc_enable",
    "page": "Essentials",
    "title": "Base.gc_enable",
    "category": "function",
    "text": "gc_enable(on::Bool)\n\nControl whether garbage collection is enabled using a boolean argument (true for enabled, false for disabled). Returns previous GC state. Disabling garbage collection should be used only with extreme caution, as it can cause memory use to grow without bound.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.macroexpand",
    "page": "Essentials",
    "title": "Base.macroexpand",
    "category": "function",
    "text": "macroexpand(x)\n\nTakes the expression x and returns an equivalent expression with all macros removed (expanded).\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.@macroexpand",
    "page": "Essentials",
    "title": "Base.@macroexpand",
    "category": "macro",
    "text": "@macroexpand\n\nReturn equivalent expression with all macros removed (expanded).\n\nThere is a subtle difference between @macroexpand and macroexpand in that expansion takes place in different contexts. This is best seen in the following example:\n\njulia> module M\n           macro m()\n               1\n           end\n           function f()\n               (@macroexpand(@m), macroexpand(:(@m)))\n           end\n       end\nM\n\njulia> macro m()\n           2\n       end\n@m (macro with 1 method)\n\njulia> M.f()\n(1, 2)\n\nWith @macroexpand the expression expands where @macroexpand appears in the code (module M in the example). With macroexpand the expression expands in the current module where the code was finally called (REPL in the example). Note that when calling macroexpand or @macroexpand directly from the REPL, both of these contexts coincide, hence there is no difference.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.expand",
    "page": "Essentials",
    "title": "Base.expand",
    "category": "function",
    "text": "expand(x)\n\nTakes the expression x and returns an equivalent expression in lowered form. See also code_lowered.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.code_lowered",
    "page": "Essentials",
    "title": "Base.code_lowered",
    "category": "function",
    "text": "code_lowered(f, types)\n\nReturns an array of lowered ASTs for the methods matching the given generic function and type signature.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.@code_lowered",
    "page": "Essentials",
    "title": "Base.@code_lowered",
    "category": "macro",
    "text": "@code_lowered\n\nEvaluates the arguments to the function or macro call, determines their types, and calls code_lowered on the resulting expression.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.code_typed",
    "page": "Essentials",
    "title": "Base.code_typed",
    "category": "function",
    "text": "code_typed(f, types; optimize=true)\n\nReturns an array of lowered and type-inferred ASTs for the methods matching the given generic function and type signature. The keyword argument optimize controls whether additional optimizations, such as inlining, are also applied.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.@code_typed",
    "page": "Essentials",
    "title": "Base.@code_typed",
    "category": "macro",
    "text": "@code_typed\n\nEvaluates the arguments to the function or macro call, determines their types, and calls code_typed on the resulting expression.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.code_warntype",
    "page": "Essentials",
    "title": "Base.code_warntype",
    "category": "function",
    "text": "code_warntype([io::IO], f, types)\n\nPrints lowered and type-inferred ASTs for the methods matching the given generic function and type signature to io which defaults to STDOUT. The ASTs are annotated in such a way as to cause \"non-leaf\" types to be emphasized (if color is available, displayed in red). This serves as a warning of potential type instability. Not all non-leaf types are particularly problematic for performance, so the results need to be used judiciously. See @code_warntype for more information.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.@code_warntype",
    "page": "Essentials",
    "title": "Base.@code_warntype",
    "category": "macro",
    "text": "@code_warntype\n\nEvaluates the arguments to the function or macro call, determines their types, and calls code_warntype on the resulting expression.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.code_llvm",
    "page": "Essentials",
    "title": "Base.code_llvm",
    "category": "function",
    "text": "code_llvm([io], f, types)\n\nPrints the LLVM bitcodes generated for running the method matching the given generic function and type signature to io which defaults to STDOUT.\n\nAll metadata and dbg.* calls are removed from the printed bitcode. Use code_llvm_raw for the full IR.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.@code_llvm",
    "page": "Essentials",
    "title": "Base.@code_llvm",
    "category": "macro",
    "text": "@code_llvm\n\nEvaluates the arguments to the function or macro call, determines their types, and calls code_llvm on the resulting expression.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.code_native",
    "page": "Essentials",
    "title": "Base.code_native",
    "category": "function",
    "text": "code_native([io], f, types, [syntax])\n\nPrints the native assembly instructions generated for running the method matching the given generic function and type signature to io which defaults to STDOUT. Switch assembly syntax using syntax symbol parameter set to :att for AT&T syntax or :intel for Intel syntax. Output is AT&T syntax by default.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.@code_native",
    "page": "Essentials",
    "title": "Base.@code_native",
    "category": "macro",
    "text": "@code_native\n\nEvaluates the arguments to the function or macro call, determines their types, and calls code_native on the resulting expression.\n\n\n\n"
},

{
    "location": "stdlib/base/#Base.precompile",
    "page": "Essentials",
    "title": "Base.precompile",
    "category": "function",
    "text": "precompile(f,args::Tuple{Vararg{Any}})\n\nCompile the given function f for the argument tuple (of types) args, but do not execute it.\n\n\n\n"
},

{
    "location": "stdlib/base/#Internals-1",
    "page": "Essentials",
    "title": "Internals",
    "category": "section",
    "text": "Base.gc\nBase.gc_enable\nBase.macroexpand\nBase.@macroexpand\nBase.expand\nBase.code_lowered\nBase.@code_lowered\nBase.code_typed\nBase.@code_typed\nBase.code_warntype\nBase.@code_warntype\nBase.code_llvm\nBase.@code_llvm\nBase.code_native\nBase.@code_native\nBase.precompile"
},

{
    "location": "stdlib/collections/#",
    "page": "Collections and Data Structures",
    "title": "Collections and Data Structures",
    "category": "page",
    "text": ""
},

{
    "location": "stdlib/collections/#Collections-and-Data-Structures-1",
    "page": "Collections and Data Structures",
    "title": "Collections and Data Structures",
    "category": "section",
    "text": ""
},

{
    "location": "stdlib/collections/#Base.start",
    "page": "Collections and Data Structures",
    "title": "Base.start",
    "category": "function",
    "text": "start(iter) -> state\n\nGet initial iteration state for an iterable object.\n\nExamples\n\njulia> start(1:5)\n1\n\njulia> start([1;2;3])\n1\n\njulia> start([4;2;3])\n1\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.done",
    "page": "Collections and Data Structures",
    "title": "Base.done",
    "category": "function",
    "text": "done(iter, state) -> Bool\n\nTest whether we are done iterating.\n\nExamples\n\njulia> done(1:5, 3)\nfalse\n\njulia> done(1:5, 5)\nfalse\n\njulia> done(1:5, 6)\ntrue\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.next",
    "page": "Collections and Data Structures",
    "title": "Base.next",
    "category": "function",
    "text": "next(iter, state) -> item, state\n\nFor a given iterable object and iteration state, return the current item and the next iteration state.\n\nExamples\n\njulia> next(1:5, 3)\n(3, 4)\n\njulia> next(1:5, 5)\n(5, 6)\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.iteratorsize",
    "page": "Collections and Data Structures",
    "title": "Base.iteratorsize",
    "category": "function",
    "text": "iteratorsize(itertype::Type) -> IteratorSize\n\nGiven the type of an iterator, returns one of the following values:\n\nSizeUnknown() if the length (number of elements) cannot be determined in advance.\nHasLength() if there is a fixed, finite length.\nHasShape() if there is a known length plus a notion of multidimensional shape (as for an array).  In this case the size function is valid for the iterator.\nIsInfinite() if the iterator yields values forever.\n\nThe default value (for iterators that do not define this function) is HasLength(). This means that most iterators are assumed to implement length.\n\nThis trait is generally used to select between algorithms that pre-allocate space for their result, and algorithms that resize their result incrementally.\n\njulia> Base.iteratorsize(1:5)\nBase.HasShape()\n\njulia> Base.iteratorsize((2,3))\nBase.HasLength()\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.iteratoreltype",
    "page": "Collections and Data Structures",
    "title": "Base.iteratoreltype",
    "category": "function",
    "text": "iteratoreltype(itertype::Type) -> IteratorEltype\n\nGiven the type of an iterator, returns one of the following values:\n\nEltypeUnknown() if the type of elements yielded by the iterator is not known in advance.\nHasEltype() if the element type is known, and eltype would return a meaningful value.\n\nHasEltype() is the default, since iterators are assumed to implement eltype.\n\nThis trait is generally used to select between algorithms that pre-allocate a specific type of result, and algorithms that pick a result type based on the types of yielded values.\n\njulia> Base.iteratoreltype(1:5)\nBase.HasEltype()\n\n\n\n"
},

{
    "location": "stdlib/collections/#lib-collections-iteration-1",
    "page": "Collections and Data Structures",
    "title": "Iteration",
    "category": "section",
    "text": "Sequential iteration is implemented by the methods start(), done(), and next(). The general for loop:for i = I   # or  \"for i in I\"\n    # body\nendis translated into:state = start(I)\nwhile !done(I, state)\n    (i, state) = next(I, state)\n    # body\nendThe state object may be anything, and should be chosen appropriately for each iterable type. See the manual section on the iteration interface for more details about defining a custom iterable type.Base.start\nBase.done\nBase.next\nBase.iteratorsize\nBase.iteratoreltypeFully implemented by:Range\nUnitRange\nTuple\nNumber\nAbstractArray\nIntSet\nObjectIdDict\nDict\nWeakKeyDict\nEachLine\nAbstractString\nSet"
},

{
    "location": "stdlib/collections/#Base.isempty",
    "page": "Collections and Data Structures",
    "title": "Base.isempty",
    "category": "function",
    "text": "isempty(collection) -> Bool\n\nDetermine whether a collection is empty (has no elements).\n\nExamples\n\njulia> isempty([])\ntrue\n\njulia> isempty([1 2 3])\nfalse\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.empty!",
    "page": "Collections and Data Structures",
    "title": "Base.empty!",
    "category": "function",
    "text": "empty!(collection) -> collection\n\nRemove all elements from a collection.\n\njulia> A = Dict(\"a\" => 1, \"b\" => 2)\nDict{String,Int64} with 2 entries:\n  \"b\" => 2\n  \"a\" => 1\n\njulia> empty!(A);\n\njulia> A\nDict{String,Int64} with 0 entries\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.length-Tuple{Any}",
    "page": "Collections and Data Structures",
    "title": "Base.length",
    "category": "method",
    "text": "length(collection) -> Integer\n\nFor ordered, indexable collections, returns the maximum index i for which getindex(collection, i) is valid. For unordered collections, returns the number of elements.\n\nExamples\n\njulia> length(1:5)\n5\n\njulia> length([1; 2; 3; 4])\n4\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.endof",
    "page": "Collections and Data Structures",
    "title": "Base.endof",
    "category": "function",
    "text": "endof(collection) -> Integer\n\nReturns the last index of the collection.\n\nExample\n\njulia> endof([1,2,4])\n3\n\n\n\n"
},

{
    "location": "stdlib/collections/#General-Collections-1",
    "page": "Collections and Data Structures",
    "title": "General Collections",
    "category": "section",
    "text": "Base.isempty\nBase.empty!\nBase.length(::Any)\nBase.endofFully implemented by:Range\nUnitRange\nTuple\nNumber\nAbstractArray\nIntSet\nObjectIdDict\nDict\nWeakKeyDict\nAbstractString\nSet"
},

{
    "location": "stdlib/collections/#Base.in",
    "page": "Collections and Data Structures",
    "title": "Base.in",
    "category": "function",
    "text": "in(item, collection) -> Bool\n∈(item,collection) -> Bool\n∋(collection,item) -> Bool\n∉(item,collection) -> Bool\n∌(collection,item) -> Bool\n\nDetermine whether an item is in the given collection, in the sense that it is == to one of the values generated by iterating over the collection. Some collections need a slightly different definition; for example Sets check whether the item isequal to one of the elements. Dicts look for (key,value) pairs, and the key is compared using isequal. To test for the presence of a key in a dictionary, use haskey or k in keys(dict).\n\njulia> a = 1:3:20\n1:3:19\n\njulia> 4 in a\ntrue\n\njulia> 5 in a\nfalse\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.eltype",
    "page": "Collections and Data Structures",
    "title": "Base.eltype",
    "category": "function",
    "text": "eltype(type)\n\nDetermine the type of the elements generated by iterating a collection of the given type. For associative collection types, this will be a Pair{KeyType,ValType}. The definition eltype(x) = eltype(typeof(x)) is provided for convenience so that instances can be passed instead of types. However the form that accepts a type argument should be defined for new types.\n\njulia> eltype(ones(Float32,2,2))\nFloat32\n\njulia> eltype(ones(Int8,2,2))\nInt8\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.indexin",
    "page": "Collections and Data Structures",
    "title": "Base.indexin",
    "category": "function",
    "text": "indexin(a, b)\n\nReturns a vector containing the highest index in b for each value in a that is a member of b . The output vector contains 0 wherever a is not a member of b.\n\nExamples\n\njulia> a = [\'a\', \'b\', \'c\', \'b\', \'d\', \'a\'];\n\njulia> b = [\'a\',\'b\',\'c\'];\n\njulia> indexin(a,b)\n6-element Array{Int64,1}:\n 1\n 2\n 3\n 2\n 0\n 1\n\njulia> indexin(b,a)\n3-element Array{Int64,1}:\n 6\n 4\n 3\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.findin",
    "page": "Collections and Data Structures",
    "title": "Base.findin",
    "category": "function",
    "text": "findin(a, b)\n\nReturns the indices of elements in collection a that appear in collection b.\n\nExamples\n\njulia> a = collect(1:3:15)\n5-element Array{Int64,1}:\n  1\n  4\n  7\n 10\n 13\n\njulia> b = collect(2:4:10)\n3-element Array{Int64,1}:\n  2\n  6\n 10\n\njulia> findin(a,b) # 10 is the only common element\n1-element Array{Int64,1}:\n 4\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.unique",
    "page": "Collections and Data Structures",
    "title": "Base.unique",
    "category": "function",
    "text": "unique(itr)\n\nReturns an array containing one value from itr for each unique value, as determined by isequal.\n\njulia> unique([1; 2; 2; 6])\n3-element Array{Int64,1}:\n 1\n 2\n 6\n\n\n\nunique(f, itr)\n\nReturns an array containing one value from itr for each unique value produced by f applied to elements of itr.\n\njulia> unique(isodd, [1; 2; 2; 6])\n2-element Array{Int64,1}:\n 1\n 2\n\n\n\nunique(itr[, dim])\n\nReturns an array containing only the unique elements of the iterable itr, in the order that the first of each set of equivalent elements originally appears. If dim is specified, returns unique regions of the array itr along dim.\n\njulia> A = map(isodd, reshape(collect(1:8), (2,2,2)))\n2×2×2 Array{Bool,3}:\n[:, :, 1] =\n  true   true\n false  false\n\n[:, :, 2] =\n  true   true\n false  false\n\njulia> unique(A)\n2-element Array{Bool,1}:\n  true\n false\n\njulia> unique(A, 2)\n2×1×2 Array{Bool,3}:\n[:, :, 1] =\n  true\n false\n\n[:, :, 2] =\n  true\n false\n\njulia> unique(A, 3)\n2×2×1 Array{Bool,3}:\n[:, :, 1] =\n  true   true\n false  false\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.allunique",
    "page": "Collections and Data Structures",
    "title": "Base.allunique",
    "category": "function",
    "text": "allunique(itr) -> Bool\n\nReturn true if all values from itr are distinct when compared with isequal.\n\njulia> a = [1; 2; 3]\n3-element Array{Int64,1}:\n 1\n 2\n 3\n\njulia> allunique([a, a])\nfalse\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.reduce-Tuple{Any,Any,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.reduce",
    "category": "method",
    "text": "reduce(op, v0, itr)\n\nReduce the given collection ìtr with the given binary operator op. v0 must be a neutral element for op that will be returned for empty collections. It is unspecified whether v0 is used for non-empty collections.\n\nReductions for certain commonly-used operators have special implementations which should be used instead: maximum(itr), minimum(itr), sum(itr), prod(itr), any(itr), all(itr).\n\nThe associativity of the reduction is implementation dependent. This means that you can\'t use non-associative operations like - because it is undefined whether reduce(-,[1,2,3]) should be evaluated as (1-2)-3 or 1-(2-3). Use foldl or foldr instead for guaranteed left or right associativity.\n\nSome operations accumulate error, and parallelism will also be easier if the reduction can be executed in groups. Future versions of Julia might change the algorithm. Note that the elements are not reordered if you use an ordered collection.\n\nExamples\n\njulia> reduce(*, 1, [2; 3; 4])\n24\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.reduce-Tuple{Any,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.reduce",
    "category": "method",
    "text": "reduce(op, itr)\n\nLike reduce(op, v0, itr). This cannot be used with empty collections, except for some special cases (e.g. when op is one of +, *, max, min, &, |) when Julia can determine the neutral element of op.\n\njulia> reduce(*, [2; 3; 4])\n24\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.foldl-Tuple{Any,Any,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.foldl",
    "category": "method",
    "text": "foldl(op, v0, itr)\n\nLike reduce, but with guaranteed left associativity. v0 will be used exactly once.\n\njulia> foldl(-, 1, 2:5)\n-13\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.foldl-Tuple{Any,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.foldl",
    "category": "method",
    "text": "foldl(op, itr)\n\nLike foldl(op, v0, itr), but using the first element of itr as v0. In general, this cannot be used with empty collections (see reduce(op, itr)).\n\njulia> foldl(-, 2:5)\n-10\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.foldr-Tuple{Any,Any,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.foldr",
    "category": "method",
    "text": "foldr(op, v0, itr)\n\nLike reduce, but with guaranteed right associativity. v0 will be used exactly once.\n\njulia> foldr(-, 1, 2:5)\n-1\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.foldr-Tuple{Any,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.foldr",
    "category": "method",
    "text": "foldr(op, itr)\n\nLike foldr(op, v0, itr), but using the last element of itr as v0. In general, this cannot be used with empty collections (see reduce(op, itr)).\n\njulia> foldr(-, 2:5)\n-2\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.maximum-Tuple{Any}",
    "page": "Collections and Data Structures",
    "title": "Base.maximum",
    "category": "method",
    "text": "maximum(itr)\n\nReturns the largest element in a collection.\n\njulia> maximum(-20.5:10)\n9.5\n\njulia> maximum([1,2,3])\n3\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.maximum-Tuple{Any,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.maximum",
    "category": "method",
    "text": "maximum(A, dims)\n\nCompute the maximum value of an array over the given dimensions. See also the max(a,b) function to take the maximum of two or more arguments, which can be applied elementwise to arrays via max.(a,b).\n\njulia> A = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> maximum(A, 1)\n1×2 Array{Int64,2}:\n 3  4\n\njulia> maximum(A, 2)\n2×1 Array{Int64,2}:\n 2\n 4\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.maximum!",
    "page": "Collections and Data Structures",
    "title": "Base.maximum!",
    "category": "function",
    "text": "maximum!(r, A)\n\nCompute the maximum value of A over the singleton dimensions of r, and write results to r.\n\nExamples\n\njulia> A = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> maximum!([1; 1], A)\n2-element Array{Int64,1}:\n 2\n 4\n\njulia> maximum!([1 1], A)\n1×2 Array{Int64,2}:\n 3  4\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.minimum-Tuple{Any}",
    "page": "Collections and Data Structures",
    "title": "Base.minimum",
    "category": "method",
    "text": "minimum(itr)\n\nReturns the smallest element in a collection.\n\njulia> minimum(-20.5:10)\n-20.5\n\njulia> minimum([1,2,3])\n1\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.minimum-Tuple{Any,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.minimum",
    "category": "method",
    "text": "minimum(A, dims)\n\nCompute the minimum value of an array over the given dimensions. See also the min(a,b) function to take the minimum of two or more arguments, which can be applied elementwise to arrays via min.(a,b).\n\nExamples\n\njulia> A = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> minimum(A, 1)\n1×2 Array{Int64,2}:\n 1  2\n\njulia> minimum(A, 2)\n2×1 Array{Int64,2}:\n 1\n 3\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.minimum!",
    "page": "Collections and Data Structures",
    "title": "Base.minimum!",
    "category": "function",
    "text": "minimum!(r, A)\n\nCompute the minimum value of A over the singleton dimensions of r, and write results to r.\n\nExamples\n\njulia> A = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> minimum!([1; 1], A)\n2-element Array{Int64,1}:\n 1\n 3\n\njulia> minimum!([1 1], A)\n1×2 Array{Int64,2}:\n 1  2\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.extrema-Tuple{Any}",
    "page": "Collections and Data Structures",
    "title": "Base.extrema",
    "category": "method",
    "text": "extrema(itr) -> Tuple\n\nCompute both the minimum and maximum element in a single pass, and return them as a 2-tuple.\n\njulia> extrema(2:10)\n(2, 10)\n\njulia> extrema([9,pi,4.5])\n(3.141592653589793, 9.0)\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.extrema-Tuple{AbstractArray,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.extrema",
    "category": "method",
    "text": "extrema(A, dims) -> Array{Tuple}\n\nCompute the minimum and maximum elements of an array over the given dimensions.\n\nExample\n\njulia> A = reshape(collect(1:2:16), (2,2,2))\n2×2×2 Array{Int64,3}:\n[:, :, 1] =\n 1  5\n 3  7\n\n[:, :, 2] =\n  9  13\n 11  15\n\njulia> extrema(A, (1,2))\n1×1×2 Array{Tuple{Int64,Int64},3}:\n[:, :, 1] =\n (1, 7)\n\n[:, :, 2] =\n (9, 15)\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.indmax",
    "page": "Collections and Data Structures",
    "title": "Base.indmax",
    "category": "function",
    "text": "indmax(itr) -> Integer\n\nReturns the index of the maximum element in a collection. If there are multiple maximal elements, then the first one will be returned. NaN values are ignored, unless all elements are NaN.\n\nThe collection must not be empty.\n\nExamples\n\njulia> indmax([8,0.1,-9,pi])\n1\n\njulia> indmax([1,7,7,6])\n2\n\njulia> indmax([1,7,7,NaN])\n2\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.indmin",
    "page": "Collections and Data Structures",
    "title": "Base.indmin",
    "category": "function",
    "text": "indmin(itr) -> Integer\n\nReturns the index of the minimum element in a collection. If there are multiple minimal elements, then the first one will be returned. NaN values are ignored, unless all elements are NaN.\n\nThe collection must not be empty.\n\nExamples\n\njulia> indmin([8,0.1,-9,pi])\n3\n\njulia> indmin([7,1,1,6])\n2\n\njulia> indmin([7,1,1,NaN])\n2\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.findmax-Tuple{Any}",
    "page": "Collections and Data Structures",
    "title": "Base.findmax",
    "category": "method",
    "text": "findmax(itr) -> (x, index)\n\nReturns the maximum element of the collection itr and its index. If there are multiple maximal elements, then the first one will be returned. NaN values are ignored, unless all elements are NaN.\n\nThe collection must not be empty.\n\nExamples\n\njulia> findmax([8,0.1,-9,pi])\n(8.0, 1)\n\njulia> findmax([1,7,7,6])\n(7, 2)\n\njulia> findmax([1,7,7,NaN])\n(7.0, 2)\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.findmax-Tuple{AbstractArray,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.findmax",
    "category": "method",
    "text": "findmax(A, region) -> (maxval, index)\n\nFor an array input, returns the value and index of the maximum over the given region.\n\nExamples\n\njulia> A = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> findmax(A,1)\n([3 4], [2 4])\n\njulia> findmax(A,2)\n([2; 4], [3; 4])\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.findmin-Tuple{Any}",
    "page": "Collections and Data Structures",
    "title": "Base.findmin",
    "category": "method",
    "text": "findmin(itr) -> (x, index)\n\nReturns the minimum element of the collection itr and its index. If there are multiple minimal elements, then the first one will be returned. NaN values are ignored, unless all elements are NaN.\n\nThe collection must not be empty.\n\nExamples\n\njulia> findmin([8,0.1,-9,pi])\n(-9.0, 3)\n\njulia> findmin([7,1,1,6])\n(1, 2)\n\njulia> findmin([7,1,1,NaN])\n(1.0, 2)\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.findmin-Tuple{AbstractArray,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.findmin",
    "category": "method",
    "text": "findmin(A, region) -> (minval, index)\n\nFor an array input, returns the value and index of the minimum over the given region.\n\nExamples\n\njulia> A = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> findmin(A, 1)\n([1 2], [1 3])\n\njulia> findmin(A, 2)\n([1; 3], [1; 2])\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.findmax!",
    "page": "Collections and Data Structures",
    "title": "Base.findmax!",
    "category": "function",
    "text": "findmax!(rval, rind, A, [init=true]) -> (maxval, index)\n\nFind the maximum of A and the corresponding linear index along singleton dimensions of rval and rind, and store the results in rval and rind.\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.findmin!",
    "page": "Collections and Data Structures",
    "title": "Base.findmin!",
    "category": "function",
    "text": "findmin!(rval, rind, A, [init=true]) -> (minval, index)\n\nFind the minimum of A and the corresponding linear index along singleton dimensions of rval and rind, and store the results in rval and rind.\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.sum",
    "page": "Collections and Data Structures",
    "title": "Base.sum",
    "category": "function",
    "text": "sum(f, itr)\n\nSum the results of calling function f on each element of itr.\n\njulia> sum(abs2, [2; 3; 4])\n29\n\n\n\nsum(itr)\n\nReturns the sum of all elements in a collection.\n\njulia> sum(1:20)\n210\n\n\n\nsum(A, dims)\n\nSum elements of an array over the given dimensions.\n\nExamples\n\njulia> A = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> sum(A, 1)\n1×2 Array{Int64,2}:\n 4  6\n\njulia> sum(A, 2)\n2×1 Array{Int64,2}:\n 3\n 7\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.sum!",
    "page": "Collections and Data Structures",
    "title": "Base.sum!",
    "category": "function",
    "text": "sum!(r, A)\n\nSum elements of A over the singleton dimensions of r, and write results to r.\n\nExamples\n\njulia> A = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> sum!([1; 1], A)\n2-element Array{Int64,1}:\n 3\n 7\n\njulia> sum!([1 1], A)\n1×2 Array{Int64,2}:\n 4  6\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.prod",
    "page": "Collections and Data Structures",
    "title": "Base.prod",
    "category": "function",
    "text": "prod(f, itr)\n\nReturns the product of f applied to each element of itr.\n\njulia> prod(abs2, [2; 3; 4])\n576\n\n\n\nprod(itr)\n\nReturns the product of all elements of a collection.\n\njulia> prod(1:20)\n2432902008176640000\n\n\n\nprod(A, dims)\n\nMultiply elements of an array over the given dimensions.\n\nExamples\n\njulia> A = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> prod(A, 1)\n1×2 Array{Int64,2}:\n 3  8\n\njulia> prod(A, 2)\n2×1 Array{Int64,2}:\n  2\n 12\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.prod!",
    "page": "Collections and Data Structures",
    "title": "Base.prod!",
    "category": "function",
    "text": "prod!(r, A)\n\nMultiply elements of A over the singleton dimensions of r, and write results to r.\n\nExamples\n\njulia> A = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> prod!([1; 1], A)\n2-element Array{Int64,1}:\n  2\n 12\n\njulia> prod!([1 1], A)\n1×2 Array{Int64,2}:\n 3  8\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.any-Tuple{Any}",
    "page": "Collections and Data Structures",
    "title": "Base.any",
    "category": "method",
    "text": "any(itr) -> Bool\n\nTest whether any elements of a boolean collection are true, returning true as soon as the first true value in itr is encountered (short-circuiting).\n\njulia> a = [true,false,false,true]\n4-element Array{Bool,1}:\n  true\n false\n false\n  true\n\njulia> any(a)\ntrue\n\njulia> any((println(i); v) for (i, v) in enumerate(a))\n1\ntrue\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.any-Tuple{AbstractArray,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.any",
    "category": "method",
    "text": "any(A, dims)\n\nTest whether any values along the given dimensions of an array are true.\n\nExamples\n\njulia> A = [true false; true false]\n2×2 Array{Bool,2}:\n true  false\n true  false\n\njulia> any(A, 1)\n1×2 Array{Bool,2}:\n true  false\n\njulia> any(A, 2)\n2×1 Array{Bool,2}:\n true\n true\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.any!",
    "page": "Collections and Data Structures",
    "title": "Base.any!",
    "category": "function",
    "text": "any!(r, A)\n\nTest whether any values in A along the singleton dimensions of r are true, and write results to r.\n\nExamples\n\njulia> A = [true false; true false]\n2×2 Array{Bool,2}:\n true  false\n true  false\n\njulia> any!([1; 1], A)\n2-element Array{Int64,1}:\n 1\n 1\n\njulia> any!([1 1], A)\n1×2 Array{Int64,2}:\n 1  0\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.all-Tuple{Any}",
    "page": "Collections and Data Structures",
    "title": "Base.all",
    "category": "method",
    "text": "all(itr) -> Bool\n\nTest whether all elements of a boolean collection are true, returning false as soon as the first false value in itr is encountered (short-circuiting).\n\njulia> a = [true,false,false,true]\n4-element Array{Bool,1}:\n  true\n false\n false\n  true\n\njulia> all(a)\nfalse\n\njulia> all((println(i); v) for (i, v) in enumerate(a))\n1\n2\nfalse\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.all-Tuple{AbstractArray,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.all",
    "category": "method",
    "text": "all(A, dims)\n\nTest whether all values along the given dimensions of an array are true.\n\nExamples\n\njulia> A = [true false; true true]\n2×2 Array{Bool,2}:\n true  false\n true   true\n\njulia> all(A, 1)\n1×2 Array{Bool,2}:\n true  false\n\njulia> all(A, 2)\n2×1 Array{Bool,2}:\n false\n  true\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.all!",
    "page": "Collections and Data Structures",
    "title": "Base.all!",
    "category": "function",
    "text": "all!(r, A)\n\nTest whether all values in A along the singleton dimensions of r are true, and write results to r.\n\nExamples\n\njulia> A = [true false; true false]\n2×2 Array{Bool,2}:\n true  false\n true  false\n\njulia> all!([1; 1], A)\n2-element Array{Int64,1}:\n 0\n 0\n\njulia> all!([1 1], A)\n1×2 Array{Int64,2}:\n 1  0\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.count",
    "page": "Collections and Data Structures",
    "title": "Base.count",
    "category": "function",
    "text": "count(p, itr) -> Integer\ncount(itr) -> Integer\n\nCount the number of elements in itr for which predicate p returns true. If p is omitted, counts the number of true elements in itr (which should be a collection of boolean values).\n\njulia> count(i->(4<=i<=6), [2,3,4,5,6])\n3\n\njulia> count([true, false, true, true])\n3\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.any-Tuple{Any,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.any",
    "category": "method",
    "text": "any(p, itr) -> Bool\n\nDetermine whether predicate p returns true for any elements of itr, returning true as soon as the first item in itr for which p returns true is encountered (short-circuiting).\n\njulia> any(i->(4<=i<=6), [3,5,7])\ntrue\n\njulia> any(i -> (println(i); i > 3), 1:10)\n1\n2\n3\n4\ntrue\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.all-Tuple{Any,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.all",
    "category": "method",
    "text": "all(p, itr) -> Bool\n\nDetermine whether predicate p returns true for all elements of itr, returning false as soon as the first item in itr for which p returns false is encountered (short-circuiting).\n\njulia> all(i->(4<=i<=6), [4,5,6])\ntrue\n\njulia> all(i -> (println(i); i < 3), 1:10)\n1\n2\n3\nfalse\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.foreach",
    "page": "Collections and Data Structures",
    "title": "Base.foreach",
    "category": "function",
    "text": "foreach(f, c...) -> Void\n\nCall function f on each element of iterable c. For multiple iterable arguments, f is called elementwise. foreach should be used instead of map when the results of f are not needed, for example in foreach(println, array).\n\nExample\n\njulia> a = 1:3:7;\n\njulia> foreach(x -> println(x^2), a)\n1\n16\n49\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.map",
    "page": "Collections and Data Structures",
    "title": "Base.map",
    "category": "function",
    "text": "map(f, c...) -> collection\n\nTransform collection c by applying f to each element. For multiple collection arguments, apply f elementwise.\n\nExamples\n\njulia> map(x -> x * 2, [1, 2, 3])\n3-element Array{Int64,1}:\n 2\n 4\n 6\n\njulia> map(+, [1, 2, 3], [10, 20, 30])\n3-element Array{Int64,1}:\n 11\n 22\n 33\n\n\n\nmap(f, x::Nullable)\n\nReturn f applied to the value of x if it has one, as a Nullable. If x is null, then return a null value of type Nullable{S}. S is guaranteed to be either Union{} or a concrete type. Whichever of these is chosen is an implementation detail, but typically the choice that maximizes performance would be used. If x has a value, then the return type is guaranteed to be of type Nullable{typeof(f(x))}.\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.map!",
    "page": "Collections and Data Structures",
    "title": "Base.map!",
    "category": "function",
    "text": "map!(function, destination, collection...)\n\nLike map, but stores the result in destination rather than a new collection. destination must be at least as large as the first collection.\n\nExample\n\njulia> x = zeros(3);\n\njulia> map!(x -> x * 2, x, [1, 2, 3]);\n\njulia> x\n3-element Array{Float64,1}:\n 2.0\n 4.0\n 6.0\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.mapreduce-NTuple{4,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.mapreduce",
    "category": "method",
    "text": "mapreduce(f, op, v0, itr)\n\nApply function f to each element in itr, and then reduce the result using the binary function op. v0 must be a neutral element for op that will be returned for empty collections. It is unspecified whether v0 is used for non-empty collections.\n\nmapreduce is functionally equivalent to calling reduce(op, v0, map(f, itr)), but will in general execute faster since no intermediate collection needs to be created. See documentation for reduce and map.\n\njulia> mapreduce(x->x^2, +, [1:3;]) # == 1 + 4 + 9\n14\n\nThe associativity of the reduction is implementation-dependent. Additionally, some implementations may reuse the return value of f for elements that appear multiple times in itr. Use mapfoldl or mapfoldr instead for guaranteed left or right associativity and invocation of f for every value.\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.mapreduce-Tuple{Any,Any,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.mapreduce",
    "category": "method",
    "text": "mapreduce(f, op, itr)\n\nLike mapreduce(f, op, v0, itr). In general, this cannot be used with empty collections (see reduce(op, itr)).\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.mapfoldl-NTuple{4,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.mapfoldl",
    "category": "method",
    "text": "mapfoldl(f, op, v0, itr)\n\nLike mapreduce, but with guaranteed left associativity, as in foldl. v0 will be used exactly once.\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.mapfoldl-Tuple{Any,Any,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.mapfoldl",
    "category": "method",
    "text": "mapfoldl(f, op, itr)\n\nLike mapfoldl(f, op, v0, itr), but using the first element of itr as v0. In general, this cannot be used with empty collections (see reduce(op, itr)).\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.mapfoldr-NTuple{4,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.mapfoldr",
    "category": "method",
    "text": "mapfoldr(f, op, v0, itr)\n\nLike mapreduce, but with guaranteed right associativity, as in foldr. v0 will be used exactly once.\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.mapfoldr-Tuple{Any,Any,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.mapfoldr",
    "category": "method",
    "text": "mapfoldr(f, op, itr)\n\nLike mapfoldr(f, op, v0, itr), but using the first element of itr as v0. In general, this cannot be used with empty collections (see reduce(op, itr)).\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.first",
    "page": "Collections and Data Structures",
    "title": "Base.first",
    "category": "function",
    "text": "first(coll)\n\nGet the first element of an iterable collection. Returns the start point of a Range even if it is empty.\n\njulia> first(2:2:10)\n2\n\njulia> first([1; 2; 3; 4])\n1\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.last",
    "page": "Collections and Data Structures",
    "title": "Base.last",
    "category": "function",
    "text": "last(coll)\n\nGet the last element of an ordered collection, if it can be computed in O(1) time. This is accomplished by calling endof to get the last index. Returns the end point of a Range even if it is empty.\n\njulia> last(1:2:10)\n9\n\njulia> last([1; 2; 3; 4])\n4\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.step",
    "page": "Collections and Data Structures",
    "title": "Base.step",
    "category": "function",
    "text": "step(r)\n\nGet the step size of a Range object.\n\njulia> step(1:10)\n1\n\njulia> step(1:2:10)\n2\n\njulia> step(2.5:0.3:10.9)\n0.3\n\njulia> step(linspace(2.5,10.9,85))\n0.1\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.collect-Tuple{Any}",
    "page": "Collections and Data Structures",
    "title": "Base.collect",
    "category": "method",
    "text": "collect(collection)\n\nReturn an Array of all items in a collection or iterator. For associative collections, returns Pair{KeyType, ValType}. If the argument is array-like or is an iterator with the HasShape() trait, the result will have the same shape and number of dimensions as the argument.\n\nExample\n\njulia> collect(1:2:13)\n7-element Array{Int64,1}:\n  1\n  3\n  5\n  7\n  9\n 11\n 13\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.collect-Tuple{Type,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.collect",
    "category": "method",
    "text": "collect(element_type, collection)\n\nReturn an Array with the given element type of all items in a collection or iterable. The result has the same shape and number of dimensions as collection.\n\njulia> collect(Float64, 1:2:5)\n3-element Array{Float64,1}:\n 1.0\n 3.0\n 5.0\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.issubset-Tuple{Any,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.issubset",
    "category": "method",
    "text": "issubset(a, b)\n⊆(a,b) -> Bool\n⊈(a,b) -> Bool\n⊊(a,b) -> Bool\n\nDetermine whether every element of a is also in b, using in.\n\nExamples\n\njulia> issubset([1, 2], [1, 2, 3])\ntrue\n\njulia> issubset([1, 2, 3], [1, 2])\nfalse\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.filter",
    "page": "Collections and Data Structures",
    "title": "Base.filter",
    "category": "function",
    "text": "filter(function, collection)\n\nReturn a copy of collection, removing elements for which function is false. For associative collections, the function is passed two arguments (key and value).\n\nExamples\n\njulia> a = 1:10\n1:10\n\njulia> filter(isodd, a)\n5-element Array{Int64,1}:\n 1\n 3\n 5\n 7\n 9\n\njulia> d = Dict(1=>\"a\", 2=>\"b\")\nDict{Int64,String} with 2 entries:\n  2 => \"b\"\n  1 => \"a\"\n\njulia> filter((x,y)->isodd(x), d)\nDict{Int64,String} with 1 entry:\n  1 => \"a\"\n\n\n\nfilter(p, x::Nullable)\n\nReturn null if either x is null or p(get(x)) is false, and x otherwise.\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.filter!",
    "page": "Collections and Data Structures",
    "title": "Base.filter!",
    "category": "function",
    "text": "filter!(function, collection)\n\nUpdate collection, removing elements for which function is false. For associative collections, the function is passed two arguments (key and value).\n\nExample\n\njulia> filter!(isodd, collect(1:10))\n5-element Array{Int64,1}:\n 1\n 3\n 5\n 7\n 9\n\n\n\n"
},

{
    "location": "stdlib/collections/#Iterable-Collections-1",
    "page": "Collections and Data Structures",
    "title": "Iterable Collections",
    "category": "section",
    "text": "Base.in\nBase.eltype\nBase.indexin\nBase.findin\nBase.unique\nBase.allunique\nBase.reduce(::Any, ::Any, ::Any)\nBase.reduce(::Any, ::Any)\nBase.foldl(::Any, ::Any, ::Any)\nBase.foldl(::Any, ::Any)\nBase.foldr(::Any, ::Any, ::Any)\nBase.foldr(::Any, ::Any)\nBase.maximum(::Any)\nBase.maximum(::Any, ::Any)\nBase.maximum!\nBase.minimum(::Any)\nBase.minimum(::Any, ::Any)\nBase.minimum!\nBase.extrema(::Any)\nBase.extrema(::AbstractArray, ::Any)\nBase.indmax\nBase.indmin\nBase.findmax(::Any)\nBase.findmax(::AbstractArray, ::Any)\nBase.findmin(::Any)\nBase.findmin(::AbstractArray, ::Any)\nBase.findmax!\nBase.findmin!\nBase.sum\nBase.sum!\nBase.prod\nBase.prod!\nBase.any(::Any)\nBase.any(::AbstractArray, ::Any)\nBase.any!\nBase.all(::Any)\nBase.all(::AbstractArray, ::Any)\nBase.all!\nBase.count\nBase.any(::Any, ::Any)\nBase.all(::Any, ::Any)\nBase.foreach\nBase.map\nBase.map!\nBase.mapreduce(::Any, ::Any, ::Any, ::Any)\nBase.mapreduce(::Any, ::Any, ::Any)\nBase.mapfoldl(::Any, ::Any, ::Any, ::Any)\nBase.mapfoldl(::Any, ::Any, ::Any)\nBase.mapfoldr(::Any, ::Any, ::Any, ::Any)\nBase.mapfoldr(::Any, ::Any, ::Any)\nBase.first\nBase.last\nBase.step\nBase.collect(::Any)\nBase.collect(::Type, ::Any)\nBase.issubset(::Any, ::Any)\nBase.filter\nBase.filter!"
},

{
    "location": "stdlib/collections/#Base.getindex-Tuple{Any,Vararg{Any,N} where N}",
    "page": "Collections and Data Structures",
    "title": "Base.getindex",
    "category": "method",
    "text": "getindex(collection, key...)\n\nRetrieve the value(s) stored at the given key or index within a collection. The syntax a[i,j,...] is converted by the compiler to getindex(a, i, j, ...).\n\nExample\n\njulia> A = Dict(\"a\" => 1, \"b\" => 2)\nDict{String,Int64} with 2 entries:\n  \"b\" => 2\n  \"a\" => 1\n\njulia> getindex(A, \"a\")\n1\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.setindex!-Tuple{Any,Any,Vararg{Any,N} where N}",
    "page": "Collections and Data Structures",
    "title": "Base.setindex!",
    "category": "method",
    "text": "setindex!(collection, value, key...)\n\nStore the given value at the given key or index within a collection. The syntax a[i,j,...] = x is converted by the compiler to (setindex!(a, x, i, j, ...); x).\n\n\n\n"
},

{
    "location": "stdlib/collections/#Indexable-Collections-1",
    "page": "Collections and Data Structures",
    "title": "Indexable Collections",
    "category": "section",
    "text": "Base.getindex(::Any, ::Any...)\nBase.setindex!(::Any, ::Any, ::Any...)Fully implemented by:Array\nBitArray\nAbstractArray\nSubArray\nObjectIdDict\nDict\nWeakKeyDict\nAbstractStringPartially implemented by:Range\nUnitRange\nTuple"
},

{
    "location": "stdlib/collections/#Base.Dict",
    "page": "Collections and Data Structures",
    "title": "Base.Dict",
    "category": "type",
    "text": "Dict([itr])\n\nDict{K,V}() constructs a hash table with keys of type K and values of type V.\n\nGiven a single iterable argument, constructs a Dict whose key-value pairs are taken from 2-tuples (key,value) generated by the argument.\n\njulia> Dict([(\"A\", 1), (\"B\", 2)])\nDict{String,Int64} with 2 entries:\n  \"B\" => 2\n  \"A\" => 1\n\nAlternatively, a sequence of pair arguments may be passed.\n\njulia> Dict(\"A\"=>1, \"B\"=>2)\nDict{String,Int64} with 2 entries:\n  \"B\" => 2\n  \"A\" => 1\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.ObjectIdDict",
    "page": "Collections and Data Structures",
    "title": "Base.ObjectIdDict",
    "category": "type",
    "text": "ObjectIdDict([itr])\n\nObjectIdDict() constructs a hash table where the keys are (always) object identities.  Unlike Dict it is not parameterized on its key and value type and thus its eltype is always Pair{Any,Any}.\n\nSee Dict for further help.\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.WeakKeyDict",
    "page": "Collections and Data Structures",
    "title": "Base.WeakKeyDict",
    "category": "type",
    "text": "WeakKeyDict([itr])\n\nWeakKeyDict() constructs a hash table where the keys are weak references to objects, and thus may be garbage collected even when referenced in a hash table.\n\nSee Dict for further help.\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.haskey",
    "page": "Collections and Data Structures",
    "title": "Base.haskey",
    "category": "function",
    "text": "haskey(collection, key) -> Bool\n\nDetermine whether a collection has a mapping for a given key.\n\njulia> a = Dict(\'a\'=>2, \'b\'=>3)\nDict{Char,Int64} with 2 entries:\n  \'b\' => 3\n  \'a\' => 2\n\njulia> haskey(a,\'a\')\ntrue\n\njulia> haskey(a,\'c\')\nfalse\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.get-Tuple{Any,Any,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.get",
    "category": "method",
    "text": "get(collection, key, default)\n\nReturn the value stored for the given key, or the given default value if no mapping for the key is present.\n\nExamples\n\njulia> d = Dict(\"a\"=>1, \"b\"=>2);\n\njulia> get(d, \"a\", 3)\n1\n\njulia> get(d, \"c\", 3)\n3\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.get",
    "page": "Collections and Data Structures",
    "title": "Base.get",
    "category": "function",
    "text": "get(f::Function, collection, key)\n\nReturn the value stored for the given key, or if no mapping for the key is present, return f().  Use get! to also store the default value in the dictionary.\n\nThis is intended to be called using do block syntax\n\nget(dict, key) do\n    # default value calculated here\n    time()\nend\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.get!-Tuple{Any,Any,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.get!",
    "category": "method",
    "text": "get!(collection, key, default)\n\nReturn the value stored for the given key, or if no mapping for the key is present, store key => default, and return default.\n\nExamples\n\njulia> d = Dict(\"a\"=>1, \"b\"=>2, \"c\"=>3);\n\njulia> get!(d, \"a\", 5)\n1\n\njulia> get!(d, \"d\", 4)\n4\n\njulia> d\nDict{String,Int64} with 4 entries:\n  \"c\" => 3\n  \"b\" => 2\n  \"a\" => 1\n  \"d\" => 4\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.get!-Tuple{Function,Any,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.get!",
    "category": "method",
    "text": "get!(f::Function, collection, key)\n\nReturn the value stored for the given key, or if no mapping for the key is present, store key => f(), and return f().\n\nThis is intended to be called using do block syntax:\n\nget!(dict, key) do\n    # default value calculated here\n    time()\nend\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.getkey",
    "page": "Collections and Data Structures",
    "title": "Base.getkey",
    "category": "function",
    "text": "getkey(collection, key, default)\n\nReturn the key matching argument key if one exists in collection, otherwise return default.\n\njulia> a = Dict(\'a\'=>2, \'b\'=>3)\nDict{Char,Int64} with 2 entries:\n  \'b\' => 3\n  \'a\' => 2\n\njulia> getkey(a,\'a\',1)\n\'a\': ASCII/Unicode U+0061 (category Ll: Letter, lowercase)\n\njulia> getkey(a,\'d\',\'a\')\n\'a\': ASCII/Unicode U+0061 (category Ll: Letter, lowercase)\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.delete!",
    "page": "Collections and Data Structures",
    "title": "Base.delete!",
    "category": "function",
    "text": "delete!(collection, key)\n\nDelete the mapping for the given key in a collection, and return the collection.\n\nExample\n\njulia> d = Dict(\"a\"=>1, \"b\"=>2)\nDict{String,Int64} with 2 entries:\n  \"b\" => 2\n  \"a\" => 1\n\njulia> delete!(d, \"b\")\nDict{String,Int64} with 1 entry:\n  \"a\" => 1\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.pop!-Tuple{Any,Any,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.pop!",
    "category": "method",
    "text": "pop!(collection, key[, default])\n\nDelete and return the mapping for key if it exists in collection, otherwise return default, or throw an error if default is not specified.\n\nExamples\n\njulia> d = Dict(\"a\"=>1, \"b\"=>2, \"c\"=>3);\n\njulia> pop!(d, \"a\")\n1\n\njulia> pop!(d, \"d\")\nERROR: KeyError: key \"d\" not found\nStacktrace:\n [1] pop!(::Dict{String,Int64}, ::String) at ./dict.jl:539\n\njulia> pop!(d, \"e\", 4)\n4\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.keys",
    "page": "Collections and Data Structures",
    "title": "Base.keys",
    "category": "function",
    "text": "keys(a::Associative)\n\nReturn an iterator over all keys in a collection. collect(keys(a)) returns an array of keys. Since the keys are stored internally in a hash table, the order in which they are returned may vary. But keys(a) and values(a) both iterate a and return the elements in the same order.\n\njulia> a = Dict(\'a\'=>2, \'b\'=>3)\nDict{Char,Int64} with 2 entries:\n  \'b\' => 3\n  \'a\' => 2\n\njulia> collect(keys(a))\n2-element Array{Char,1}:\n \'b\'\n \'a\'\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.values",
    "page": "Collections and Data Structures",
    "title": "Base.values",
    "category": "function",
    "text": "values(a::Associative)\n\nReturn an iterator over all values in a collection. collect(values(a)) returns an array of values. Since the values are stored internally in a hash table, the order in which they are returned may vary. But keys(a) and values(a) both iterate a and return the elements in the same order.\n\njulia> a = Dict(\'a\'=>2, \'b\'=>3)\nDict{Char,Int64} with 2 entries:\n  \'b\' => 3\n  \'a\' => 2\n\njulia> collect(values(a))\n2-element Array{Int64,1}:\n 3\n 2\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.merge",
    "page": "Collections and Data Structures",
    "title": "Base.merge",
    "category": "function",
    "text": "merge(d::Associative, others::Associative...)\n\nConstruct a merged collection from the given collections. If necessary, the types of the resulting collection will be promoted to accommodate the types of the merged collections. If the same key is present in another collection, the value for that key will be the value it has in the last collection listed.\n\njulia> a = Dict(\"foo\" => 0.0, \"bar\" => 42.0)\nDict{String,Float64} with 2 entries:\n  \"bar\" => 42.0\n  \"foo\" => 0.0\n\njulia> b = Dict(\"baz\" => 17, \"bar\" => 4711)\nDict{String,Int64} with 2 entries:\n  \"bar\" => 4711\n  \"baz\" => 17\n\njulia> merge(a, b)\nDict{String,Float64} with 3 entries:\n  \"bar\" => 4711.0\n  \"baz\" => 17.0\n  \"foo\" => 0.0\n\njulia> merge(b, a)\nDict{String,Float64} with 3 entries:\n  \"bar\" => 42.0\n  \"baz\" => 17.0\n  \"foo\" => 0.0\n\n\n\nmerge(combine, d::Associative, others::Associative...)\n\nConstruct a merged collection from the given collections. If necessary, the types of the resulting collection will be promoted to accommodate the types of the merged collections. Values with the same key will be combined using the combiner function.\n\njulia> a = Dict(\"foo\" => 0.0, \"bar\" => 42.0)\nDict{String,Float64} with 2 entries:\n  \"bar\" => 42.0\n  \"foo\" => 0.0\n\njulia> b = Dict(\"baz\" => 17, \"bar\" => 4711)\nDict{String,Int64} with 2 entries:\n  \"bar\" => 4711\n  \"baz\" => 17\n\njulia> merge(+, a, b)\nDict{String,Float64} with 3 entries:\n  \"bar\" => 4753.0\n  \"baz\" => 17.0\n  \"foo\" => 0.0\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.merge!",
    "page": "Collections and Data Structures",
    "title": "Base.merge!",
    "category": "function",
    "text": "Merge changes into current head \n\n\n\nInternal implementation of merge. Returns true if merge was successful, otherwise false\n\n\n\nmerge!(repo::GitRepo; kwargs...) -> Bool\n\nPerform a git merge on the repository repo, merging commits with diverging history into the current branch. Returns true if the merge succeeded, false if not.\n\nThe keyword arguments are:\n\ncommittish::AbstractString=\"\": Merge the named commit(s) in committish.\nbranch::AbstractString=\"\": Merge the branch branch and all its commits since it diverged from the current branch.\nfastforward::Bool=false: If fastforward is true, only merge if the merge is a fast-forward (the current branch head is an ancestor of the commits to be merged), otherwise refuse to merge and return false. This is equivalent to the git CLI option --ff-only.\nmerge_opts::MergeOptions=MergeOptions(): merge_opts specifies options for the merge, such as merge strategy in case of conflicts.\ncheckout_opts::CheckoutOptions=CheckoutOptions(): checkout_opts specifies options for the checkout step.\n\nEquivalent to git merge [--ff-only] [<committish> | <branch>].\n\nnote: Note\nIf you specify a branch, this must be done in reference format, since the string will be turned into a GitReference. For example, if you wanted to merge branch branch_a, you would call merge!(repo, branch=\"refs/heads/branch_a\").\n\n\n\nmerge!(d::Associative, others::Associative...)\n\nUpdate collection with pairs from the other collections. See also merge.\n\njulia> d1 = Dict(1 => 2, 3 => 4);\n\njulia> d2 = Dict(1 => 4, 4 => 5);\n\njulia> merge!(d1, d2);\n\njulia> d1\nDict{Int64,Int64} with 3 entries:\n  4 => 5\n  3 => 4\n  1 => 4\n\n\n\nmerge!(combine, d::Associative, others::Associative...)\n\nUpdate collection with pairs from the other collections. Values with the same key will be combined using the combiner function.\n\njulia> d1 = Dict(1 => 2, 3 => 4);\n\njulia> d2 = Dict(1 => 4, 4 => 5);\n\njulia> merge!(+, d1, d2);\n\njulia> d1\nDict{Int64,Int64} with 3 entries:\n  4 => 5\n  3 => 4\n  1 => 6\n\njulia> merge!(-, d1, d1);\n\njulia> d1\nDict{Int64,Int64} with 3 entries:\n  4 => 0\n  3 => 0\n  1 => 0\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.sizehint!",
    "page": "Collections and Data Structures",
    "title": "Base.sizehint!",
    "category": "function",
    "text": "sizehint!(s, n)\n\nSuggest that collection s reserve capacity for at least n elements. This can improve performance.\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.keytype",
    "page": "Collections and Data Structures",
    "title": "Base.keytype",
    "category": "function",
    "text": "keytype(type)\n\nGet the key type of an associative collection type. Behaves similarly to eltype.\n\njulia> keytype(Dict(Int32(1) => \"foo\"))\nInt32\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.valtype",
    "page": "Collections and Data Structures",
    "title": "Base.valtype",
    "category": "function",
    "text": "valtype(type)\n\nGet the value type of an associative collection type. Behaves similarly to eltype.\n\njulia> valtype(Dict(Int32(1) => \"foo\"))\nString\n\n\n\n"
},

{
    "location": "stdlib/collections/#Associative-Collections-1",
    "page": "Collections and Data Structures",
    "title": "Associative Collections",
    "category": "section",
    "text": "Dict is the standard associative collection. Its implementation uses hash() as the hashing function for the key, and isequal() to determine equality. Define these two functions for custom types to override how they are stored in a hash table.ObjectIdDict is a special hash table where the keys are always object identities.WeakKeyDict is a hash table implementation where the keys are weak references to objects, and thus may be garbage collected even when referenced in a hash table.Dicts can be created by passing pair objects constructed with =>() to a Dict constructor: Dict(\"A\"=>1, \"B\"=>2). This call will attempt to infer type information from the keys and values (i.e. this example creates a Dict{String, Int64}). To explicitly specify types use the syntax Dict{KeyType,ValueType}(...). For example, Dict{String,Int32}(\"A\"=>1, \"B\"=>2).Associative collections may also be created with generators. For example, Dict(i => f(i) for i = 1:10).Given a dictionary D, the syntax D[x] returns the value of key x (if it exists) or throws an error, and D[x] = y stores the key-value pair x => y in D (replacing any existing value for the key x).  Multiple arguments to D[...] are converted to tuples; for example, the syntax D[x,y]  is equivalent to D[(x,y)], i.e. it refers to the value keyed by the tuple (x,y).Base.Dict\nBase.ObjectIdDict\nBase.WeakKeyDict\nBase.haskey\nBase.get(::Any, ::Any, ::Any)\nBase.get\nBase.get!(::Any, ::Any, ::Any)\nBase.get!(::Function, ::Any, ::Any)\nBase.getkey\nBase.delete!\nBase.pop!(::Any, ::Any, ::Any)\nBase.keys\nBase.values\nBase.merge\nBase.merge!\nBase.sizehint!\nBase.keytype\nBase.valtypeFully implemented by:ObjectIdDict\nDict\nWeakKeyDictPartially implemented by:IntSet\nSet\nEnvHash\nArray\nBitArray"
},

{
    "location": "stdlib/collections/#Base.Set",
    "page": "Collections and Data Structures",
    "title": "Base.Set",
    "category": "type",
    "text": "Set([itr])\n\nConstruct a Set of the values generated by the given iterable object, or an empty set. Should be used instead of IntSet for sparse integer sets, or for sets of arbitrary objects.\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.IntSet",
    "page": "Collections and Data Structures",
    "title": "Base.IntSet",
    "category": "type",
    "text": "IntSet([itr])\n\nConstruct a sorted set of positive Ints generated by the given iterable object, or an empty set. Implemented as a bit string, and therefore designed for dense integer sets. Only Ints greater than 0 can be stored. If the set will be sparse (for example holding a few very large integers), use Set instead.\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.union",
    "page": "Collections and Data Structures",
    "title": "Base.union",
    "category": "function",
    "text": "union(s1,s2...)\n∪(s1,s2...)\n\nConstruct the union of two or more sets. Maintains order with arrays.\n\nExamples\n\njulia> union([1, 2], [3, 4])\n4-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n\njulia> union([1, 2], [2, 4])\n3-element Array{Int64,1}:\n 1\n 2\n 4\n\njulia> union([4, 2], [1, 2])\n3-element Array{Int64,1}:\n 4\n 2\n 1\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.union!",
    "page": "Collections and Data Structures",
    "title": "Base.union!",
    "category": "function",
    "text": "union!(s, iterable)\n\nUnion each element of iterable into set s in-place.\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.intersect",
    "page": "Collections and Data Structures",
    "title": "Base.intersect",
    "category": "function",
    "text": "intersect(s1,s2...)\n∩(s1,s2)\n\nConstruct the intersection of two or more sets. Maintains order and multiplicity of the first argument for arrays and ranges.\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.setdiff",
    "page": "Collections and Data Structures",
    "title": "Base.setdiff",
    "category": "function",
    "text": "setdiff(a, b)\n\nConstruct the set of elements in a but not b. Maintains order with arrays. Note that both arguments must be collections, and both will be iterated over. In particular, setdiff(set,element) where element is a potential member of set, will not work in general.\n\nExample\n\njulia> setdiff([1,2,3],[3,4,5])\n2-element Array{Int64,1}:\n 1\n 2\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.setdiff!",
    "page": "Collections and Data Structures",
    "title": "Base.setdiff!",
    "category": "function",
    "text": "setdiff!(s, iterable)\n\nRemove each element of iterable from set s in-place.\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.symdiff",
    "page": "Collections and Data Structures",
    "title": "Base.symdiff",
    "category": "function",
    "text": "symdiff(a, b, rest...)\n\nConstruct the symmetric difference of elements in the passed in sets or arrays. Maintains order with arrays.\n\nExample\n\njulia> symdiff([1,2,3],[3,4,5],[4,5,6])\n3-element Array{Int64,1}:\n 1\n 2\n 6\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.symdiff!-Tuple{IntSet,Integer}",
    "page": "Collections and Data Structures",
    "title": "Base.symdiff!",
    "category": "method",
    "text": "symdiff!(s, n)\n\nThe set s is destructively modified to toggle the inclusion of integer n.\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.symdiff!-Tuple{IntSet,Any}",
    "page": "Collections and Data Structures",
    "title": "Base.symdiff!",
    "category": "method",
    "text": "symdiff!(s, itr)\n\nFor each element in itr, destructively toggle its inclusion in set s.\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.symdiff!-Tuple{IntSet,IntSet}",
    "page": "Collections and Data Structures",
    "title": "Base.symdiff!",
    "category": "method",
    "text": "symdiff!(s, itr)\n\nFor each element in itr, destructively toggle its inclusion in set s.\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.intersect!",
    "page": "Collections and Data Structures",
    "title": "Base.intersect!",
    "category": "function",
    "text": "intersect!(s1::IntSet, s2::IntSet)\n\nIntersects sets s1 and s2 and overwrites the set s1 with the result. If needed, s1 will be expanded to the size of s2.\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.issubset",
    "page": "Collections and Data Structures",
    "title": "Base.issubset",
    "category": "function",
    "text": "issubset(A, S) -> Bool\n⊆(A,S) -> Bool\n\nReturn true if A is a subset of or equal to S.\n\n\n\n"
},

{
    "location": "stdlib/collections/#Set-Like-Collections-1",
    "page": "Collections and Data Structures",
    "title": "Set-Like Collections",
    "category": "section",
    "text": "Base.Set\nBase.IntSet\nBase.union\nBase.union!\nBase.intersect\nBase.setdiff\nBase.setdiff!\nBase.symdiff\nBase.symdiff!(::IntSet, ::Integer)\nBase.symdiff!(::IntSet, ::Any)\nBase.symdiff!(::IntSet, ::IntSet)\nBase.intersect!\nBase.issubsetFully implemented by:IntSet\nSetPartially implemented by:Array"
},

{
    "location": "stdlib/collections/#Base.push!",
    "page": "Collections and Data Structures",
    "title": "Base.push!",
    "category": "function",
    "text": "push!(collection, items...) -> collection\n\nInsert one or more items at the end of collection.\n\nExample\n\njulia> push!([1, 2, 3], 4, 5, 6)\n6-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n 5\n 6\n\nUse append! to add all the elements of another collection to collection. The result of the preceding example is equivalent to append!([1, 2, 3], [4, 5, 6]).\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.pop!-Tuple{Any}",
    "page": "Collections and Data Structures",
    "title": "Base.pop!",
    "category": "method",
    "text": "pop!(collection) -> item\n\nRemove the last item in collection and return it.\n\nExamples\n\njulia> A=[1, 2, 3, 4, 5, 6]\n6-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n 5\n 6\n\njulia> pop!(A)\n6\n\njulia> A\n5-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n 5\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.unshift!",
    "page": "Collections and Data Structures",
    "title": "Base.unshift!",
    "category": "function",
    "text": "unshift!(collection, items...) -> collection\n\nInsert one or more items at the beginning of collection.\n\nExample\n\njulia> unshift!([1, 2, 3, 4], 5, 6)\n6-element Array{Int64,1}:\n 5\n 6\n 1\n 2\n 3\n 4\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.shift!",
    "page": "Collections and Data Structures",
    "title": "Base.shift!",
    "category": "function",
    "text": "shift!(collection) -> item\n\nRemove the first item from collection.\n\nExample\n\njulia> A = [1, 2, 3, 4, 5, 6]\n6-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n 5\n 6\n\njulia> shift!(A)\n1\n\njulia> A\n5-element Array{Int64,1}:\n 2\n 3\n 4\n 5\n 6\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.insert!",
    "page": "Collections and Data Structures",
    "title": "Base.insert!",
    "category": "function",
    "text": "insert!(a::Vector, index::Integer, item)\n\nInsert an item into a at the given index. index is the index of item in the resulting a.\n\nExample\n\njulia> insert!([6, 5, 4, 2, 1], 4, 3)\n6-element Array{Int64,1}:\n 6\n 5\n 4\n 3\n 2\n 1\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.deleteat!",
    "page": "Collections and Data Structures",
    "title": "Base.deleteat!",
    "category": "function",
    "text": "deleteat!(a::Vector, i::Integer)\n\nRemove the item at the given i and return the modified a. Subsequent items are shifted to fill the resulting gap.\n\nExample\n\njulia> deleteat!([6, 5, 4, 3, 2, 1], 2)\n5-element Array{Int64,1}:\n 6\n 4\n 3\n 2\n 1\n\n\n\ndeleteat!(a::Vector, inds)\n\nRemove the items at the indices given by inds, and return the modified a. Subsequent items are shifted to fill the resulting gap.\n\ninds can be either an iterator or a collection of sorted and unique integer indices, or a boolean vector of the same length as a with true indicating entries to delete.\n\nExamples\n\njulia> deleteat!([6, 5, 4, 3, 2, 1], 1:2:5)\n3-element Array{Int64,1}:\n 5\n 3\n 1\n\njulia> deleteat!([6, 5, 4, 3, 2, 1], [true, false, true, false, true, false])\n3-element Array{Int64,1}:\n 5\n 3\n 1\n\njulia> deleteat!([6, 5, 4, 3, 2, 1], (2, 2))\nERROR: ArgumentError: indices must be unique and sorted\nStacktrace:\n [1] _deleteat!(::Array{Int64,1}, ::Tuple{Int64,Int64}) at ./array.jl:921\n [2] deleteat!(::Array{Int64,1}, ::Tuple{Int64,Int64}) at ./array.jl:908\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.splice!",
    "page": "Collections and Data Structures",
    "title": "Base.splice!",
    "category": "function",
    "text": "splice!(a::Vector, index::Integer, [replacement]) -> item\n\nRemove the item at the given index, and return the removed item. Subsequent items are shifted left to fill the resulting gap. If specified, replacement values from an ordered collection will be spliced in place of the removed item.\n\nExamples\n\njulia> A = [6, 5, 4, 3, 2, 1]; splice!(A, 5)\n2\n\njulia> A\n5-element Array{Int64,1}:\n 6\n 5\n 4\n 3\n 1\n\njulia> splice!(A, 5, -1)\n1\n\njulia> A\n5-element Array{Int64,1}:\n  6\n  5\n  4\n  3\n -1\n\njulia> splice!(A, 1, [-1, -2, -3])\n6\n\njulia> A\n7-element Array{Int64,1}:\n -1\n -2\n -3\n  5\n  4\n  3\n -1\n\nTo insert replacement before an index n without removing any items, use splice!(collection, n:n-1, replacement).\n\n\n\nsplice!(a::Vector, range, [replacement]) -> items\n\nRemove items in the specified index range, and return a collection containing the removed items. Subsequent items are shifted left to fill the resulting gap. If specified, replacement values from an ordered collection will be spliced in place of the removed items.\n\nTo insert replacement before an index n without removing any items, use splice!(collection, n:n-1, replacement).\n\nExample\n\njulia> splice!(A, 4:3, 2)\n0-element Array{Int64,1}\n\njulia> A\n8-element Array{Int64,1}:\n -1\n -2\n -3\n  2\n  5\n  4\n  3\n -1\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.resize!",
    "page": "Collections and Data Structures",
    "title": "Base.resize!",
    "category": "function",
    "text": "resize!(a::Vector, n::Integer) -> Vector\n\nResize a to contain n elements. If n is smaller than the current collection length, the first n elements will be retained. If n is larger, the new elements are not guaranteed to be initialized.\n\nExamples\n\njulia> resize!([6, 5, 4, 3, 2, 1], 3)\n3-element Array{Int64,1}:\n 6\n 5\n 4\n\njulia> a = resize!([6, 5, 4, 3, 2, 1], 8);\n\njulia> length(a)\n8\n\njulia> a[1:6]\n6-element Array{Int64,1}:\n 6\n 5\n 4\n 3\n 2\n 1\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.append!",
    "page": "Collections and Data Structures",
    "title": "Base.append!",
    "category": "function",
    "text": "append!(collection, collection2) -> collection.\n\nAdd the elements of collection2 to the end of collection.\n\nExamples\n\njulia> append!([1],[2,3])\n3-element Array{Int64,1}:\n 1\n 2\n 3\n\njulia> append!([1, 2, 3], [4, 5, 6])\n6-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n 5\n 6\n\nUse push! to add individual items to collection which are not already themselves in another collection. The result is of the preceding example is equivalent to push!([1, 2, 3], 4, 5, 6).\n\n\n\n"
},

{
    "location": "stdlib/collections/#Base.prepend!",
    "page": "Collections and Data Structures",
    "title": "Base.prepend!",
    "category": "function",
    "text": "prepend!(a::Vector, items) -> collection\n\nInsert the elements of items to the beginning of a.\n\nExample\n\njulia> prepend!([3],[1,2])\n3-element Array{Int64,1}:\n 1\n 2\n 3\n\n\n\n"
},

{
    "location": "stdlib/collections/#Dequeues-1",
    "page": "Collections and Data Structures",
    "title": "Dequeues",
    "category": "section",
    "text": "Base.push!\nBase.pop!(::Any)\nBase.unshift!\nBase.shift!\nBase.insert!\nBase.deleteat!\nBase.splice!\nBase.resize!\nBase.append!\nBase.prepend!Fully implemented by:Vector (a.k.a. 1-dimensional Array)\nBitVector (a.k.a. 1-dimensional BitArray)"
},

{
    "location": "stdlib/math/#",
    "page": "Mathematics",
    "title": "Mathematics",
    "category": "page",
    "text": ""
},

{
    "location": "stdlib/math/#Mathematics-1",
    "page": "Mathematics",
    "title": "Mathematics",
    "category": "section",
    "text": ""
},

{
    "location": "stdlib/math/#Base.:--Tuple{Any}",
    "page": "Mathematics",
    "title": "Base.:-",
    "category": "method",
    "text": "-(x)\n\nUnary minus operator.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.:+",
    "page": "Mathematics",
    "title": "Base.:+",
    "category": "function",
    "text": "+(x, y...)\n\nAddition operator. x+y+z+... calls this function with all arguments, i.e. +(x, y, z, ...).\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.:--Tuple{Any,Any}",
    "page": "Mathematics",
    "title": "Base.:-",
    "category": "method",
    "text": "-(x, y)\n\nSubtraction operator.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.:*-Tuple{Any,Vararg{Any,N} where N}",
    "page": "Mathematics",
    "title": "Base.:*",
    "category": "method",
    "text": "*(x, y...)\n\nMultiplication operator. x*y*z*... calls this function with all arguments, i.e. *(x, y, z, ...).\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.:/",
    "page": "Mathematics",
    "title": "Base.:/",
    "category": "function",
    "text": "/(x, y)\n\nRight division operator: multiplication of x by the inverse of y on the right. Gives floating-point results for integer arguments.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.:\\-Tuple{Any,Any}",
    "page": "Mathematics",
    "title": "Base.:\\",
    "category": "method",
    "text": "\\(x, y)\n\nLeft division operator: multiplication of y by the inverse of x on the left. Gives floating-point results for integer arguments.\n\njulia> 3 \\ 6\n2.0\n\njulia> inv(3) * 6\n2.0\n\njulia> A = [1 2; 3 4]; x = [5, 6];\n\njulia> A \\ x\n2-element Array{Float64,1}:\n -4.0\n  4.5\n\njulia> inv(A) * x\n2-element Array{Float64,1}:\n -4.0\n  4.5\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.:^-Tuple{Number,Number}",
    "page": "Mathematics",
    "title": "Base.:^",
    "category": "method",
    "text": "^(x, y)\n\nExponentiation operator. If x is a matrix, computes matrix exponentiation.\n\nIf y is an Int literal (e.g. 2 in x^2 or -3 in x^-3), the Julia code x^y is transformed by the compiler to Base.literal_pow(^, x, Val{y}), to enable compile-time specialization on the value of the exponent. (As a default fallback we have Base.literal_pow(^, x, Val{y}) = ^(x,y), where usually ^ == Base.^ unless ^ has been defined in the calling namespace.)\n\njulia> 3^5\n243\n\njulia> A = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> A^3\n2×2 Array{Int64,2}:\n 37   54\n 81  118\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.fma",
    "page": "Mathematics",
    "title": "Base.fma",
    "category": "function",
    "text": "fma(x, y, z)\n\nComputes x*y+z without rounding the intermediate result x*y. On some systems this is significantly more expensive than x*y+z. fma is used to improve accuracy in certain algorithms. See muladd.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.muladd",
    "page": "Mathematics",
    "title": "Base.muladd",
    "category": "function",
    "text": "muladd(x, y, z)\n\nCombined multiply-add, computes x*y+z in an efficient manner. This may on some systems be equivalent to x*y+z, or to fma(x,y,z). muladd is used to improve performance. See fma.\n\nExample\n\njulia> muladd(3, 2, 1)\n7\n\njulia> 3 * 2 + 1\n7\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.div",
    "page": "Mathematics",
    "title": "Base.div",
    "category": "function",
    "text": "div(x, y)\n÷(x, y)\n\nThe quotient from Euclidean division. Computes x/y, truncated to an integer.\n\njulia> 9 ÷ 4\n2\n\njulia> -5 ÷ 3\n-1\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.fld",
    "page": "Mathematics",
    "title": "Base.fld",
    "category": "function",
    "text": "fld(x, y)\n\nLargest integer less than or equal to x/y.\n\njulia> fld(7.3,5.5)\n1.0\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.cld",
    "page": "Mathematics",
    "title": "Base.cld",
    "category": "function",
    "text": "cld(x, y)\n\nSmallest integer larger than or equal to x/y.\n\njulia> cld(5.5,2.2)\n3.0\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.mod",
    "page": "Mathematics",
    "title": "Base.mod",
    "category": "function",
    "text": "mod(x, y)\nrem(x, y, RoundDown)\n\nThe reduction of x modulo y, or equivalently, the remainder of x after floored division by y, i.e.\n\nx - y*fld(x,y)\n\nif computed without intermediate rounding.\n\nThe result will have the same sign as y, and magnitude less than abs(y) (with some exceptions, see note below).\n\nnote: Note\nWhen used with floating point values, the exact result may not be representable by the type, and so rounding error may occur. In particular, if the exact result is very close to y, then it may be rounded to y.\n\njulia> mod(8, 3)\n2\n\njulia> mod(9, 3)\n0\n\njulia> mod(8.9, 3)\n2.9000000000000004\n\njulia> mod(eps(), 3)\n2.220446049250313e-16\n\njulia> mod(-eps(), 3)\n3.0\n\n\n\nrem(x::Integer, T::Type{<:Integer}) -> T\nmod(x::Integer, T::Type{<:Integer}) -> T\n%(x::Integer, T::Type{<:Integer}) -> T\n\nFind y::T such that x ≡ y (mod n), where n is the number of integers representable in T, and y is an integer in [typemin(T),typemax(T)]. If T can represent any integer (e.g. T == BigInt), then this operation corresponds to a conversion to T.\n\njulia> 129 % Int8\n-127\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.rem",
    "page": "Mathematics",
    "title": "Base.rem",
    "category": "function",
    "text": "rem(x, y)\n%(x, y)\n\nRemainder from Euclidean division, returning a value of the same sign as x, and smaller in magnitude than y. This value is always exact.\n\njulia> x = 15; y = 4;\n\njulia> x % y\n3\n\njulia> x == div(x, y) * y + rem(x, y)\ntrue\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.rem2pi",
    "page": "Mathematics",
    "title": "Base.Math.rem2pi",
    "category": "function",
    "text": "rem2pi(x, r::RoundingMode)\n\nCompute the remainder of x after integer division by 2π, with the quotient rounded according to the rounding mode r. In other words, the quantity\n\nx - 2π*round(x/(2π),r)\n\nwithout any intermediate rounding. This internally uses a high precision approximation of 2π, and so will give a more accurate result than rem(x,2π,r)\n\nif r == RoundNearest, then the result is in the interval - . This will generally be the most accurate result.\nif r == RoundToZero, then the result is in the interval 0 2 if x is positive,. or -2 0 otherwise.\nif r == RoundDown, then the result is in the interval 0 2.\nif r == RoundUp, then the result is in the interval -2 0.\n\nExample\n\njulia> rem2pi(7pi/4, RoundNearest)\n-0.7853981633974485\n\njulia> rem2pi(7pi/4, RoundDown)\n5.497787143782138\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.mod2pi",
    "page": "Mathematics",
    "title": "Base.Math.mod2pi",
    "category": "function",
    "text": "mod2pi(x)\n\nModulus after division by 2π, returning in the range 02).\n\nThis function computes a floating point representation of the modulus after division by numerically exact 2π, and is therefore not exactly the same as mod(x,2π), which would compute the modulus of x relative to division by the floating-point number 2π.\n\nExample\n\njulia> mod2pi(9*pi/4)\n0.7853981633974481\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.divrem",
    "page": "Mathematics",
    "title": "Base.divrem",
    "category": "function",
    "text": "divrem(x, y)\n\nThe quotient and remainder from Euclidean division. Equivalent to (div(x,y), rem(x,y)) or (x÷y, x%y).\n\njulia> divrem(3,7)\n(0, 3)\n\njulia> divrem(7,3)\n(2, 1)\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.fldmod",
    "page": "Mathematics",
    "title": "Base.fldmod",
    "category": "function",
    "text": "fldmod(x, y)\n\nThe floored quotient and modulus after division. Equivalent to (fld(x,y), mod(x,y)).\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.fld1",
    "page": "Mathematics",
    "title": "Base.fld1",
    "category": "function",
    "text": "fld1(x, y)\n\nFlooring division, returning a value consistent with mod1(x,y)\n\nSee also: mod1.\n\njulia> x = 15; y = 4;\n\njulia> fld1(x, y)\n4\n\njulia> x == fld(x, y) * y + mod(x, y)\ntrue\n\njulia> x == (fld1(x, y) - 1) * y + mod1(x, y)\ntrue\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.mod1",
    "page": "Mathematics",
    "title": "Base.mod1",
    "category": "function",
    "text": "mod1(x, y)\n\nModulus after flooring division, returning a value r such that mod(r, y) == mod(x, y) in the range (0 y for positive y and in the range y0) for negative y.\n\njulia> mod1(4, 2)\n2\n\njulia> mod1(4, 3)\n1\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.fldmod1",
    "page": "Mathematics",
    "title": "Base.fldmod1",
    "category": "function",
    "text": "fldmod1(x, y)\n\nReturn (fld1(x,y), mod1(x,y)).\n\nSee also: fld1, mod1.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.://",
    "page": "Mathematics",
    "title": "Base.://",
    "category": "function",
    "text": "//(num, den)\n\nDivide two integers or rational numbers, giving a Rational result.\n\njulia> 3 // 5\n3//5\n\njulia> (3 // 5) // (2 // 1)\n3//10\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.rationalize",
    "page": "Mathematics",
    "title": "Base.rationalize",
    "category": "function",
    "text": "rationalize([T<:Integer=Int,] x; tol::Real=eps(x))\n\nApproximate floating point number x as a Rational number with components of the given integer type. The result will differ from x by no more than tol. If T is not provided, it defaults to Int.\n\njulia> rationalize(5.6)\n28//5\n\njulia> a = rationalize(BigInt, 10.3)\n103//10\n\njulia> typeof(numerator(a))\nBigInt\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.numerator",
    "page": "Mathematics",
    "title": "Base.numerator",
    "category": "function",
    "text": "numerator(x)\n\nNumerator of the rational representation of x.\n\njulia> numerator(2//3)\n2\n\njulia> numerator(4)\n4\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.denominator",
    "page": "Mathematics",
    "title": "Base.denominator",
    "category": "function",
    "text": "denominator(x)\n\nDenominator of the rational representation of x.\n\njulia> denominator(2//3)\n3\n\njulia> denominator(4)\n1\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.:<<",
    "page": "Mathematics",
    "title": "Base.:<<",
    "category": "function",
    "text": "<<(x, n)\n\nLeft bit shift operator, x << n. For n >= 0, the result is x shifted left by n bits, filling with 0s. This is equivalent to x * 2^n. For n < 0, this is equivalent to x >> -n.\n\njulia> Int8(3) << 2\n12\n\njulia> bits(Int8(3))\n\"00000011\"\n\njulia> bits(Int8(12))\n\"00001100\"\n\nSee also >>, >>>.\n\n\n\n<<(B::BitVector, n) -> BitVector\n\nLeft bit shift operator, B << n. For n >= 0, the result is B with elements shifted n positions backwards, filling with false values. If n < 0, elements are shifted forwards. Equivalent to B >> -n.\n\nExamples\n\njulia> B = BitVector([true, false, true, false, false])\n5-element BitArray{1}:\n  true\n false\n  true\n false\n false\n\njulia> B << 1\n5-element BitArray{1}:\n false\n  true\n false\n false\n false\n\njulia> B << -1\n5-element BitArray{1}:\n false\n  true\n false\n  true\n false\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.:>>",
    "page": "Mathematics",
    "title": "Base.:>>",
    "category": "function",
    "text": ">>(x, n)\n\nRight bit shift operator, x >> n. For n >= 0, the result is x shifted right by n bits, where n >= 0, filling with 0s if x >= 0, 1s if x < 0, preserving the sign of x. This is equivalent to fld(x, 2^n). For n < 0, this is equivalent to x << -n.\n\njulia> Int8(13) >> 2\n3\n\njulia> bits(Int8(13))\n\"00001101\"\n\njulia> bits(Int8(3))\n\"00000011\"\n\njulia> Int8(-14) >> 2\n-4\n\njulia> bits(Int8(-14))\n\"11110010\"\n\njulia> bits(Int8(-4))\n\"11111100\"\n\nSee also >>>, <<.\n\n\n\n>>(B::BitVector, n) -> BitVector\n\nRight bit shift operator, B >> n. For n >= 0, the result is B with elements shifted n positions forward, filling with false values. If n < 0, elements are shifted backwards. Equivalent to B << -n.\n\nExample\n\njulia> B = BitVector([true, false, true, false, false])\n5-element BitArray{1}:\n  true\n false\n  true\n false\n false\n\njulia> B >> 1\n5-element BitArray{1}:\n false\n  true\n false\n  true\n false\n\njulia> B >> -1\n5-element BitArray{1}:\n false\n  true\n false\n false\n false\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.:>>>",
    "page": "Mathematics",
    "title": "Base.:>>>",
    "category": "function",
    "text": ">>>(x, n)\n\nUnsigned right bit shift operator, x >>> n. For n >= 0, the result is x shifted right by n bits, where n >= 0, filling with 0s. For n < 0, this is equivalent to x << -n.\n\nFor Unsigned integer types, this is equivalent to >>. For Signed integer types, this is equivalent to signed(unsigned(x) >> n).\n\njulia> Int8(-14) >>> 2\n60\n\njulia> bits(Int8(-14))\n\"11110010\"\n\njulia> bits(Int8(60))\n\"00111100\"\n\nBigInts are treated as if having infinite size, so no filling is required and this is equivalent to >>.\n\nSee also >>, <<.\n\n\n\n>>>(B::BitVector, n) -> BitVector\n\nUnsigned right bitshift operator, B >>> n. Equivalent to B >> n. See >> for details and examples.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.colon",
    "page": "Mathematics",
    "title": "Base.colon",
    "category": "function",
    "text": "colon(start, [step], stop)\n\nCalled by : syntax for constructing ranges.\n\njulia> colon(1, 2, 5)\n1:2:5\n\n\n\n:(start, [step], stop)\n\nRange operator. a:b constructs a range from a to b with a step size of 1, and a:s:b is similar but uses a step size of s. These syntaxes call the function colon. The colon is also used in indexing to select whole dimensions.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.range",
    "page": "Mathematics",
    "title": "Base.range",
    "category": "function",
    "text": "range(start, [step], length)\n\nConstruct a range by length, given a starting value and optional step (defaults to 1).\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.OneTo",
    "page": "Mathematics",
    "title": "Base.OneTo",
    "category": "type",
    "text": "Base.OneTo(n)\n\nDefine an AbstractUnitRange that behaves like 1:n, with the added distinction that the lower limit is guaranteed (by the type system) to be 1.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.StepRangeLen",
    "page": "Mathematics",
    "title": "Base.StepRangeLen",
    "category": "type",
    "text": "StepRangeLen{T,R,S}(ref::R, step::S, len, [offset=1])\n\nA range r where r[i] produces values of type T, parametrized by a reference value, a step, and the length.  By default ref is the starting value r[1], but alternatively you can supply it as the value of r[offset] for some other index 1 <= offset <= len.  In conjunction with TwicePrecision this can be used to implement ranges that are free of roundoff error.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.:==",
    "page": "Mathematics",
    "title": "Base.:==",
    "category": "function",
    "text": "==(x, y)\n\nGeneric equality operator, giving a single Bool result. Falls back to ===. Should be implemented for all types with a notion of equality, based on the abstract value that an instance represents. For example, all numeric types are compared by numeric value, ignoring type. Strings are compared as sequences of characters, ignoring encoding.\n\nFollows IEEE semantics for floating-point numbers.\n\nCollections should generally implement == by calling == recursively on all contents.\n\nNew numeric types should implement this function for two arguments of the new type, and handle comparison to other types via promotion rules where possible.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.:!=",
    "page": "Mathematics",
    "title": "Base.:!=",
    "category": "function",
    "text": "!=(x, y)\n≠(x,y)\n\nNot-equals comparison operator. Always gives the opposite answer as ==. New types should generally not implement this, and rely on the fallback definition !=(x,y) = !(x==y) instead.\n\njulia> 3 != 2\ntrue\n\njulia> \"foo\" ≠ \"foo\"\nfalse\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.:!==",
    "page": "Mathematics",
    "title": "Base.:!==",
    "category": "function",
    "text": "!==(x, y)\n≢(x,y)\n\nEquivalent to !(x === y).\n\njulia> a = [1, 2]; b = [1, 2];\n\njulia> a ≢ b\ntrue\n\njulia> a ≢ a\nfalse\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.:<",
    "page": "Mathematics",
    "title": "Base.:<",
    "category": "function",
    "text": "<(x, y)\n\nLess-than comparison operator. New numeric types should implement this function for two arguments of the new type. Because of the behavior of floating-point NaN values, < implements a partial order. Types with a canonical partial order should implement <, and types with a canonical total order should implement isless.\n\njulia> \'a\' < \'b\'\ntrue\n\njulia> \"abc\" < \"abd\"\ntrue\n\njulia> 5 < 3\nfalse\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.:<=",
    "page": "Mathematics",
    "title": "Base.:<=",
    "category": "function",
    "text": "<=(x, y)\n≤(x,y)\n\nLess-than-or-equals comparison operator.\n\njulia> \'a\' <= \'b\'\ntrue\n\njulia> 7 ≤ 7 ≤ 9\ntrue\n\njulia> \"abc\" ≤ \"abc\"\ntrue\n\njulia> 5 <= 3\nfalse\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.:>",
    "page": "Mathematics",
    "title": "Base.:>",
    "category": "function",
    "text": ">(x, y)\n\nGreater-than comparison operator. Generally, new types should implement < instead of this function, and rely on the fallback definition >(x, y) = y < x.\n\njulia> \'a\' > \'b\'\nfalse\n\njulia> 7 > 3 > 1\ntrue\n\njulia> \"abc\" > \"abd\"\nfalse\n\njulia> 5 > 3\ntrue\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.:>=",
    "page": "Mathematics",
    "title": "Base.:>=",
    "category": "function",
    "text": ">=(x, y)\n≥(x,y)\n\nGreater-than-or-equals comparison operator.\n\njulia> \'a\' >= \'b\'\nfalse\n\njulia> 7 ≥ 7 ≥ 3\ntrue\n\njulia> \"abc\" ≥ \"abc\"\ntrue\n\njulia> 5 >= 3\ntrue\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.cmp",
    "page": "Mathematics",
    "title": "Base.cmp",
    "category": "function",
    "text": "cmp(x,y)\n\nReturn -1, 0, or 1 depending on whether x is less than, equal to, or greater than y, respectively. Uses the total order implemented by isless. For floating-point numbers, uses < but throws an error for unordered arguments.\n\njulia> cmp(1, 2)\n-1\n\njulia> cmp(2, 1)\n1\n\njulia> cmp(2+im, 3-im)\nERROR: MethodError: no method matching isless(::Complex{Int64}, ::Complex{Int64})\n[...]\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.:~",
    "page": "Mathematics",
    "title": "Base.:~",
    "category": "function",
    "text": "~(x)\n\nBitwise not.\n\nExamples\n\njulia> ~4\n-5\n\njulia> ~10\n-11\n\njulia> ~true\nfalse\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.:&",
    "page": "Mathematics",
    "title": "Base.:&",
    "category": "function",
    "text": "&(x, y)\n\nBitwise and.\n\nExamples\n\njulia> 4 & 10\n0\n\njulia> 4 & 12\n4\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.:|",
    "page": "Mathematics",
    "title": "Base.:|",
    "category": "function",
    "text": "|(x, y)\n\nBitwise or.\n\nExamples\n\njulia> 4 | 10\n14\n\njulia> 4 | 1\n5\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.xor",
    "page": "Mathematics",
    "title": "Base.xor",
    "category": "function",
    "text": "xor(x, y)\n⊻(x, y)\n\nBitwise exclusive or of x and y.  The infix operation a ⊻ b is a synonym for xor(a,b), and ⊻ can be typed by tab-completing \\xor or \\veebar in the Julia REPL.\n\njulia> [true; true; false] .⊻ [true; false; false]\n3-element BitArray{1}:\n false\n  true\n false\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.:!",
    "page": "Mathematics",
    "title": "Base.:!",
    "category": "function",
    "text": "!(x)\n\nBoolean not.\n\njulia> !true\nfalse\n\njulia> !false\ntrue\n\njulia> .![true false true]\n1×3 BitArray{2}:\n false  true  false\n\n\n\n!f::Function\n\nPredicate function negation: when the argument of ! is a function, it returns a function which computes the boolean negation of f. Example:\n\njulia> str = \"∀ ε > 0, ∃ δ > 0: |x-y| < δ ⇒ |f(x)-f(y)| < ε\"\n\"∀ ε > 0, ∃ δ > 0: |x-y| < δ ⇒ |f(x)-f(y)| < ε\"\n\njulia> filter(isalpha, str)\n\"εδxyδfxfyε\"\n\njulia> filter(!isalpha, str)\n\"∀  > 0, ∃  > 0: |-| <  ⇒ |()-()| < \"\n\n\n\n"
},

{
    "location": "stdlib/math/#&&",
    "page": "Mathematics",
    "title": "&&",
    "category": "keyword",
    "text": "x && y\n\nShort-circuiting boolean AND.\n\n\n\n"
},

{
    "location": "stdlib/math/#||",
    "page": "Mathematics",
    "title": "||",
    "category": "keyword",
    "text": "x || y\n\nShort-circuiting boolean OR.\n\n\n\n"
},

{
    "location": "stdlib/math/#math-ops-1",
    "page": "Mathematics",
    "title": "Mathematical Operators",
    "category": "section",
    "text": "Base.:-(::Any)\nBase.:(+)\nBase.:-(::Any, ::Any)\nBase.:*(::Any, ::Any...)\nBase.:(/)\nBase.:\\(::Any, ::Any)\nBase.:^(::Number, ::Number)\nBase.fma\nBase.muladd\nBase.div\nBase.fld\nBase.cld\nBase.mod\nBase.rem\nBase.rem2pi\nBase.Math.mod2pi\nBase.divrem\nBase.fldmod\nBase.fld1\nBase.mod1\nBase.fldmod1\nBase.:(//)\nBase.rationalize\nBase.numerator\nBase.denominator\nBase.:(<<)\nBase.:(>>)\nBase.:(>>>)\nBase.colon\nBase.range\nBase.OneTo\nBase.StepRangeLen\nBase.:(==)\nBase.:(!=)\nBase.:(!==)\nBase.:(<)\nBase.:(<=)\nBase.:(>)\nBase.:(>=)\nBase.cmp\nBase.:(~)\nBase.:(&)\nBase.:(|)\nBase.xor\nBase.:(!)\n&&\n||"
},

{
    "location": "stdlib/math/#Base.isapprox",
    "page": "Mathematics",
    "title": "Base.isapprox",
    "category": "function",
    "text": "isapprox(x, y; rtol::Real=sqrt(eps), atol::Real=0, nans::Bool=false, norm::Function)\n\nInexact equality comparison: true if norm(x-y) <= atol + rtol*max(norm(x), norm(y)). The default atol is zero and the default rtol depends on the types of x and y. The keyword argument nans determines whether or not NaN values are considered equal (defaults to false).\n\nFor real or complex floating-point values, rtol defaults to sqrt(eps(typeof(real(x-y)))). This corresponds to requiring equality of about half of the significand digits. For other types, rtol defaults to zero.\n\nx and y may also be arrays of numbers, in which case norm defaults to vecnorm but may be changed by passing a norm::Function keyword argument. (For numbers, norm is the same thing as abs.) When x and y are arrays, if norm(x-y) is not finite (i.e. ±Inf or NaN), the comparison falls back to checking whether all elements of x and y are approximately equal component-wise.\n\nThe binary operator ≈ is equivalent to isapprox with the default arguments, and x ≉ y is equivalent to !isapprox(x,y).\n\njulia> 0.1 ≈ (0.1 - 1e-10)\ntrue\n\njulia> isapprox(10, 11; atol = 2)\ntrue\n\njulia> isapprox([10.0^9, 1.0], [10.0^9, 2.0])\ntrue\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.sin",
    "page": "Mathematics",
    "title": "Base.sin",
    "category": "function",
    "text": "sin(x)\n\nCompute sine of x, where x is in radians.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.cos",
    "page": "Mathematics",
    "title": "Base.cos",
    "category": "function",
    "text": "cos(x)\n\nCompute cosine of x, where x is in radians.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.tan",
    "page": "Mathematics",
    "title": "Base.tan",
    "category": "function",
    "text": "tan(x)\n\nCompute tangent of x, where x is in radians.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.sind",
    "page": "Mathematics",
    "title": "Base.Math.sind",
    "category": "function",
    "text": "sind(x)\n\nCompute sine of x, where x is in degrees. \n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.cosd",
    "page": "Mathematics",
    "title": "Base.Math.cosd",
    "category": "function",
    "text": "cosd(x)\n\nCompute cosine of x, where x is in degrees. \n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.tand",
    "page": "Mathematics",
    "title": "Base.Math.tand",
    "category": "function",
    "text": "tand(x)\n\nCompute tangent of x, where x is in degrees. \n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.sinpi",
    "page": "Mathematics",
    "title": "Base.Math.sinpi",
    "category": "function",
    "text": "sinpi(x)\n\nCompute sin(pi x) more accurately than sin(pi*x), especially for large x.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.cospi",
    "page": "Mathematics",
    "title": "Base.Math.cospi",
    "category": "function",
    "text": "cospi(x)\n\nCompute cos(pi x) more accurately than cos(pi*x), especially for large x.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.sinh",
    "page": "Mathematics",
    "title": "Base.sinh",
    "category": "function",
    "text": "sinh(x)\n\nCompute hyperbolic sine of x.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.cosh",
    "page": "Mathematics",
    "title": "Base.cosh",
    "category": "function",
    "text": "cosh(x)\n\nCompute hyperbolic cosine of x.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.tanh",
    "page": "Mathematics",
    "title": "Base.tanh",
    "category": "function",
    "text": "tanh(x)\n\nCompute hyperbolic tangent of x.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.asin",
    "page": "Mathematics",
    "title": "Base.asin",
    "category": "function",
    "text": "asin(x)\n\nCompute the inverse sine of x, where the output is in radians.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.acos",
    "page": "Mathematics",
    "title": "Base.acos",
    "category": "function",
    "text": "acos(x)\n\nCompute the inverse cosine of x, where the output is in radians\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.atan",
    "page": "Mathematics",
    "title": "Base.atan",
    "category": "function",
    "text": "atan(x)\n\nCompute the inverse tangent of x, where the output is in radians.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.atan2",
    "page": "Mathematics",
    "title": "Base.Math.atan2",
    "category": "function",
    "text": "atan2(y, x)\n\nCompute the inverse tangent of y/x, using the signs of both x and y to determine the quadrant of the return value.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.asind",
    "page": "Mathematics",
    "title": "Base.Math.asind",
    "category": "function",
    "text": "asind(x)\n\nCompute the inverse sine of x, where the output is in degrees. \n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.acosd",
    "page": "Mathematics",
    "title": "Base.Math.acosd",
    "category": "function",
    "text": "acosd(x)\n\nCompute the inverse cosine of x, where the output is in degrees. \n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.atand",
    "page": "Mathematics",
    "title": "Base.Math.atand",
    "category": "function",
    "text": "atand(x)\n\nCompute the inverse tangent of x, where the output is in degrees. \n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.sec",
    "page": "Mathematics",
    "title": "Base.Math.sec",
    "category": "function",
    "text": "sec(x)\n\nCompute the secant of x, where x is in radians.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.csc",
    "page": "Mathematics",
    "title": "Base.Math.csc",
    "category": "function",
    "text": "csc(x)\n\nCompute the cosecant of x, where x is in radians.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.cot",
    "page": "Mathematics",
    "title": "Base.Math.cot",
    "category": "function",
    "text": "cot(x)\n\nCompute the cotangent of x, where x is in radians.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.secd",
    "page": "Mathematics",
    "title": "Base.Math.secd",
    "category": "function",
    "text": "secd(x)\n\nCompute the secant of x, where x is in degrees.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.cscd",
    "page": "Mathematics",
    "title": "Base.Math.cscd",
    "category": "function",
    "text": "cscd(x)\n\nCompute the cosecant of x, where x is in degrees.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.cotd",
    "page": "Mathematics",
    "title": "Base.Math.cotd",
    "category": "function",
    "text": "cotd(x)\n\nCompute the cotangent of x, where x is in degrees.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.asec",
    "page": "Mathematics",
    "title": "Base.Math.asec",
    "category": "function",
    "text": "asec(x)\n\nCompute the inverse secant of x, where the output is in radians. \n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.acsc",
    "page": "Mathematics",
    "title": "Base.Math.acsc",
    "category": "function",
    "text": "acsc(x)\n\nCompute the inverse cosecant of x, where the output is in radians. \n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.acot",
    "page": "Mathematics",
    "title": "Base.Math.acot",
    "category": "function",
    "text": "acot(x)\n\nCompute the inverse cotangent of x, where the output is in radians. \n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.asecd",
    "page": "Mathematics",
    "title": "Base.Math.asecd",
    "category": "function",
    "text": "asecd(x)\n\nCompute the inverse secant of x, where the output is in degrees. \n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.acscd",
    "page": "Mathematics",
    "title": "Base.Math.acscd",
    "category": "function",
    "text": "acscd(x)\n\nCompute the inverse cosecant of x, where the output is in degrees. \n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.acotd",
    "page": "Mathematics",
    "title": "Base.Math.acotd",
    "category": "function",
    "text": "acotd(x)\n\nCompute the inverse cotangent of x, where the output is in degrees. \n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.sech",
    "page": "Mathematics",
    "title": "Base.Math.sech",
    "category": "function",
    "text": "sech(x)\n\nCompute the hyperbolic secant of x\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.csch",
    "page": "Mathematics",
    "title": "Base.Math.csch",
    "category": "function",
    "text": "csch(x)\n\nCompute the hyperbolic cosecant of x.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.coth",
    "page": "Mathematics",
    "title": "Base.Math.coth",
    "category": "function",
    "text": "coth(x)\n\nCompute the hyperbolic cotangent of x.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.asinh",
    "page": "Mathematics",
    "title": "Base.asinh",
    "category": "function",
    "text": "asinh(x)\n\nCompute the inverse hyperbolic sine of x.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.acosh",
    "page": "Mathematics",
    "title": "Base.acosh",
    "category": "function",
    "text": "acosh(x)\n\nCompute the inverse hyperbolic cosine of x.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.atanh",
    "page": "Mathematics",
    "title": "Base.atanh",
    "category": "function",
    "text": "atanh(x)\n\nCompute the inverse hyperbolic tangent of x.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.asech",
    "page": "Mathematics",
    "title": "Base.Math.asech",
    "category": "function",
    "text": "asech(x)\n\nCompute the inverse hyperbolic secant of x. \n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.acsch",
    "page": "Mathematics",
    "title": "Base.Math.acsch",
    "category": "function",
    "text": "acsch(x)\n\nCompute the inverse hyperbolic cosecant of x. \n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.acoth",
    "page": "Mathematics",
    "title": "Base.Math.acoth",
    "category": "function",
    "text": "acoth(x)\n\nCompute the inverse hyperbolic cotangent of x. \n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.sinc",
    "page": "Mathematics",
    "title": "Base.Math.sinc",
    "category": "function",
    "text": "sinc(x)\n\nCompute sin(pi x)  (pi x) if x neq 0, and 1 if x = 0.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.cosc",
    "page": "Mathematics",
    "title": "Base.Math.cosc",
    "category": "function",
    "text": "cosc(x)\n\nCompute cos(pi x)  x - sin(pi x)  (pi x^2) if x neq 0, and 0 if x = 0. This is the derivative of sinc(x).\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.deg2rad",
    "page": "Mathematics",
    "title": "Base.Math.deg2rad",
    "category": "function",
    "text": "deg2rad(x)\n\nConvert x from degrees to radians.\n\njulia> deg2rad(90)\n1.5707963267948966\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.rad2deg",
    "page": "Mathematics",
    "title": "Base.Math.rad2deg",
    "category": "function",
    "text": "rad2deg(x)\n\nConvert x from radians to degrees.\n\njulia> rad2deg(pi)\n180.0\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.hypot",
    "page": "Mathematics",
    "title": "Base.Math.hypot",
    "category": "function",
    "text": "hypot(x, y)\n\nCompute the hypotenuse sqrtx^2+y^2 avoiding overflow and underflow.\n\nExamples\n\njulia> a = 10^10;\n\njulia> hypot(a, a)\n1.4142135623730951e10\n\njulia> √(a^2 + a^2) # a^2 overflows\nERROR: DomainError:\nsqrt will only return a complex result if called with a complex argument. Try sqrt(complex(x)).\nStacktrace:\n [1] sqrt(::Int64) at ./math.jl:434\n\n\n\nhypot(x...)\n\nCompute the hypotenuse sqrtsum x_i^2 avoiding overflow and underflow.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.log-Tuple{Any}",
    "page": "Mathematics",
    "title": "Base.log",
    "category": "method",
    "text": "log(x)\n\nCompute the natural logarithm of x. Throws DomainError for negative Real arguments. Use complex negative arguments to obtain complex results.\n\nThere is an experimental variant in the Base.Math.JuliaLibm module, which is typically faster and more accurate.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.log-Tuple{Number,Number}",
    "page": "Mathematics",
    "title": "Base.log",
    "category": "method",
    "text": "log(b,x)\n\nCompute the base b logarithm of x. Throws DomainError for negative Real arguments.\n\njulia> log(4,8)\n1.5\n\njulia> log(4,2)\n0.5\n\nnote: Note\nIf b is a power of 2 or 10, log2 or log10 should be used, as these will typically be faster and more accurate. For example,julia> log(100,1000000)\n2.9999999999999996\n\njulia> log10(1000000)/2\n3.0\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.log2",
    "page": "Mathematics",
    "title": "Base.log2",
    "category": "function",
    "text": "log2(x)\n\nCompute the logarithm of x to base 2. Throws DomainError for negative Real arguments.\n\nExample\n\njulia> log2(4)\n2.0\n\njulia> log2(10)\n3.321928094887362\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.log10",
    "page": "Mathematics",
    "title": "Base.log10",
    "category": "function",
    "text": "log10(x)\n\nCompute the logarithm of x to base 10. Throws DomainError for negative Real arguments.\n\nExample\n\njulia> log10(100)\n2.0\n\njulia> log10(2)\n0.3010299956639812\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.log1p",
    "page": "Mathematics",
    "title": "Base.log1p",
    "category": "function",
    "text": "log1p(x)\n\nAccurate natural logarithm of 1+x. Throws DomainError for Real arguments less than -1.\n\nThere is an experimental variant in the Base.Math.JuliaLibm module, which is typically faster and more accurate.\n\nExamples\n\njulia> log1p(-0.5)\n-0.6931471805599453\n\njulia> log1p(0)\n0.0\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.frexp",
    "page": "Mathematics",
    "title": "Base.Math.frexp",
    "category": "function",
    "text": "frexp(val)\n\nReturn (x,exp) such that x has a magnitude in the interval 12 1) or 0, and val is equal to x times 2^exp.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.exp",
    "page": "Mathematics",
    "title": "Base.exp",
    "category": "function",
    "text": "exp(x)\n\nCompute the natural base exponential of x, in other words e^x.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.exp2",
    "page": "Mathematics",
    "title": "Base.exp2",
    "category": "function",
    "text": "exp2(x)\n\nCompute the base 2 exponential of x, in other words 2^x.\n\nExamples\n\njulia> exp2(5)\n32.0\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.exp10",
    "page": "Mathematics",
    "title": "Base.exp10",
    "category": "function",
    "text": "exp10(x)\n\nCompute 10^x.\n\nExamples\n\njulia> exp10(2)\n100.0\n\njulia> exp10(0.2)\n1.5848931924611136\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.ldexp",
    "page": "Mathematics",
    "title": "Base.Math.ldexp",
    "category": "function",
    "text": "ldexp(x, n)\n\nCompute x times 2^n.\n\nExample\n\njulia> ldexp(5., 2)\n20.0\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.modf",
    "page": "Mathematics",
    "title": "Base.Math.modf",
    "category": "function",
    "text": "modf(x)\n\nReturn a tuple (fpart,ipart) of the fractional and integral parts of a number. Both parts have the same sign as the argument.\n\nExample\n\njulia> modf(3.5)\n(0.5, 3.0)\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.expm1",
    "page": "Mathematics",
    "title": "Base.expm1",
    "category": "function",
    "text": "expm1(x)\n\nAccurately compute e^x-1.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.round-Tuple{Type,Any}",
    "page": "Mathematics",
    "title": "Base.round",
    "category": "method",
    "text": "round([T,] x, [digits, [base]], [r::RoundingMode])\n\nRounds x to an integer value according to the provided RoundingMode, returning a value of the same type as x. When not specifying a rounding mode the global mode will be used (see rounding), which by default is round to the nearest integer (RoundNearest mode), with ties (fractional values of 0.5) being rounded to the nearest even integer.\n\njulia> round(1.7)\n2.0\n\njulia> round(1.5)\n2.0\n\njulia> round(2.5)\n2.0\n\nThe optional RoundingMode argument will change how the number gets rounded.\n\nround(T, x, [r::RoundingMode]) converts the result to type T, throwing an InexactError if the value is not representable.\n\nround(x, digits) rounds to the specified number of digits after the decimal place (or before if negative). round(x, digits, base) rounds using a base other than 10.\n\njulia> round(pi, 2)\n3.14\n\njulia> round(pi, 3, 2)\n3.125\n\nnote: Note\nRounding to specified digits in bases other than 2 can be inexact when operating on binary floating point numbers. For example, the Float64 value represented by 1.15 is actually less than 1.15, yet will be rounded to 1.2.julia> x = 1.15\n1.15\n\njulia> @sprintf \"%.20f\" x\n\"1.14999999999999991118\"\n\njulia> x < 115//100\ntrue\n\njulia> round(x, 1)\n1.2\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Rounding.RoundingMode",
    "page": "Mathematics",
    "title": "Base.Rounding.RoundingMode",
    "category": "type",
    "text": "RoundingMode\n\nA type used for controlling the rounding mode of floating point operations (via rounding/setrounding functions), or as optional arguments for rounding to the nearest integer (via the round function).\n\nCurrently supported rounding modes are:\n\nRoundNearest (default)\nRoundNearestTiesAway\nRoundNearestTiesUp\nRoundToZero\nRoundFromZero (BigFloat only)\nRoundUp\nRoundDown\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Rounding.RoundNearest",
    "page": "Mathematics",
    "title": "Base.Rounding.RoundNearest",
    "category": "constant",
    "text": "RoundNearest\n\nThe default rounding mode. Rounds to the nearest integer, with ties (fractional values of 0.5) being rounded to the nearest even integer.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Rounding.RoundNearestTiesAway",
    "page": "Mathematics",
    "title": "Base.Rounding.RoundNearestTiesAway",
    "category": "constant",
    "text": "RoundNearestTiesAway\n\nRounds to nearest integer, with ties rounded away from zero (C/C++ round behaviour).\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Rounding.RoundNearestTiesUp",
    "page": "Mathematics",
    "title": "Base.Rounding.RoundNearestTiesUp",
    "category": "constant",
    "text": "RoundNearestTiesUp\n\nRounds to nearest integer, with ties rounded toward positive infinity (Java/JavaScript round behaviour).\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Rounding.RoundToZero",
    "page": "Mathematics",
    "title": "Base.Rounding.RoundToZero",
    "category": "constant",
    "text": "RoundToZero\n\nround using this rounding mode is an alias for trunc.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Rounding.RoundUp",
    "page": "Mathematics",
    "title": "Base.Rounding.RoundUp",
    "category": "constant",
    "text": "RoundUp\n\nround using this rounding mode is an alias for ceil.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Rounding.RoundDown",
    "page": "Mathematics",
    "title": "Base.Rounding.RoundDown",
    "category": "constant",
    "text": "RoundDown\n\nround using this rounding mode is an alias for floor.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.round-Union{Tuple{Complex{T},RoundingMode{MR},RoundingMode{MI}}, Tuple{MI}, Tuple{MR}, Tuple{T}} where MI where MR where T<:AbstractFloat",
    "page": "Mathematics",
    "title": "Base.round",
    "category": "method",
    "text": "round(z, RoundingModeReal, RoundingModeImaginary)\n\nReturns the nearest integral value of the same type as the complex-valued z to z, breaking ties using the specified RoundingModes. The first RoundingMode is used for rounding the real components while the second is used for rounding the imaginary components.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.ceil",
    "page": "Mathematics",
    "title": "Base.ceil",
    "category": "function",
    "text": "ceil([T,] x, [digits, [base]])\n\nceil(x) returns the nearest integral value of the same type as x that is greater than or equal to x.\n\nceil(T, x) converts the result to type T, throwing an InexactError if the value is not representable.\n\ndigits and base work as for round.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.floor",
    "page": "Mathematics",
    "title": "Base.floor",
    "category": "function",
    "text": "floor([T,] x, [digits, [base]])\n\nfloor(x) returns the nearest integral value of the same type as x that is less than or equal to x.\n\nfloor(T, x) converts the result to type T, throwing an InexactError if the value is not representable.\n\ndigits and base work as for round.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.trunc",
    "page": "Mathematics",
    "title": "Base.trunc",
    "category": "function",
    "text": "trunc([T,] x, [digits, [base]])\n\ntrunc(x) returns the nearest integral value of the same type as x whose absolute value is less than or equal to x.\n\ntrunc(T, x) converts the result to type T, throwing an InexactError if the value is not representable.\n\ndigits and base work as for round.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.unsafe_trunc",
    "page": "Mathematics",
    "title": "Base.unsafe_trunc",
    "category": "function",
    "text": "unsafe_trunc(T, x)\n\nunsafe_trunc(T, x) returns the nearest integral value of type T whose absolute value is less than or equal to x. If the value is not representable by T, an arbitrary value will be returned.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.signif",
    "page": "Mathematics",
    "title": "Base.signif",
    "category": "function",
    "text": "signif(x, digits, [base])\n\nRounds (in the sense of round) x so that there are digits significant digits, under a base base representation, default 10. E.g., signif(123.456, 2) is 120.0, and signif(357.913, 4, 2) is 352.0.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.min",
    "page": "Mathematics",
    "title": "Base.min",
    "category": "function",
    "text": "min(x, y, ...)\n\nReturn the minimum of the arguments. See also the minimum function to take the minimum element from a collection.\n\njulia> min(2, 5, 1)\n1\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.max",
    "page": "Mathematics",
    "title": "Base.max",
    "category": "function",
    "text": "max(x, y, ...)\n\nReturn the maximum of the arguments. See also the maximum function to take the maximum element from a collection.\n\njulia> max(2, 5, 1)\n5\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.minmax",
    "page": "Mathematics",
    "title": "Base.minmax",
    "category": "function",
    "text": "minmax(x, y)\n\nReturn (min(x,y), max(x,y)). See also: extrema that returns (minimum(x), maximum(x)).\n\njulia> minmax(\'c\',\'b\')\n(\'b\', \'c\')\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.clamp",
    "page": "Mathematics",
    "title": "Base.Math.clamp",
    "category": "function",
    "text": "clamp(x, lo, hi)\n\nReturn x if lo <= x <= hi. If x < lo, return lo. If x > hi, return hi. Arguments are promoted to a common type.\n\njulia> clamp.([pi, 1.0, big(10.)], 2., 9.)\n3-element Array{BigFloat,1}:\n 3.141592653589793238462643383279502884197169399375105820974944592307816406286198\n 2.000000000000000000000000000000000000000000000000000000000000000000000000000000\n 9.000000000000000000000000000000000000000000000000000000000000000000000000000000\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.clamp!",
    "page": "Mathematics",
    "title": "Base.Math.clamp!",
    "category": "function",
    "text": "clamp!(array::AbstractArray, lo, hi)\n\nRestrict values in array to the specified range, in-place. See also clamp.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.abs",
    "page": "Mathematics",
    "title": "Base.abs",
    "category": "function",
    "text": "abs(x)\n\nThe absolute value of x.\n\nWhen abs is applied to signed integers, overflow may occur, resulting in the return of a negative value. This overflow occurs only when abs is applied to the minimum representable value of a signed integer. That is, when x == typemin(typeof(x)), abs(x) == x < 0, not -x as might be expected.\n\njulia> abs(-3)\n3\n\njulia> abs(1 + im)\n1.4142135623730951\n\njulia> abs(typemin(Int64))\n-9223372036854775808\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Checked.checked_abs",
    "page": "Mathematics",
    "title": "Base.Checked.checked_abs",
    "category": "function",
    "text": "Base.checked_abs(x)\n\nCalculates abs(x), checking for overflow errors where applicable. For example, standard two\'s complement signed integers (e.g. Int) cannot represent abs(typemin(Int)), thus leading to an overflow.\n\nThe overflow protection may impose a perceptible performance penalty.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Checked.checked_neg",
    "page": "Mathematics",
    "title": "Base.Checked.checked_neg",
    "category": "function",
    "text": "Base.checked_neg(x)\n\nCalculates -x, checking for overflow errors where applicable. For example, standard two\'s complement signed integers (e.g. Int) cannot represent -typemin(Int), thus leading to an overflow.\n\nThe overflow protection may impose a perceptible performance penalty.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Checked.checked_add",
    "page": "Mathematics",
    "title": "Base.Checked.checked_add",
    "category": "function",
    "text": "Base.checked_add(x, y)\n\nCalculates x+y, checking for overflow errors where applicable.\n\nThe overflow protection may impose a perceptible performance penalty.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Checked.checked_sub",
    "page": "Mathematics",
    "title": "Base.Checked.checked_sub",
    "category": "function",
    "text": "Base.checked_sub(x, y)\n\nCalculates x-y, checking for overflow errors where applicable.\n\nThe overflow protection may impose a perceptible performance penalty.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Checked.checked_mul",
    "page": "Mathematics",
    "title": "Base.Checked.checked_mul",
    "category": "function",
    "text": "Base.checked_mul(x, y)\n\nCalculates x*y, checking for overflow errors where applicable.\n\nThe overflow protection may impose a perceptible performance penalty.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Checked.checked_div",
    "page": "Mathematics",
    "title": "Base.Checked.checked_div",
    "category": "function",
    "text": "Base.checked_div(x, y)\n\nCalculates div(x,y), checking for overflow errors where applicable.\n\nThe overflow protection may impose a perceptible performance penalty.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Checked.checked_rem",
    "page": "Mathematics",
    "title": "Base.Checked.checked_rem",
    "category": "function",
    "text": "Base.checked_rem(x, y)\n\nCalculates x%y, checking for overflow errors where applicable.\n\nThe overflow protection may impose a perceptible performance penalty.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Checked.checked_fld",
    "page": "Mathematics",
    "title": "Base.Checked.checked_fld",
    "category": "function",
    "text": "Base.checked_fld(x, y)\n\nCalculates fld(x,y), checking for overflow errors where applicable.\n\nThe overflow protection may impose a perceptible performance penalty.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Checked.checked_mod",
    "page": "Mathematics",
    "title": "Base.Checked.checked_mod",
    "category": "function",
    "text": "Base.checked_mod(x, y)\n\nCalculates mod(x,y), checking for overflow errors where applicable.\n\nThe overflow protection may impose a perceptible performance penalty.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Checked.checked_cld",
    "page": "Mathematics",
    "title": "Base.Checked.checked_cld",
    "category": "function",
    "text": "Base.checked_cld(x, y)\n\nCalculates cld(x,y), checking for overflow errors where applicable.\n\nThe overflow protection may impose a perceptible performance penalty.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Checked.add_with_overflow",
    "page": "Mathematics",
    "title": "Base.Checked.add_with_overflow",
    "category": "function",
    "text": "Base.add_with_overflow(x, y) -> (r, f)\n\nCalculates r = x+y, with the flag f indicating whether overflow has occurred.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Checked.sub_with_overflow",
    "page": "Mathematics",
    "title": "Base.Checked.sub_with_overflow",
    "category": "function",
    "text": "Base.sub_with_overflow(x, y) -> (r, f)\n\nCalculates r = x-y, with the flag f indicating whether overflow has occurred.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Checked.mul_with_overflow",
    "page": "Mathematics",
    "title": "Base.Checked.mul_with_overflow",
    "category": "function",
    "text": "Base.mul_with_overflow(x, y) -> (r, f)\n\nCalculates r = x*y, with the flag f indicating whether overflow has occurred.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.abs2",
    "page": "Mathematics",
    "title": "Base.abs2",
    "category": "function",
    "text": "abs2(x)\n\nSquared absolute value of x.\n\njulia> abs2(-3)\n9\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.copysign",
    "page": "Mathematics",
    "title": "Base.copysign",
    "category": "function",
    "text": "copysign(x, y) -> z\n\nReturn z which has the magnitude of x and the same sign as y.\n\nExamples\n\njulia> copysign(1, -2)\n-1\n\njulia> copysign(-1, 2)\n1\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.sign",
    "page": "Mathematics",
    "title": "Base.sign",
    "category": "function",
    "text": "sign(x)\n\nReturn zero if x==0 and xx otherwise (i.e., ±1 for real x).\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.signbit",
    "page": "Mathematics",
    "title": "Base.signbit",
    "category": "function",
    "text": "signbit(x)\n\nReturns true if the value of the sign of x is negative, otherwise false.\n\nExamples\n\njulia> signbit(-4)\ntrue\n\njulia> signbit(5)\nfalse\n\njulia> signbit(5.5)\nfalse\n\njulia> signbit(-4.1)\ntrue\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.flipsign",
    "page": "Mathematics",
    "title": "Base.flipsign",
    "category": "function",
    "text": "flipsign(x, y)\n\nReturn x with its sign flipped if y is negative. For example abs(x) = flipsign(x,x).\n\njulia> flipsign(5, 3)\n5\n\njulia> flipsign(5, -3)\n-5\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.sqrt",
    "page": "Mathematics",
    "title": "Base.sqrt",
    "category": "function",
    "text": "sqrt(x)\n\nReturn sqrtx. Throws DomainError for negative Real arguments. Use complex negative arguments instead. The prefix operator √ is equivalent to sqrt.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.isqrt",
    "page": "Mathematics",
    "title": "Base.isqrt",
    "category": "function",
    "text": "isqrt(n::Integer)\n\nInteger square root: the largest integer m such that m*m <= n.\n\njulia> isqrt(5)\n2\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.cbrt",
    "page": "Mathematics",
    "title": "Base.Math.cbrt",
    "category": "function",
    "text": "cbrt(x::Real)\n\nReturn the cube root of x, i.e. x^13. Negative values are accepted (returning the negative real root when x  0).\n\nThe prefix operator ∛ is equivalent to cbrt.\n\njulia> cbrt(big(27))\n3.000000000000000000000000000000000000000000000000000000000000000000000000000000\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.real-Tuple{Complex}",
    "page": "Mathematics",
    "title": "Base.real",
    "category": "method",
    "text": "real(z)\n\nReturn the real part of the complex number z.\n\njulia> real(1 + 3im)\n1\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.imag",
    "page": "Mathematics",
    "title": "Base.imag",
    "category": "function",
    "text": "imag(z)\n\nReturn the imaginary part of the complex number z.\n\njulia> imag(1 + 3im)\n3\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.reim",
    "page": "Mathematics",
    "title": "Base.reim",
    "category": "function",
    "text": "reim(z)\n\nReturn both the real and imaginary parts of the complex number z.\n\njulia> reim(1 + 3im)\n(1, 3)\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.conj",
    "page": "Mathematics",
    "title": "Base.conj",
    "category": "function",
    "text": "conj(z)\n\nCompute the complex conjugate of a complex number z.\n\njulia> conj(1 + 3im)\n1 - 3im\n\n\n\nconj(v::RowVector)\n\nReturns a ConjArray lazy view of the input, where each element is conjugated.\n\nExample\n\njulia> v = [1+im, 1-im].\'\n1×2 RowVector{Complex{Int64},Array{Complex{Int64},1}}:\n 1+1im  1-1im\n\njulia> conj(v)\n1×2 RowVector{Complex{Int64},ConjArray{Complex{Int64},1,Array{Complex{Int64},1}}}:\n 1-1im  1+1im\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.angle",
    "page": "Mathematics",
    "title": "Base.angle",
    "category": "function",
    "text": "angle(z)\n\nCompute the phase angle in radians of a complex number z.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.cis",
    "page": "Mathematics",
    "title": "Base.cis",
    "category": "function",
    "text": "cis(z)\n\nReturn exp(iz).\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.binomial",
    "page": "Mathematics",
    "title": "Base.binomial",
    "category": "function",
    "text": "binomial(n, k)\n\nNumber of ways to choose k out of n items.\n\nExample\n\njulia> binomial(5, 3)\n10\n\njulia> factorial(5) ÷ (factorial(5-3) * factorial(3))\n10\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.factorial",
    "page": "Mathematics",
    "title": "Base.factorial",
    "category": "function",
    "text": "factorial(n)\n\nFactorial of n. If n is an Integer, the factorial is computed as an integer (promoted to at least 64 bits). Note that this may overflow if n is not small, but you can use factorial(big(n)) to compute the result exactly in arbitrary precision. If n is not an Integer, factorial(n) is equivalent to gamma(n+1).\n\njulia> factorial(6)\n720\n\njulia> factorial(21)\nERROR: OverflowError()\n[...]\n\njulia> factorial(21.0)\n5.109094217170944e19\n\njulia> factorial(big(21))\n51090942171709440000\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.gcd",
    "page": "Mathematics",
    "title": "Base.gcd",
    "category": "function",
    "text": "gcd(x,y)\n\nGreatest common (positive) divisor (or zero if x and y are both zero).\n\nExamples\n\njulia> gcd(6,9)\n3\n\njulia> gcd(6,-9)\n3\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.lcm",
    "page": "Mathematics",
    "title": "Base.lcm",
    "category": "function",
    "text": "lcm(x,y)\n\nLeast common (non-negative) multiple.\n\nExamples\n\njulia> lcm(2,3)\n6\n\njulia> lcm(-2,3)\n6\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.gcdx",
    "page": "Mathematics",
    "title": "Base.gcdx",
    "category": "function",
    "text": "gcdx(x,y)\n\nComputes the greatest common (positive) divisor of x and y and their Bézout coefficients, i.e. the integer coefficients u and v that satisfy ux+vy = d = gcd(xy). gcdx(xy) returns (duv).\n\nExamples\n\njulia> gcdx(12, 42)\n(6, -3, 1)\n\njulia> gcdx(240, 46)\n(2, -9, 47)\n\nnote: Note\nBézout coefficients are not uniquely defined. gcdx returns the minimal Bézout coefficients that are computed by the extended Euclidean algorithm. (Ref: D. Knuth, TAoCP, 2/e, p. 325, Algorithm X.) For signed integers, these coefficients u and v are minimal in the sense that u  yd and v  xd. Furthermore, the signs of u and v are chosen so that d is positive. For unsigned integers, the coefficients u and v might be near their typemax, and the identity then holds only via the unsigned integers\' modulo arithmetic.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.ispow2",
    "page": "Mathematics",
    "title": "Base.ispow2",
    "category": "function",
    "text": "ispow2(n::Integer) -> Bool\n\nTest whether n is a power of two.\n\nExamples\n\njulia> ispow2(4)\ntrue\n\njulia> ispow2(5)\nfalse\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.nextpow2",
    "page": "Mathematics",
    "title": "Base.nextpow2",
    "category": "function",
    "text": "nextpow2(n::Integer)\n\nThe smallest power of two not less than n. Returns 0 for n==0, and returns -nextpow2(-n) for negative arguments.\n\nExamples\n\njulia> nextpow2(16)\n16\n\njulia> nextpow2(17)\n32\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.prevpow2",
    "page": "Mathematics",
    "title": "Base.prevpow2",
    "category": "function",
    "text": "prevpow2(n::Integer)\n\nThe largest power of two not greater than n. Returns 0 for n==0, and returns -prevpow2(-n) for negative arguments.\n\nExamples\n\njulia> prevpow2(5)\n4\n\njulia> prevpow2(0)\n0\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.nextpow",
    "page": "Mathematics",
    "title": "Base.nextpow",
    "category": "function",
    "text": "nextpow(a, x)\n\nThe smallest a^n not less than x, where n is a non-negative integer. a must be greater than 1, and x must be greater than 0.\n\nExamples\n\njulia> nextpow(2, 7)\n8\n\njulia> nextpow(2, 9)\n16\n\njulia> nextpow(5, 20)\n25\n\njulia> nextpow(4, 16)\n16\n\nSee also prevpow.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.prevpow",
    "page": "Mathematics",
    "title": "Base.prevpow",
    "category": "function",
    "text": "prevpow(a, x)\n\nThe largest a^n not greater than x, where n is a non-negative integer. a must be greater than 1, and x must not be less than 1.\n\nExamples\n\njulia> prevpow(2, 7)\n4\n\njulia> prevpow(2, 9)\n8\n\njulia> prevpow(5, 20)\n5\n\njulia> prevpow(4, 16)\n16\n\nSee also nextpow.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.nextprod",
    "page": "Mathematics",
    "title": "Base.nextprod",
    "category": "function",
    "text": "nextprod([k_1, k_2,...], n)\n\nNext integer greater than or equal to n that can be written as prod k_i^p_i for integers p_1, p_2, etc.\n\nExample\n\njulia> nextprod([2, 3], 105)\n108\n\njulia> 2^2 * 3^3\n108\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.invmod",
    "page": "Mathematics",
    "title": "Base.invmod",
    "category": "function",
    "text": "invmod(x,m)\n\nTake the inverse of x modulo m: y such that x y = 1 pmod m, with div(xy) = 0. This is undefined for m = 0, or if gcd(xm) neq 1.\n\nExamples\n\njulia> invmod(2,5)\n3\n\njulia> invmod(2,3)\n2\n\njulia> invmod(5,6)\n5\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.powermod",
    "page": "Mathematics",
    "title": "Base.powermod",
    "category": "function",
    "text": "powermod(x::Integer, p::Integer, m)\n\nCompute x^p pmod m.\n\nExamples\n\njulia> powermod(2, 6, 5)\n4\n\njulia> mod(2^6, 5)\n4\n\njulia> powermod(5, 2, 20)\n5\n\njulia> powermod(5, 2, 19)\n6\n\njulia> powermod(5, 3, 19)\n11\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.gamma",
    "page": "Mathematics",
    "title": "Base.Math.gamma",
    "category": "function",
    "text": "gamma(x)\n\nCompute the gamma function of x.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.lgamma",
    "page": "Mathematics",
    "title": "Base.Math.lgamma",
    "category": "function",
    "text": "lgamma(x)\n\nCompute the logarithm of the absolute value of gamma for Real x, while for Complex x compute the principal branch cut of the logarithm of gamma(x) (defined for negative real(x) by analytic continuation from positive real(x)).\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.lfact",
    "page": "Mathematics",
    "title": "Base.Math.lfact",
    "category": "function",
    "text": "lfact(x)\n\nCompute the logarithmic factorial of a nonnegative integer x. Equivalent to lgamma of x + 1, but lgamma extends this function to non-integer x.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.beta",
    "page": "Mathematics",
    "title": "Base.Math.beta",
    "category": "function",
    "text": "beta(x, y)\n\nEuler integral of the first kind operatornameB(xy) = Gamma(x)Gamma(y)Gamma(x+y).\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.lbeta",
    "page": "Mathematics",
    "title": "Base.Math.lbeta",
    "category": "function",
    "text": "lbeta(x, y)\n\nNatural logarithm of the absolute value of the beta function log(operatornameB(xy)).\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.ndigits",
    "page": "Mathematics",
    "title": "Base.ndigits",
    "category": "function",
    "text": "ndigits(n::Integer, b::Integer=10)\n\nCompute the number of digits in integer n written in base b. The base b must not be in [-1, 0, 1].\n\nExamples\n\njulia> ndigits(12345)\n5\n\njulia> ndigits(1022, 16)\n3\n\njulia> base(16, 1022)\n\"3fe\"\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.widemul",
    "page": "Mathematics",
    "title": "Base.widemul",
    "category": "function",
    "text": "widemul(x, y)\n\nMultiply x and y, giving the result as a larger type.\n\njulia> widemul(Float32(3.), 4.)\n1.200000000000000000000000000000000000000000000000000000000000000000000000000000e+01\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.Math.@evalpoly",
    "page": "Mathematics",
    "title": "Base.Math.@evalpoly",
    "category": "macro",
    "text": "@evalpoly(z, c...)\n\nEvaluate the polynomial sum_k ck z^k-1 for the coefficients c[1], c[2], ...; that is, the coefficients are given in ascending order by power of z.  This macro expands to efficient inline code that uses either Horner\'s method or, for complex z, a more efficient Goertzel-like algorithm.\n\njulia> @evalpoly(3, 1, 0, 1)\n10\n\njulia> @evalpoly(2, 1, 0, 1)\n5\n\njulia> @evalpoly(2, 1, 1, 1)\n7\n\n\n\n"
},

{
    "location": "stdlib/math/#Mathematical-Functions-1",
    "page": "Mathematics",
    "title": "Mathematical Functions",
    "category": "section",
    "text": "Base.isapprox\nBase.sin\nBase.cos\nBase.tan\nBase.Math.sind\nBase.Math.cosd\nBase.Math.tand\nBase.Math.sinpi\nBase.Math.cospi\nBase.sinh\nBase.cosh\nBase.tanh\nBase.asin\nBase.acos\nBase.atan\nBase.Math.atan2\nBase.Math.asind\nBase.Math.acosd\nBase.Math.atand\nBase.Math.sec\nBase.Math.csc\nBase.Math.cot\nBase.Math.secd\nBase.Math.cscd\nBase.Math.cotd\nBase.Math.asec\nBase.Math.acsc\nBase.Math.acot\nBase.Math.asecd\nBase.Math.acscd\nBase.Math.acotd\nBase.Math.sech\nBase.Math.csch\nBase.Math.coth\nBase.asinh\nBase.acosh\nBase.atanh\nBase.Math.asech\nBase.Math.acsch\nBase.Math.acoth\nBase.Math.sinc\nBase.Math.cosc\nBase.Math.deg2rad\nBase.Math.rad2deg\nBase.Math.hypot\nBase.log(::Any)\nBase.log(::Number, ::Number)\nBase.log2\nBase.log10\nBase.log1p\nBase.Math.frexp\nBase.exp\nBase.exp2\nBase.exp10\nBase.Math.ldexp\nBase.Math.modf\nBase.expm1\nBase.round(::Type, ::Any)\nBase.Rounding.RoundingMode\nBase.Rounding.RoundNearest\nBase.Rounding.RoundNearestTiesAway\nBase.Rounding.RoundNearestTiesUp\nBase.Rounding.RoundToZero\nBase.Rounding.RoundUp\nBase.Rounding.RoundDown\nBase.round{T <: AbstractFloat, MR, MI}(::Complex{T}, ::RoundingMode{MR}, ::RoundingMode{MI})\nBase.ceil\nBase.floor\nBase.trunc\nBase.unsafe_trunc\nBase.signif\nBase.min\nBase.max\nBase.minmax\nBase.Math.clamp\nBase.Math.clamp!\nBase.abs\nBase.Checked.checked_abs\nBase.Checked.checked_neg\nBase.Checked.checked_add\nBase.Checked.checked_sub\nBase.Checked.checked_mul\nBase.Checked.checked_div\nBase.Checked.checked_rem\nBase.Checked.checked_fld\nBase.Checked.checked_mod\nBase.Checked.checked_cld\nBase.Checked.add_with_overflow\nBase.Checked.sub_with_overflow\nBase.Checked.mul_with_overflow\nBase.abs2\nBase.copysign\nBase.sign\nBase.signbit\nBase.flipsign\nBase.sqrt\nBase.isqrt\nBase.Math.cbrt\nBase.real(::Complex)\nBase.imag\nBase.reim\nBase.conj\nBase.angle\nBase.cis\nBase.binomial\nBase.factorial\nBase.gcd\nBase.lcm\nBase.gcdx\nBase.ispow2\nBase.nextpow2\nBase.prevpow2\nBase.nextpow\nBase.prevpow\nBase.nextprod\nBase.invmod\nBase.powermod\nBase.Math.gamma\nBase.Math.lgamma\nBase.Math.lfact\nBase.Math.beta\nBase.Math.lbeta\nBase.ndigits\nBase.widemul\nBase.Math.@evalpoly"
},

{
    "location": "stdlib/math/#Base.mean",
    "page": "Mathematics",
    "title": "Base.mean",
    "category": "function",
    "text": "mean(f::Function, v)\n\nApply the function f to each element of v and take the mean.\n\njulia> mean(√, [1, 2, 3])\n1.3820881233139908\n\njulia> mean([√1, √2, √3])\n1.3820881233139908\n\n\n\nmean(v[, region])\n\nCompute the mean of whole array v, or optionally along the dimensions in region.\n\nnote: Note\nJulia does not ignore NaN values in the computation. For applications requiring the handling of missing data, the DataArrays.jl package is recommended.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.mean!",
    "page": "Mathematics",
    "title": "Base.mean!",
    "category": "function",
    "text": "mean!(r, v)\n\nCompute the mean of v over the singleton dimensions of r, and write results to r.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.std",
    "page": "Mathematics",
    "title": "Base.std",
    "category": "function",
    "text": "std(v[, region]; corrected::Bool=true, mean=nothing)\n\nCompute the sample standard deviation of a vector or array v, optionally along dimensions in region. The algorithm returns an estimator of the generative distribution\'s standard deviation under the assumption that each entry of v is an IID drawn from that generative distribution. This computation is equivalent to calculating sqrt(sum((v - mean(v)).^2) / (length(v) - 1)). A pre-computed mean may be provided. If corrected is true, then the sum is scaled with n-1, whereas the sum is scaled with n if corrected is false where n = length(x).\n\nnote: Note\nJulia does not ignore NaN values in the computation. For applications requiring the handling of missing data, the DataArrays.jl package is recommended.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.stdm",
    "page": "Mathematics",
    "title": "Base.stdm",
    "category": "function",
    "text": "stdm(v, m::Number; corrected::Bool=true)\n\nCompute the sample standard deviation of a vector v with known mean m. If corrected is true, then the sum is scaled with n-1, whereas the sum is scaled with n if corrected is false where n = length(x).\n\nnote: Note\nJulia does not ignore NaN values in the computation. For applications requiring the handling of missing data, the DataArrays.jl package is recommended.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.var",
    "page": "Mathematics",
    "title": "Base.var",
    "category": "function",
    "text": "var(v[, region]; corrected::Bool=true, mean=nothing)\n\nCompute the sample variance of a vector or array v, optionally along dimensions in region. The algorithm will return an estimator of the generative distribution\'s variance under the assumption that each entry of v is an IID drawn from that generative distribution. This computation is equivalent to calculating sum(abs2, v - mean(v)) / (length(v) - 1). If corrected is true, then the sum is scaled with n-1, whereas the sum is scaled with n if corrected is false where n = length(x). The mean mean over the region may be provided.\n\nnote: Note\nJulia does not ignore NaN values in the computation. For applications requiring the handling of missing data, the DataArrays.jl package is recommended.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.varm",
    "page": "Mathematics",
    "title": "Base.varm",
    "category": "function",
    "text": "varm(v, m[, region]; corrected::Bool=true)\n\nCompute the sample variance of a collection v with known mean(s) m, optionally over region. m may contain means for each dimension of v. If corrected is true, then the sum is scaled with n-1, whereas the sum is scaled with n if corrected is false where n = length(x).\n\nnote: Note\nJulia does not ignore NaN values in the computation. For applications requiring the handling of missing data, the DataArrays.jl package is recommended.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.middle",
    "page": "Mathematics",
    "title": "Base.middle",
    "category": "function",
    "text": "middle(x)\n\nCompute the middle of a scalar value, which is equivalent to x itself, but of the type of middle(x, x) for consistency.\n\n\n\nmiddle(x, y)\n\nCompute the middle of two reals x and y, which is equivalent in both value and type to computing their mean ((x + y) / 2).\n\n\n\nmiddle(range)\n\nCompute the middle of a range, which consists of computing the mean of its extrema. Since a range is sorted, the mean is performed with the first and last element.\n\njulia> middle(1:10)\n5.5\n\n\n\nmiddle(a)\n\nCompute the middle of an array a, which consists of finding its extrema and then computing their mean.\n\njulia> a = [1,2,3.6,10.9]\n4-element Array{Float64,1}:\n  1.0\n  2.0\n  3.6\n 10.9\n\njulia> middle(a)\n5.95\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.median",
    "page": "Mathematics",
    "title": "Base.median",
    "category": "function",
    "text": "median(v[, region])\n\nCompute the median of an entire array v, or, optionally, along the dimensions in region. For an even number of elements no exact median element exists, so the result is equivalent to calculating mean of two median elements.\n\nnote: Note\nJulia does not ignore NaN values in the computation. For applications requiring the handling of missing data, the DataArrays.jl package is recommended.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.median!",
    "page": "Mathematics",
    "title": "Base.median!",
    "category": "function",
    "text": "median!(v)\n\nLike median, but may overwrite the input vector.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.quantile",
    "page": "Mathematics",
    "title": "Base.quantile",
    "category": "function",
    "text": "quantile(v, p; sorted=false)\n\nCompute the quantile(s) of a vector v at a specified probability or vector p. The keyword argument sorted indicates whether v can be assumed to be sorted.\n\nThe p should be on the interval [0,1], and v should not have any NaN values.\n\nQuantiles are computed via linear interpolation between the points ((k-1)/(n-1), v[k]), for k = 1:n where n = length(v). This corresponds to Definition 7 of Hyndman and Fan (1996), and is the same as the R default.\n\nnote: Note\nJulia does not ignore NaN values in the computation. For applications requiring the handling of missing data, the DataArrays.jl package is recommended. quantile will throw an ArgumentError in the presence of NaN values in the data array.\n\nHyndman, R.J and Fan, Y. (1996) \"Sample Quantiles in Statistical Packages\", The American Statistician, Vol. 50, No. 4, pp. 361-365\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.quantile!",
    "page": "Mathematics",
    "title": "Base.quantile!",
    "category": "function",
    "text": "quantile!([q, ] v, p; sorted=false)\n\nCompute the quantile(s) of a vector v at the probabilities p, with optional output into array q (if not provided, a new output array is created). The keyword argument sorted indicates whether v can be assumed to be sorted; if false (the default), then the elements of v may be partially sorted.\n\nThe elements of p should be on the interval [0,1], and v should not have any NaN values.\n\nQuantiles are computed via linear interpolation between the points ((k-1)/(n-1), v[k]), for k = 1:n where n = length(v). This corresponds to Definition 7 of Hyndman and Fan (1996), and is the same as the R default.\n\nnote: Note\nJulia does not ignore NaN values in the computation. For applications requiring the handling of missing data, the DataArrays.jl package is recommended. quantile! will throw an ArgumentError in the presence of NaN values in the data array.\n\nHyndman, R.J and Fan, Y. (1996) \"Sample Quantiles in Statistical Packages\", The American Statistician, Vol. 50, No. 4, pp. 361-365\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.cov",
    "page": "Mathematics",
    "title": "Base.cov",
    "category": "function",
    "text": "cov(x[, corrected=true])\n\nCompute the variance of the vector x. If corrected is true (the default) then the sum is scaled with n-1, whereas the sum is scaled with n if corrected is false where n = length(x).\n\n\n\ncov(X[, vardim=1, corrected=true])\n\nCompute the covariance matrix of the matrix X along the dimension vardim. If corrected is true (the default) then the sum is scaled with n-1, whereas the sum is scaled with n if corrected is false where n = size(X, vardim).\n\n\n\ncov(x, y[, corrected=true])\n\nCompute the covariance between the vectors x and y. If corrected is true (the default), computes frac1n-1sum_i=1^n (x_i-bar x) (y_i-bar y)^* where * denotes the complex conjugate and n = length(x) = length(y). If corrected is false, computes rac1nsum_i=1^n (x_i-bar x) (y_i-bar y)^*.\n\n\n\ncov(X, Y[, vardim=1, corrected=true])\n\nCompute the covariance between the vectors or matrices X and Y along the dimension vardim. If corrected is true (the default) then the sum is scaled with n-1, whereas the sum is scaled with n if corrected is false where n = size(X, vardim) = size(Y, vardim).\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.cor",
    "page": "Mathematics",
    "title": "Base.cor",
    "category": "function",
    "text": "cor(x)\n\nReturn the number one.\n\n\n\ncor(X[, vardim=1])\n\nCompute the Pearson correlation matrix of the matrix X along the dimension vardim.\n\n\n\ncor(x, y)\n\nCompute the Pearson correlation between the vectors x and y.\n\n\n\ncor(X, Y[, vardim=1])\n\nCompute the Pearson correlation between the vectors or matrices X and Y along the dimension vardim.\n\n\n\n"
},

{
    "location": "stdlib/math/#Statistics-1",
    "page": "Mathematics",
    "title": "Statistics",
    "category": "section",
    "text": "Base.mean\nBase.mean!\nBase.std\nBase.stdm\nBase.var\nBase.varm\nBase.middle\nBase.median\nBase.median!\nBase.quantile\nBase.quantile!\nBase.cov\nBase.cor"
},

{
    "location": "stdlib/math/#Base.DFT.fft",
    "page": "Mathematics",
    "title": "Base.DFT.fft",
    "category": "function",
    "text": "fft(A [, dims])\n\nPerforms a multidimensional FFT of the array A. The optional dims argument specifies an iterable subset of dimensions (e.g. an integer, range, tuple, or array) to transform along. Most efficient if the size of A along the transformed dimensions is a product of small primes; see nextprod(). See also plan_fft() for even greater efficiency.\n\nA one-dimensional FFT computes the one-dimensional discrete Fourier transform (DFT) as defined by\n\noperatornameDFT(A)k =\n  sum_n=1^operatornamelength(A)\n  expleft(-ifrac2pi\n  (n-1)(k-1)operatornamelength(A) right) An\n\nA multidimensional FFT simply performs this operation along each transformed dimension of A.\n\nnote: Note\nJulia starts FFTW up with 1 thread by default. Higher performance is usually possible by increasing number of threads. Use FFTW.set_num_threads(Sys.CPU_CORES) to use as many threads as cores on your system.\nThis performs a multidimensional FFT by default. FFT libraries in other languages such as Python and Octave perform a one-dimensional FFT along the first non-singleton dimension of the array. This is worth noting while performing comparisons. For more details, refer to the Noteworthy Differences from other Languages section of the manual.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.fft!",
    "page": "Mathematics",
    "title": "Base.DFT.fft!",
    "category": "function",
    "text": "fft!(A [, dims])\n\nSame as fft, but operates in-place on A, which must be an array of complex floating-point numbers.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.ifft",
    "page": "Mathematics",
    "title": "Base.DFT.ifft",
    "category": "function",
    "text": "ifft(A [, dims])\n\nMultidimensional inverse FFT.\n\nA one-dimensional inverse FFT computes\n\noperatornameIDFT(A)k = frac1operatornamelength(A)\nsum_n=1^operatornamelength(A) expleft(+ifrac2pi (n-1)(k-1)\noperatornamelength(A) right) An\n\nA multidimensional inverse FFT simply performs this operation along each transformed dimension of A.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.ifft!",
    "page": "Mathematics",
    "title": "Base.DFT.ifft!",
    "category": "function",
    "text": "ifft!(A [, dims])\n\nSame as ifft, but operates in-place on A.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.bfft",
    "page": "Mathematics",
    "title": "Base.DFT.bfft",
    "category": "function",
    "text": "bfft(A [, dims])\n\nSimilar to ifft, but computes an unnormalized inverse (backward) transform, which must be divided by the product of the sizes of the transformed dimensions in order to obtain the inverse. (This is slightly more efficient than ifft because it omits a scaling step, which in some applications can be combined with other computational steps elsewhere.)\n\noperatornameBDFT(A)k = operatornamelength(A) operatornameIDFT(A)k\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.bfft!",
    "page": "Mathematics",
    "title": "Base.DFT.bfft!",
    "category": "function",
    "text": "bfft!(A [, dims])\n\nSame as bfft, but operates in-place on A.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.plan_fft",
    "page": "Mathematics",
    "title": "Base.DFT.plan_fft",
    "category": "function",
    "text": "plan_fft(A [, dims]; flags=FFTW.ESTIMATE;  timelimit=Inf)\n\nPre-plan an optimized FFT along given dimensions (dims) of arrays matching the shape and type of A.  (The first two arguments have the same meaning as for fft.) Returns an object P which represents the linear operator computed by the FFT, and which contains all of the information needed to compute fft(A, dims) quickly.\n\nTo apply P to an array A, use P * A; in general, the syntax for applying plans is much like that of matrices.  (A plan can only be applied to arrays of the same size as the A for which the plan was created.)  You can also apply a plan with a preallocated output array Â by calling A_mul_B!(Â, plan, A).  (For A_mul_B!, however, the input array A must be a complex floating-point array like the output Â.) You can compute the inverse-transform plan by inv(P) and apply the inverse plan with P \\ Â (the inverse plan is cached and reused for subsequent calls to inv or \\), and apply the inverse plan to a pre-allocated output array A with A_ldiv_B!(A, P, Â).\n\nThe flags argument is a bitwise-or of FFTW planner flags, defaulting to FFTW.ESTIMATE. e.g. passing FFTW.MEASURE or FFTW.PATIENT will instead spend several seconds (or more) benchmarking different possible FFT algorithms and picking the fastest one; see the FFTW manual for more information on planner flags.  The optional timelimit argument specifies a rough upper bound on the allowed planning time, in seconds. Passing FFTW.MEASURE or FFTW.PATIENT may cause the input array A to be overwritten with zeros during plan creation.\n\nplan_fft! is the same as plan_fft but creates a plan that operates in-place on its argument (which must be an array of complex floating-point numbers). plan_ifft and so on are similar but produce plans that perform the equivalent of the inverse transforms ifft and so on.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.plan_ifft",
    "page": "Mathematics",
    "title": "Base.DFT.plan_ifft",
    "category": "function",
    "text": "plan_ifft(A [, dims]; flags=FFTW.ESTIMATE;  timelimit=Inf)\n\nSame as plan_fft, but produces a plan that performs inverse transforms ifft.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.plan_bfft",
    "page": "Mathematics",
    "title": "Base.DFT.plan_bfft",
    "category": "function",
    "text": "plan_bfft(A [, dims]; flags=FFTW.ESTIMATE;  timelimit=Inf)\n\nSame as plan_fft, but produces a plan that performs an unnormalized backwards transform bfft.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.plan_fft!",
    "page": "Mathematics",
    "title": "Base.DFT.plan_fft!",
    "category": "function",
    "text": "plan_fft!(A [, dims]; flags=FFTW.ESTIMATE;  timelimit=Inf)\n\nSame as plan_fft, but operates in-place on A.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.plan_ifft!",
    "page": "Mathematics",
    "title": "Base.DFT.plan_ifft!",
    "category": "function",
    "text": "plan_ifft!(A [, dims]; flags=FFTW.ESTIMATE;  timelimit=Inf)\n\nSame as plan_ifft, but operates in-place on A.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.plan_bfft!",
    "page": "Mathematics",
    "title": "Base.DFT.plan_bfft!",
    "category": "function",
    "text": "plan_bfft!(A [, dims]; flags=FFTW.ESTIMATE;  timelimit=Inf)\n\nSame as plan_bfft, but operates in-place on A.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.rfft",
    "page": "Mathematics",
    "title": "Base.DFT.rfft",
    "category": "function",
    "text": "rfft(A [, dims])\n\nMultidimensional FFT of a real array A, exploiting the fact that the transform has conjugate symmetry in order to save roughly half the computational time and storage costs compared with fft. If A has size (n_1, ..., n_d), the result has size (div(n_1,2)+1, ..., n_d).\n\nThe optional dims argument specifies an iterable subset of one or more dimensions of A to transform, similar to fft. Instead of (roughly) halving the first dimension of A in the result, the dims[1] dimension is (roughly) halved in the same way.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.irfft",
    "page": "Mathematics",
    "title": "Base.DFT.irfft",
    "category": "function",
    "text": "irfft(A, d [, dims])\n\nInverse of rfft: for a complex array A, gives the corresponding real array whose FFT yields A in the first half. As for rfft, dims is an optional subset of dimensions to transform, defaulting to 1:ndims(A).\n\nd is the length of the transformed real array along the dims[1] dimension, which must satisfy div(d,2)+1 == size(A,dims[1]). (This parameter cannot be inferred from size(A) since both 2*size(A,dims[1])-2 as well as 2*size(A,dims[1])-1 are valid sizes for the transformed real array.)\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.brfft",
    "page": "Mathematics",
    "title": "Base.DFT.brfft",
    "category": "function",
    "text": "brfft(A, d [, dims])\n\nSimilar to irfft but computes an unnormalized inverse transform (similar to bfft), which must be divided by the product of the sizes of the transformed dimensions (of the real output array) in order to obtain the inverse transform.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.plan_rfft",
    "page": "Mathematics",
    "title": "Base.DFT.plan_rfft",
    "category": "function",
    "text": "plan_rfft(A [, dims]; flags=FFTW.ESTIMATE;  timelimit=Inf)\n\nPre-plan an optimized real-input FFT, similar to plan_fft except for rfft instead of fft. The first two arguments, and the size of the transformed result, are the same as for rfft.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.plan_brfft",
    "page": "Mathematics",
    "title": "Base.DFT.plan_brfft",
    "category": "function",
    "text": "plan_brfft(A, d [, dims]; flags=FFTW.ESTIMATE;  timelimit=Inf)\n\nPre-plan an optimized real-input unnormalized transform, similar to plan_rfft except for brfft instead of rfft. The first two arguments and the size of the transformed result, are the same as for brfft.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.plan_irfft",
    "page": "Mathematics",
    "title": "Base.DFT.plan_irfft",
    "category": "function",
    "text": "plan_irfft(A, d [, dims]; flags=FFTW.ESTIMATE;  timelimit=Inf)\n\nPre-plan an optimized inverse real-input FFT, similar to plan_rfft except for irfft and brfft, respectively. The first three arguments have the same meaning as for irfft.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.FFTW.dct",
    "page": "Mathematics",
    "title": "Base.DFT.FFTW.dct",
    "category": "function",
    "text": "dct(A [, dims])\n\nPerforms a multidimensional type-II discrete cosine transform (DCT) of the array A, using the unitary normalization of the DCT. The optional dims argument specifies an iterable subset of dimensions (e.g. an integer, range, tuple, or array) to transform along.  Most efficient if the size of A along the transformed dimensions is a product of small primes; see nextprod. See also plan_dct for even greater efficiency.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.FFTW.dct!",
    "page": "Mathematics",
    "title": "Base.DFT.FFTW.dct!",
    "category": "function",
    "text": "dct!(A [, dims])\n\nSame as dct!, except that it operates in-place on A, which must be an array of real or complex floating-point values.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.FFTW.idct",
    "page": "Mathematics",
    "title": "Base.DFT.FFTW.idct",
    "category": "function",
    "text": "idct(A [, dims])\n\nComputes the multidimensional inverse discrete cosine transform (DCT) of the array A (technically, a type-III DCT with the unitary normalization). The optional dims argument specifies an iterable subset of dimensions (e.g. an integer, range, tuple, or array) to transform along.  Most efficient if the size of A along the transformed dimensions is a product of small primes; see nextprod.  See also plan_idct for even greater efficiency.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.FFTW.idct!",
    "page": "Mathematics",
    "title": "Base.DFT.FFTW.idct!",
    "category": "function",
    "text": "idct!(A [, dims])\n\nSame as idct!, but operates in-place on A.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.FFTW.plan_dct",
    "page": "Mathematics",
    "title": "Base.DFT.FFTW.plan_dct",
    "category": "function",
    "text": "plan_dct(A [, dims [, flags [, timelimit]]])\n\nPre-plan an optimized discrete cosine transform (DCT), similar to plan_fft except producing a function that computes dct. The first two arguments have the same meaning as for dct.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.FFTW.plan_dct!",
    "page": "Mathematics",
    "title": "Base.DFT.FFTW.plan_dct!",
    "category": "function",
    "text": "plan_dct!(A [, dims [, flags [, timelimit]]])\n\nSame as plan_dct, but operates in-place on A.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.FFTW.plan_idct",
    "page": "Mathematics",
    "title": "Base.DFT.FFTW.plan_idct",
    "category": "function",
    "text": "plan_idct(A [, dims [, flags [, timelimit]]])\n\nPre-plan an optimized inverse discrete cosine transform (DCT), similar to plan_fft except producing a function that computes idct. The first two arguments have the same meaning as for idct.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.FFTW.plan_idct!",
    "page": "Mathematics",
    "title": "Base.DFT.FFTW.plan_idct!",
    "category": "function",
    "text": "plan_idct!(A [, dims [, flags [, timelimit]]])\n\nSame as plan_idct, but operates in-place on A.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.fftshift-Tuple{Any}",
    "page": "Mathematics",
    "title": "Base.DFT.fftshift",
    "category": "method",
    "text": "fftshift(x)\n\nSwap the first and second halves of each dimension of x.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.fftshift-Tuple{Any,Any}",
    "page": "Mathematics",
    "title": "Base.DFT.fftshift",
    "category": "method",
    "text": "fftshift(x,dim)\n\nSwap the first and second halves of the given dimension or iterable of dimensions of array x.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.ifftshift",
    "page": "Mathematics",
    "title": "Base.DFT.ifftshift",
    "category": "function",
    "text": "ifftshift(x, [dim])\n\nUndoes the effect of fftshift.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DSP.filt",
    "page": "Mathematics",
    "title": "Base.DSP.filt",
    "category": "function",
    "text": "filt(b, a, x, [si])\n\nApply filter described by vectors a and b to vector x, with an optional initial filter state vector si (defaults to zeros).\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DSP.filt!",
    "page": "Mathematics",
    "title": "Base.DSP.filt!",
    "category": "function",
    "text": "filt!(out, b, a, x, [si])\n\nSame as filt but writes the result into the out argument, which may alias the input x to modify it in-place.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DSP.deconv",
    "page": "Mathematics",
    "title": "Base.DSP.deconv",
    "category": "function",
    "text": "deconv(b,a) -> c\n\nConstruct vector c such that b = conv(a,c) + r. Equivalent to polynomial division.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DSP.conv",
    "page": "Mathematics",
    "title": "Base.DSP.conv",
    "category": "function",
    "text": "conv(u,v)\n\nConvolution of two vectors. Uses FFT algorithm.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DSP.conv2",
    "page": "Mathematics",
    "title": "Base.DSP.conv2",
    "category": "function",
    "text": "conv2(u,v,A)\n\n2-D convolution of the matrix A with the 2-D separable kernel generated by the vectors u and v. Uses 2-D FFT algorithm.\n\n\n\nconv2(B,A)\n\n2-D convolution of the matrix B with the matrix A. Uses 2-D FFT algorithm.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DSP.xcorr",
    "page": "Mathematics",
    "title": "Base.DSP.xcorr",
    "category": "function",
    "text": "xcorr(u,v)\n\nCompute the cross-correlation of two vectors.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.FFTW.r2r",
    "page": "Mathematics",
    "title": "Base.DFT.FFTW.r2r",
    "category": "function",
    "text": "r2r(A, kind [, dims])\n\nPerforms a multidimensional real-input/real-output (r2r) transform of type kind of the array A, as defined in the FFTW manual. kind specifies either a discrete cosine transform of various types (FFTW.REDFT00, FFTW.REDFT01, FFTW.REDFT10, or FFTW.REDFT11), a discrete sine transform of various types (FFTW.RODFT00, FFTW.RODFT01, FFTW.RODFT10, or FFTW.RODFT11), a real-input DFT with halfcomplex-format output (FFTW.R2HC and its inverse FFTW.HC2R), or a discrete Hartley transform (FFTW.DHT).  The kind argument may be an array or tuple in order to specify different transform types along the different dimensions of A; kind[end] is used for any unspecified dimensions.  See the FFTW manual for precise definitions of these transform types, at http://www.fftw.org/doc.\n\nThe optional dims argument specifies an iterable subset of dimensions (e.g. an integer, range, tuple, or array) to transform along. kind[i] is then the transform type for dims[i], with kind[end] being used for i > length(kind).\n\nSee also plan_r2r to pre-plan optimized r2r transforms.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.FFTW.r2r!",
    "page": "Mathematics",
    "title": "Base.DFT.FFTW.r2r!",
    "category": "function",
    "text": "r2r!(A, kind [, dims])\n\nSame as r2r, but operates in-place on A, which must be an array of real or complex floating-point numbers.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.FFTW.plan_r2r",
    "page": "Mathematics",
    "title": "Base.DFT.FFTW.plan_r2r",
    "category": "function",
    "text": "plan_r2r(A, kind [, dims [, flags [, timelimit]]])\n\nPre-plan an optimized r2r transform, similar to plan_fft except that the transforms (and the first three arguments) correspond to r2r and r2r!, respectively.\n\n\n\n"
},

{
    "location": "stdlib/math/#Base.DFT.FFTW.plan_r2r!",
    "page": "Mathematics",
    "title": "Base.DFT.FFTW.plan_r2r!",
    "category": "function",
    "text": "plan_r2r!(A, kind [, dims [, flags [, timelimit]]])\n\nSimilar to plan_fft, but corresponds to r2r!.\n\n\n\n"
},

{
    "location": "stdlib/math/#Signal-Processing-1",
    "page": "Mathematics",
    "title": "Signal Processing",
    "category": "section",
    "text": "Fast Fourier transform (FFT) functions in Julia are implemented by calling functions from FFTW.Base.DFT.fft\nBase.DFT.fft!\nBase.DFT.ifft\nBase.DFT.ifft!\nBase.DFT.bfft\nBase.DFT.bfft!\nBase.DFT.plan_fft\nBase.DFT.plan_ifft\nBase.DFT.plan_bfft\nBase.DFT.plan_fft!\nBase.DFT.plan_ifft!\nBase.DFT.plan_bfft!\nBase.DFT.rfft\nBase.DFT.irfft\nBase.DFT.brfft\nBase.DFT.plan_rfft\nBase.DFT.plan_brfft\nBase.DFT.plan_irfft\nBase.DFT.FFTW.dct\nBase.DFT.FFTW.dct!\nBase.DFT.FFTW.idct\nBase.DFT.FFTW.idct!\nBase.DFT.FFTW.plan_dct\nBase.DFT.FFTW.plan_dct!\nBase.DFT.FFTW.plan_idct\nBase.DFT.FFTW.plan_idct!\nBase.DFT.fftshift(::Any)\nBase.DFT.fftshift(::Any, ::Any)\nBase.DFT.ifftshift\nBase.DSP.filt\nBase.DSP.filt!\nBase.DSP.deconv\nBase.DSP.conv\nBase.DSP.conv2\nBase.DSP.xcorrThe following functions are defined within the Base.FFTW module.Base.DFT.FFTW.r2r\nBase.DFT.FFTW.r2r!\nBase.DFT.FFTW.plan_r2r\nBase.DFT.FFTW.plan_r2r!"
},

{
    "location": "stdlib/numbers/#",
    "page": "Numbers",
    "title": "Numbers",
    "category": "page",
    "text": ""
},

{
    "location": "stdlib/numbers/#lib-numbers-1",
    "page": "Numbers",
    "title": "Numbers",
    "category": "section",
    "text": ""
},

{
    "location": "stdlib/numbers/#Standard-Numeric-Types-1",
    "page": "Numbers",
    "title": "Standard Numeric Types",
    "category": "section",
    "text": ""
},

{
    "location": "stdlib/numbers/#Core.Number",
    "page": "Numbers",
    "title": "Core.Number",
    "category": "type",
    "text": "Number\n\nAbstract supertype for all number types.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Core.Real",
    "page": "Numbers",
    "title": "Core.Real",
    "category": "type",
    "text": "Real <: Number\n\nAbstract supertype for all real numbers.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Core.AbstractFloat",
    "page": "Numbers",
    "title": "Core.AbstractFloat",
    "category": "type",
    "text": "AbstractFloat <: Real\n\nAbstract supertype for all floating point numbers.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Core.Integer",
    "page": "Numbers",
    "title": "Core.Integer",
    "category": "type",
    "text": "Integer <: Real\n\nAbstract supertype for all integers.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Core.Signed",
    "page": "Numbers",
    "title": "Core.Signed",
    "category": "type",
    "text": "Signed <: Integer\n\nAbstract supertype for all signed integers.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Core.Unsigned",
    "page": "Numbers",
    "title": "Core.Unsigned",
    "category": "type",
    "text": "Unsigned <: Integer\n\nAbstract supertype for all unsigned integers.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Abstract-number-types-1",
    "page": "Numbers",
    "title": "Abstract number types",
    "category": "section",
    "text": "Core.Number\nCore.Real\nCore.AbstractFloat\nCore.Integer\nCore.Signed\nCore.Unsigned"
},

{
    "location": "stdlib/numbers/#Core.Float16",
    "page": "Numbers",
    "title": "Core.Float16",
    "category": "type",
    "text": "Float16 <: AbstractFloat\n\n16-bit floating point number type.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Core.Float32",
    "page": "Numbers",
    "title": "Core.Float32",
    "category": "type",
    "text": "Float32 <: AbstractFloat\n\n32-bit floating point number type.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Core.Float64",
    "page": "Numbers",
    "title": "Core.Float64",
    "category": "type",
    "text": "Float64 <: AbstractFloat\n\n64-bit floating point number type.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.MPFR.BigFloat",
    "page": "Numbers",
    "title": "Base.MPFR.BigFloat",
    "category": "type",
    "text": "BigFloat <: AbstractFloat\n\nArbitrary precision floating point number type.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Core.Bool",
    "page": "Numbers",
    "title": "Core.Bool",
    "category": "type",
    "text": "Bool <: Integer\n\nBoolean type.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Core.Int8",
    "page": "Numbers",
    "title": "Core.Int8",
    "category": "type",
    "text": "Int8 <: Signed\n\n8-bit signed integer type.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Core.UInt8",
    "page": "Numbers",
    "title": "Core.UInt8",
    "category": "type",
    "text": "UInt8 <: Unsigned\n\n8-bit unsigned integer type.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Core.Int16",
    "page": "Numbers",
    "title": "Core.Int16",
    "category": "type",
    "text": "Int16 <: Signed\n\n16-bit signed integer type.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Core.UInt16",
    "page": "Numbers",
    "title": "Core.UInt16",
    "category": "type",
    "text": "UInt16 <: Unsigned\n\n16-bit unsigned integer type.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Core.Int32",
    "page": "Numbers",
    "title": "Core.Int32",
    "category": "type",
    "text": "Int32 <: Signed\n\n32-bit signed integer type.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Core.UInt32",
    "page": "Numbers",
    "title": "Core.UInt32",
    "category": "type",
    "text": "UInt32 <: Unsigned\n\n32-bit unsigned integer type.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Core.Int64",
    "page": "Numbers",
    "title": "Core.Int64",
    "category": "type",
    "text": "Int64 <: Signed\n\n64-bit signed integer type.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Core.UInt64",
    "page": "Numbers",
    "title": "Core.UInt64",
    "category": "type",
    "text": "UInt64 <: Unsigned\n\n64-bit unsigned integer type.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Core.Int128",
    "page": "Numbers",
    "title": "Core.Int128",
    "category": "type",
    "text": "Int128 <: Signed\n\n128-bit signed integer type.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Core.UInt128",
    "page": "Numbers",
    "title": "Core.UInt128",
    "category": "type",
    "text": "UInt128 <: Unsigned\n\n128-bit unsigned integer type.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.GMP.BigInt",
    "page": "Numbers",
    "title": "Base.GMP.BigInt",
    "category": "type",
    "text": "BigInt <: Integer\n\nArbitrary precision integer type.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.Complex",
    "page": "Numbers",
    "title": "Base.Complex",
    "category": "type",
    "text": "Complex{T<:Real} <: Number\n\nComplex number type with real and imaginary part of type T.\n\nComplex32, Complex64 and Complex128 are aliases for Complex{Float16}, Complex{Float32} and Complex{Float64} respectively.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.Rational",
    "page": "Numbers",
    "title": "Base.Rational",
    "category": "type",
    "text": "Rational{T<:Integer} <: Real\n\nRational number type, with numerator and denominator of type T.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.Irrational",
    "page": "Numbers",
    "title": "Base.Irrational",
    "category": "type",
    "text": "Irrational <: Real\n\nIrrational number type.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Concrete-number-types-1",
    "page": "Numbers",
    "title": "Concrete number types",
    "category": "section",
    "text": "Core.Float16\nCore.Float32\nCore.Float64\nBase.BigFloat\nCore.Bool\nCore.Int8\nCore.UInt8\nCore.Int16\nCore.UInt16\nCore.Int32\nCore.UInt32\nCore.Int64\nCore.UInt64\nCore.Int128\nCore.UInt128\nBase.BigInt\nBase.Complex\nBase.Rational\nBase.Irrational"
},

{
    "location": "stdlib/numbers/#Base.bin",
    "page": "Numbers",
    "title": "Base.bin",
    "category": "function",
    "text": "bin(n, pad::Int=1)\n\nConvert an integer to a binary string, optionally specifying a number of digits to pad to.\n\njulia> bin(10,2)\n\"1010\"\n\njulia> bin(10,8)\n\"00001010\"\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.hex",
    "page": "Numbers",
    "title": "Base.hex",
    "category": "function",
    "text": "hex(n, pad::Int=1)\n\nConvert an integer to a hexadecimal string, optionally specifying a number of digits to pad to.\n\njulia> hex(20)\n\"14\"\n\njulia> hex(20, 3)\n\"014\"\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.dec",
    "page": "Numbers",
    "title": "Base.dec",
    "category": "function",
    "text": "dec(n, pad::Int=1)\n\nConvert an integer to a decimal string, optionally specifying a number of digits to pad to.\n\nExamples\n\njulia> dec(20)\n\"20\"\n\njulia> dec(20, 3)\n\"020\"\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.oct",
    "page": "Numbers",
    "title": "Base.oct",
    "category": "function",
    "text": "oct(n, pad::Int=1)\n\nConvert an integer to an octal string, optionally specifying a number of digits to pad to.\n\njulia> oct(20)\n\"24\"\n\njulia> oct(20, 3)\n\"024\"\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.base",
    "page": "Numbers",
    "title": "Base.base",
    "category": "function",
    "text": "base(base::Integer, n::Integer, pad::Integer=1)\n\nConvert an integer n to a string in the given base, optionally specifying a number of digits to pad to.\n\njulia> base(13,5,4)\n\"0005\"\n\njulia> base(5,13,4)\n\"0023\"\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.digits",
    "page": "Numbers",
    "title": "Base.digits",
    "category": "function",
    "text": "digits([T<:Integer], n::Integer, base::T=10, pad::Integer=1)\n\nReturns an array with element type T (default Int) of the digits of n in the given base, optionally padded with zeros to a specified size. More significant digits are at higher indexes, such that n == sum([digits[k]*base^(k-1) for k=1:length(digits)]).\n\nExamples\n\njulia> digits(10, 10)\n2-element Array{Int64,1}:\n 0\n 1\n\njulia> digits(10, 2)\n4-element Array{Int64,1}:\n 0\n 1\n 0\n 1\n\njulia> digits(10, 2, 6)\n6-element Array{Int64,1}:\n 0\n 1\n 0\n 1\n 0\n 0\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.digits!",
    "page": "Numbers",
    "title": "Base.digits!",
    "category": "function",
    "text": "digits!(array, n::Integer, base::Integer=10)\n\nFills an array of the digits of n in the given base. More significant digits are at higher indexes. If the array length is insufficient, the least significant digits are filled up to the array length. If the array length is excessive, the excess portion is filled with zeros.\n\nExamples\n\njulia> digits!([2,2,2,2], 10, 2)\n4-element Array{Int64,1}:\n 0\n 1\n 0\n 1\n\njulia> digits!([2,2,2,2,2,2], 10, 2)\n6-element Array{Int64,1}:\n 0\n 1\n 0\n 1\n 0\n 0\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.bits",
    "page": "Numbers",
    "title": "Base.bits",
    "category": "function",
    "text": "bits(n)\n\nA string giving the literal bit representation of a number.\n\nExample\n\njulia> bits(4)\n\"0000000000000000000000000000000000000000000000000000000000000100\"\n\njulia> bits(2.2)\n\"0100000000000001100110011001100110011001100110011001100110011010\"\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.parse-Tuple{Type,Any,Any}",
    "page": "Numbers",
    "title": "Base.parse",
    "category": "method",
    "text": "parse(type, str, [base])\n\nParse a string as a number. If the type is an integer type, then a base can be specified (the default is 10). If the type is a floating point type, the string is parsed as a decimal floating point number. If the string does not contain a valid number, an error is raised.\n\njulia> parse(Int, \"1234\")\n1234\n\njulia> parse(Int, \"1234\", 5)\n194\n\njulia> parse(Int, \"afc\", 16)\n2812\n\njulia> parse(Float64, \"1.2e-3\")\n0.0012\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.tryparse",
    "page": "Numbers",
    "title": "Base.tryparse",
    "category": "function",
    "text": "tryparse(type, str, [base])\n\nLike parse, but returns a Nullable of the requested type. The result will be null if the string does not contain a valid number.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.big",
    "page": "Numbers",
    "title": "Base.big",
    "category": "function",
    "text": "big(x)\n\nConvert a number to a maximum precision representation (typically BigInt or BigFloat). See BigFloat for information about some pitfalls with floating-point numbers.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.signed",
    "page": "Numbers",
    "title": "Base.signed",
    "category": "function",
    "text": "signed(x)\n\nConvert a number to a signed integer. If the argument is unsigned, it is reinterpreted as signed without checking for overflow.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.unsigned",
    "page": "Numbers",
    "title": "Base.unsigned",
    "category": "function",
    "text": "unsigned(x) -> Unsigned\n\nConvert a number to an unsigned integer. If the argument is signed, it is reinterpreted as unsigned without checking for negative values.\n\nExamples\n\njulia> unsigned(-2)\n0xfffffffffffffffe\n\njulia> unsigned(2)\n0x0000000000000002\n\njulia> signed(unsigned(-2))\n-2\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.float-Tuple{Any}",
    "page": "Numbers",
    "title": "Base.float",
    "category": "method",
    "text": "float(x)\n\nConvert a number or array to a floating point data type. When passed a string, this function is equivalent to parse(Float64, x).\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.Math.significand",
    "page": "Numbers",
    "title": "Base.Math.significand",
    "category": "function",
    "text": "significand(x)\n\nExtract the significand(s) (a.k.a. mantissa), in binary representation, of a floating-point number. If x is a non-zero finite number, then the result will be a number of the same type on the interval 12). Otherwise x is returned.\n\nExamples\n\njulia> significand(15.2)/15.2\n0.125\n\njulia> significand(15.2)*8\n15.2\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.Math.exponent",
    "page": "Numbers",
    "title": "Base.Math.exponent",
    "category": "function",
    "text": "exponent(x) -> Int\n\nGet the exponent of a normalized floating-point number.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.complex-Tuple{Complex}",
    "page": "Numbers",
    "title": "Base.complex",
    "category": "method",
    "text": "complex(r, [i])\n\nConvert real numbers or arrays to complex. i defaults to zero.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.bswap",
    "page": "Numbers",
    "title": "Base.bswap",
    "category": "function",
    "text": "bswap(n)\n\nByte-swap an integer. Flip the bits of its binary representation.\n\nExamples\n\njulia> a = bswap(4)\n288230376151711744\n\njulia> bswap(a)\n4\n\njulia> bin(1)\n\"1\"\n\njulia> bin(bswap(1))\n\"100000000000000000000000000000000000000000000000000000000\"\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.num2hex",
    "page": "Numbers",
    "title": "Base.num2hex",
    "category": "function",
    "text": "num2hex(f)\n\nGet a hexadecimal string of the binary representation of a floating point number.\n\nExample\n\njulia> num2hex(2.2)\n\"400199999999999a\"\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.hex2num",
    "page": "Numbers",
    "title": "Base.hex2num",
    "category": "function",
    "text": "hex2num(str)\n\nConvert a hexadecimal string to the floating point number it represents.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.hex2bytes",
    "page": "Numbers",
    "title": "Base.hex2bytes",
    "category": "function",
    "text": "hex2bytes(s::AbstractString)\n\nConvert an arbitrarily long hexadecimal string to its binary representation. Returns an Array{UInt8,1}, i.e. an array of bytes.\n\njulia> a = hex(12345)\n\"3039\"\n\njulia> hex2bytes(a)\n2-element Array{UInt8,1}:\n 0x30\n 0x39\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.bytes2hex",
    "page": "Numbers",
    "title": "Base.bytes2hex",
    "category": "function",
    "text": "bytes2hex(bin_arr::Array{UInt8, 1}) -> String\n\nConvert an array of bytes to its hexadecimal representation. All characters are in lower-case.\n\njulia> a = hex(12345)\n\"3039\"\n\njulia> b = hex2bytes(a)\n2-element Array{UInt8,1}:\n 0x30\n 0x39\n\njulia> bytes2hex(b)\n\"3039\"\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Data-Formats-1",
    "page": "Numbers",
    "title": "Data Formats",
    "category": "section",
    "text": "Base.bin\nBase.hex\nBase.dec\nBase.oct\nBase.base\nBase.digits\nBase.digits!\nBase.bits\nBase.parse(::Type, ::Any, ::Any)\nBase.tryparse\nBase.big\nBase.signed\nBase.unsigned\nBase.float(::Any)\nBase.Math.significand\nBase.Math.exponent\nBase.complex(::Complex)\nBase.bswap\nBase.num2hex\nBase.hex2num\nBase.hex2bytes\nBase.bytes2hex"
},

{
    "location": "stdlib/numbers/#Base.one",
    "page": "Numbers",
    "title": "Base.one",
    "category": "function",
    "text": "one(x)\none(T::type)\n\nReturn a multiplicative identity for x: a value such that one(x)*x == x*one(x) == x.  Alternatively one(T) can take a type T, in which case one returns a multiplicative identity for any x of type T.\n\nIf possible, one(x) returns a value of the same type as x, and one(T) returns a value of type T.  However, this may not be the case for types representing dimensionful quantities (e.g. time in days), since the multiplicative identity must be dimensionless.  In that case, one(x) should return an identity value of the same precision (and shape, for matrices) as x.\n\nIf you want a quantity that is of the same type as x, or of type T, even if x is dimensionful, use oneunit instead.\n\njulia> one(3.7)\n1.0\n\njulia> one(Int)\n1\n\njulia> one(Dates.Day(1))\n1\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.oneunit",
    "page": "Numbers",
    "title": "Base.oneunit",
    "category": "function",
    "text": "oneunit(x::T)\noneunit(T::Type)\n\nReturns T(one(x)), where T is either the type of the argument or (if a type is passed) the argument.  This differs from one for dimensionful quantities: one is dimensionless (a multiplicative identity) while oneunit is dimensionful (of the same type as x, or of type T).\n\njulia> oneunit(3.7)\n1.0\n\njulia> oneunit(Dates.Day)\n1 day\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.zero",
    "page": "Numbers",
    "title": "Base.zero",
    "category": "function",
    "text": "zero(x)\n\nGet the additive identity element for the type of x (x can also specify the type itself).\n\njulia> zero(1)\n0\n\njulia> zero(big\"2.0\")\n0.000000000000000000000000000000000000000000000000000000000000000000000000000000\n\njulia> zero(rand(2,2))\n2×2 Array{Float64,2}:\n 0.0  0.0\n 0.0  0.0\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.pi",
    "page": "Numbers",
    "title": "Base.pi",
    "category": "constant",
    "text": "pi\nπ\n\nThe constant pi.\n\njulia> pi\nπ = 3.1415926535897...\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.im",
    "page": "Numbers",
    "title": "Base.im",
    "category": "constant",
    "text": "im\n\nThe imaginary unit.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.eu",
    "page": "Numbers",
    "title": "Base.eu",
    "category": "constant",
    "text": "e\neu\n\nThe constant e.\n\njulia> e\ne = 2.7182818284590...\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.catalan",
    "page": "Numbers",
    "title": "Base.catalan",
    "category": "constant",
    "text": "catalan\n\nCatalan\'s constant.\n\njulia> catalan\ncatalan = 0.9159655941772...\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.eulergamma",
    "page": "Numbers",
    "title": "Base.eulergamma",
    "category": "constant",
    "text": "γ\neulergamma\n\nEuler\'s constant.\n\njulia> eulergamma\nγ = 0.5772156649015...\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.golden",
    "page": "Numbers",
    "title": "Base.golden",
    "category": "constant",
    "text": "φ\ngolden\n\nThe golden ratio.\n\njulia> golden\nφ = 1.6180339887498...\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.Inf",
    "page": "Numbers",
    "title": "Base.Inf",
    "category": "constant",
    "text": "Inf\n\nPositive infinity of type Float64.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.Inf32",
    "page": "Numbers",
    "title": "Base.Inf32",
    "category": "constant",
    "text": "Inf32\n\nPositive infinity of type Float32.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.Inf16",
    "page": "Numbers",
    "title": "Base.Inf16",
    "category": "constant",
    "text": "Inf16\n\nPositive infinity of type Float16.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.NaN",
    "page": "Numbers",
    "title": "Base.NaN",
    "category": "constant",
    "text": "NaN\n\nA not-a-number value of type Float64.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.NaN32",
    "page": "Numbers",
    "title": "Base.NaN32",
    "category": "constant",
    "text": "NaN32\n\nA not-a-number value of type Float32.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.NaN16",
    "page": "Numbers",
    "title": "Base.NaN16",
    "category": "constant",
    "text": "NaN16\n\nA not-a-number value of type Float16.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.issubnormal",
    "page": "Numbers",
    "title": "Base.issubnormal",
    "category": "function",
    "text": "issubnormal(f) -> Bool\n\nTest whether a floating point number is subnormal.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.isfinite",
    "page": "Numbers",
    "title": "Base.isfinite",
    "category": "function",
    "text": "isfinite(f) -> Bool\n\nTest whether a number is finite.\n\njulia> isfinite(5)\ntrue\n\njulia> isfinite(NaN32)\nfalse\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.isinf",
    "page": "Numbers",
    "title": "Base.isinf",
    "category": "function",
    "text": "isinf(f) -> Bool\n\nTest whether a number is infinite.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.isnan",
    "page": "Numbers",
    "title": "Base.isnan",
    "category": "function",
    "text": "isnan(f) -> Bool\n\nTest whether a floating point number is not a number (NaN).\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.iszero",
    "page": "Numbers",
    "title": "Base.iszero",
    "category": "function",
    "text": "iszero(x)\n\nReturn true if x == zero(x); if x is an array, this checks whether all of the elements of x are zero.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.nextfloat",
    "page": "Numbers",
    "title": "Base.nextfloat",
    "category": "function",
    "text": "nextfloat(x::AbstractFloat, n::Integer)\n\nThe result of n iterative applications of nextfloat to x if n >= 0, or -n applications of prevfloat if n < 0.\n\n\n\nnextfloat(x::AbstractFloat)\n\nReturns the smallest floating point number y of the same type as x such x < y. If no such y exists (e.g. if x is Inf or NaN), then returns x.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.prevfloat",
    "page": "Numbers",
    "title": "Base.prevfloat",
    "category": "function",
    "text": "prevfloat(x::AbstractFloat)\n\nReturns the largest floating point number y of the same type as x such y < x. If no such y exists (e.g. if x is -Inf or NaN), then returns x.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.isinteger",
    "page": "Numbers",
    "title": "Base.isinteger",
    "category": "function",
    "text": "isinteger(x) -> Bool\n\nTest whether x is numerically equal to some integer.\n\njulia> isinteger(4.0)\ntrue\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.isreal",
    "page": "Numbers",
    "title": "Base.isreal",
    "category": "function",
    "text": "isreal(x) -> Bool\n\nTest whether x or all its elements are numerically equal to some real number.\n\njulia> isreal(5.)\ntrue\n\njulia> isreal([4.; complex(0,1)])\nfalse\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Core.Float32-Tuple{Any}",
    "page": "Numbers",
    "title": "Core.Float32",
    "category": "method",
    "text": "Float32(x [, mode::RoundingMode])\n\nCreate a Float32 from x. If x is not exactly representable then mode determines how x is rounded.\n\nExamples\n\njulia> Float32(1/3, RoundDown)\n0.3333333f0\n\njulia> Float32(1/3, RoundUp)\n0.33333334f0\n\nSee RoundingMode for available rounding modes.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Core.Float64-Tuple{Any}",
    "page": "Numbers",
    "title": "Core.Float64",
    "category": "method",
    "text": "Float64(x [, mode::RoundingMode])\n\nCreate a Float64 from x. If x is not exactly representable then mode determines how x is rounded.\n\nExamples\n\njulia> Float64(pi, RoundDown)\n3.141592653589793\n\njulia> Float64(pi, RoundUp)\n3.1415926535897936\n\nSee RoundingMode for available rounding modes.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.GMP.BigInt-Tuple{Any}",
    "page": "Numbers",
    "title": "Base.GMP.BigInt",
    "category": "method",
    "text": "BigInt(x)\n\nCreate an arbitrary precision integer. x may be an Int (or anything that can be converted to an Int). The usual mathematical operators are defined for this type, and results are promoted to a BigInt.\n\nInstances can be constructed from strings via parse, or using the big string literal.\n\njulia> parse(BigInt, \"42\")\n42\n\njulia> big\"313\"\n313\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.MPFR.BigFloat-Tuple{Any}",
    "page": "Numbers",
    "title": "Base.MPFR.BigFloat",
    "category": "method",
    "text": "BigFloat(x)\n\nCreate an arbitrary precision floating point number. x may be an Integer, a Float64 or a BigInt. The usual mathematical operators are defined for this type, and results are promoted to a BigFloat.\n\nNote that because decimal literals are converted to floating point numbers when parsed, BigFloat(2.1) may not yield what you expect. You may instead prefer to initialize constants from strings via parse, or using the big string literal.\n\njulia> BigFloat(2.1)\n2.100000000000000088817841970012523233890533447265625000000000000000000000000000\n\njulia> big\"2.1\"\n2.099999999999999999999999999999999999999999999999999999999999999999999999999986\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.Rounding.rounding",
    "page": "Numbers",
    "title": "Base.Rounding.rounding",
    "category": "function",
    "text": "rounding(T)\n\nGet the current floating point rounding mode for type T, controlling the rounding of basic arithmetic functions (+, -, *, / and sqrt) and type conversion.\n\nSee RoundingMode for available modes.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.Rounding.setrounding-Tuple{Type,Any}",
    "page": "Numbers",
    "title": "Base.Rounding.setrounding",
    "category": "method",
    "text": "setrounding(T, mode)\n\nSet the rounding mode of floating point type T, controlling the rounding of basic arithmetic functions (+, -, *, / and sqrt) and type conversion. Other numerical functions may give incorrect or invalid values when using rounding modes other than the default RoundNearest.\n\nNote that this may affect other types, for instance changing the rounding mode of Float64 will change the rounding mode of Float32. See RoundingMode for available modes.\n\nwarning: Warning\nThis feature is still experimental, and may give unexpected or incorrect values.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.Rounding.setrounding-Tuple{Function,Type,RoundingMode}",
    "page": "Numbers",
    "title": "Base.Rounding.setrounding",
    "category": "method",
    "text": "setrounding(f::Function, T, mode)\n\nChange the rounding mode of floating point type T for the duration of f. It is logically equivalent to:\n\nold = rounding(T)\nsetrounding(T, mode)\nf()\nsetrounding(T, old)\n\nSee RoundingMode for available rounding modes.\n\nwarning: Warning\nThis feature is still experimental, and may give unexpected or incorrect values. A known problem is the interaction with compiler optimisations, e.g.julia> setrounding(Float64,RoundDown) do\n           1.1 + 0.1\n       end\n1.2000000000000002Here the compiler is constant folding, that is evaluating a known constant expression at compile time, however the rounding mode is only changed at runtime, so this is not reflected in the function result. This can be avoided by moving constants outside the expression, e.g.julia> x = 1.1; y = 0.1;\n\njulia> setrounding(Float64,RoundDown) do\n           x + y\n       end\n1.2\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.Rounding.get_zero_subnormals",
    "page": "Numbers",
    "title": "Base.Rounding.get_zero_subnormals",
    "category": "function",
    "text": "get_zero_subnormals() -> Bool\n\nReturns false if operations on subnormal floating-point values (\"denormals\") obey rules for IEEE arithmetic, and true if they might be converted to zeros.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.Rounding.set_zero_subnormals",
    "page": "Numbers",
    "title": "Base.Rounding.set_zero_subnormals",
    "category": "function",
    "text": "set_zero_subnormals(yes::Bool) -> Bool\n\nIf yes is false, subsequent floating-point operations follow rules for IEEE arithmetic on subnormal values (\"denormals\"). Otherwise, floating-point operations are permitted (but not required) to convert subnormal inputs or outputs to zero. Returns true unless yes==true but the hardware does not support zeroing of subnormal numbers.\n\nset_zero_subnormals(true) can speed up some computations on some hardware. However, it can break identities such as (x-y==0) == (x==y).\n\n\n\n"
},

{
    "location": "stdlib/numbers/#General-Number-Functions-and-Constants-1",
    "page": "Numbers",
    "title": "General Number Functions and Constants",
    "category": "section",
    "text": "Base.one\nBase.oneunit\nBase.zero\nBase.pi\nBase.im\nBase.eu\nBase.catalan\nBase.eulergamma\nBase.golden\nBase.Inf\nBase.Inf32\nBase.Inf16\nBase.NaN\nBase.NaN32\nBase.NaN16\nBase.issubnormal\nBase.isfinite\nBase.isinf\nBase.isnan\nBase.iszero\nBase.nextfloat\nBase.prevfloat\nBase.isinteger\nBase.isreal\nCore.Float32(::Any)\nCore.Float64(::Any)\nBase.GMP.BigInt(::Any)\nBase.MPFR.BigFloat(::Any)\nBase.Rounding.rounding\nBase.Rounding.setrounding(::Type, ::Any)\nBase.Rounding.setrounding(::Function, ::Type, ::RoundingMode)\nBase.Rounding.get_zero_subnormals\nBase.Rounding.set_zero_subnormals"
},

{
    "location": "stdlib/numbers/#Base.count_ones",
    "page": "Numbers",
    "title": "Base.count_ones",
    "category": "function",
    "text": "count_ones(x::Integer) -> Integer\n\nNumber of ones in the binary representation of x.\n\njulia> count_ones(7)\n3\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.count_zeros",
    "page": "Numbers",
    "title": "Base.count_zeros",
    "category": "function",
    "text": "count_zeros(x::Integer) -> Integer\n\nNumber of zeros in the binary representation of x.\n\njulia> count_zeros(Int32(2 ^ 16 - 1))\n16\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.leading_zeros",
    "page": "Numbers",
    "title": "Base.leading_zeros",
    "category": "function",
    "text": "leading_zeros(x::Integer) -> Integer\n\nNumber of zeros leading the binary representation of x.\n\njulia> leading_zeros(Int32(1))\n31\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.leading_ones",
    "page": "Numbers",
    "title": "Base.leading_ones",
    "category": "function",
    "text": "leading_ones(x::Integer) -> Integer\n\nNumber of ones leading the binary representation of x.\n\njulia> leading_ones(UInt32(2 ^ 32 - 2))\n31\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.trailing_zeros",
    "page": "Numbers",
    "title": "Base.trailing_zeros",
    "category": "function",
    "text": "trailing_zeros(x::Integer) -> Integer\n\nNumber of zeros trailing the binary representation of x.\n\njulia> trailing_zeros(2)\n1\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.trailing_ones",
    "page": "Numbers",
    "title": "Base.trailing_ones",
    "category": "function",
    "text": "trailing_ones(x::Integer) -> Integer\n\nNumber of ones trailing the binary representation of x.\n\njulia> trailing_ones(3)\n2\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.isodd",
    "page": "Numbers",
    "title": "Base.isodd",
    "category": "function",
    "text": "isodd(x::Integer) -> Bool\n\nReturns true if x is odd (that is, not divisible by 2), and false otherwise.\n\njulia> isodd(9)\ntrue\n\njulia> isodd(10)\nfalse\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.iseven",
    "page": "Numbers",
    "title": "Base.iseven",
    "category": "function",
    "text": "iseven(x::Integer) -> Bool\n\nReturns true is x is even (that is, divisible by 2), and false otherwise.\n\njulia> iseven(9)\nfalse\n\njulia> iseven(10)\ntrue\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Integers-1",
    "page": "Numbers",
    "title": "Integers",
    "category": "section",
    "text": "Base.count_ones\nBase.count_zeros\nBase.leading_zeros\nBase.leading_ones\nBase.trailing_zeros\nBase.trailing_ones\nBase.isodd\nBase.iseven"
},

{
    "location": "stdlib/numbers/#Base.precision",
    "page": "Numbers",
    "title": "Base.precision",
    "category": "function",
    "text": "precision(num::AbstractFloat)\n\nGet the precision of a floating point number, as defined by the effective number of bits in the mantissa.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.precision-Tuple{Type{BigFloat}}",
    "page": "Numbers",
    "title": "Base.precision",
    "category": "method",
    "text": "precision(BigFloat)\n\nGet the precision (in bits) currently used for BigFloat arithmetic.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.MPFR.setprecision",
    "page": "Numbers",
    "title": "Base.MPFR.setprecision",
    "category": "function",
    "text": "setprecision([T=BigFloat,] precision::Int)\n\nSet the precision (in bits) to be used for T arithmetic.\n\n\n\nsetprecision(f::Function, [T=BigFloat,] precision::Integer)\n\nChange the T arithmetic precision (in bits) for the duration of f. It is logically equivalent to:\n\nold = precision(BigFloat)\nsetprecision(BigFloat, precision)\nf()\nsetprecision(BigFloat, old)\n\nOften used as setprecision(T, precision) do ... end\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.MPFR.BigFloat-Tuple{Any,Int64}",
    "page": "Numbers",
    "title": "Base.MPFR.BigFloat",
    "category": "method",
    "text": "BigFloat(x, prec::Int)\n\nCreate a representation of x as a BigFloat with precision prec.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.MPFR.BigFloat-Tuple{Union{AbstractFloat, Integer, String},RoundingMode}",
    "page": "Numbers",
    "title": "Base.MPFR.BigFloat",
    "category": "method",
    "text": "BigFloat(x, rounding::RoundingMode)\n\nCreate a representation of x as a BigFloat with the current global precision and rounding mode rounding.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.MPFR.BigFloat-Tuple{Any,Int64,RoundingMode}",
    "page": "Numbers",
    "title": "Base.MPFR.BigFloat",
    "category": "method",
    "text": "BigFloat(x, prec::Int, rounding::RoundingMode)\n\nCreate a representation of x as a BigFloat with precision prec and rounding mode rounding.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.MPFR.BigFloat-Tuple{String}",
    "page": "Numbers",
    "title": "Base.MPFR.BigFloat",
    "category": "method",
    "text": "BigFloat(x::String)\n\nCreate a representation of the string x as a BigFloat.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#BigFloats-1",
    "page": "Numbers",
    "title": "BigFloats",
    "category": "section",
    "text": "The BigFloat type implements arbitrary-precision floating-point arithmetic using the GNU MPFR library.Base.precision\nBase.MPFR.precision(::Type{BigFloat})\nBase.MPFR.setprecision\nBase.MPFR.BigFloat(x, prec::Int)\nBigFloat(x::Union{Integer, AbstractFloat, String}, rounding::RoundingMode)\nBase.MPFR.BigFloat(x, prec::Int, rounding::RoundingMode)\nBase.MPFR.BigFloat(x::String)"
},

{
    "location": "stdlib/numbers/#Base.Random.srand",
    "page": "Numbers",
    "title": "Base.Random.srand",
    "category": "function",
    "text": "srand([rng=GLOBAL_RNG], [seed]) -> rng\nsrand([rng=GLOBAL_RNG], filename, n=4) -> rng\n\nReseed the random number generator. If a seed is provided, the RNG will give a reproducible sequence of numbers, otherwise Julia will get entropy from the system. For MersenneTwister, the seed may be a non-negative integer, a vector of UInt32 integers or a filename, in which case the seed is read from a file (4n bytes are read from the file, where n is an optional argument). RandomDevice does not support seeding.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.Random.MersenneTwister",
    "page": "Numbers",
    "title": "Base.Random.MersenneTwister",
    "category": "type",
    "text": "MersenneTwister(seed)\n\nCreate a MersenneTwister RNG object. Different RNG objects can have their own seeds, which may be useful for generating different streams of random numbers.\n\nExample\n\njulia> rng = MersenneTwister(1234);\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.Random.RandomDevice",
    "page": "Numbers",
    "title": "Base.Random.RandomDevice",
    "category": "type",
    "text": "RandomDevice()\n\nCreate a RandomDevice RNG object. Two such objects will always generate different streams of random numbers.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.Random.rand",
    "page": "Numbers",
    "title": "Base.Random.rand",
    "category": "function",
    "text": "rand([rng=GLOBAL_RNG], [S], [dims...])\n\nPick a random element or array of random elements from the set of values specified by S; S can be\n\nan indexable collection (for example 1:n or [\'x\',\'y\',\'z\']), or\na type: the set of values to pick from is then equivalent to typemin(S):typemax(S) for integers (this is not applicable to BigInt), and to 0 1) for floating point numbers;\n\nS defaults to Float64.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.Random.rand!",
    "page": "Numbers",
    "title": "Base.Random.rand!",
    "category": "function",
    "text": "rand!([rng=GLOBAL_RNG], A, [coll])\n\nPopulate the array A with random values. If the indexable collection coll is specified, the values are picked randomly from coll. This is equivalent to copy!(A, rand(rng, coll, size(A))) or copy!(A, rand(rng, eltype(A), size(A))) but without allocating a new array.\n\nExample\n\njulia> rng = MersenneTwister(1234);\n\njulia> rand!(rng, zeros(5))\n5-element Array{Float64,1}:\n 0.590845\n 0.766797\n 0.566237\n 0.460085\n 0.794026\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.Random.bitrand",
    "page": "Numbers",
    "title": "Base.Random.bitrand",
    "category": "function",
    "text": "bitrand([rng=GLOBAL_RNG], [dims...])\n\nGenerate a BitArray of random boolean values.\n\nExample\n\njulia> rng = MersenneTwister(1234);\n\njulia> bitrand(rng, 10)\n10-element BitArray{1}:\n  true\n  true\n  true\n false\n  true\n false\n false\n  true\n false\n  true\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.Random.randn",
    "page": "Numbers",
    "title": "Base.Random.randn",
    "category": "function",
    "text": "randn([rng=GLOBAL_RNG], [T=Float64], [dims...])\n\nGenerate a normally-distributed random number of type T with mean 0 and standard deviation 1. Optionally generate an array of normally-distributed random numbers. The Base module currently provides an implementation for the types Float16, Float32, and Float64 (the default).\n\nExamples\n\njulia> rng = MersenneTwister(1234);\n\njulia> randn(rng, Float64)\n0.8673472019512456\n\njulia> randn(rng, Float32, (2, 4))\n2×4 Array{Float32,2}:\n -0.901744  -0.902914  2.21188   -0.271735\n -0.494479   0.864401  0.532813   0.502334\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.Random.randn!",
    "page": "Numbers",
    "title": "Base.Random.randn!",
    "category": "function",
    "text": "randn!([rng=GLOBAL_RNG], A::AbstractArray) -> A\n\nFill the array A with normally-distributed (mean 0, standard deviation 1) random numbers. Also see the rand function.\n\nExample\n\njulia> rng = MersenneTwister(1234);\n\njulia> randn!(rng, zeros(5))\n5-element Array{Float64,1}:\n  0.867347\n -0.901744\n -0.494479\n -0.902914\n  0.864401\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.Random.randexp",
    "page": "Numbers",
    "title": "Base.Random.randexp",
    "category": "function",
    "text": "randexp([rng=GLOBAL_RNG], [T=Float64], [dims...])\n\nGenerate a random number of type T according to the exponential distribution with scale 1. Optionally generate an array of such random numbers. The Base module currently provides an implementation for the types Float16, Float32, and Float64 (the default).\n\nExamples\n\njulia> rng = MersenneTwister(1234);\n\njulia> randexp(rng, Float32)\n2.4835055f0\n\njulia> randexp(rng, 3, 3)\n3×3 Array{Float64,2}:\n 1.5167    1.30652   0.344435\n 0.604436  2.78029   0.418516\n 0.695867  0.693292  0.643644\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.Random.randexp!",
    "page": "Numbers",
    "title": "Base.Random.randexp!",
    "category": "function",
    "text": "randexp!([rng=GLOBAL_RNG], A::AbstractArray) -> A\n\nFill the array A with random numbers following the exponential distribution (with scale 1).\n\nExample\n\njulia> rng = MersenneTwister(1234);\n\njulia> randexp!(rng, zeros(5))\n5-element Array{Float64,1}:\n 2.48351\n 1.5167\n 0.604436\n 0.695867\n 1.30652\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Base.Random.randjump",
    "page": "Numbers",
    "title": "Base.Random.randjump",
    "category": "function",
    "text": "randjump(r::MersenneTwister, jumps::Integer, [jumppoly::AbstractString=dSFMT.JPOLY1e21]) -> Vector{MersenneTwister}\n\nCreate an array of the size jumps of initialized MersenneTwister RNG objects. The first RNG object given as a parameter and following MersenneTwister RNGs in the array are initialized such that a state of the RNG object in the array would be moved forward (without generating numbers) from a previous RNG object array element on a particular number of steps encoded by the jump polynomial jumppoly.\n\nDefault jump polynomial moves forward MersenneTwister RNG state by 10^20 steps.\n\n\n\n"
},

{
    "location": "stdlib/numbers/#Random-Numbers-1",
    "page": "Numbers",
    "title": "Random Numbers",
    "category": "section",
    "text": "Random number generation in Julia uses the Mersenne Twister library via MersenneTwister objects. Julia has a global RNG, which is used by default. Other RNG types can be plugged in by inheriting the AbstractRNG type; they can then be used to have multiple streams of random numbers. Besides MersenneTwister, Julia also provides the RandomDevice RNG type, which is a wrapper over the OS provided entropy.Most functions related to random generation accept an optional AbstractRNG as the first argument, rng , which defaults to the global one if not provided. Morever, some of them accept optionally dimension specifications dims... (which can be given as a tuple) to generate arrays of random values.A MersenneTwister or RandomDevice RNG can generate random numbers of the following types: Float16, Float32, Float64, Bool, Int8, UInt8, Int16, UInt16, Int32, UInt32, Int64, UInt64, Int128, UInt128, BigInt (or complex numbers of those types). Random floating point numbers are generated uniformly in 0 1). As BigInt represents unbounded integers, the interval must be specified (e.g. rand(big(1:6))).Base.Random.srand\nBase.Random.MersenneTwister\nBase.Random.RandomDevice\nBase.Random.rand\nBase.Random.rand!\nBase.Random.bitrand\nBase.Random.randn\nBase.Random.randn!\nBase.Random.randexp\nBase.Random.randexp!\nBase.Random.randjump"
},

{
    "location": "stdlib/strings/#",
    "page": "Strings",
    "title": "Strings",
    "category": "page",
    "text": ""
},

{
    "location": "stdlib/strings/#Base.length-Tuple{AbstractString}",
    "page": "Strings",
    "title": "Base.length",
    "category": "method",
    "text": "length(s::AbstractString)\n\nThe number of characters in string s.\n\nExample\n\njulia> length(\"jμΛIα\")\n5\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.sizeof-Tuple{AbstractString}",
    "page": "Strings",
    "title": "Base.sizeof",
    "category": "method",
    "text": "sizeof(s::AbstractString)\n\nThe number of bytes in string s.\n\nExample\n\njulia> sizeof(\"❤\")\n3\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.:*-Tuple{AbstractString,Vararg{Any,N} where N}",
    "page": "Strings",
    "title": "Base.:*",
    "category": "method",
    "text": "*(x, y...)\n\nMultiplication operator. x*y*z*... calls this function with all arguments, i.e. *(x, y, z, ...).\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.:^-Tuple{AbstractString,Integer}",
    "page": "Strings",
    "title": "Base.:^",
    "category": "method",
    "text": "^(s::AbstractString, n::Integer)\n\nRepeat n times the string s. The repeat function is an alias to this operator.\n\njulia> \"Test \"^3\n\"Test Test Test \"\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.string",
    "page": "Strings",
    "title": "Base.string",
    "category": "function",
    "text": "string(xs...)\n\nCreate a string from any values using the print function.\n\njulia> string(\"a\", 1, true)\n\"a1true\"\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.repr",
    "page": "Strings",
    "title": "Base.repr",
    "category": "function",
    "text": "repr(x)\n\nCreate a string from any value using the showall function.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Core.String-Tuple{AbstractString}",
    "page": "Strings",
    "title": "Core.String",
    "category": "method",
    "text": "String(s::AbstractString)\n\nConvert a string to a contiguous byte array representation encoded as UTF-8 bytes. This representation is often appropriate for passing strings to C.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.transcode",
    "page": "Strings",
    "title": "Base.transcode",
    "category": "function",
    "text": "transcode(T, src)\n\nConvert string data between Unicode encodings. src is either a String or a Vector{UIntXX} of UTF-XX code units, where XX is 8, 16, or 32. T indicates the encoding of the return value: String to return a (UTF-8 encoded) String or UIntXX to return a Vector{UIntXX} of UTF-XX data.   (The alias Cwchar_t can also be used as the integer type, for converting wchar_t* strings used by external C libraries.)\n\nThe transcode function succeeds as long as the input data can be reasonably represented in the target encoding; it always succeeds for conversions between UTF-XX encodings, even for invalid Unicode data.\n\nOnly conversion to/from UTF-8 is currently supported.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.unsafe_string",
    "page": "Strings",
    "title": "Base.unsafe_string",
    "category": "function",
    "text": "unsafe_string(p::Ptr{UInt8}, [length::Integer])\n\nCopy a string from the address of a C-style (NUL-terminated) string encoded as UTF-8. (The pointer can be safely freed afterwards.) If length is specified (the length of the data in bytes), the string does not have to be NUL-terminated.\n\nThis function is labelled \"unsafe\" because it will crash if p is not a valid memory address to data of the requested length.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.codeunit-Tuple{AbstractString,Integer}",
    "page": "Strings",
    "title": "Base.codeunit",
    "category": "method",
    "text": "codeunit(s::AbstractString, i::Integer)\n\nGet the ith code unit of an encoded string. For example, returns the ith byte of the representation of a UTF-8 string.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.ascii",
    "page": "Strings",
    "title": "Base.ascii",
    "category": "function",
    "text": "ascii(s::AbstractString)\n\nConvert a string to String type and check that it contains only ASCII data, otherwise throwing an ArgumentError indicating the position of the first non-ASCII byte.\n\njulia> ascii(\"abcdeγfgh\")\nERROR: ArgumentError: invalid ASCII at index 6 in \"abcdeγfgh\"\nStacktrace:\n [1] ascii(::String) at ./strings/util.jl:479\n\njulia> ascii(\"abcdefgh\")\n\"abcdefgh\"\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.@r_str",
    "page": "Strings",
    "title": "Base.@r_str",
    "category": "macro",
    "text": "@r_str -> Regex\n\nConstruct a regex, such as r\"^[a-z]*$\". The regex also accepts one or more flags, listed after the ending quote, to change its behaviour:\n\ni enables case-insensitive matching\nm treats the ^ and $ tokens as matching the start and end of individual lines, as opposed to the whole string.\ns allows the . modifier to match newlines.\nx enables \"comment mode\": whitespace is enabled except when escaped with \\, and # is treated as starting a comment.\n\nFor example, this regex has all three flags enabled:\n\njulia> match(r\"a+.*b+.*?d$\"ism, \"Goodbye,\\nOh, angry,\\nBad world\\n\")\nRegexMatch(\"angry,\\nBad world\")\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.Docs.@html_str",
    "page": "Strings",
    "title": "Base.Docs.@html_str",
    "category": "macro",
    "text": "@html_str -> Docs.HTML\n\nCreate an HTML object from a literal string.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.Docs.@text_str",
    "page": "Strings",
    "title": "Base.Docs.@text_str",
    "category": "macro",
    "text": "@text_str -> Docs.Text\n\nCreate a Text object from a literal string.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.UTF8proc.normalize_string",
    "page": "Strings",
    "title": "Base.UTF8proc.normalize_string",
    "category": "function",
    "text": "normalize_string(s::AbstractString, normalform::Symbol)\n\nNormalize the string s according to one of the four \"normal forms\" of the Unicode standard: normalform can be :NFC, :NFD, :NFKC, or :NFKD.  Normal forms C (canonical composition) and D (canonical decomposition) convert different visually identical representations of the same abstract string into a single canonical form, with form C being more compact.  Normal forms KC and KD additionally canonicalize \"compatibility equivalents\": they convert characters that are abstractly similar but visually distinct into a single canonical choice (e.g. they expand ligatures into the individual characters), with form KC being more compact.\n\nAlternatively, finer control and additional transformations may be be obtained by calling normalize_string(s; keywords...), where any number of the following boolean keywords options (which all default to false except for compose) are specified:\n\ncompose=false: do not perform canonical composition\ndecompose=true: do canonical decomposition instead of canonical composition (compose=true is ignored if present)\ncompat=true: compatibility equivalents are canonicalized\ncasefold=true: perform Unicode case folding, e.g. for case-insensitive string comparison\nnewline2lf=true, newline2ls=true, or newline2ps=true: convert various newline sequences (LF, CRLF, CR, NEL) into a linefeed (LF), line-separation (LS), or paragraph-separation (PS) character, respectively\nstripmark=true: strip diacritical marks (e.g. accents)\nstripignore=true: strip Unicode\'s \"default ignorable\" characters (e.g. the soft hyphen or the left-to-right marker)\nstripcc=true: strip control characters; horizontal tabs and form feeds are converted to spaces; newlines are also converted to spaces unless a newline-conversion flag was specified\nrejectna=true: throw an error if unassigned code points are found\nstable=true: enforce Unicode Versioning Stability\n\nFor example, NFKC corresponds to the options compose=true, compat=true, stable=true.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.UTF8proc.graphemes",
    "page": "Strings",
    "title": "Base.UTF8proc.graphemes",
    "category": "function",
    "text": "graphemes(s::AbstractString) -> GraphemeIterator\n\nReturns an iterator over substrings of s that correspond to the extended graphemes in the string, as defined by Unicode UAX #29. (Roughly, these are what users would perceive as single characters, even though they may contain more than one codepoint; for example a letter combined with an accent mark is a single grapheme.)\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.isvalid-Tuple{Any}",
    "page": "Strings",
    "title": "Base.isvalid",
    "category": "method",
    "text": "isvalid(value) -> Bool\n\nReturns true if the given value is valid for its type, which currently can be either Char or String.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.isvalid-Tuple{Any,Any}",
    "page": "Strings",
    "title": "Base.isvalid",
    "category": "method",
    "text": "isvalid(T, value) -> Bool\n\nReturns true if the given value is valid for that type. Types currently can be either Char or String. Values for Char can be of type Char or UInt32. Values for String can be of that type, or Vector{UInt8}.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.isvalid-Tuple{AbstractString,Integer}",
    "page": "Strings",
    "title": "Base.isvalid",
    "category": "method",
    "text": "isvalid(str::AbstractString, i::Integer)\n\nTells whether index i is valid for the given string.\n\nExamples\n\njulia> str = \"αβγdef\";\n\njulia> isvalid(str, 1)\ntrue\n\njulia> str[1]\n\'α\': Unicode U+03b1 (category Ll: Letter, lowercase)\n\njulia> isvalid(str, 2)\nfalse\n\njulia> str[2]\nERROR: UnicodeError: invalid character index\n[...]\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.UTF8proc.is_assigned_char",
    "page": "Strings",
    "title": "Base.UTF8proc.is_assigned_char",
    "category": "function",
    "text": "is_assigned_char(c) -> Bool\n\nReturns true if the given char or integer is an assigned Unicode code point.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.ismatch",
    "page": "Strings",
    "title": "Base.ismatch",
    "category": "function",
    "text": "ismatch(r::Regex, s::AbstractString) -> Bool\n\nTest whether a string contains a match of the given regular expression.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.match",
    "page": "Strings",
    "title": "Base.match",
    "category": "function",
    "text": "match(r::Regex, s::AbstractString[, idx::Integer[, addopts]])\n\nSearch for the first match of the regular expression r in s and return a RegexMatch object containing the match, or nothing if the match failed. The matching substring can be retrieved by accessing m.match and the captured sequences can be retrieved by accessing m.captures The optional idx argument specifies an index at which to start the search.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.eachmatch",
    "page": "Strings",
    "title": "Base.eachmatch",
    "category": "function",
    "text": "eachmatch(r::Regex, s::AbstractString[, overlap::Bool=false])\n\nSearch for all matches of a the regular expression r in s and return a iterator over the matches. If overlap is true, the matching sequences are allowed to overlap indices in the original string, otherwise they must be from distinct character ranges.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.matchall",
    "page": "Strings",
    "title": "Base.matchall",
    "category": "function",
    "text": "matchall(r::Regex, s::AbstractString[, overlap::Bool=false]) -> Vector{AbstractString}\n\nReturn a vector of the matching substrings from eachmatch.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.lpad",
    "page": "Strings",
    "title": "Base.lpad",
    "category": "function",
    "text": "lpad(s, n::Integer, p::AbstractString=\" \")\n\nMake a string at least n columns wide when printed by padding s on the left with copies of p.\n\njulia> lpad(\"March\",10)\n\"     March\"\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.rpad",
    "page": "Strings",
    "title": "Base.rpad",
    "category": "function",
    "text": "rpad(s, n::Integer, p::AbstractString=\" \")\n\nMake a string at least n columns wide when printed by padding s on the right with copies of p.\n\njulia> rpad(\"March\",20)\n\"March               \"\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.search",
    "page": "Strings",
    "title": "Base.search",
    "category": "function",
    "text": "search(string::AbstractString, chars::Chars, [start::Integer])\n\nSearch for the first occurrence of the given characters within the given string. The second argument may be a single character, a vector or a set of characters, a string, or a regular expression (though regular expressions are only allowed on contiguous strings, such as ASCII or UTF-8 strings). The third argument optionally specifies a starting index. The return value is a range of indexes where the matching sequence is found, such that s[search(s,x)] == x:\n\nsearch(string, \"substring\") = start:end such that string[start:end] == \"substring\", or 0:-1 if unmatched.\n\nsearch(string, \'c\') = index such that string[index] == \'c\', or 0 if unmatched.\n\njulia> search(\"Hello to the world\", \"z\")\n0:-1\n\njulia> search(\"JuliaLang\",\"Julia\")\n1:5\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.rsearch",
    "page": "Strings",
    "title": "Base.rsearch",
    "category": "function",
    "text": "rsearch(s::AbstractString, chars::Chars, [start::Integer])\n\nSimilar to search, but returning the last occurrence of the given characters within the given string, searching in reverse from start.\n\njulia> rsearch(\"aaabbb\",\"b\")\n6:6\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.searchindex",
    "page": "Strings",
    "title": "Base.searchindex",
    "category": "function",
    "text": "searchindex(s::AbstractString, substring, [start::Integer])\n\nSimilar to search, but return only the start index at which the substring is found, or 0 if it is not.\n\njulia> searchindex(\"Hello to the world\", \"z\")\n0\n\njulia> searchindex(\"JuliaLang\",\"Julia\")\n1\n\njulia> searchindex(\"JuliaLang\",\"Lang\")\n6\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.rsearchindex",
    "page": "Strings",
    "title": "Base.rsearchindex",
    "category": "function",
    "text": "rsearchindex(s::AbstractString, substring, [start::Integer])\n\nSimilar to rsearch, but return only the start index at which the substring is found, or 0 if it is not.\n\njulia> rsearchindex(\"aaabbb\",\"b\")\n6\n\njulia> rsearchindex(\"aaabbb\",\"a\")\n3\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.contains-Tuple{AbstractString,AbstractString}",
    "page": "Strings",
    "title": "Base.contains",
    "category": "method",
    "text": "contains(haystack::AbstractString, needle::AbstractString)\n\nDetermine whether the second argument is a substring of the first.\n\njulia> contains(\"JuliaLang is pretty cool!\", \"Julia\")\ntrue\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.reverse-Tuple{AbstractString}",
    "page": "Strings",
    "title": "Base.reverse",
    "category": "method",
    "text": "reverse(s::AbstractString) -> AbstractString\n\nReverses a string.\n\njulia> reverse(\"JuliaLang\")\n\"gnaLailuJ\"\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.replace",
    "page": "Strings",
    "title": "Base.replace",
    "category": "function",
    "text": "replace(string::AbstractString, pat, r[, n::Integer=0])\n\nSearch for the given pattern pat, and replace each occurrence with r. If n is provided, replace at most n occurrences. As with search, the second argument may be a single character, a vector or a set of characters, a string, or a regular expression. If r is a function, each occurrence is replaced with r(s) where s is the matched substring. If pat is a regular expression and r is a SubstitutionString, then capture group references in r are replaced with the corresponding matched text.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.split",
    "page": "Strings",
    "title": "Base.split",
    "category": "function",
    "text": "split(s::AbstractString, [chars]; limit::Integer=0, keep::Bool=true)\n\nReturn an array of substrings by splitting the given string on occurrences of the given character delimiters, which may be specified in any of the formats allowed by search\'s second argument (i.e. a single character, collection of characters, string, or regular expression). If chars is omitted, it defaults to the set of all space characters, and keep is taken to be false. The two keyword arguments are optional: they are a maximum size for the result and a flag determining whether empty fields should be kept in the result.\n\njulia> a = \"Ma.rch\"\n\"Ma.rch\"\n\njulia> split(a,\".\")\n2-element Array{SubString{String},1}:\n \"Ma\"\n \"rch\"\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.rsplit",
    "page": "Strings",
    "title": "Base.rsplit",
    "category": "function",
    "text": "rsplit(s::AbstractString, [chars]; limit::Integer=0, keep::Bool=true)\n\nSimilar to split, but starting from the end of the string.\n\njulia> a = \"M.a.r.c.h\"\n\"M.a.r.c.h\"\n\njulia> rsplit(a,\".\")\n5-element Array{SubString{String},1}:\n \"M\"\n \"a\"\n \"r\"\n \"c\"\n \"h\"\n\njulia> rsplit(a,\".\";limit=1)\n1-element Array{SubString{String},1}:\n \"M.a.r.c.h\"\n\njulia> rsplit(a,\".\";limit=2)\n2-element Array{SubString{String},1}:\n \"M.a.r.c\"\n \"h\"\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.strip",
    "page": "Strings",
    "title": "Base.strip",
    "category": "function",
    "text": "strip(s::AbstractString, [chars::Chars])\n\nReturn s with any leading and trailing whitespace removed. If chars (a character, or vector or set of characters) is provided, instead remove characters contained in it.\n\njulia> strip(\"{3, 5}\\n\", [\'{\', \'}\', \'\\n\'])\n\"3, 5\"\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.lstrip",
    "page": "Strings",
    "title": "Base.lstrip",
    "category": "function",
    "text": "lstrip(s::AbstractString[, chars::Chars])\n\nReturn s with any leading whitespace and delimiters removed. The default delimiters to remove are \' \', \\t, \\n, \\v, \\f, and \\r. If chars (a character, or vector or set of characters) is provided, instead remove characters contained in it.\n\njulia> a = lpad(\"March\", 20)\n\"               March\"\n\njulia> lstrip(a)\n\"March\"\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.rstrip",
    "page": "Strings",
    "title": "Base.rstrip",
    "category": "function",
    "text": "rstrip(s::AbstractString[, chars::Chars])\n\nReturn s with any trailing whitespace and delimiters removed. The default delimiters to remove are \' \', \\t, \\n, \\v, \\f, and \\r. If chars (a character, or vector or set of characters) is provided, instead remove characters contained in it.\n\njulia> a = rpad(\"March\", 20)\n\"March               \"\n\njulia> rstrip(a)\n\"March\"\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.startswith",
    "page": "Strings",
    "title": "Base.startswith",
    "category": "function",
    "text": "startswith(s::AbstractString, prefix::AbstractString)\n\nReturns true if s starts with prefix. If prefix is a vector or set of characters, tests whether the first character of s belongs to that set.\n\nSee also endswith.\n\njulia> startswith(\"JuliaLang\", \"Julia\")\ntrue\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.endswith",
    "page": "Strings",
    "title": "Base.endswith",
    "category": "function",
    "text": "endswith(s::AbstractString, suffix::AbstractString)\n\nReturns true if s ends with suffix. If suffix is a vector or set of characters, tests whether the last character of s belongs to that set.\n\nSee also startswith.\n\njulia> endswith(\"Sunday\", \"day\")\ntrue\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.uppercase",
    "page": "Strings",
    "title": "Base.uppercase",
    "category": "function",
    "text": "uppercase(s::AbstractString)\n\nReturns s with all characters converted to uppercase.\n\nExample\n\njulia> uppercase(\"Julia\")\n\"JULIA\"\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.lowercase",
    "page": "Strings",
    "title": "Base.lowercase",
    "category": "function",
    "text": "lowercase(s::AbstractString)\n\nReturns s with all characters converted to lowercase.\n\nExample\n\njulia> lowercase(\"STRINGS AND THINGS\")\n\"strings and things\"\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.titlecase",
    "page": "Strings",
    "title": "Base.titlecase",
    "category": "function",
    "text": "titlecase(s::AbstractString)\n\nCapitalizes the first character of each word in s.\n\nExample\n\njulia> titlecase(\"the julia programming language\")\n\"The Julia Programming Language\"\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.ucfirst",
    "page": "Strings",
    "title": "Base.ucfirst",
    "category": "function",
    "text": "ucfirst(s::AbstractString)\n\nReturns string with the first character converted to uppercase.\n\nExample\n\njulia> ucfirst(\"python\")\n\"Python\"\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.lcfirst",
    "page": "Strings",
    "title": "Base.lcfirst",
    "category": "function",
    "text": "lcfirst(s::AbstractString)\n\nReturns string with the first character converted to lowercase.\n\nExample\n\njulia> lcfirst(\"Julia\")\n\"julia\"\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.join",
    "page": "Strings",
    "title": "Base.join",
    "category": "function",
    "text": "join(io::IO, strings, delim, [last])\n\nJoin an array of strings into a single string, inserting the given delimiter between adjacent strings. If last is given, it will be used instead of delim between the last two strings. For example,\n\njulia> join([\"apples\", \"bananas\", \"pineapples\"], \", \", \" and \")\n\"apples, bananas and pineapples\"\n\nstrings can be any iterable over elements x which are convertible to strings via print(io::IOBuffer, x). strings will be printed to io.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.chop",
    "page": "Strings",
    "title": "Base.chop",
    "category": "function",
    "text": "chop(s::AbstractString)\n\nRemove the last character from s.\n\njulia> a = \"March\"\n\"March\"\n\njulia> chop(a)\n\"Marc\"\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.chomp",
    "page": "Strings",
    "title": "Base.chomp",
    "category": "function",
    "text": "chomp(s::AbstractString)\n\nRemove a single trailing newline from a string.\n\njulia> chomp(\"Hello\\n\")\n\"Hello\"\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.ind2chr",
    "page": "Strings",
    "title": "Base.ind2chr",
    "category": "function",
    "text": "ind2chr(s::AbstractString, i::Integer)\n\nConvert a byte index i to a character index with respect to string s.\n\nSee also chr2ind.\n\nExample\n\njulia> str = \"αβγdef\";\n\njulia> ind2chr(str, 3)\n2\n\njulia> chr2ind(str, 2)\n3\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.chr2ind",
    "page": "Strings",
    "title": "Base.chr2ind",
    "category": "function",
    "text": "chr2ind(s::AbstractString, i::Integer)\n\nConvert a character index i to a byte index.\n\nSee also ind2chr.\n\nExample\n\njulia> str = \"αβγdef\";\n\njulia> chr2ind(str, 2)\n3\n\njulia> ind2chr(str, 3)\n2\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.nextind",
    "page": "Strings",
    "title": "Base.nextind",
    "category": "function",
    "text": "nextind(str::AbstractString, i::Integer)\n\nGet the next valid string index after i. Returns a value greater than endof(str) at or after the end of the string.\n\nExamples\n\njulia> str = \"αβγdef\";\n\njulia> nextind(str, 1)\n3\n\njulia> endof(str)\n9\n\njulia> nextind(str, 9)\n10\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.prevind",
    "page": "Strings",
    "title": "Base.prevind",
    "category": "function",
    "text": "prevind(str::AbstractString, i::Integer)\n\nGet the previous valid string index before i. Returns a value less than 1 at the beginning of the string.\n\nExamples\n\njulia> prevind(\"αβγdef\", 3)\n1\n\njulia> prevind(\"αβγdef\", 1)\n0\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.Random.randstring",
    "page": "Strings",
    "title": "Base.Random.randstring",
    "category": "function",
    "text": "randstring([rng,] len=8)\n\nCreate a random ASCII string of length len, consisting of upper- and lower-case letters and the digits 0-9. The optional rng argument specifies a random number generator, see Random Numbers.\n\nExample\n\njulia> rng = MersenneTwister(1234);\n\njulia> randstring(rng, 4)\n\"mbDd\"\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.UTF8proc.charwidth",
    "page": "Strings",
    "title": "Base.UTF8proc.charwidth",
    "category": "function",
    "text": "charwidth(c)\n\nGives the number of columns needed to print a character.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.strwidth",
    "page": "Strings",
    "title": "Base.strwidth",
    "category": "function",
    "text": "strwidth(s::AbstractString)\n\nGives the number of columns needed to print a string.\n\nExample\n\njulia> strwidth(\"March\")\n5\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.UTF8proc.isalnum",
    "page": "Strings",
    "title": "Base.UTF8proc.isalnum",
    "category": "function",
    "text": "isalnum(c::Char) -> Bool\n\nTests whether a character is alphanumeric. A character is classified as alphabetic if it belongs to the Unicode general category Letter or Number, i.e. a character whose category code begins with \'L\' or \'N\'.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.UTF8proc.isalpha",
    "page": "Strings",
    "title": "Base.UTF8proc.isalpha",
    "category": "function",
    "text": "isalpha(c::Char) -> Bool\n\nTests whether a character is alphabetic. A character is classified as alphabetic if it belongs to the Unicode general category Letter, i.e. a character whose category code begins with \'L\'.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.isascii",
    "page": "Strings",
    "title": "Base.isascii",
    "category": "function",
    "text": "isascii(c::Union{Char,AbstractString}) -> Bool\n\nTests whether a character belongs to the ASCII character set, or whether this is true for all elements of a string.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.UTF8proc.iscntrl",
    "page": "Strings",
    "title": "Base.UTF8proc.iscntrl",
    "category": "function",
    "text": "iscntrl(c::Char) -> Bool\n\nTests whether a character is a control character. Control characters are the non-printing characters of the Latin-1 subset of Unicode.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.UTF8proc.isdigit",
    "page": "Strings",
    "title": "Base.UTF8proc.isdigit",
    "category": "function",
    "text": "isdigit(c::Char) -> Bool\n\nTests whether a character is a numeric digit (0-9).\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.UTF8proc.isgraph",
    "page": "Strings",
    "title": "Base.UTF8proc.isgraph",
    "category": "function",
    "text": "isgraph(c::Char) -> Bool\n\nTests whether a character is printable, and not a space. Any character that would cause a printer to use ink should be classified with isgraph(c)==true.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.UTF8proc.islower",
    "page": "Strings",
    "title": "Base.UTF8proc.islower",
    "category": "function",
    "text": "islower(c::Char) -> Bool\n\nTests whether a character is a lowercase letter. A character is classified as lowercase if it belongs to Unicode category Ll, Letter: Lowercase.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.UTF8proc.isnumber",
    "page": "Strings",
    "title": "Base.UTF8proc.isnumber",
    "category": "function",
    "text": "isnumber(c::Char) -> Bool\n\nTests whether a character is numeric. A character is classified as numeric if it belongs to the Unicode general category Number, i.e. a character whose category code begins with \'N\'.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.UTF8proc.isprint",
    "page": "Strings",
    "title": "Base.UTF8proc.isprint",
    "category": "function",
    "text": "isprint(c::Char) -> Bool\n\nTests whether a character is printable, including spaces, but not a control character.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.UTF8proc.ispunct",
    "page": "Strings",
    "title": "Base.UTF8proc.ispunct",
    "category": "function",
    "text": "ispunct(c::Char) -> Bool\n\nTests whether a character belongs to the Unicode general category Punctuation, i.e. a character whose category code begins with \'P\'.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.UTF8proc.isspace",
    "page": "Strings",
    "title": "Base.UTF8proc.isspace",
    "category": "function",
    "text": "isspace(c::Char) -> Bool\n\nTests whether a character is any whitespace character. Includes ASCII characters \'\\t\', \'\\n\', \'\\v\', \'\\f\', \'\\r\', and \' \', Latin-1 character U+0085, and characters in Unicode category Zs.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.UTF8proc.isupper",
    "page": "Strings",
    "title": "Base.UTF8proc.isupper",
    "category": "function",
    "text": "isupper(c::Char) -> Bool\n\nTests whether a character is an uppercase letter. A character is classified as uppercase if it belongs to Unicode category Lu, Letter: Uppercase, or Lt, Letter: Titlecase.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.isxdigit",
    "page": "Strings",
    "title": "Base.isxdigit",
    "category": "function",
    "text": "isxdigit(c::Char) -> Bool\n\nTests whether a character is a valid hexadecimal digit. Note that this does not include x (as in the standard 0x prefix).\n\nExample\n\njulia> isxdigit(\'a\')\ntrue\n\njulia> isxdigit(\'x\')\nfalse\n\n\n\n"
},

{
    "location": "stdlib/strings/#Core.Symbol",
    "page": "Strings",
    "title": "Core.Symbol",
    "category": "type",
    "text": "Symbol(x...) -> Symbol\n\nCreate a Symbol by concatenating the string representations of the arguments together.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.escape_string",
    "page": "Strings",
    "title": "Base.escape_string",
    "category": "function",
    "text": "escape_string([io,] str::AbstractString[, esc::AbstractString]) -> AbstractString\n\nGeneral escaping of traditional C and Unicode escape sequences. Any characters in esc are also escaped (with a backslash). See also unescape_string.\n\n\n\n"
},

{
    "location": "stdlib/strings/#Base.unescape_string",
    "page": "Strings",
    "title": "Base.unescape_string",
    "category": "function",
    "text": "unescape_string([io,] s::AbstractString) -> AbstractString\n\nGeneral unescaping of traditional C and Unicode escape sequences. Reverse of escape_string.\n\n\n\n"
},

{
    "location": "stdlib/strings/#lib-strings-1",
    "page": "Strings",
    "title": "Strings",
    "category": "section",
    "text": "Base.length(::AbstractString)\nBase.sizeof(::AbstractString)\nBase.:*(::AbstractString, ::Any...)\nBase.:^(::AbstractString, ::Integer)\nBase.string\nBase.repr\nCore.String(::AbstractString)\nBase.transcode\nBase.unsafe_string\nBase.codeunit(::AbstractString, ::Integer)\nBase.ascii\nBase.@r_str\nBase.Docs.@html_str\nBase.Docs.@text_str\nBase.UTF8proc.normalize_string\nBase.UTF8proc.graphemes\nBase.isvalid(::Any)\nBase.isvalid(::Any, ::Any)\nBase.isvalid(::AbstractString, ::Integer)\nBase.UTF8proc.is_assigned_char\nBase.ismatch\nBase.match\nBase.eachmatch\nBase.matchall\nBase.lpad\nBase.rpad\nBase.search\nBase.rsearch\nBase.searchindex\nBase.rsearchindex\nBase.contains(::AbstractString, ::AbstractString)\nBase.reverse(::AbstractString)\nBase.replace\nBase.split\nBase.rsplit\nBase.strip\nBase.lstrip\nBase.rstrip\nBase.startswith\nBase.endswith\nBase.uppercase\nBase.lowercase\nBase.titlecase\nBase.ucfirst\nBase.lcfirst\nBase.join\nBase.chop\nBase.chomp\nBase.ind2chr\nBase.chr2ind\nBase.nextind\nBase.prevind\nBase.Random.randstring\nBase.UTF8proc.charwidth\nBase.strwidth\nBase.UTF8proc.isalnum\nBase.UTF8proc.isalpha\nBase.isascii\nBase.UTF8proc.iscntrl\nBase.UTF8proc.isdigit\nBase.UTF8proc.isgraph\nBase.UTF8proc.islower\nBase.UTF8proc.isnumber\nBase.UTF8proc.isprint\nBase.UTF8proc.ispunct\nBase.UTF8proc.isspace\nBase.UTF8proc.isupper\nBase.isxdigit\nCore.Symbol\nBase.escape_string\nBase.unescape_string"
},

{
    "location": "stdlib/arrays/#",
    "page": "Arrays",
    "title": "Arrays",
    "category": "page",
    "text": ""
},

{
    "location": "stdlib/arrays/#lib-arrays-1",
    "page": "Arrays",
    "title": "Arrays",
    "category": "section",
    "text": ""
},

{
    "location": "stdlib/arrays/#Core.AbstractArray",
    "page": "Arrays",
    "title": "Core.AbstractArray",
    "category": "type",
    "text": "AbstractArray{T, N}\n\nAbstract array supertype which arrays inherit from.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Core.Array",
    "page": "Arrays",
    "title": "Core.Array",
    "category": "type",
    "text": "Array{T}(dims)\nArray{T,N}(dims)\n\nConstruct an uninitialized N-dimensional dense array with element type T, where N is determined from the length or number of dims. dims may be a tuple or a series of integer arguments corresponding to the lengths in each dimension. If the rank N is supplied explicitly as in Array{T,N}(dims), then it must match the length or number of dims.\n\nExample\n\njulia> A = Array{Float64, 2}(2, 2);\n\njulia> ndims(A)\n2\n\njulia> eltype(A)\nFloat64\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.getindex-Tuple{Type,Vararg{Any,N} where N}",
    "page": "Arrays",
    "title": "Base.getindex",
    "category": "method",
    "text": "getindex(type[, elements...])\n\nConstruct a 1-d array of the specified type. This is usually called with the syntax Type[]. Element values can be specified using Type[a,b,c,...].\n\nExample\n\njulia> Int8[1, 2, 3]\n3-element Array{Int8,1}:\n 1\n 2\n 3\n\njulia> getindex(Int8, 1, 2, 3)\n3-element Array{Int8,1}:\n 1\n 2\n 3\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.zeros",
    "page": "Arrays",
    "title": "Base.zeros",
    "category": "function",
    "text": "zeros([A::AbstractArray,] [T=eltype(A)::Type,] [dims=size(A)::Tuple])\n\nCreate an array of all zeros with the same layout as A, element type T and size dims. The A argument can be skipped, which behaves like Array{Float64,0}() was passed. For convenience dims may also be passed in variadic form.\n\nExamples\n\njulia> zeros(1)\n1-element Array{Float64,1}:\n 0.0\n\njulia> zeros(Int8, 2, 3)\n2×3 Array{Int8,2}:\n 0  0  0\n 0  0  0\n\njulia> A = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> zeros(A)\n2×2 Array{Int64,2}:\n 0  0\n 0  0\n\njulia> zeros(A, Float64)\n2×2 Array{Float64,2}:\n 0.0  0.0\n 0.0  0.0\n\njulia> zeros(A, Bool, (3,))\n3-element Array{Bool,1}:\n false\n false\n false\n\nSee also ones, similar.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.ones",
    "page": "Arrays",
    "title": "Base.ones",
    "category": "function",
    "text": "ones([A::AbstractArray,] [T=eltype(A)::Type,] [dims=size(A)::Tuple])\n\nCreate an array of all ones with the same layout as A, element type T and size dims. The A argument can be skipped, which behaves like Array{Float64,0}() was passed. For convenience dims may also be passed in variadic form.\n\nExamples\n\njulia> ones(Complex128, 2, 3)\n2×3 Array{Complex{Float64},2}:\n 1.0+0.0im  1.0+0.0im  1.0+0.0im\n 1.0+0.0im  1.0+0.0im  1.0+0.0im\n\njulia> ones(1,2)\n1×2 Array{Float64,2}:\n 1.0  1.0\n\njulia> A = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> ones(A)\n2×2 Array{Int64,2}:\n 1  1\n 1  1\n\njulia> ones(A, Float64)\n2×2 Array{Float64,2}:\n 1.0  1.0\n 1.0  1.0\n\njulia> ones(A, Bool, (3,))\n3-element Array{Bool,1}:\n true\n true\n true\n\nSee also zeros, similar.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.BitArray",
    "page": "Arrays",
    "title": "Base.BitArray",
    "category": "type",
    "text": "BitArray(dims::Integer...)\nBitArray{N}(dims::NTuple{N,Int})\n\nConstruct an uninitialized BitArray with the given dimensions. Behaves identically to the Array constructor.\n\njulia> BitArray(2, 2)\n2×2 BitArray{2}:\n false  false\n false  true\n\njulia> BitArray((3, 1))\n3×1 BitArray{2}:\n false\n true\n false\n\n\n\nBitArray(itr)\n\nConstruct a BitArray generated by the given iterable object. The shape is inferred from the itr object.\n\njulia> BitArray([1 0; 0 1])\n2×2 BitArray{2}:\n  true  false\n false   true\n\njulia> BitArray(x+y == 3 for x = 1:2, y = 1:3)\n2×3 BitArray{2}:\n false   true  false\n  true  false  false\n\njulia> BitArray(x+y == 3 for x = 1:2 for y = 1:3)\n6-element BitArray{1}:\n false\n  true\n false\n  true\n false\n false\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.trues",
    "page": "Arrays",
    "title": "Base.trues",
    "category": "function",
    "text": "trues(dims)\n\nCreate a BitArray with all values set to true.\n\njulia> trues(2,3)\n2×3 BitArray{2}:\n true  true  true\n true  true  true\n\n\n\ntrues(A)\n\nCreate a BitArray with all values set to true of the same shape as A.\n\njulia> A = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> trues(A)\n2×2 BitArray{2}:\n true  true\n true  true\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.falses",
    "page": "Arrays",
    "title": "Base.falses",
    "category": "function",
    "text": "falses(dims)\n\nCreate a BitArray with all values set to false.\n\njulia> falses(2,3)\n2×3 BitArray{2}:\n false  false  false\n false  false  false\n\n\n\nfalses(A)\n\nCreate a BitArray with all values set to false of the same shape as A.\n\njulia> A = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> falses(A)\n2×2 BitArray{2}:\n false  false\n false  false\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.fill",
    "page": "Arrays",
    "title": "Base.fill",
    "category": "function",
    "text": "fill(x, dims)\n\nCreate an array filled with the value x. For example, fill(1.0, (5,5)) returns a 5×5 array of floats, with each element initialized to 1.0.\n\njulia> fill(1.0, (5,5))\n5×5 Array{Float64,2}:\n 1.0  1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0  1.0\n\nIf x is an object reference, all elements will refer to the same object. fill(Foo(), dims) will return an array filled with the result of evaluating Foo() once.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.fill!",
    "page": "Arrays",
    "title": "Base.fill!",
    "category": "function",
    "text": "fill!(A, x)\n\nFill array A with the value x. If x is an object reference, all elements will refer to the same object. fill!(A, Foo()) will return A filled with the result of evaluating Foo() once.\n\nExamples\n\njulia> A = zeros(2,3)\n2×3 Array{Float64,2}:\n 0.0  0.0  0.0\n 0.0  0.0  0.0\n\njulia> fill!(A, 2.)\n2×3 Array{Float64,2}:\n 2.0  2.0  2.0\n 2.0  2.0  2.0\n\njulia> a = [1, 1, 1]; A = fill!(Vector{Vector{Int}}(3), a); a[1] = 2; A\n3-element Array{Array{Int64,1},1}:\n [2, 1, 1]\n [2, 1, 1]\n [2, 1, 1]\n\njulia> x = 0; f() = (global x += 1; x); fill!(Vector{Int}(3), f())\n3-element Array{Int64,1}:\n 1\n 1\n 1\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.similar-Tuple{AbstractArray}",
    "page": "Arrays",
    "title": "Base.similar",
    "category": "method",
    "text": "similar(array, [element_type=eltype(array)], [dims=size(array)])\n\nCreate an uninitialized mutable array with the given element type and size, based upon the given source array. The second and third arguments are both optional, defaulting to the given array\'s eltype and size. The dimensions may be specified either as a single tuple argument or as a series of integer arguments.\n\nCustom AbstractArray subtypes may choose which specific array type is best-suited to return for the given element type and dimensionality. If they do not specialize this method, the default is an Array{element_type}(dims...).\n\nFor example, similar(1:10, 1, 4) returns an uninitialized Array{Int,2} since ranges are neither mutable nor support 2 dimensions:\n\njulia> similar(1:10, 1, 4)\n1×4 Array{Int64,2}:\n 4419743872  4374413872  4419743888  0\n\nConversely, similar(trues(10,10), 2) returns an uninitialized BitVector with two elements since BitArrays are both mutable and can support 1-dimensional arrays:\n\njulia> similar(trues(10,10), 2)\n2-element BitArray{1}:\n false\n false\n\nSince BitArrays can only store elements of type Bool, however, if you request a different element type it will create a regular Array instead:\n\njulia> similar(falses(10), Float64, 2, 4)\n2×4 Array{Float64,2}:\n 2.18425e-314  2.18425e-314  2.18425e-314  2.18425e-314\n 2.18425e-314  2.18425e-314  2.18425e-314  2.18425e-314\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.similar-Tuple{Any,Tuple}",
    "page": "Arrays",
    "title": "Base.similar",
    "category": "method",
    "text": "similar(storagetype, indices)\n\nCreate an uninitialized mutable array analogous to that specified by storagetype, but with indices specified by the last argument. storagetype might be a type or a function.\n\nExamples:\n\nsimilar(Array{Int}, indices(A))\n\ncreates an array that \"acts like\" an Array{Int} (and might indeed be backed by one), but which is indexed identically to A. If A has conventional indexing, this will be identical to Array{Int}(size(A)), but if A has unconventional indexing then the indices of the result will match A.\n\nsimilar(BitArray, (indices(A, 2),))\n\nwould create a 1-dimensional logical array whose indices match those of the columns of A.\n\nsimilar(dims->zeros(Int, dims), indices(A))\n\nwould create an array of Int, initialized to zero, matching the indices of A.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.eye",
    "page": "Arrays",
    "title": "Base.eye",
    "category": "function",
    "text": "eye([T::Type=Float64,] m::Integer, n::Integer)\n\nm-by-n identity matrix. The default element type is Float64.\n\nExamples\n\njulia> eye(3, 4)\n3×4 Array{Float64,2}:\n 1.0  0.0  0.0  0.0\n 0.0  1.0  0.0  0.0\n 0.0  0.0  1.0  0.0\n\njulia> eye(2, 2)\n2×2 Array{Float64,2}:\n 1.0  0.0\n 0.0  1.0\n\njulia> eye(Int, 2, 2)\n2×2 Array{Int64,2}:\n 1  0\n 0  1\n\n\n\neye(m, n)\n\nm-by-n identity matrix.\n\n\n\neye([T::Type=Float64,] n::Integer)\n\nn-by-n identity matrix. The default element type is Float64.\n\nExamples\n\njulia> eye(Int, 2)\n2×2 Array{Int64,2}:\n 1  0\n 0  1\n\njulia> eye(2)\n2×2 Array{Float64,2}:\n 1.0  0.0\n 0.0  1.0\n\n\n\neye(A)\n\nConstructs an identity matrix of the same dimensions and type as A.\n\njulia> A = [1 2 3; 4 5 6; 7 8 9]\n3×3 Array{Int64,2}:\n 1  2  3\n 4  5  6\n 7  8  9\n\njulia> eye(A)\n3×3 Array{Int64,2}:\n 1  0  0\n 0  1  0\n 0  0  1\n\nNote the difference from ones.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.linspace",
    "page": "Arrays",
    "title": "Base.linspace",
    "category": "function",
    "text": "linspace(start, stop, n=50)\n\nConstruct a range of n linearly spaced elements from start to stop.\n\njulia> linspace(1.3,2.9,9)\n1.3:0.2:2.9\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.logspace",
    "page": "Arrays",
    "title": "Base.logspace",
    "category": "function",
    "text": "logspace(start::Real, stop::Real, n::Integer=50)\n\nConstruct a vector of n logarithmically spaced numbers from 10^start to 10^stop.\n\njulia> logspace(1.,10.,5)\n5-element Array{Float64,1}:\n   10.0\n 1778.28\n    3.16228e5\n    5.62341e7\n    1.0e10\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.Random.randsubseq",
    "page": "Arrays",
    "title": "Base.Random.randsubseq",
    "category": "function",
    "text": "randsubseq(A, p) -> Vector\n\nReturn a vector consisting of a random subsequence of the given array A, where each element of A is included (in order) with independent probability p. (Complexity is linear in p*length(A), so this function is efficient even if p is small and A is large.) Technically, this process is known as \"Bernoulli sampling\" of A.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.Random.randsubseq!",
    "page": "Arrays",
    "title": "Base.Random.randsubseq!",
    "category": "function",
    "text": "randsubseq!(S, A, p)\n\nLike randsubseq, but the results are stored in S (which is resized as needed).\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Constructors-and-Types-1",
    "page": "Arrays",
    "title": "Constructors and Types",
    "category": "section",
    "text": "Core.AbstractArray\nCore.Array\nBase.getindex(::Type, ::Any...)\nBase.zeros\nBase.ones\nBase.BitArray\nBase.trues\nBase.falses\nBase.fill\nBase.fill!\nBase.similar(::AbstractArray)\nBase.similar(::Any, ::Tuple)\nBase.eye\nBase.linspace\nBase.logspace\nBase.Random.randsubseq\nBase.Random.randsubseq!"
},

{
    "location": "stdlib/arrays/#Base.ndims",
    "page": "Arrays",
    "title": "Base.ndims",
    "category": "function",
    "text": "ndims(A::AbstractArray) -> Integer\n\nReturns the number of dimensions of A.\n\njulia> A = ones(3,4,5);\n\njulia> ndims(A)\n3\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.size",
    "page": "Arrays",
    "title": "Base.size",
    "category": "function",
    "text": "size(A::AbstractArray, [dim...])\n\nReturns a tuple containing the dimensions of A. Optionally you can specify the dimension(s) you want the length of, and get the length of that dimension, or a tuple of the lengths of dimensions you asked for.\n\njulia> A = ones(2,3,4);\n\njulia> size(A, 2)\n3\n\njulia> size(A,3,2)\n(4, 3)\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.indices-Tuple{Any}",
    "page": "Arrays",
    "title": "Base.indices",
    "category": "method",
    "text": "indices(A)\n\nReturns the tuple of valid indices for array A.\n\njulia> A = ones(5,6,7);\n\njulia> indices(A)\n(Base.OneTo(5), Base.OneTo(6), Base.OneTo(7))\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.indices-Tuple{AbstractArray,Any}",
    "page": "Arrays",
    "title": "Base.indices",
    "category": "method",
    "text": "indices(A, d)\n\nReturns the valid range of indices for array A along dimension d.\n\njulia> A = ones(5,6,7);\n\njulia> indices(A,2)\nBase.OneTo(6)\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.length-Tuple{AbstractArray}",
    "page": "Arrays",
    "title": "Base.length",
    "category": "method",
    "text": "length(A::AbstractArray) -> Integer\n\nReturns the number of elements in A.\n\njulia> A = ones(3,4,5);\n\njulia> length(A)\n60\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.eachindex",
    "page": "Arrays",
    "title": "Base.eachindex",
    "category": "function",
    "text": "eachindex(A...)\n\nCreates an iterable object for visiting each index of an AbstractArray A in an efficient manner. For array types that have opted into fast linear indexing (like Array), this is simply the range 1:length(A). For other array types, this returns a specialized Cartesian range to efficiently index into the array with indices specified for every dimension. For other iterables, including strings and dictionaries, this returns an iterator object supporting arbitrary index types (e.g. unevenly spaced or non-integer indices).\n\nExample for a sparse 2-d array:\n\njulia> A = sparse([1, 1, 2], [1, 3, 1], [1, 2, -5])\n2×3 SparseMatrixCSC{Int64,Int64} with 3 stored entries:\n  [1, 1]  =  1\n  [2, 1]  =  -5\n  [1, 3]  =  2\n\njulia> for iter in eachindex(A)\n           @show iter.I[1], iter.I[2]\n           @show A[iter]\n       end\n(iter.I[1], iter.I[2]) = (1, 1)\nA[iter] = 1\n(iter.I[1], iter.I[2]) = (2, 1)\nA[iter] = -5\n(iter.I[1], iter.I[2]) = (1, 2)\nA[iter] = 0\n(iter.I[1], iter.I[2]) = (2, 2)\nA[iter] = 0\n(iter.I[1], iter.I[2]) = (1, 3)\nA[iter] = 2\n(iter.I[1], iter.I[2]) = (2, 3)\nA[iter] = 0\n\nIf you supply more than one AbstractArray argument, eachindex will create an iterable object that is fast for all arguments (a UnitRange if all inputs have fast linear indexing, a CartesianRange otherwise). If the arrays have different sizes and/or dimensionalities, eachindex returns an iterable that spans the largest range along each dimension.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.linearindices",
    "page": "Arrays",
    "title": "Base.linearindices",
    "category": "function",
    "text": "linearindices(A)\n\nReturns a UnitRange specifying the valid range of indices for A[i] where i is an Int. For arrays with conventional indexing (indices start at 1), or any multidimensional array, this is 1:length(A); however, for one-dimensional arrays with unconventional indices, this is indices(A, 1).\n\nCalling this function is the \"safe\" way to write algorithms that exploit linear indexing.\n\njulia> A = ones(5,6,7);\n\njulia> b = linearindices(A);\n\njulia> extrema(b)\n(1, 210)\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.IndexStyle",
    "page": "Arrays",
    "title": "Base.IndexStyle",
    "category": "type",
    "text": "IndexStyle(A)\nIndexStyle(typeof(A))\n\nIndexStyle specifies the \"native indexing style\" for array A. When you define a new AbstractArray type, you can choose to implement either linear indexing or cartesian indexing.  If you decide to implement linear indexing, then you must set this trait for your array type:\n\nBase.IndexStyle(::Type{<:MyArray}) = IndexLinear()\n\nThe default is IndexCartesian().\n\nJulia\'s internal indexing machinery will automatically (and invisibly) convert all indexing operations into the preferred style using sub2ind or ind2sub. This allows users to access elements of your array using any indexing style, even when explicit methods have not been provided.\n\nIf you define both styles of indexing for your AbstractArray, this trait can be used to select the most performant indexing style. Some methods check this trait on their inputs, and dispatch to different algorithms depending on the most efficient access pattern. In particular, eachindex creates an iterator whose type depends on the setting of this trait.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.countnz",
    "page": "Arrays",
    "title": "Base.countnz",
    "category": "function",
    "text": "countnz(A) -> Integer\n\nCounts the number of nonzero values in array A (dense or sparse). Note that this is not a constant-time operation. For sparse matrices, one should usually use nnz, which returns the number of stored values.\n\njulia> A = [1 2 4; 0 0 1; 1 1 0]\n3×3 Array{Int64,2}:\n 1  2  4\n 0  0  1\n 1  1  0\n\njulia> countnz(A)\n6\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.conj!",
    "page": "Arrays",
    "title": "Base.conj!",
    "category": "function",
    "text": "conj!(A)\n\nTransform an array to its complex conjugate in-place.\n\nSee also conj.\n\nExample\n\njulia> A = [1+im 2-im; 2+2im 3+im]\n2×2 Array{Complex{Int64},2}:\n 1+1im  2-1im\n 2+2im  3+1im\n\njulia> conj!(A);\n\njulia> A\n2×2 Array{Complex{Int64},2}:\n 1-1im  2+1im\n 2-2im  3-1im\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.stride",
    "page": "Arrays",
    "title": "Base.stride",
    "category": "function",
    "text": "stride(A, k::Integer)\n\nReturns the distance in memory (in number of elements) between adjacent elements in dimension k.\n\njulia> A = ones(3,4,5);\n\njulia> stride(A,2)\n3\n\njulia> stride(A,3)\n12\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.strides",
    "page": "Arrays",
    "title": "Base.strides",
    "category": "function",
    "text": "strides(A)\n\nReturns a tuple of the memory strides in each dimension.\n\njulia> A = ones(3,4,5);\n\njulia> strides(A)\n(1, 3, 12)\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.ind2sub",
    "page": "Arrays",
    "title": "Base.ind2sub",
    "category": "function",
    "text": "ind2sub(a, index) -> subscripts\n\nReturns a tuple of subscripts into array a corresponding to the linear index index.\n\njulia> A = ones(5,6,7);\n\njulia> ind2sub(A,35)\n(5, 1, 2)\n\njulia> ind2sub(A,70)\n(5, 2, 3)\n\n\n\nind2sub(dims, index) -> subscripts\n\nReturns a tuple of subscripts into an array with dimensions dims, corresponding to the linear index index.\n\nExample:\n\ni, j, ... = ind2sub(size(A), indmax(A))\n\nprovides the indices of the maximum element.\n\njulia> ind2sub((3,4),2)\n(2, 1)\n\njulia> ind2sub((3,4),3)\n(3, 1)\n\njulia> ind2sub((3,4),4)\n(1, 2)\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.sub2ind",
    "page": "Arrays",
    "title": "Base.sub2ind",
    "category": "function",
    "text": "sub2ind(dims, i, j, k...) -> index\n\nThe inverse of ind2sub, returns the linear index corresponding to the provided subscripts.\n\njulia> sub2ind((5,6,7),1,2,3)\n66\n\njulia> sub2ind((5,6,7),1,6,3)\n86\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.LinAlg.checksquare",
    "page": "Arrays",
    "title": "Base.LinAlg.checksquare",
    "category": "function",
    "text": "LinAlg.checksquare(A)\n\nCheck that a matrix is square, then return its common dimension. For multiple arguments, return a vector.\n\nExample\n\njulia> A = ones(4,4); B = zeros(5,5);\n\njulia> LinAlg.checksquare(A, B)\n2-element Array{Int64,1}:\n 4\n 5\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Basic-functions-1",
    "page": "Arrays",
    "title": "Basic functions",
    "category": "section",
    "text": "Base.ndims\nBase.size\nBase.indices(::Any)\nBase.indices(::AbstractArray, ::Any)\nBase.length(::AbstractArray)\nBase.eachindex\nBase.linearindices\nBase.IndexStyle\nBase.countnz\nBase.conj!\nBase.stride\nBase.strides\nBase.ind2sub\nBase.sub2ind\nBase.LinAlg.checksquare"
},

{
    "location": "stdlib/arrays/#Base.broadcast",
    "page": "Arrays",
    "title": "Base.broadcast",
    "category": "function",
    "text": "broadcast(f, As...)\n\nBroadcasts the arrays, tuples, Refs, nullables, and/or scalars As to a container of the appropriate type and dimensions. In this context, anything that is not a subtype of AbstractArray, Ref (except for Ptrs), Tuple, or Nullable is considered a scalar. The resulting container is established by the following rules:\n\nIf all the arguments are scalars, it returns a scalar.\nIf the arguments are tuples and zero or more scalars, it returns a tuple.\nIf the arguments contain at least one array or Ref, it returns an array (expanding singleton dimensions), and treats Refs as 0-dimensional arrays, and tuples as 1-dimensional arrays.\n\nThe following additional rule applies to Nullable arguments: If there is at least one Nullable, and all the arguments are scalars or Nullable, it returns a Nullable treating Nullables as \"containers\".\n\nA special syntax exists for broadcasting: f.(args...) is equivalent to broadcast(f, args...), and nested f.(g.(args...)) calls are fused into a single broadcast loop.\n\njulia> A = [1, 2, 3, 4, 5]\n5-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n 5\n\njulia> B = [1 2; 3 4; 5 6; 7 8; 9 10]\n5×2 Array{Int64,2}:\n 1   2\n 3   4\n 5   6\n 7   8\n 9  10\n\njulia> broadcast(+, A, B)\n5×2 Array{Int64,2}:\n  2   3\n  5   6\n  8   9\n 11  12\n 14  15\n\njulia> parse.(Int, [\"1\", \"2\"])\n2-element Array{Int64,1}:\n 1\n 2\n\njulia> abs.((1, -2))\n(1, 2)\n\njulia> broadcast(+, 1.0, (0, -2.0))\n(1.0, -1.0)\n\njulia> broadcast(+, 1.0, (0, -2.0), Ref(1))\n2-element Array{Float64,1}:\n 2.0\n 0.0\n\njulia> (+).([[0,2], [1,3]], Ref{Vector{Int}}([1,-1]))\n2-element Array{Array{Int64,1},1}:\n [1, 1]\n [2, 2]\n\njulia> string.((\"one\",\"two\",\"three\",\"four\"), \": \", 1:4)\n4-element Array{String,1}:\n \"one: 1\"\n \"two: 2\"\n \"three: 3\"\n \"four: 4\"\n\njulia> Nullable(\"X\") .* \"Y\"\nNullable{String}(\"XY\")\n\njulia> broadcast(/, 1.0, Nullable(2.0))\nNullable{Float64}(0.5)\n\njulia> (1 + im) ./ Nullable{Int}()\nNullable{Complex{Float64}}()\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.broadcast!",
    "page": "Arrays",
    "title": "Base.broadcast!",
    "category": "function",
    "text": "broadcast!(f, dest, As...)\n\nLike broadcast, but store the result of broadcast(f, As...) in the dest array. Note that dest is only used to store the result, and does not supply arguments to f unless it is also listed in the As, as in broadcast!(f, A, A, B) to perform A[:] = broadcast(f, A, B).\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.Broadcast.@__dot__",
    "page": "Arrays",
    "title": "Base.Broadcast.@__dot__",
    "category": "macro",
    "text": "@. expr\n\nConvert every function call or operator in expr into a \"dot call\" (e.g. convert f(x) to f.(x)), and convert every assignment in expr to a \"dot assignment\" (e.g. convert += to .+=).\n\nIf you want to avoid adding dots for selected function calls in expr, splice those function calls in with $.  For example, @. sqrt(abs($sort(x))) is equivalent to sqrt.(abs.(sort(x))) (no dot for sort).\n\n(@. is equivalent to a call to @__dot__.)\n\njulia> x = 1.0:3.0; y = similar(x);\n\njulia> @. y = x + 3 * sin(x)\n3-element Array{Float64,1}:\n 3.52441\n 4.72789\n 3.42336\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.Broadcast.broadcast_getindex",
    "page": "Arrays",
    "title": "Base.Broadcast.broadcast_getindex",
    "category": "function",
    "text": "broadcast_getindex(A, inds...)\n\nBroadcasts the inds arrays to a common size like broadcast and returns an array of the results A[ks...], where ks goes over the positions in the broadcast result A.\n\njulia> A = [1, 2, 3, 4, 5]\n5-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n 5\n\njulia> B = [1 2; 3 4; 5 6; 7 8; 9 10]\n5×2 Array{Int64,2}:\n 1   2\n 3   4\n 5   6\n 7   8\n 9  10\n\njulia> C = broadcast(+,A,B)\n5×2 Array{Int64,2}:\n  2   3\n  5   6\n  8   9\n 11  12\n 14  15\n\njulia> broadcast_getindex(C,[1,2,10])\n3-element Array{Int64,1}:\n  2\n  5\n 15\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.Broadcast.broadcast_setindex!",
    "page": "Arrays",
    "title": "Base.Broadcast.broadcast_setindex!",
    "category": "function",
    "text": "broadcast_setindex!(A, X, inds...)\n\nBroadcasts the X and inds arrays to a common size and stores the value from each position in X at the indices in A given by the same positions in inds.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Broadcast-and-vectorization-1",
    "page": "Arrays",
    "title": "Broadcast and vectorization",
    "category": "section",
    "text": "See also the dot syntax for vectorizing functions; for example, f.(args...) implicitly calls broadcast(f, args...). Rather than relying on \"vectorized\" methods of functions like sin to operate on arrays, you should use sin.(a) to vectorize via broadcast.Base.broadcast\nBase.Broadcast.broadcast!\nBase.@__dot__\nBase.Broadcast.broadcast_getindex\nBase.Broadcast.broadcast_setindex!"
},

{
    "location": "stdlib/arrays/#Base.getindex-Tuple{AbstractArray,Vararg{Any,N} where N}",
    "page": "Arrays",
    "title": "Base.getindex",
    "category": "method",
    "text": "getindex(A, inds...)\n\nReturns a subset of array A as specified by inds, where each ind may be an Int, a Range, or a Vector. See the manual section on array indexing for details.\n\nExamples\n\njulia> A = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> getindex(A, 1)\n1\n\njulia> getindex(A, [2, 1])\n2-element Array{Int64,1}:\n 3\n 1\n\njulia> getindex(A, 2:4)\n3-element Array{Int64,1}:\n 3\n 2\n 4\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.setindex!-Tuple{AbstractArray,Any,Vararg{Any,N} where N}",
    "page": "Arrays",
    "title": "Base.setindex!",
    "category": "method",
    "text": "setindex!(A, X, inds...)\n\nStore values from array X within some subset of A as specified by inds.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.copy!-Tuple{AbstractArray,CartesianRange,AbstractArray,CartesianRange}",
    "page": "Arrays",
    "title": "Base.copy!",
    "category": "method",
    "text": "copy!(dest, Rdest::CartesianRange, src, Rsrc::CartesianRange) -> dest\n\nCopy the block of src in the range of Rsrc to the block of dest in the range of Rdest. The sizes of the two regions must match.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.isassigned",
    "page": "Arrays",
    "title": "Base.isassigned",
    "category": "function",
    "text": "isassigned(array, i) -> Bool\n\nTests whether the given array has a value associated with index i. Returns false if the index is out of bounds, or has an undefined reference.\n\njulia> isassigned(rand(3, 3), 5)\ntrue\n\njulia> isassigned(rand(3, 3), 3 * 3 + 1)\nfalse\n\njulia> mutable struct Foo end\n\njulia> v = similar(rand(3), Foo)\n3-element Array{Foo,1}:\n #undef\n #undef\n #undef\n\njulia> isassigned(v, 1)\nfalse\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.Colon",
    "page": "Arrays",
    "title": "Base.Colon",
    "category": "type",
    "text": "Colon()\n\nColons (:) are used to signify indexing entire objects or dimensions at once.\n\nVery few operations are defined on Colons directly; instead they are converted by to_indices to an internal vector type (Base.Slice) to represent the collection of indices they span before being used.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.IteratorsMD.CartesianIndex",
    "page": "Arrays",
    "title": "Base.IteratorsMD.CartesianIndex",
    "category": "type",
    "text": "CartesianIndex(i, j, k...)   -> I\nCartesianIndex((i, j, k...)) -> I\n\nCreate a multidimensional index I, which can be used for indexing a multidimensional array A.  In particular, A[I] is equivalent to A[i,j,k...].  One can freely mix integer and CartesianIndex indices; for example, A[Ipre, i, Ipost] (where Ipre and Ipost are CartesianIndex indices and i is an Int) can be a useful expression when writing algorithms that work along a single dimension of an array of arbitrary dimensionality.\n\nA CartesianIndex is sometimes produced by eachindex, and always when iterating with an explicit CartesianRange.\n\nExample\n\njulia> A = reshape(collect(1:16), (2, 2, 2, 2))\n2×2×2×2 Array{Int64,4}:\n[:, :, 1, 1] =\n 1  3\n 2  4\n\n[:, :, 2, 1] =\n 5  7\n 6  8\n\n[:, :, 1, 2] =\n  9  11\n 10  12\n\n[:, :, 2, 2] =\n 13  15\n 14  16\n\njulia> A[CartesianIndex((1, 1, 1, 1))]\n1\n\njulia> A[CartesianIndex((1, 1, 1, 2))]\n9\n\njulia> A[CartesianIndex((1, 1, 2, 1))]\n5\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.IteratorsMD.CartesianRange",
    "page": "Arrays",
    "title": "Base.IteratorsMD.CartesianRange",
    "category": "type",
    "text": "CartesianRange(Istart::CartesianIndex, Istop::CartesianIndex) -> R\nCartesianRange(sz::Dims) -> R\nCartesianRange(istart:istop, jstart:jstop, ...) -> R\n\nDefine a region R spanning a multidimensional rectangular range of integer indices. These are most commonly encountered in the context of iteration, where for I in R ... end will return CartesianIndex indices I equivalent to the nested loops\n\nfor j = jstart:jstop\n    for i = istart:istop\n        ...\n    end\nend\n\nConsequently these can be useful for writing algorithms that work in arbitrary dimensions.\n\njulia> foreach(println, CartesianRange((2, 2, 2)))\nCartesianIndex{3}((1, 1, 1))\nCartesianIndex{3}((2, 1, 1))\nCartesianIndex{3}((1, 2, 1))\nCartesianIndex{3}((2, 2, 1))\nCartesianIndex{3}((1, 1, 2))\nCartesianIndex{3}((2, 1, 2))\nCartesianIndex{3}((1, 2, 2))\nCartesianIndex{3}((2, 2, 2))\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.to_indices",
    "page": "Arrays",
    "title": "Base.to_indices",
    "category": "function",
    "text": "to_indices(A, I::Tuple)\n\nConvert the tuple I to a tuple of indices for use in indexing into array A.\n\nThe returned tuple must only contain either Ints or AbstractArrays of scalar indices that are supported by array A. It will error upon encountering a novel index type that it does not know how to process.\n\nFor simple index types, it defers to the unexported Base.to_index(A, i) to process each index i. While this internal function is not intended to be called directly, Base.to_index may be extended by custom array or index types to provide custom indexing behaviors.\n\nMore complicated index types may require more context about the dimension into which they index. To support those cases, to_indices(A, I) calls to_indices(A, indices(A), I), which then recursively walks through both the given tuple of indices and the dimensional indices of A in tandem. As such, not all index types are guaranteed to propagate to Base.to_index.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.checkbounds",
    "page": "Arrays",
    "title": "Base.checkbounds",
    "category": "function",
    "text": "checkbounds(Bool, A, I...)\n\nReturn true if the specified indices I are in bounds for the given array A. Subtypes of AbstractArray should specialize this method if they need to provide custom bounds checking behaviors; however, in many cases one can rely on A\'s indices and checkindex.\n\nSee also checkindex.\n\njulia> A = rand(3, 3);\n\njulia> checkbounds(Bool, A, 2)\ntrue\n\njulia> checkbounds(Bool, A, 3, 4)\nfalse\n\njulia> checkbounds(Bool, A, 1:3)\ntrue\n\njulia> checkbounds(Bool, A, 1:3, 2:4)\nfalse\n\n\n\ncheckbounds(A, I...)\n\nThrow an error if the specified indices I are not in bounds for the given array A.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.checkindex",
    "page": "Arrays",
    "title": "Base.checkindex",
    "category": "function",
    "text": "checkindex(Bool, inds::AbstractUnitRange, index)\n\nReturn true if the given index is within the bounds of inds. Custom types that would like to behave as indices for all arrays can extend this method in order to provide a specialized bounds checking implementation.\n\njulia> checkindex(Bool,1:20,8)\ntrue\n\njulia> checkindex(Bool,1:20,21)\nfalse\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Indexing-and-assignment-1",
    "page": "Arrays",
    "title": "Indexing and assignment",
    "category": "section",
    "text": "Base.getindex(::AbstractArray, ::Any...)\nBase.setindex!(::AbstractArray, ::Any, ::Any...)\nBase.copy!(::AbstractArray, ::CartesianRange, ::AbstractArray, ::CartesianRange)\nBase.isassigned\nBase.Colon\nBase.CartesianIndex\nBase.CartesianRange\nBase.to_indices\nBase.checkbounds\nBase.checkindex"
},

{
    "location": "stdlib/arrays/#Base.view",
    "page": "Arrays",
    "title": "Base.view",
    "category": "function",
    "text": "view(A, inds...)\n\nLike getindex, but returns a view into the parent array A with the given indices instead of making a copy.  Calling getindex or setindex! on the returned SubArray computes the indices to the parent array on the fly without checking bounds.\n\njulia> A = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> b = view(A, :, 1)\n2-element SubArray{Int64,1,Array{Int64,2},Tuple{Base.Slice{Base.OneTo{Int64}},Int64},true}:\n 1\n 3\n\njulia> fill!(b, 0)\n2-element SubArray{Int64,1,Array{Int64,2},Tuple{Base.Slice{Base.OneTo{Int64}},Int64},true}:\n 0\n 0\n\njulia> A # Note A has changed even though we modified b\n2×2 Array{Int64,2}:\n 0  2\n 0  4\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.@view",
    "page": "Arrays",
    "title": "Base.@view",
    "category": "macro",
    "text": "@view A[inds...]\n\nCreates a SubArray from an indexing expression. This can only be applied directly to a reference expression (e.g. @view A[1,2:end]), and should not be used as the target of an assignment (e.g. @view(A[1,2:end]) = ...).  See also @views to switch an entire block of code to use views for slicing.\n\njulia> A = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> b = @view A[:, 1]\n2-element SubArray{Int64,1,Array{Int64,2},Tuple{Base.Slice{Base.OneTo{Int64}},Int64},true}:\n 1\n 3\n\njulia> fill!(b, 0)\n2-element SubArray{Int64,1,Array{Int64,2},Tuple{Base.Slice{Base.OneTo{Int64}},Int64},true}:\n 0\n 0\n\njulia> A\n2×2 Array{Int64,2}:\n 0  2\n 0  4\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.@views",
    "page": "Arrays",
    "title": "Base.@views",
    "category": "macro",
    "text": "@views expression\n\nConvert every array-slicing operation in the given expression (which may be a begin/end block, loop, function, etc.) to return a view.   Scalar indices, non-array types, and explicit getindex calls (as opposed to array[...]) are unaffected.\n\nNote that the @views macro only affects array[...] expressions that appear explicitly in the given expression, not array slicing that occurs in functions called by that code.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.parent",
    "page": "Arrays",
    "title": "Base.parent",
    "category": "function",
    "text": "parent(A)\n\nReturns the \"parent array\" of an array view type (e.g., SubArray), or the array itself if it is not a view.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.parentindexes",
    "page": "Arrays",
    "title": "Base.parentindexes",
    "category": "function",
    "text": "parentindexes(A)\n\nFrom an array view A, returns the corresponding indexes in the parent.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.slicedim",
    "page": "Arrays",
    "title": "Base.slicedim",
    "category": "function",
    "text": "slicedim(A, d::Integer, i)\n\nReturn all the data of A where the index for dimension d equals i. Equivalent to A[:,:,...,i,:,:,...] where i is in position d.\n\nExample\n\njulia> A = [1 2 3 4; 5 6 7 8]\n2×4 Array{Int64,2}:\n 1  2  3  4\n 5  6  7  8\n\njulia> slicedim(A,2,3)\n2-element Array{Int64,1}:\n 3\n 7\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.reinterpret",
    "page": "Arrays",
    "title": "Base.reinterpret",
    "category": "function",
    "text": "reinterpret(type, A)\n\nChange the type-interpretation of a block of memory. For arrays, this constructs an array with the same binary data as the given array, but with the specified element type. For example, reinterpret(Float32, UInt32(7)) interprets the 4 bytes corresponding to UInt32(7) as a Float32.\n\nwarning: Warning\nIt is not allowed to reinterpret an array to an element type with a larger alignment then the alignment of the array. For a normal Array, this is the alignment of its element type. For a reinterpreted array, this is the alignment of the Array it was reinterpreted from. For example, reinterpret(UInt32, UInt8[0, 0, 0, 0]) is not allowed but reinterpret(UInt32, reinterpret(UInt8, Float32[1.0])) is allowed.\n\nExamples\n\njulia> reinterpret(Float32, UInt32(7))\n1.0f-44\n\njulia> reinterpret(Float32, UInt32[1 2 3 4 5])\n1×5 Array{Float32,2}:\n 1.4013f-45  2.8026f-45  4.2039f-45  5.60519f-45  7.00649f-45\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.reshape",
    "page": "Arrays",
    "title": "Base.reshape",
    "category": "function",
    "text": "reshape(A, dims...) -> R\nreshape(A, dims) -> R\n\nReturn an array R with the same data as A, but with different dimension sizes or number of dimensions. The two arrays share the same underlying data, so that setting elements of R alters the values of A and vice versa.\n\nThe new dimensions may be specified either as a list of arguments or as a shape tuple. At most one dimension may be specified with a :, in which case its length is computed such that its product with all the specified dimensions is equal to the length of the original array A. The total number of elements must not change.\n\njulia> A = collect(1:16)\n16-element Array{Int64,1}:\n  1\n  2\n  3\n  4\n  5\n  6\n  7\n  8\n  9\n 10\n 11\n 12\n 13\n 14\n 15\n 16\n\njulia> reshape(A, (4, 4))\n4×4 Array{Int64,2}:\n 1  5   9  13\n 2  6  10  14\n 3  7  11  15\n 4  8  12  16\n\njulia> reshape(A, 2, :)\n2×8 Array{Int64,2}:\n 1  3  5  7   9  11  13  15\n 2  4  6  8  10  12  14  16\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.squeeze",
    "page": "Arrays",
    "title": "Base.squeeze",
    "category": "function",
    "text": "squeeze(A, dims)\n\nRemove the dimensions specified by dims from array A. Elements of dims must be unique and within the range 1:ndims(A). size(A,i) must equal 1 for all i in dims.\n\nExample\n\njulia> a = reshape(collect(1:4),(2,2,1,1))\n2×2×1×1 Array{Int64,4}:\n[:, :, 1, 1] =\n 1  3\n 2  4\n\njulia> squeeze(a,3)\n2×2×1 Array{Int64,3}:\n[:, :, 1] =\n 1  3\n 2  4\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.vec",
    "page": "Arrays",
    "title": "Base.vec",
    "category": "function",
    "text": "vec(a::AbstractArray) -> Vector\n\nReshape the array a as a one-dimensional column vector. The resulting array shares the same underlying data as a, so modifying one will also modify the other.\n\nExample\n\njulia> a = [1 2 3; 4 5 6]\n2×3 Array{Int64,2}:\n 1  2  3\n 4  5  6\n\njulia> vec(a)\n6-element Array{Int64,1}:\n 1\n 4\n 2\n 5\n 3\n 6\n\nSee also reshape.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Views-(SubArrays-and-other-view-types)-1",
    "page": "Arrays",
    "title": "Views (SubArrays and other view types)",
    "category": "section",
    "text": "Base.view\nBase.@view\nBase.@views\nBase.parent\nBase.parentindexes\nBase.slicedim\nBase.reinterpret\nBase.reshape\nBase.squeeze\nBase.vec"
},

{
    "location": "stdlib/arrays/#Base.cat",
    "page": "Arrays",
    "title": "Base.cat",
    "category": "function",
    "text": "cat(dims, A...)\n\nConcatenate the input arrays along the specified dimensions in the iterable dims. For dimensions not in dims, all input arrays should have the same size, which will also be the size of the output array along that dimension. For dimensions in dims, the size of the output array is the sum of the sizes of the input arrays along that dimension. If dims is a single number, the different arrays are tightly stacked along that dimension. If dims is an iterable containing several dimensions, this allows one to construct block diagonal matrices and their higher-dimensional analogues by simultaneously increasing several dimensions for every new input array and putting zero blocks elsewhere. For example, cat([1,2], matrices...) builds a block diagonal matrix, i.e. a block matrix with matrices[1], matrices[2], ... as diagonal blocks and matching zero blocks away from the diagonal.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.vcat",
    "page": "Arrays",
    "title": "Base.vcat",
    "category": "function",
    "text": "vcat(A...)\n\nConcatenate along dimension 1.\n\njulia> a = [1 2 3 4 5]\n1×5 Array{Int64,2}:\n 1  2  3  4  5\n\njulia> b = [6 7 8 9 10; 11 12 13 14 15]\n2×5 Array{Int64,2}:\n  6   7   8   9  10\n 11  12  13  14  15\n\njulia> vcat(a,b)\n3×5 Array{Int64,2}:\n  1   2   3   4   5\n  6   7   8   9  10\n 11  12  13  14  15\n\njulia> c = ([1 2 3], [4 5 6])\n([1 2 3], [4 5 6])\n\njulia> vcat(c...)\n2×3 Array{Int64,2}:\n 1  2  3\n 4  5  6\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.hcat",
    "page": "Arrays",
    "title": "Base.hcat",
    "category": "function",
    "text": "hcat(A...)\n\nConcatenate along dimension 2.\n\njulia> a = [1; 2; 3; 4; 5]\n5-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n 5\n\njulia> b = [6 7; 8 9; 10 11; 12 13; 14 15]\n5×2 Array{Int64,2}:\n  6   7\n  8   9\n 10  11\n 12  13\n 14  15\n\njulia> hcat(a,b)\n5×3 Array{Int64,2}:\n 1   6   7\n 2   8   9\n 3  10  11\n 4  12  13\n 5  14  15\n\njulia> c = ([1; 2; 3], [4; 5; 6])\n([1, 2, 3], [4, 5, 6])\n\njulia> hcat(c...)\n3×2 Array{Int64,2}:\n 1  4\n 2  5\n 3  6\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.hvcat",
    "page": "Arrays",
    "title": "Base.hvcat",
    "category": "function",
    "text": "hvcat(rows::Tuple{Vararg{Int}}, values...)\n\nHorizontal and vertical concatenation in one call. This function is called for block matrix syntax. The first argument specifies the number of arguments to concatenate in each block row.\n\njulia> a, b, c, d, e, f = 1, 2, 3, 4, 5, 6\n(1, 2, 3, 4, 5, 6)\n\njulia> [a b c; d e f]\n2×3 Array{Int64,2}:\n 1  2  3\n 4  5  6\n\njulia> hvcat((3,3), a,b,c,d,e,f)\n2×3 Array{Int64,2}:\n 1  2  3\n 4  5  6\n\njulia> [a b;c d; e f]\n3×2 Array{Int64,2}:\n 1  2\n 3  4\n 5  6\n\njulia> hvcat((2,2,2), a,b,c,d,e,f)\n3×2 Array{Int64,2}:\n 1  2\n 3  4\n 5  6\n\nIf the first argument is a single integer n, then all block rows are assumed to have n block columns.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.flipdim",
    "page": "Arrays",
    "title": "Base.flipdim",
    "category": "function",
    "text": "flipdim(A, d::Integer)\n\nReverse A in dimension d.\n\nExample\n\njulia> b = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> flipdim(b,2)\n2×2 Array{Int64,2}:\n 2  1\n 4  3\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.circshift",
    "page": "Arrays",
    "title": "Base.circshift",
    "category": "function",
    "text": "circshift(A, shifts)\n\nCircularly shift the data in an array. The second argument is a vector giving the amount to shift in each dimension.\n\nExample\n\njulia> b = reshape(collect(1:16), (4,4))\n4×4 Array{Int64,2}:\n 1  5   9  13\n 2  6  10  14\n 3  7  11  15\n 4  8  12  16\n\njulia> circshift(b, (0,2))\n4×4 Array{Int64,2}:\n  9  13  1  5\n 10  14  2  6\n 11  15  3  7\n 12  16  4  8\n\njulia> circshift(b, (-1,0))\n4×4 Array{Int64,2}:\n 2  6  10  14\n 3  7  11  15\n 4  8  12  16\n 1  5   9  13\n\nSee also circshift!.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.circshift!",
    "page": "Arrays",
    "title": "Base.circshift!",
    "category": "function",
    "text": "circshift!(dest, src, shifts)\n\nCircularly shift the data in src, storing the result in dest. shifts specifies the amount to shift in each dimension.\n\nThe dest array must be distinct from the src array (they cannot alias each other).\n\nSee also circshift.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.circcopy!",
    "page": "Arrays",
    "title": "Base.circcopy!",
    "category": "function",
    "text": "circcopy!(dest, src)\n\nCopy src to dest, indexing each dimension modulo its length. src and dest must have the same size, but can be offset in their indices; any offset results in a (circular) wraparound. If the arrays have overlapping indices, then on the domain of the overlap dest agrees with src.\n\nExample\n\njulia> src = reshape(collect(1:16), (4,4))\n4×4 Array{Int64,2}:\n 1  5   9  13\n 2  6  10  14\n 3  7  11  15\n 4  8  12  16\n\njulia> dest = OffsetArray{Int}((0:3,2:5))\n\njulia> circcopy!(dest, src)\nOffsetArrays.OffsetArray{Int64,2,Array{Int64,2}} with indices 0:3×2:5:\n 8  12  16  4\n 5   9  13  1\n 6  10  14  2\n 7  11  15  3\n\njulia> dest[1:3,2:4] == src[1:3,2:4]\ntrue\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.contains-Tuple{Function,Any,Any}",
    "page": "Arrays",
    "title": "Base.contains",
    "category": "method",
    "text": "contains(fun, itr, x) -> Bool\n\nReturns true if there is at least one element y in itr such that fun(y,x) is true.\n\njulia> vec = [10, 100, 200]\n3-element Array{Int64,1}:\n  10\n 100\n 200\n\njulia> contains(==, vec, 200)\ntrue\n\njulia> contains(==, vec, 300)\nfalse\n\njulia> contains(>, vec, 100)\ntrue\n\njulia> contains(>, vec, 200)\nfalse\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.find-Tuple{Any}",
    "page": "Arrays",
    "title": "Base.find",
    "category": "method",
    "text": "find(A)\n\nReturn a vector of the linear indexes of the non-zeros in A (determined by A[i]!=0). A common use of this is to convert a boolean array to an array of indexes of the true elements. If there are no non-zero elements of A, find returns an empty array.\n\nExamples\n\njulia> A = [true false; false true]\n2×2 Array{Bool,2}:\n  true  false\n false   true\n\njulia> find(A)\n2-element Array{Int64,1}:\n 1\n 4\n\njulia> find(zeros(3))\n0-element Array{Int64,1}\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.find-Tuple{Function,Any}",
    "page": "Arrays",
    "title": "Base.find",
    "category": "method",
    "text": "find(f::Function, A)\n\nReturn a vector I of the linear indexes of A where f(A[I]) returns true. If there are no such elements of A, find returns an empty array.\n\nExamples\n\njulia> A = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> find(isodd,A)\n2-element Array{Int64,1}:\n 1\n 2\n\njulia> find(isodd, [2, 4])\n0-element Array{Int64,1}\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.findn",
    "page": "Arrays",
    "title": "Base.findn",
    "category": "function",
    "text": "findn(A)\n\nReturn a vector of indexes for each dimension giving the locations of the non-zeros in A (determined by A[i]!=0). If there are no non-zero elements of A, findn returns a 2-tuple of empty arrays.\n\nExamples\n\njulia> A = [1 2 0; 0 0 3; 0 4 0]\n3×3 Array{Int64,2}:\n 1  2  0\n 0  0  3\n 0  4  0\n\njulia> findn(A)\n([1, 1, 3, 2], [1, 2, 2, 3])\n\njulia> A = zeros(2,2)\n2×2 Array{Float64,2}:\n 0.0  0.0\n 0.0  0.0\n\njulia> findn(A)\n(Int64[], Int64[])\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.findnz",
    "page": "Arrays",
    "title": "Base.findnz",
    "category": "function",
    "text": "findnz(A)\n\nReturn a tuple (I, J, V) where I and J are the row and column indexes of the non-zero values in matrix A, and V is a vector of the non-zero values.\n\nExample\n\njulia> A = [1 2 0; 0 0 3; 0 4 0]\n3×3 Array{Int64,2}:\n 1  2  0\n 0  0  3\n 0  4  0\n\njulia> findnz(A)\n([1, 1, 3, 2], [1, 2, 2, 3], [1, 2, 4, 3])\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.findfirst-Tuple{Any}",
    "page": "Arrays",
    "title": "Base.findfirst",
    "category": "method",
    "text": "findfirst(A)\n\nReturn the linear index of the first non-zero value in A (determined by A[i]!=0). Returns 0 if no such value is found.\n\nExamples\n\njulia> A = [0 0; 1 0]\n2×2 Array{Int64,2}:\n 0  0\n 1  0\n\njulia> findfirst(A)\n2\n\njulia> findfirst(zeros(3))\n0\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.findfirst-Tuple{Any,Any}",
    "page": "Arrays",
    "title": "Base.findfirst",
    "category": "method",
    "text": "findfirst(A, v)\n\nReturn the linear index of the first element equal to v in A. Returns 0 if v is not found.\n\nExamples\n\njulia> A = [4 6; 2 2]\n2×2 Array{Int64,2}:\n 4  6\n 2  2\n\njulia> findfirst(A,2)\n2\n\njulia> findfirst(A,3)\n0\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.findfirst-Tuple{Function,Any}",
    "page": "Arrays",
    "title": "Base.findfirst",
    "category": "method",
    "text": "findfirst(predicate::Function, A)\n\nReturn the linear index of the first element of A for which predicate returns true. Returns 0 if there is no such element.\n\nExamples\n\njulia> A = [1 4; 2 2]\n2×2 Array{Int64,2}:\n 1  4\n 2  2\n\njulia> findfirst(iseven, A)\n2\n\njulia> findfirst(x -> x>10, A)\n0\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.findlast-Tuple{Any}",
    "page": "Arrays",
    "title": "Base.findlast",
    "category": "method",
    "text": "findlast(A)\n\nReturn the linear index of the last non-zero value in A (determined by A[i]!=0). Returns 0 if there is no non-zero value in A.\n\nExamples\n\njulia> A = [1 0; 1 0]\n2×2 Array{Int64,2}:\n 1  0\n 1  0\n\njulia> findlast(A)\n2\n\njulia> A = zeros(2,2)\n2×2 Array{Float64,2}:\n 0.0  0.0\n 0.0  0.0\n\njulia> findlast(A)\n0\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.findlast-Tuple{Any,Any}",
    "page": "Arrays",
    "title": "Base.findlast",
    "category": "method",
    "text": "findlast(A, v)\n\nReturn the linear index of the last element equal to v in A. Returns 0 if there is no element of A equal to v.\n\nExamples\n\njulia> A = [1 2; 2 1]\n2×2 Array{Int64,2}:\n 1  2\n 2  1\n\njulia> findlast(A,1)\n4\n\njulia> findlast(A,2)\n3\n\njulia> findlast(A,3)\n0\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.findlast-Tuple{Function,Any}",
    "page": "Arrays",
    "title": "Base.findlast",
    "category": "method",
    "text": "findlast(predicate::Function, A)\n\nReturn the linear index of the last element of A for which predicate returns true. Returns 0 if there is no such element.\n\nExamples\n\njulia> A = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> findlast(isodd, A)\n2\n\njulia> findlast(x -> x > 5, A)\n0\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.findnext-Tuple{Any,Integer}",
    "page": "Arrays",
    "title": "Base.findnext",
    "category": "method",
    "text": "findnext(A, i::Integer)\n\nFind the next linear index >= i of a non-zero element of A, or 0 if not found.\n\nExamples\n\njulia> A = [0 0; 1 0]\n2×2 Array{Int64,2}:\n 0  0\n 1  0\n\njulia> findnext(A,1)\n2\n\njulia> findnext(A,3)\n0\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.findnext-Tuple{Function,Any,Integer}",
    "page": "Arrays",
    "title": "Base.findnext",
    "category": "method",
    "text": "findnext(predicate::Function, A, i::Integer)\n\nFind the next linear index >= i of an element of A for which predicate returns true, or 0 if not found.\n\nExamples\n\njulia> A = [1 4; 2 2]\n2×2 Array{Int64,2}:\n 1  4\n 2  2\n\njulia> findnext(isodd, A, 1)\n1\n\njulia> findnext(isodd, A, 2)\n0\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.findnext-Tuple{Any,Any,Integer}",
    "page": "Arrays",
    "title": "Base.findnext",
    "category": "method",
    "text": "findnext(A, v, i::Integer)\n\nFind the next linear index >= i of an element of A equal to v (using ==), or 0 if not found.\n\nExamples\n\njulia> A = [1 4; 2 2]\n2×2 Array{Int64,2}:\n 1  4\n 2  2\n\njulia> findnext(A,4,4)\n0\n\njulia> findnext(A,4,3)\n3\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.findprev-Tuple{Any,Integer}",
    "page": "Arrays",
    "title": "Base.findprev",
    "category": "method",
    "text": "findprev(A, i::Integer)\n\nFind the previous linear index <= i of a non-zero element of A, or 0 if not found.\n\nExamples\n\njulia> A = [0 0; 1 2]\n2×2 Array{Int64,2}:\n 0  0\n 1  2\n\njulia> findprev(A,2)\n2\n\njulia> findprev(A,1)\n0\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.findprev-Tuple{Function,Any,Integer}",
    "page": "Arrays",
    "title": "Base.findprev",
    "category": "method",
    "text": "findprev(predicate::Function, A, i::Integer)\n\nFind the previous linear index <= i of an element of A for which predicate returns true, or 0 if not found.\n\nExamples\n\njulia> A = [4 6; 1 2]\n2×2 Array{Int64,2}:\n 4  6\n 1  2\n\njulia> findprev(isodd, A, 1)\n0\n\njulia> findprev(isodd, A, 3)\n2\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.findprev-Tuple{Any,Any,Integer}",
    "page": "Arrays",
    "title": "Base.findprev",
    "category": "method",
    "text": "findprev(A, v, i::Integer)\n\nFind the previous linear index <= i of an element of A equal to v (using ==), or 0 if not found.\n\nExamples\n\njulia> A = [0 0; 1 2]\n2×2 Array{Int64,2}:\n 0  0\n 1  2\n\njulia> findprev(A, 1, 4)\n2\n\njulia> findprev(A, 1, 1)\n0\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.permutedims",
    "page": "Arrays",
    "title": "Base.permutedims",
    "category": "function",
    "text": "permutedims(A, perm)\n\nPermute the dimensions of array A. perm is a vector specifying a permutation of length ndims(A). This is a generalization of transpose for multi-dimensional arrays. Transpose is equivalent to permutedims(A, [2,1]).\n\nSee also: PermutedDimsArray.\n\nExample\n\njulia> A = reshape(collect(1:8), (2,2,2))\n2×2×2 Array{Int64,3}:\n[:, :, 1] =\n 1  3\n 2  4\n\n[:, :, 2] =\n 5  7\n 6  8\n\njulia> permutedims(A, [3, 2, 1])\n2×2×2 Array{Int64,3}:\n[:, :, 1] =\n 1  3\n 5  7\n\n[:, :, 2] =\n 2  4\n 6  8\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.permutedims!",
    "page": "Arrays",
    "title": "Base.permutedims!",
    "category": "function",
    "text": "permutedims!(dest, src, perm)\n\nPermute the dimensions of array src and store the result in the array dest. perm is a vector specifying a permutation of length ndims(src). The preallocated array dest should have size(dest) == size(src)[perm] and is completely overwritten. No in-place permutation is supported and unexpected results will happen if src and dest have overlapping memory regions.\n\nSee also permutedims.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.PermutedDimsArrays.PermutedDimsArray",
    "page": "Arrays",
    "title": "Base.PermutedDimsArrays.PermutedDimsArray",
    "category": "type",
    "text": "PermutedDimsArray(A, perm) -> B\n\nGiven an AbstractArray A, create a view B such that the dimensions appear to be permuted. Similar to permutedims, except that no copying occurs (B shares storage with A).\n\nSee also: permutedims.\n\nExample\n\njulia> A = rand(3,5,4);\n\njulia> B = PermutedDimsArray(A, (3,1,2));\n\njulia> size(B)\n(4, 3, 5)\n\njulia> B[3,1,2] == A[1,2,3]\ntrue\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.promote_shape",
    "page": "Arrays",
    "title": "Base.promote_shape",
    "category": "function",
    "text": "promote_shape(s1, s2)\n\nCheck two array shapes for compatibility, allowing trailing singleton dimensions, and return whichever shape has more dimensions.\n\njulia> a = ones(3,4,1,1,1);\n\njulia> b = ones(3,4);\n\njulia> promote_shape(a,b)\n(Base.OneTo(3), Base.OneTo(4), Base.OneTo(1), Base.OneTo(1), Base.OneTo(1))\n\njulia> promote_shape((2,3,1,4), (2, 3, 1, 4, 1))\n(2, 3, 1, 4, 1)\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Concatenation-and-permutation-1",
    "page": "Arrays",
    "title": "Concatenation and permutation",
    "category": "section",
    "text": "Base.cat\nBase.vcat\nBase.hcat\nBase.hvcat\nBase.flipdim\nBase.circshift\nBase.circshift!\nBase.circcopy!\nBase.contains(::Function, ::Any, ::Any)\nBase.find(::Any)\nBase.find(::Function, ::Any)\nBase.findn\nBase.findnz\nBase.findfirst(::Any)\nBase.findfirst(::Any, ::Any)\nBase.findfirst(::Function, ::Any)\nBase.findlast(::Any)\nBase.findlast(::Any, ::Any)\nBase.findlast(::Function, ::Any)\nBase.findnext(::Any, ::Integer)\nBase.findnext(::Function, ::Any, ::Integer)\nBase.findnext(::Any, ::Any, ::Integer)\nBase.findprev(::Any, ::Integer)\nBase.findprev(::Function, ::Any, ::Integer)\nBase.findprev(::Any, ::Any, ::Integer)\nBase.permutedims\nBase.permutedims!\nBase.PermutedDimsArray\nBase.promote_shape"
},

{
    "location": "stdlib/arrays/#Base.accumulate-Tuple{Any,Any,Integer}",
    "page": "Arrays",
    "title": "Base.accumulate",
    "category": "method",
    "text": "accumulate(op, A, dim=1)\n\nCumulative operation op along a dimension dim (defaults to 1). See also accumulate! to use a preallocated output array, both for performance and to control the precision of the output (e.g. to avoid overflow). For common operations there are specialized variants of accumulate, see: cumsum, cumprod\n\njulia> accumulate(+, [1,2,3])\n3-element Array{Int64,1}:\n 1\n 3\n 6\n\njulia> accumulate(*, [1,2,3])\n3-element Array{Int64,1}:\n 1\n 2\n 6\n\n\n\naccumulate(op, v0, A)\n\nLike accumulate, but using a starting element v0. The first entry of the result will be op(v0, first(A)). For example:\n\njulia> accumulate(+, 100, [1,2,3])\n3-element Array{Int64,1}:\n 101\n 103\n 106\n\njulia> accumulate(min, 0, [1,2,-1])\n3-element Array{Int64,1}:\n  0\n  0\n -1\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.accumulate!",
    "page": "Arrays",
    "title": "Base.accumulate!",
    "category": "function",
    "text": "accumulate!(op, B, A, dim=1)\n\nCumulative operation op on A along a dimension, storing the result in B. The dimension defaults to 1. See also accumulate.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.cumprod",
    "page": "Arrays",
    "title": "Base.cumprod",
    "category": "function",
    "text": "cumprod(A, dim=1)\n\nCumulative product along a dimension dim (defaults to 1). See also cumprod! to use a preallocated output array, both for performance and to control the precision of the output (e.g. to avoid overflow).\n\njulia> a = [1 2 3; 4 5 6]\n2×3 Array{Int64,2}:\n 1  2  3\n 4  5  6\n\njulia> cumprod(a,1)\n2×3 Array{Int64,2}:\n 1   2   3\n 4  10  18\n\njulia> cumprod(a,2)\n2×3 Array{Int64,2}:\n 1   2    6\n 4  20  120\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.cumprod!",
    "page": "Arrays",
    "title": "Base.cumprod!",
    "category": "function",
    "text": "cumprod!(B, A, dim::Integer=1)\n\nCumulative product of A along a dimension, storing the result in B. The dimension defaults to 1. See also cumprod.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.cumsum",
    "page": "Arrays",
    "title": "Base.cumsum",
    "category": "function",
    "text": "cumsum(A, dim=1)\n\nCumulative sum along a dimension dim (defaults to 1). See also cumsum! to use a preallocated output array, both for performance and to control the precision of the output (e.g. to avoid overflow).\n\njulia> a = [1 2 3; 4 5 6]\n2×3 Array{Int64,2}:\n 1  2  3\n 4  5  6\n\njulia> cumsum(a,1)\n2×3 Array{Int64,2}:\n 1  2  3\n 5  7  9\n\njulia> cumsum(a,2)\n2×3 Array{Int64,2}:\n 1  3   6\n 4  9  15\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.cumsum!",
    "page": "Arrays",
    "title": "Base.cumsum!",
    "category": "function",
    "text": "cumsum!(B, A, dim::Integer=1)\n\nCumulative sum of A along a dimension, storing the result in B. The dimension defaults to 1. See also cumsum.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.cumsum_kbn",
    "page": "Arrays",
    "title": "Base.cumsum_kbn",
    "category": "function",
    "text": "cumsum_kbn(A, [dim::Integer=1])\n\nCumulative sum along a dimension, using the Kahan-Babuska-Neumaier compensated summation algorithm for additional accuracy. The dimension defaults to 1.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.LinAlg.diff",
    "page": "Arrays",
    "title": "Base.LinAlg.diff",
    "category": "function",
    "text": "diff(A, [dim::Integer=1])\n\nFinite difference operator of matrix or vector A. If A is a matrix, compute the finite difference over a dimension dim (default 1).\n\nExample\n\njulia> a = [2 4; 6 16]\n2×2 Array{Int64,2}:\n 2   4\n 6  16\n\njulia> diff(a,2)\n2×1 Array{Int64,2}:\n  2\n 10\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.LinAlg.gradient",
    "page": "Arrays",
    "title": "Base.LinAlg.gradient",
    "category": "function",
    "text": "gradient(F::AbstractVector, [h::Real])\n\nCompute differences along vector F, using h as the spacing between points. The default spacing is one.\n\nExample\n\njulia> a = [2,4,6,8];\n\njulia> gradient(a)\n4-element Array{Float64,1}:\n 2.0\n 2.0\n 2.0\n 2.0\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.rot180",
    "page": "Arrays",
    "title": "Base.rot180",
    "category": "function",
    "text": "rot180(A)\n\nRotate matrix A 180 degrees.\n\nExample\n\njulia> a = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> rot180(a)\n2×2 Array{Int64,2}:\n 4  3\n 2  1\n\n\n\nrot180(A, k)\n\nRotate matrix A 180 degrees an integer k number of times. If k is even, this is equivalent to a copy.\n\nExamples\n\njulia> a = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> rot180(a,1)\n2×2 Array{Int64,2}:\n 4  3\n 2  1\n\njulia> rot180(a,2)\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.rotl90",
    "page": "Arrays",
    "title": "Base.rotl90",
    "category": "function",
    "text": "rotl90(A)\n\nRotate matrix A left 90 degrees.\n\nExample\n\njulia> a = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> rotl90(a)\n2×2 Array{Int64,2}:\n 2  4\n 1  3\n\n\n\nrotl90(A, k)\n\nRotate matrix A left 90 degrees an integer k number of times. If k is zero or a multiple of four, this is equivalent to a copy.\n\nExamples\n\njulia> a = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> rotl90(a,1)\n2×2 Array{Int64,2}:\n 2  4\n 1  3\n\njulia> rotl90(a,2)\n2×2 Array{Int64,2}:\n 4  3\n 2  1\n\njulia> rotl90(a,3)\n2×2 Array{Int64,2}:\n 3  1\n 4  2\n\njulia> rotl90(a,4)\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.rotr90",
    "page": "Arrays",
    "title": "Base.rotr90",
    "category": "function",
    "text": "rotr90(A)\n\nRotate matrix A right 90 degrees.\n\nExample\n\njulia> a = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> rotr90(a)\n2×2 Array{Int64,2}:\n 3  1\n 4  2\n\n\n\nrotr90(A, k)\n\nRotate matrix A right 90 degrees an integer k number of times. If k is zero or a multiple of four, this is equivalent to a copy.\n\nExamples\n\njulia> a = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> rotr90(a,1)\n2×2 Array{Int64,2}:\n 3  1\n 4  2\n\njulia> rotr90(a,2)\n2×2 Array{Int64,2}:\n 4  3\n 2  1\n\njulia> rotr90(a,3)\n2×2 Array{Int64,2}:\n 2  4\n 1  3\n\njulia> rotr90(a,4)\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.reducedim",
    "page": "Arrays",
    "title": "Base.reducedim",
    "category": "function",
    "text": "reducedim(f, A, region[, v0])\n\nReduce 2-argument function f along dimensions of A. region is a vector specifying the dimensions to reduce, and v0 is the initial value to use in the reductions. For +, *, max and min the v0 argument is optional.\n\nThe associativity of the reduction is implementation-dependent; if you need a particular associativity, e.g. left-to-right, you should write your own loop. See documentation for reduce.\n\nExamples\n\njulia> a = reshape(collect(1:16), (4,4))\n4×4 Array{Int64,2}:\n 1  5   9  13\n 2  6  10  14\n 3  7  11  15\n 4  8  12  16\n\njulia> reducedim(max, a, 2)\n4×1 Array{Int64,2}:\n 13\n 14\n 15\n 16\n\njulia> reducedim(max, a, 1)\n1×4 Array{Int64,2}:\n 4  8  12  16\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.mapreducedim",
    "page": "Arrays",
    "title": "Base.mapreducedim",
    "category": "function",
    "text": "mapreducedim(f, op, A, region[, v0])\n\nEvaluates to the same as reducedim(op, map(f, A), region, f(v0)), but is generally faster because the intermediate array is avoided.\n\nExamples\n\njulia> a = reshape(collect(1:16), (4,4))\n4×4 Array{Int64,2}:\n 1  5   9  13\n 2  6  10  14\n 3  7  11  15\n 4  8  12  16\n\njulia> mapreducedim(isodd, *, a, 1)\n1×4 Array{Bool,2}:\n false  false  false  false\n\njulia> mapreducedim(isodd, |, a, 1, true)\n1×4 Array{Bool,2}:\n true  true  true  true\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.mapslices",
    "page": "Arrays",
    "title": "Base.mapslices",
    "category": "function",
    "text": "mapslices(f, A, dims)\n\nTransform the given dimensions of array A using function f. f is called on each slice of A of the form A[...,:,...,:,...]. dims is an integer vector specifying where the colons go in this expression. The results are concatenated along the remaining dimensions. For example, if dims is [1,2] and A is 4-dimensional, f is called on A[:,:,i,j] for all i and j.\n\nExamples\n\njulia> a = reshape(collect(1:16),(2,2,2,2))\n2×2×2×2 Array{Int64,4}:\n[:, :, 1, 1] =\n 1  3\n 2  4\n\n[:, :, 2, 1] =\n 5  7\n 6  8\n\n[:, :, 1, 2] =\n  9  11\n 10  12\n\n[:, :, 2, 2] =\n 13  15\n 14  16\n\njulia> mapslices(sum, a, [1,2])\n1×1×2×2 Array{Int64,4}:\n[:, :, 1, 1] =\n 10\n\n[:, :, 2, 1] =\n 26\n\n[:, :, 1, 2] =\n 42\n\n[:, :, 2, 2] =\n 58\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.sum_kbn",
    "page": "Arrays",
    "title": "Base.sum_kbn",
    "category": "function",
    "text": "sum_kbn(A)\n\nReturns the sum of all elements of A, using the Kahan-Babuska-Neumaier compensated summation algorithm for additional accuracy.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Array-functions-1",
    "page": "Arrays",
    "title": "Array functions",
    "category": "section",
    "text": "Base.accumulate(::Any, ::Any, ::Integer)\nBase.accumulate!\nBase.cumprod\nBase.cumprod!\nBase.cumsum\nBase.cumsum!\nBase.cumsum_kbn\nBase.LinAlg.diff\nBase.LinAlg.gradient\nBase.rot180\nBase.rotl90\nBase.rotr90\nBase.reducedim\nBase.mapreducedim\nBase.mapslices\nBase.sum_kbn"
},

{
    "location": "stdlib/arrays/#Base.Random.randperm",
    "page": "Arrays",
    "title": "Base.Random.randperm",
    "category": "function",
    "text": "randperm([rng=GLOBAL_RNG,] n::Integer)\n\nConstruct a random permutation of length n. The optional rng argument specifies a random number generator (see Random Numbers). To randomly permute a arbitrary vector, see shuffle or shuffle!.\n\nExample\n\njulia> rng = MersenneTwister(1234);\n\njulia> randperm(rng, 4)\n4-element Array{Int64,1}:\n 2\n 1\n 4\n 3\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.invperm",
    "page": "Arrays",
    "title": "Base.invperm",
    "category": "function",
    "text": "invperm(v)\n\nReturn the inverse permutation of v. If B = A[v], then A == B[invperm(v)].\n\nExample\n\njulia> v = [2; 4; 3; 1];\n\njulia> invperm(v)\n4-element Array{Int64,1}:\n 4\n 1\n 3\n 2\n\njulia> A = [\'a\',\'b\',\'c\',\'d\'];\n\njulia> B = A[v]\n4-element Array{Char,1}:\n \'b\'\n \'d\'\n \'c\'\n \'a\'\n\njulia> B[invperm(v)]\n4-element Array{Char,1}:\n \'a\'\n \'b\'\n \'c\'\n \'d\'\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.isperm",
    "page": "Arrays",
    "title": "Base.isperm",
    "category": "function",
    "text": "isperm(v) -> Bool\n\nReturns true if v is a valid permutation.\n\nExamples\n\njulia> isperm([1; 2])\ntrue\n\njulia> isperm([1; 3])\nfalse\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.permute!-Tuple{Any,AbstractArray{T,1} where T}",
    "page": "Arrays",
    "title": "Base.permute!",
    "category": "method",
    "text": "permute!(v, p)\n\nPermute vector v in-place, according to permutation p. No checking is done to verify that p is a permutation.\n\nTo return a new permutation, use v[p]. Note that this is generally faster than permute!(v,p) for large vectors.\n\nSee also ipermute!.\n\nExample\n\njulia> A = [1, 1, 3, 4];\n\njulia> perm = [2, 4, 3, 1];\n\njulia> permute!(A, perm);\n\njulia> A\n4-element Array{Int64,1}:\n 1\n 4\n 3\n 1\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.ipermute!",
    "page": "Arrays",
    "title": "Base.ipermute!",
    "category": "function",
    "text": "ipermute!(v, p)\n\nLike permute!, but the inverse of the given permutation is applied.\n\nExample\n\njulia> A = [1, 1, 3, 4];\n\njulia> perm = [2, 4, 3, 1];\n\njulia> ipermute!(A, perm);\n\njulia> A\n4-element Array{Int64,1}:\n 4\n 1\n 3\n 1\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.Random.randcycle",
    "page": "Arrays",
    "title": "Base.Random.randcycle",
    "category": "function",
    "text": "randcycle([rng=GLOBAL_RNG,] n::Integer)\n\nConstruct a random cyclic permutation of length n. The optional rng argument specifies a random number generator, see Random Numbers.\n\nExample\n\njulia> rng = MersenneTwister(1234);\n\njulia> randcycle(rng, 6)\n6-element Array{Int64,1}:\n 3\n 5\n 4\n 6\n 1\n 2\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.Random.shuffle",
    "page": "Arrays",
    "title": "Base.Random.shuffle",
    "category": "function",
    "text": "shuffle([rng=GLOBAL_RNG,] v)\n\nReturn a randomly permuted copy of v. The optional rng argument specifies a random number generator (see Random Numbers). To permute v in-place, see shuffle!.  To obtain randomly permuted indices, see randperm.\n\nExample\n\njulia> rng = MersenneTwister(1234);\n\njulia> shuffle(rng, collect(1:10))\n10-element Array{Int64,1}:\n  6\n  1\n 10\n  2\n  3\n  9\n  5\n  7\n  4\n  8\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.Random.shuffle!",
    "page": "Arrays",
    "title": "Base.Random.shuffle!",
    "category": "function",
    "text": "shuffle!([rng=GLOBAL_RNG,] v)\n\nIn-place version of shuffle: randomly permute the array v in-place, optionally supplying the random-number generator rng.\n\nExample\n\njulia> rng = MersenneTwister(1234);\n\njulia> shuffle!(rng, collect(1:16))\n16-element Array{Int64,1}:\n  2\n 15\n  5\n 14\n  1\n  9\n 10\n  6\n 11\n  3\n 16\n  7\n  4\n 12\n  8\n 13\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.reverse",
    "page": "Arrays",
    "title": "Base.reverse",
    "category": "function",
    "text": "reverse(v [, start=1 [, stop=length(v) ]] )\n\nReturn a copy of v reversed from start to stop.\n\nExamples\n\njulia> A = collect(1:5)\n5-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n 5\n\njulia> reverse(A)\n5-element Array{Int64,1}:\n 5\n 4\n 3\n 2\n 1\n\njulia> reverse(A, 1, 4)\n5-element Array{Int64,1}:\n 4\n 3\n 2\n 1\n 5\n\njulia> reverse(A, 3, 5)\n5-element Array{Int64,1}:\n 1\n 2\n 5\n 4\n 3\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.reverseind",
    "page": "Arrays",
    "title": "Base.reverseind",
    "category": "function",
    "text": "reverseind(v, i)\n\nGiven an index i in reverse(v), return the corresponding index in v so that v[reverseind(v,i)] == reverse(v)[i]. (This can be nontrivial in the case where v is a Unicode string.)\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.reverse!",
    "page": "Arrays",
    "title": "Base.reverse!",
    "category": "function",
    "text": "reverse!(v [, start=1 [, stop=length(v) ]]) -> v\n\nIn-place version of reverse.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Combinatorics-1",
    "page": "Arrays",
    "title": "Combinatorics",
    "category": "section",
    "text": "Base.Random.randperm\nBase.invperm\nBase.isperm\nBase.permute!(::Any, ::AbstractVector)\nBase.ipermute!\nBase.Random.randcycle\nBase.Random.shuffle\nBase.Random.shuffle!\nBase.reverse\nBase.reverseind\nBase.reverse!"
},

{
    "location": "stdlib/arrays/#Base.flipbits!",
    "page": "Arrays",
    "title": "Base.flipbits!",
    "category": "function",
    "text": "flipbits!(B::BitArray{N}) -> BitArray{N}\n\nPerforms a bitwise not operation on B. See ~.\n\nExample\n\njulia> A = trues(2,2)\n2×2 BitArray{2}:\n true  true\n true  true\n\njulia> flipbits!(A)\n2×2 BitArray{2}:\n false  false\n false  false\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.rol!",
    "page": "Arrays",
    "title": "Base.rol!",
    "category": "function",
    "text": "rol!(dest::BitVector, src::BitVector, i::Integer) -> BitVector\n\nPerforms a left rotation operation on src and puts the result into dest. i controls how far to rotate the bits.\n\n\n\nrol!(B::BitVector, i::Integer) -> BitVector\n\nPerforms a left rotation operation in-place on B. i controls how far to rotate the bits.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.rol",
    "page": "Arrays",
    "title": "Base.rol",
    "category": "function",
    "text": "rol(B::BitVector, i::Integer) -> BitVector\n\nPerforms a left rotation operation, returning a new BitVector. i controls how far to rotate the bits. See also rol!.\n\nExamples\n\njulia> A = BitArray([true, true, false, false, true])\n5-element BitArray{1}:\n  true\n  true\n false\n false\n  true\n\njulia> rol(A,1)\n5-element BitArray{1}:\n  true\n false\n false\n  true\n  true\n\njulia> rol(A,2)\n5-element BitArray{1}:\n false\n false\n  true\n  true\n  true\n\njulia> rol(A,5)\n5-element BitArray{1}:\n  true\n  true\n false\n false\n  true\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.ror!",
    "page": "Arrays",
    "title": "Base.ror!",
    "category": "function",
    "text": "ror!(dest::BitVector, src::BitVector, i::Integer) -> BitVector\n\nPerforms a right rotation operation on src and puts the result into dest. i controls how far to rotate the bits.\n\n\n\nror!(B::BitVector, i::Integer) -> BitVector\n\nPerforms a right rotation operation in-place on B. i controls how far to rotate the bits.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.ror",
    "page": "Arrays",
    "title": "Base.ror",
    "category": "function",
    "text": "ror(B::BitVector, i::Integer) -> BitVector\n\nPerforms a right rotation operation on B, returning a new BitVector. i controls how far to rotate the bits. See also ror!.\n\nExamples\n\njulia> A = BitArray([true, true, false, false, true])\n5-element BitArray{1}:\n  true\n  true\n false\n false\n  true\n\njulia> ror(A,1)\n5-element BitArray{1}:\n  true\n  true\n  true\n false\n false\n\njulia> ror(A,2)\n5-element BitArray{1}:\n false\n  true\n  true\n  true\n false\n\njulia> ror(A,5)\n5-element BitArray{1}:\n  true\n  true\n false\n false\n  true\n\n\n\n"
},

{
    "location": "stdlib/arrays/#BitArrays-1",
    "page": "Arrays",
    "title": "BitArrays",
    "category": "section",
    "text": "BitArrays are space-efficient \"packed\" boolean arrays, which store one bit per boolean value.  They can be used similarly to Array{Bool} arrays (which store one byte per boolean value), and can be converted to/from the latter via Array(bitarray) and BitArray(array), respectively.Base.flipbits!\nBase.rol!\nBase.rol\nBase.ror!\nBase.ror"
},

{
    "location": "stdlib/arrays/#Base.SparseArrays.SparseVector",
    "page": "Arrays",
    "title": "Base.SparseArrays.SparseVector",
    "category": "type",
    "text": "SparseVector{Tv,Ti<:Integer} <: AbstractSparseVector{Tv,Ti}\n\nVector type for storing sparse vectors.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.SparseArrays.SparseMatrixCSC",
    "page": "Arrays",
    "title": "Base.SparseArrays.SparseMatrixCSC",
    "category": "type",
    "text": "SparseMatrixCSC{Tv,Ti<:Integer} <: AbstractSparseMatrix{Tv,Ti}\n\nMatrix type for storing sparse matrices in the Compressed Sparse Column format.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.SparseArrays.sparse",
    "page": "Arrays",
    "title": "Base.SparseArrays.sparse",
    "category": "function",
    "text": "sparse(A)\n\nConvert an AbstractMatrix A into a sparse matrix.\n\nExample\n\njulia> A = eye(3)\n3×3 Array{Float64,2}:\n 1.0  0.0  0.0\n 0.0  1.0  0.0\n 0.0  0.0  1.0\n\njulia> sparse(A)\n3×3 SparseMatrixCSC{Float64,Int64} with 3 stored entries:\n  [1, 1]  =  1.0\n  [2, 2]  =  1.0\n  [3, 3]  =  1.0\n\n\n\nsparse(I, J, V,[ m, n, combine])\n\nCreate a sparse matrix S of dimensions m x n such that S[I[k], J[k]] = V[k]. The combine function is used to combine duplicates. If m and n are not specified, they are set to maximum(I) and maximum(J) respectively. If the combine function is not supplied, combine defaults to + unless the elements of V are Booleans in which case combine defaults to |. All elements of I must satisfy 1 <= I[k] <= m, and all elements of J must satisfy 1 <= J[k] <= n. Numerical zeros in (I, J, V) are retained as structural nonzeros; to drop numerical zeros, use dropzeros!.\n\nFor additional documentation and an expert driver, see Base.SparseArrays.sparse!.\n\nExample\n\njulia> Is = [1; 2; 3];\n\njulia> Js = [1; 2; 3];\n\njulia> Vs = [1; 2; 3];\n\njulia> sparse(Is, Js, Vs)\n3×3 SparseMatrixCSC{Int64,Int64} with 3 stored entries:\n  [1, 1]  =  1\n  [2, 2]  =  2\n  [3, 3]  =  3\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.SparseArrays.sparsevec",
    "page": "Arrays",
    "title": "Base.SparseArrays.sparsevec",
    "category": "function",
    "text": "sparsevec(I, V, [m, combine])\n\nCreate a sparse vector S of length m such that S[I[k]] = V[k]. Duplicates are combined using the combine function, which defaults to + if no combine argument is provided, unless the elements of V are Booleans in which case combine defaults to |.\n\njulia> II = [1, 3, 3, 5]; V = [0.1, 0.2, 0.3, 0.2];\n\njulia> sparsevec(II, V)\n5-element SparseVector{Float64,Int64} with 3 stored entries:\n  [1]  =  0.1\n  [3]  =  0.5\n  [5]  =  0.2\n\njulia> sparsevec(II, V, 8, -)\n8-element SparseVector{Float64,Int64} with 3 stored entries:\n  [1]  =  0.1\n  [3]  =  -0.1\n  [5]  =  0.2\n\njulia> sparsevec([1, 3, 1, 2, 2], [true, true, false, false, false])\n3-element SparseVector{Bool,Int64} with 3 stored entries:\n  [1]  =  true\n  [2]  =  false\n  [3]  =  true\n\n\n\nsparsevec(d::Dict, [m])\n\nCreate a sparse vector of length m where the nonzero indices are keys from the dictionary, and the nonzero values are the values from the dictionary.\n\njulia> sparsevec(Dict(1 => 3, 2 => 2))\n2-element SparseVector{Int64,Int64} with 2 stored entries:\n  [1]  =  3\n  [2]  =  2\n\n\n\nsparsevec(A)\n\nConvert a vector A into a sparse vector of length m.\n\nExample\n\njulia> sparsevec([1.0, 2.0, 0.0, 0.0, 3.0, 0.0])\n6-element SparseVector{Float64,Int64} with 3 stored entries:\n  [1]  =  1.0\n  [2]  =  2.0\n  [5]  =  3.0\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.SparseArrays.issparse",
    "page": "Arrays",
    "title": "Base.SparseArrays.issparse",
    "category": "function",
    "text": "issparse(S)\n\nReturns true if S is sparse, and false otherwise.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.full",
    "page": "Arrays",
    "title": "Base.full",
    "category": "function",
    "text": "full(S)\n\nConvert a sparse matrix or vector S into a dense matrix or vector.\n\nExample\n\njulia> A = speye(3)\n3×3 SparseMatrixCSC{Float64,Int64} with 3 stored entries:\n  [1, 1]  =  1.0\n  [2, 2]  =  1.0\n  [3, 3]  =  1.0\n\njulia> full(A)\n3×3 Array{Float64,2}:\n 1.0  0.0  0.0\n 0.0  1.0  0.0\n 0.0  0.0  1.0\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.SparseArrays.nnz",
    "page": "Arrays",
    "title": "Base.SparseArrays.nnz",
    "category": "function",
    "text": "nnz(A)\n\nReturns the number of stored (filled) elements in a sparse array.\n\nExample\n\njulia> A = speye(3)\n3×3 SparseMatrixCSC{Float64,Int64} with 3 stored entries:\n  [1, 1]  =  1.0\n  [2, 2]  =  1.0\n  [3, 3]  =  1.0\n\njulia> nnz(A)\n3\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.SparseArrays.spzeros",
    "page": "Arrays",
    "title": "Base.SparseArrays.spzeros",
    "category": "function",
    "text": "spzeros([type,]m[,n])\n\nCreate a sparse vector of length m or sparse matrix of size m x n. This sparse array will not contain any nonzero values. No storage will be allocated for nonzero values during construction. The type defaults to Float64 if not specified.\n\nExamples\n\njulia> spzeros(3, 3)\n3×3 SparseMatrixCSC{Float64,Int64} with 0 stored entries\n\njulia> spzeros(Float32, 4)\n4-element SparseVector{Float32,Int64} with 0 stored entries\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.SparseArrays.spones",
    "page": "Arrays",
    "title": "Base.SparseArrays.spones",
    "category": "function",
    "text": "spones(S)\n\nCreate a sparse array with the same structure as that of S, but with every nonzero element having the value 1.0.\n\nExample\n\njulia> A = sparse([1,2,3,4],[2,4,3,1],[5.,4.,3.,2.])\n4×4 SparseMatrixCSC{Float64,Int64} with 4 stored entries:\n  [4, 1]  =  2.0\n  [1, 2]  =  5.0\n  [3, 3]  =  3.0\n  [2, 4]  =  4.0\n\njulia> spones(A)\n4×4 SparseMatrixCSC{Float64,Int64} with 4 stored entries:\n  [4, 1]  =  1.0\n  [1, 2]  =  1.0\n  [3, 3]  =  1.0\n  [2, 4]  =  1.0\n\nNote the difference from speye.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.SparseArrays.speye-Tuple{Type,Integer,Integer}",
    "page": "Arrays",
    "title": "Base.SparseArrays.speye",
    "category": "method",
    "text": "speye([type,]m[,n])\n\nCreate a sparse identity matrix of size m x m. When n is supplied, create a sparse identity matrix of size m x n. The type defaults to Float64 if not specified.\n\nsparse(I, m, n) is equivalent to speye(Int, m, n), and sparse(α*I, m, n) can be used to efficiently create a sparse multiple α of the identity matrix.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.SparseArrays.speye-Tuple{SparseMatrixCSC}",
    "page": "Arrays",
    "title": "Base.SparseArrays.speye",
    "category": "method",
    "text": "speye(S)\n\nCreate a sparse identity matrix with the same size as S.\n\nExample\n\njulia> A = sparse([1,2,3,4],[2,4,3,1],[5.,4.,3.,2.])\n4×4 SparseMatrixCSC{Float64,Int64} with 4 stored entries:\n  [4, 1]  =  2.0\n  [1, 2]  =  5.0\n  [3, 3]  =  3.0\n  [2, 4]  =  4.0\n\njulia> speye(A)\n4×4 SparseMatrixCSC{Float64,Int64} with 4 stored entries:\n  [1, 1]  =  1.0\n  [2, 2]  =  1.0\n  [3, 3]  =  1.0\n  [4, 4]  =  1.0\n\nNote the difference from spones.\n\n\n\nspeye([type,]m[,n])\n\nCreate a sparse identity matrix of size m x m. When n is supplied, create a sparse identity matrix of size m x n. The type defaults to Float64 if not specified.\n\nsparse(I, m, n) is equivalent to speye(Int, m, n), and sparse(α*I, m, n) can be used to efficiently create a sparse multiple α of the identity matrix.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.SparseArrays.spdiagm",
    "page": "Arrays",
    "title": "Base.SparseArrays.spdiagm",
    "category": "function",
    "text": "spdiagm(B, d[, m, n])\n\nConstruct a sparse diagonal matrix. B is a tuple of vectors containing the diagonals and d is a tuple containing the positions of the diagonals. In the case the input contains only one diagonal, B can be a vector (instead of a tuple) and d can be the diagonal position (instead of a tuple), defaulting to 0 (diagonal). Optionally, m and n specify the size of the resulting sparse matrix.\n\nExample\n\njulia> spdiagm(([1,2,3,4],[4,3,2,1]),(-1,1))\n5×5 SparseMatrixCSC{Int64,Int64} with 8 stored entries:\n  [2, 1]  =  1\n  [1, 2]  =  4\n  [3, 2]  =  2\n  [2, 3]  =  3\n  [4, 3]  =  3\n  [3, 4]  =  2\n  [5, 4]  =  4\n  [4, 5]  =  1\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.SparseArrays.sprand",
    "page": "Arrays",
    "title": "Base.SparseArrays.sprand",
    "category": "function",
    "text": "sprand([rng],[type],m,[n],p::AbstractFloat,[rfn])\n\nCreate a random length m sparse vector or m by n sparse matrix, in which the probability of any element being nonzero is independently given by p (and hence the mean density of nonzeros is also exactly p). Nonzero values are sampled from the distribution specified by rfn and have the type type. The uniform distribution is used in case rfn is not specified. The optional rng argument specifies a random number generator, see Random Numbers.\n\nExample\n\njulia> rng = MersenneTwister(1234);\n\njulia> sprand(rng, Bool, 2, 2, 0.5)\n2×2 SparseMatrixCSC{Bool,Int64} with 2 stored entries:\n  [1, 1]  =  true\n  [2, 1]  =  true\n\njulia> sprand(rng, Float64, 3, 0.75)\n3-element SparseVector{Float64,Int64} with 1 stored entry:\n  [3]  =  0.298614\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.SparseArrays.sprandn",
    "page": "Arrays",
    "title": "Base.SparseArrays.sprandn",
    "category": "function",
    "text": "sprandn([rng], m[,n],p::AbstractFloat)\n\nCreate a random sparse vector of length m or sparse matrix of size m by n with the specified (independent) probability p of any entry being nonzero, where nonzero values are sampled from the normal distribution. The optional rng argument specifies a random number generator, see Random Numbers.\n\nExample\n\njulia> rng = MersenneTwister(1234);\n\njulia> sprandn(rng, 2, 2, 0.75)\n2×2 SparseMatrixCSC{Float64,Int64} with 3 stored entries:\n  [1, 1]  =  0.532813\n  [2, 1]  =  -0.271735\n  [2, 2]  =  0.502334\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.SparseArrays.nonzeros",
    "page": "Arrays",
    "title": "Base.SparseArrays.nonzeros",
    "category": "function",
    "text": "nonzeros(A)\n\nReturn a vector of the structural nonzero values in sparse array A. This includes zeros that are explicitly stored in the sparse array. The returned vector points directly to the internal nonzero storage of A, and any modifications to the returned vector will mutate A as well. See rowvals and nzrange.\n\nExample\n\njulia> A = speye(3)\n3×3 SparseMatrixCSC{Float64,Int64} with 3 stored entries:\n  [1, 1]  =  1.0\n  [2, 2]  =  1.0\n  [3, 3]  =  1.0\n\njulia> nonzeros(A)\n3-element Array{Float64,1}:\n 1.0\n 1.0\n 1.0\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.SparseArrays.rowvals",
    "page": "Arrays",
    "title": "Base.SparseArrays.rowvals",
    "category": "function",
    "text": "rowvals(A::SparseMatrixCSC)\n\nReturn a vector of the row indices of A. Any modifications to the returned vector will mutate A as well. Providing access to how the row indices are stored internally can be useful in conjunction with iterating over structural nonzero values. See also nonzeros and nzrange.\n\nExample\n\njulia> A = speye(3)\n3×3 SparseMatrixCSC{Float64,Int64} with 3 stored entries:\n  [1, 1]  =  1.0\n  [2, 2]  =  1.0\n  [3, 3]  =  1.0\n\njulia> rowvals(A)\n3-element Array{Int64,1}:\n 1\n 2\n 3\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.SparseArrays.nzrange",
    "page": "Arrays",
    "title": "Base.SparseArrays.nzrange",
    "category": "function",
    "text": "nzrange(A::SparseMatrixCSC, col::Integer)\n\nReturn the range of indices to the structural nonzero values of a sparse matrix column. In conjunction with nonzeros and rowvals, this allows for convenient iterating over a sparse matrix :\n\nA = sparse(I,J,V)\nrows = rowvals(A)\nvals = nonzeros(A)\nm, n = size(A)\nfor i = 1:n\n   for j in nzrange(A, i)\n      row = rows[j]\n      val = vals[j]\n      # perform sparse wizardry...\n   end\nend\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.SparseArrays.dropzeros!-Tuple{SparseMatrixCSC,Bool}",
    "page": "Arrays",
    "title": "Base.SparseArrays.dropzeros!",
    "category": "method",
    "text": "dropzeros!(A::SparseMatrixCSC, trim::Bool = true)\n\nRemoves stored numerical zeros from A, optionally trimming resulting excess space from A.rowval and A.nzval when trim is true.\n\nFor an out-of-place version, see dropzeros. For algorithmic information, see fkeep!.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.SparseArrays.dropzeros-Tuple{SparseMatrixCSC,Bool}",
    "page": "Arrays",
    "title": "Base.SparseArrays.dropzeros",
    "category": "method",
    "text": "dropzeros(A::SparseMatrixCSC, trim::Bool = true)\n\nGenerates a copy of A and removes stored numerical zeros from that copy, optionally trimming excess space from the result\'s rowval and nzval arrays when trim is true.\n\nFor an in-place version and algorithmic information, see dropzeros!.\n\nExample\n\njulia> A = sparse([1, 2, 3], [1, 2, 3], [1.0, 0.0, 1.0])\n3×3 SparseMatrixCSC{Float64,Int64} with 3 stored entries:\n  [1, 1]  =  1.0\n  [2, 2]  =  0.0\n  [3, 3]  =  1.0\n\njulia> dropzeros(A)\n3×3 SparseMatrixCSC{Float64,Int64} with 2 stored entries:\n  [1, 1]  =  1.0\n  [3, 3]  =  1.0\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.SparseArrays.dropzeros!-Tuple{SparseVector,Bool}",
    "page": "Arrays",
    "title": "Base.SparseArrays.dropzeros!",
    "category": "method",
    "text": "dropzeros!(x::SparseVector, trim::Bool = true)\n\nRemoves stored numerical zeros from x, optionally trimming resulting excess space from x.nzind and x.nzval when trim is true.\n\nFor an out-of-place version, see dropzeros. For algorithmic information, see fkeep!.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.SparseArrays.dropzeros-Tuple{SparseVector,Bool}",
    "page": "Arrays",
    "title": "Base.SparseArrays.dropzeros",
    "category": "method",
    "text": "dropzeros(x::SparseVector, trim::Bool = true)\n\nGenerates a copy of x and removes numerical zeros from that copy, optionally trimming excess space from the result\'s nzind and nzval arrays when trim is true.\n\nFor an in-place version and algorithmic information, see dropzeros!.\n\nExample\n\njulia> A = sparsevec([1, 2, 3], [1.0, 0.0, 1.0])\n3-element SparseVector{Float64,Int64} with 3 stored entries:\n  [1]  =  1.0\n  [2]  =  0.0\n  [3]  =  1.0\n\njulia> dropzeros(A)\n3-element SparseVector{Float64,Int64} with 2 stored entries:\n  [1]  =  1.0\n  [3]  =  1.0\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.SparseArrays.permute",
    "page": "Arrays",
    "title": "Base.SparseArrays.permute",
    "category": "function",
    "text": "permute{Tv,Ti}(A::SparseMatrixCSC{Tv,Ti}, p::AbstractVector{<:Integer},\n    q::AbstractVector{<:Integer})\n\nBilaterally permute A, returning PAQ (A[p,q]). Column-permutation q\'s length must match A\'s column count (length(q) == A.n). Row-permutation p\'s length must match A\'s row count (length(p) == A.m).\n\nFor expert drivers and additional information, see permute!.\n\nExample\n\njulia> A = spdiagm([1, 2, 3, 4], 0, 4, 4) + spdiagm([5, 6, 7], 1, 4, 4)\n4×4 SparseMatrixCSC{Int64,Int64} with 7 stored entries:\n  [1, 1]  =  1\n  [1, 2]  =  5\n  [2, 2]  =  2\n  [2, 3]  =  6\n  [3, 3]  =  3\n  [3, 4]  =  7\n  [4, 4]  =  4\n\njulia> permute(A, [4, 3, 2, 1], [1, 2, 3, 4])\n4×4 SparseMatrixCSC{Int64,Int64} with 7 stored entries:\n  [4, 1]  =  1\n  [3, 2]  =  2\n  [4, 2]  =  5\n  [2, 3]  =  3\n  [3, 3]  =  6\n  [1, 4]  =  4\n  [2, 4]  =  7\n\njulia> permute(A, [1, 2, 3, 4], [4, 3, 2, 1])\n4×4 SparseMatrixCSC{Int64,Int64} with 7 stored entries:\n  [3, 1]  =  7\n  [4, 1]  =  4\n  [2, 2]  =  6\n  [3, 2]  =  3\n  [1, 3]  =  5\n  [2, 3]  =  2\n  [1, 4]  =  1\n\n\n\n"
},

{
    "location": "stdlib/arrays/#Base.permute!-Union{Tuple{SparseMatrixCSC{Tv,Ti},SparseMatrixCSC{Tv,Ti},AbstractArray{Tp,1},AbstractArray{Tq,1}}, Tuple{Ti}, Tuple{Tp}, Tuple{Tq}, Tuple{Tv}} where Tq<:Integer where Tp<:Integer where Ti where Tv",
    "page": "Arrays",
    "title": "Base.permute!",
    "category": "method",
    "text": "permute!{Tv,Ti}(X::SparseMatrixCSC{Tv,Ti}, A::SparseMatrixCSC{Tv,Ti},\n    p::AbstractVector{<:Integer}, q::AbstractVector{<:Integer}[, C::SparseMatrixCSC{Tv,Ti}])\n\nBilaterally permute A, storing result PAQ (A[p,q]) in X. Stores intermediate result (AQ)^T (transpose(A[:,q])) in optional argument C if present. Requires that none of X, A, and, if present, C alias each other; to store result PAQ back into A, use the following method lacking X:\n\npermute!{Tv,Ti}(A::SparseMatrixCSC{Tv,Ti}, p::AbstractVector{<:Integer},\n    q::AbstractVector{<:Integer}[, C::SparseMatrixCSC{Tv,Ti}[, workcolptr::Vector{Ti}]])\n\nX\'s dimensions must match those of A (X.m == A.m and X.n == A.n), and X must have enough storage to accommodate all allocated entries in A (length(X.rowval) >= nnz(A) and length(X.nzval) >= nnz(A)). Column-permutation q\'s length must match A\'s column count (length(q) == A.n). Row-permutation p\'s length must match A\'s row count (length(p) == A.m).\n\nC\'s dimensions must match those of transpose(A) (C.m == A.n and C.n == A.m), and C must have enough storage to accommodate all allocated entries in A (length(C.rowval) >= nnz(A) and length(C.nzval) >= nnz(A)).\n\nFor additional (algorithmic) information, and for versions of these methods that forgo argument checking, see (unexported) parent methods unchecked_noalias_permute! and unchecked_aliasing_permute!.\n\nSee also: permute.\n\n\n\n"
},

{
    "location": "stdlib/arrays/#stdlib-sparse-arrays-1",
    "page": "Arrays",
    "title": "Sparse Vectors and Matrices",
    "category": "section",
    "text": "Sparse vectors and matrices largely support the same set of operations as their dense counterparts. The following functions are specific to sparse arrays.Base.SparseArrays.SparseVector\nBase.SparseArrays.SparseMatrixCSC\nBase.SparseArrays.sparse\nBase.SparseArrays.sparsevec\nBase.SparseArrays.issparse\nBase.full\nBase.SparseArrays.nnz\nBase.SparseArrays.spzeros\nBase.SparseArrays.spones\nBase.SparseArrays.speye(::Type, ::Integer, ::Integer)\nBase.SparseArrays.speye(::SparseMatrixCSC)\nBase.SparseArrays.spdiagm\nBase.SparseArrays.sprand\nBase.SparseArrays.sprandn\nBase.SparseArrays.nonzeros\nBase.SparseArrays.rowvals\nBase.SparseArrays.nzrange\nBase.SparseArrays.dropzeros!(::SparseMatrixCSC, ::Bool)\nBase.SparseArrays.dropzeros(::SparseMatrixCSC, ::Bool)\nBase.SparseArrays.dropzeros!(::SparseVector, ::Bool)\nBase.SparseArrays.dropzeros(::SparseVector, ::Bool)\nBase.SparseArrays.permute\nBase.permute!{Tv, Ti, Tp <: Integer, Tq <: Integer}(::SparseMatrixCSC{Tv,Ti}, ::SparseMatrixCSC{Tv,Ti}, ::AbstractArray{Tp,1}, ::AbstractArray{Tq,1})"
},

{
    "location": "stdlib/parallel/#",
    "page": "Tasks and Parallel Computing",
    "title": "Tasks and Parallel Computing",
    "category": "page",
    "text": ""
},

{
    "location": "stdlib/parallel/#Tasks-and-Parallel-Computing-1",
    "page": "Tasks and Parallel Computing",
    "title": "Tasks and Parallel Computing",
    "category": "section",
    "text": ""
},

{
    "location": "stdlib/parallel/#Core.Task",
    "page": "Tasks and Parallel Computing",
    "title": "Core.Task",
    "category": "type",
    "text": "Task(func)\n\nCreate a Task (i.e. coroutine) to execute the given function (which must be callable with no arguments). The task exits when this function returns.\n\nExample\n\njulia> a() = det(rand(1000, 1000));\n\njulia> b = Task(a);\n\nIn this example, b is a runnable Task that hasn\'t started yet.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.current_task",
    "page": "Tasks and Parallel Computing",
    "title": "Base.current_task",
    "category": "function",
    "text": "current_task()\n\nGet the currently running Task.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.istaskdone",
    "page": "Tasks and Parallel Computing",
    "title": "Base.istaskdone",
    "category": "function",
    "text": "istaskdone(t::Task) -> Bool\n\nDetermine whether a task has exited.\n\njulia> a2() = det(rand(1000, 1000));\n\njulia> b = Task(a2);\n\njulia> istaskdone(b)\nfalse\n\njulia> schedule(b);\n\njulia> yield();\n\njulia> istaskdone(b)\ntrue\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.istaskstarted",
    "page": "Tasks and Parallel Computing",
    "title": "Base.istaskstarted",
    "category": "function",
    "text": "istaskstarted(t::Task) -> Bool\n\nDetermine whether a task has started executing.\n\njulia> a3() = det(rand(1000, 1000));\n\njulia> b = Task(a3);\n\njulia> istaskstarted(b)\nfalse\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.yield",
    "page": "Tasks and Parallel Computing",
    "title": "Base.yield",
    "category": "function",
    "text": "yield()\n\nSwitch to the scheduler to allow another scheduled task to run. A task that calls this function is still runnable, and will be restarted immediately if there are no other runnable tasks.\n\n\n\nyield(t::Task, arg = nothing)\n\nA fast, unfair-scheduling version of schedule(t, arg); yield() which immediately yields to t before calling the scheduler.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.yieldto",
    "page": "Tasks and Parallel Computing",
    "title": "Base.yieldto",
    "category": "function",
    "text": "yieldto(t::Task, arg = nothing)\n\nSwitch to the given task. The first time a task is switched to, the task\'s function is called with no arguments. On subsequent switches, arg is returned from the task\'s last call to yieldto. This is a low-level call that only switches tasks, not considering states or scheduling in any way. Its use is discouraged.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.task_local_storage-Tuple{Any}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.task_local_storage",
    "category": "method",
    "text": "task_local_storage(key)\n\nLook up the value of a key in the current task\'s task-local storage.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.task_local_storage-Tuple{Any,Any}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.task_local_storage",
    "category": "method",
    "text": "task_local_storage(key, value)\n\nAssign a value to a key in the current task\'s task-local storage.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.task_local_storage-Tuple{Function,Any,Any}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.task_local_storage",
    "category": "method",
    "text": "task_local_storage(body, key, value)\n\nCall the function body with a modified task-local storage, in which value is assigned to key; the previous value of key, or lack thereof, is restored afterwards. Useful for emulating dynamic scoping.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Condition",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Condition",
    "category": "type",
    "text": "Condition()\n\nCreate an edge-triggered event source that tasks can wait for. Tasks that call wait on a Condition are suspended and queued. Tasks are woken up when notify is later called on the Condition. Edge triggering means that only tasks waiting at the time notify is called can be woken up. For level-triggered notifications, you must keep extra state to keep track of whether a notification has happened. The Channel type does this, and so can be used for level-triggered events.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.notify",
    "page": "Tasks and Parallel Computing",
    "title": "Base.notify",
    "category": "function",
    "text": "notify(condition, val=nothing; all=true, error=false)\n\nWake up tasks waiting for a condition, passing them val. If all is true (the default), all waiting tasks are woken, otherwise only one is. If error is true, the passed value is raised as an exception in the woken tasks.\n\nReturns the count of tasks woken up. Returns 0 if no tasks are waiting on condition.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.schedule",
    "page": "Tasks and Parallel Computing",
    "title": "Base.schedule",
    "category": "function",
    "text": "schedule(t::Task, [val]; error=false)\n\nAdd a Task to the scheduler\'s queue. This causes the task to run constantly when the system is otherwise idle, unless the task performs a blocking operation such as wait.\n\nIf a second argument val is provided, it will be passed to the task (via the return value of yieldto) when it runs again. If error is true, the value is raised as an exception in the woken task.\n\njulia> a5() = det(rand(1000, 1000));\n\njulia> b = Task(a5);\n\njulia> istaskstarted(b)\nfalse\n\njulia> schedule(b);\n\njulia> yield();\n\njulia> istaskstarted(b)\ntrue\n\njulia> istaskdone(b)\ntrue\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.@schedule",
    "page": "Tasks and Parallel Computing",
    "title": "Base.@schedule",
    "category": "macro",
    "text": "@schedule\n\nWrap an expression in a Task and add it to the local machine\'s scheduler queue. Similar to @async except that an enclosing @sync does NOT wait for tasks started with an @schedule.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.@task",
    "page": "Tasks and Parallel Computing",
    "title": "Base.@task",
    "category": "macro",
    "text": "@task\n\nWrap an expression in a Task without executing it, and return the Task. This only creates a task, and does not run it.\n\njulia> a1() = det(rand(1000, 1000));\n\njulia> b = @task a1();\n\njulia> istaskstarted(b)\nfalse\n\njulia> schedule(b);\n\njulia> yield();\n\njulia> istaskdone(b)\ntrue\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.sleep",
    "page": "Tasks and Parallel Computing",
    "title": "Base.sleep",
    "category": "function",
    "text": "sleep(seconds)\n\nBlock the current task for a specified number of seconds. The minimum sleep time is 1 millisecond or input of 0.001.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Channel",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Channel",
    "category": "type",
    "text": "Channel{T}(sz::Int)\n\nConstructs a Channel with an internal buffer that can hold a maximum of sz objects of type T. put! calls on a full channel block until an object is removed with take!.\n\nChannel(0) constructs an unbuffered channel. put! blocks until a matching take! is called. And vice-versa.\n\nOther constructors:\n\nChannel(Inf): equivalent to Channel{Any}(typemax(Int))\nChannel(sz): equivalent to Channel{Any}(sz)\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.put!-Tuple{Channel,Any}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.put!",
    "category": "method",
    "text": "put!(c::Channel, v)\n\nAppends an item v to the channel c. Blocks if the channel is full.\n\nFor unbuffered channels, blocks until a take! is performed by a different task.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.take!-Tuple{Channel}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.take!",
    "category": "method",
    "text": "take!(c::Channel)\n\nRemoves and returns a value from a Channel. Blocks until data is available.\n\nFor unbuffered channels, blocks until a put! is performed by a different task.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.isready-Tuple{Channel}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.isready",
    "category": "method",
    "text": "isready(c::Channel)\n\nDetermine whether a Channel has a value stored to it. Returns immediately, does not block.\n\nFor unbuffered channels returns true if there are tasks waiting on a put!.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.fetch-Tuple{Channel}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.fetch",
    "category": "method",
    "text": "fetch(c::Channel)\n\nWaits for and gets the first available item from the channel. Does not remove the item. fetch is unsupported on an unbuffered (0-size) channel.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.close-Tuple{Channel}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.close",
    "category": "method",
    "text": "close(c::Channel)\n\nCloses a channel. An exception is thrown by:\n\nput! on a closed channel.\ntake! and fetch on an empty, closed channel.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.bind-Tuple{Channel,Task}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.bind",
    "category": "method",
    "text": "bind(chnl::Channel, task::Task)\n\nAssociates the lifetime of chnl with a task. Channel chnl is automatically closed when the task terminates. Any uncaught exception in the task is propagated to all waiters on chnl.\n\nThe chnl object can be explicitly closed independent of task termination. Terminating tasks have no effect on already closed Channel objects.\n\nWhen a channel is bound to multiple tasks, the first task to terminate will close the channel. When multiple channels are bound to the same task, termination of the task will close all of the bound channels.\n\njulia> c = Channel(0);\n\njulia> task = @schedule foreach(i->put!(c, i), 1:4);\n\njulia> bind(c,task);\n\njulia> for i in c\n           @show i\n       end;\ni = 1\ni = 2\ni = 3\ni = 4\n\njulia> isopen(c)\nfalse\n\njulia> c = Channel(0);\n\njulia> task = @schedule (put!(c,1);error(\"foo\"));\n\njulia> bind(c,task);\n\njulia> take!(c)\n1\n\njulia> put!(c,1);\nERROR: foo\nStacktrace:\n [1] check_channel_state(::Channel{Any}) at ./channels.jl:131\n [2] put!(::Channel{Any}, ::Int64) at ./channels.jl:261\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.asyncmap",
    "page": "Tasks and Parallel Computing",
    "title": "Base.asyncmap",
    "category": "function",
    "text": "asyncmap(f, c...; ntasks=0, batch_size=nothing)\n\nUses multiple concurrent tasks to map f over a collection (or multiple equal length collections). For multiple collection arguments, f is applied elementwise.\n\nntasks specifies the number of tasks to run concurrently. Depending on the length of the collections, if ntasks is unspecified, up to 100 tasks will be used for concurrent mapping.\n\nntasks can also be specified as a zero-arg function. In this case, the number of tasks to run in parallel is checked before processing every element and a new task started if the value of ntasks_func() is less than the current number of tasks.\n\nIf batch_size is specified, the collection is processed in batch mode. f must then be a function that must accept a Vector of argument tuples and must return a vector of results. The input vector will have a length of batch_size or less.\n\nThe following examples highlight execution in different tasks by returning the object_id of the tasks in which the mapping function is executed.\n\nFirst, with ntasks undefined, each element is processed in a different task.\n\njulia> tskoid() = object_id(current_task());\n\njulia> asyncmap(x->tskoid(), 1:5)\n5-element Array{UInt64,1}:\n 0x6e15e66c75c75853\n 0x440f8819a1baa682\n 0x9fb3eeadd0c83985\n 0xebd3e35fe90d4050\n 0x29efc93edce2b961\n\njulia> length(unique(asyncmap(x->tskoid(), 1:5)))\n5\n\nWith ntasks=2 all elements are processed in 2 tasks.\n\njulia> asyncmap(x->tskoid(), 1:5; ntasks=2)\n5-element Array{UInt64,1}:\n 0x027ab1680df7ae94\n 0xa23d2f80cd7cf157\n 0x027ab1680df7ae94\n 0xa23d2f80cd7cf157\n 0x027ab1680df7ae94\n\njulia> length(unique(asyncmap(x->tskoid(), 1:5; ntasks=2)))\n2\n\nWith batch_size defined, the mapping function needs to be changed to accept an array of argument tuples and return an array of results. map is used in the modified mapping function to achieve this.\n\njulia> batch_func(input) = map(x->string(\"args_tuple: \", x, \", element_val: \", x[1], \", task: \", tskoid()), input)\nbatch_func (generic function with 1 method)\n\njulia> asyncmap(batch_func, 1:5; ntasks=2, batch_size=2)\n5-element Array{String,1}:\n \"args_tuple: (1,), element_val: 1, task: 9118321258196414413\"\n \"args_tuple: (2,), element_val: 2, task: 4904288162898683522\"\n \"args_tuple: (3,), element_val: 3, task: 9118321258196414413\"\n \"args_tuple: (4,), element_val: 4, task: 4904288162898683522\"\n \"args_tuple: (5,), element_val: 5, task: 9118321258196414413\"\n\nnote: Note\nCurrently, all tasks in Julia are executed in a single OS thread co-operatively. Consequently, ayncmap is beneficial only when the mapping function involves any I/O - disk, network, remote worker invocation, etc.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.asyncmap!",
    "page": "Tasks and Parallel Computing",
    "title": "Base.asyncmap!",
    "category": "function",
    "text": "asyncmap!(f, results, c...; ntasks=0, batch_size=nothing)\n\nLike asyncmap(), but stores output in results rather than returning a collection.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Tasks-1",
    "page": "Tasks and Parallel Computing",
    "title": "Tasks",
    "category": "section",
    "text": "Core.Task\nBase.current_task\nBase.istaskdone\nBase.istaskstarted\nBase.yield\nBase.yieldto\nBase.task_local_storage(::Any)\nBase.task_local_storage(::Any, ::Any)\nBase.task_local_storage(::Function, ::Any, ::Any)\nBase.Condition\nBase.notify\nBase.schedule\nBase.@schedule\nBase.@task\nBase.sleep\nBase.Channel\nBase.put!(::Channel, ::Any)\nBase.take!(::Channel)\nBase.isready(::Channel)\nBase.fetch(::Channel)\nBase.close(::Channel)\nBase.bind(c::Channel, task::Task)\nBase.asyncmap\nBase.asyncmap!"
},

{
    "location": "stdlib/parallel/#Base.Distributed.addprocs",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.addprocs",
    "category": "function",
    "text": "addprocs(manager::ClusterManager; kwargs...) -> List of process identifiers\n\nLaunches worker processes via the specified cluster manager.\n\nFor example, Beowulf clusters are supported via a custom cluster manager implemented in the package ClusterManagers.jl.\n\nThe number of seconds a newly launched worker waits for connection establishment from the master can be specified via variable JULIA_WORKER_TIMEOUT in the worker process\'s environment. Relevant only when using TCP/IP as transport.\n\n\n\naddprocs(machines; tunnel=false, sshflags=``, max_parallel=10, kwargs...) -> List of process identifiers\n\nAdd processes on remote machines via SSH. Requires julia to be installed in the same location on each node, or to be available via a shared file system.\n\nmachines is a vector of machine specifications. Workers are started for each specification.\n\nA machine specification is either a string machine_spec or a tuple - (machine_spec, count).\n\nmachine_spec is a string of the form [user@]host[:port] [bind_addr[:port]]. user defaults to current user, port to the standard ssh port. If [bind_addr[:port]] is specified, other workers will connect to this worker at the specified bind_addr and port.\n\ncount is the number of workers to be launched on the specified host. If specified as :auto it will launch as many workers as the number of cores on the specific host.\n\nKeyword arguments:\n\ntunnel: if true then SSH tunneling will be used to connect to the worker from the master process. Default is false.\nsshflags: specifies additional ssh options, e.g. sshflags=`-i /home/foo/bar.pem`\nmax_parallel: specifies the maximum number of workers connected to in parallel at a host. Defaults to 10.\ndir: specifies the working directory on the workers. Defaults to the host\'s current directory (as found by pwd())\nenable_threaded_blas: if true then  BLAS will run on multiple threads in added processes. Default is false.\nexename: name of the julia executable. Defaults to \"$JULIA_HOME/julia\" or \"$JULIA_HOME/julia-debug\" as the case may be.\nexeflags: additional flags passed to the worker processes.\ntopology: Specifies how the workers connect to each other. Sending a message between unconnected workers results in an error.\ntopology=:all_to_all: All processes are connected to each other. The default.\ntopology=:master_slave: Only the driver process, i.e. pid 1 connects to the workers. The workers do not connect to each other.\ntopology=:custom: The launch method of the cluster manager specifies the connection topology via fields ident and connect_idents in WorkerConfig. A worker with a cluster manager identity ident will connect to all workers specified in connect_idents.\n\nEnvironment variables :\n\nIf the master process fails to establish a connection with a newly launched worker within 60.0 seconds, the worker treats it as a fatal situation and terminates. This timeout can be controlled via environment variable JULIA_WORKER_TIMEOUT. The value of JULIA_WORKER_TIMEOUT on the master process specifies the number of seconds a newly launched worker waits for connection establishment.\n\n\n\naddprocs(; kwargs...) -> List of process identifiers\n\nEquivalent to addprocs(Sys.CPU_CORES; kwargs...)\n\nNote that workers do not run a .juliarc.jl startup script, nor do they synchronize their global state (such as global variables, new method definitions, and loaded modules) with any of the other running processes.\n\n\n\naddprocs(np::Integer; restrict=true, kwargs...) -> List of process identifiers\n\nLaunches workers using the in-built LocalManager which only launches workers on the local host. This can be used to take advantage of multiple cores. addprocs(4) will add 4 processes on the local machine. If restrict is true, binding is restricted to 127.0.0.1. Keyword args dir, exename, exeflags, topology, and enable_threaded_blas have the same effect as documented for addprocs(machines).\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.nprocs",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.nprocs",
    "category": "function",
    "text": "nprocs()\n\nGet the number of available processes.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.nworkers",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.nworkers",
    "category": "function",
    "text": "nworkers()\n\nGet the number of available worker processes. This is one less than nprocs(). Equal to nprocs() if nprocs() == 1.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.procs-Tuple{}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.procs",
    "category": "method",
    "text": "procs()\n\nReturns a list of all process identifiers.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.procs-Tuple{Integer}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.procs",
    "category": "method",
    "text": "procs(pid::Integer)\n\nReturns a list of all process identifiers on the same physical node. Specifically all workers bound to the same ip-address as pid are returned.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.workers",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.workers",
    "category": "function",
    "text": "workers()\n\nReturns a list of all worker process identifiers.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.rmprocs",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.rmprocs",
    "category": "function",
    "text": "rmprocs(pids...; waitfor=typemax(Int))\n\nRemoves the specified workers. Note that only process 1 can add or remove workers.\n\nArgument waitfor specifies how long to wait for the workers to shut down:     - If unspecified, rmprocs will wait until all requested pids are removed.     - An ErrorException is raised if all workers cannot be terminated before       the requested waitfor seconds.     - With a waitfor value of 0, the call returns immediately with the workers       scheduled for removal in a different task. The scheduled Task object is       returned. The user should call wait on the task before invoking any other       parallel calls.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.interrupt",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.interrupt",
    "category": "function",
    "text": "interrupt(pids::Integer...)\n\nInterrupt the current executing task on the specified workers. This is equivalent to pressing Ctrl-C on the local machine. If no arguments are given, all workers are interrupted.\n\n\n\ninterrupt(pids::AbstractVector=workers())\n\nInterrupt the current executing task on the specified workers. This is equivalent to pressing Ctrl-C on the local machine. If no arguments are given, all workers are interrupted.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.myid",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.myid",
    "category": "function",
    "text": "myid()\n\nGet the id of the current process.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.pmap",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.pmap",
    "category": "function",
    "text": "pmap([::AbstractWorkerPool], f, c...; distributed=true, batch_size=1, on_error=nothing, retry_delays=[]), retry_check=nothing) -> collection\n\nTransform collection c by applying f to each element using available workers and tasks.\n\nFor multiple collection arguments, apply f elementwise.\n\nNote that f must be made available to all worker processes; see Code Availability and Loading Packages for details.\n\nIf a worker pool is not specified, all available workers, i.e., the default worker pool is used.\n\nBy default, pmap distributes the computation over all specified workers. To use only the local process and distribute over tasks, specify distributed=false. This is equivalent to using asyncmap. For example, pmap(f, c; distributed=false) is equivalent to asyncmap(f,c; ntasks=()->nworkers())\n\npmap can also use a mix of processes and tasks via the batch_size argument. For batch sizes greater than 1, the collection is processed in multiple batches, each of length batch_size or less. A batch is sent as a single request to a free worker, where a local asyncmap processes elements from the batch using multiple concurrent tasks.\n\nAny error stops pmap from processing the remainder of the collection. To override this behavior you can specify an error handling function via argument on_error which takes in a single argument, i.e., the exception. The function can stop the processing by rethrowing the error, or, to continue, return any value which is then returned inline with the results to the caller.\n\nConsider the following two examples. The first one returns the exception object inline, the second a 0 in place of any exception:\n\njulia> pmap(x->iseven(x) ? error(\"foo\") : x, 1:4; on_error=identity)\n4-element Array{Any,1}:\n 1\n  ErrorException(\"foo\")\n 3\n  ErrorException(\"foo\")\n\njulia> pmap(x->iseven(x) ? error(\"foo\") : x, 1:4; on_error=ex->0)\n4-element Array{Int64,1}:\n 1\n 0\n 3\n 0\n\nErrors can also be handled by retrying failed computations. Keyword arguments retry_delays and retry_check are passed through to retry as keyword arguments delays and check respectively. If batching is specified, and an entire batch fails, all items in the batch are retried.\n\nNote that if both on_error and retry_delays are specified, the on_error hook is called before retrying. If on_error does not throw (or rethrow) an exception, the element will not be retried.\n\nExample: On errors, retry f on an element a maximum of 3 times without any delay between retries.\n\npmap(f, c; retry_delays = zeros(3))\n\nExample: Retry f only if the exception is not of type InexactError, with exponentially increasing delays up to 3 times. Return a NaN in place for all InexactError occurrences.\n\npmap(f, c; on_error = e->(isa(e, InexactError) ? NaN : rethrow(e)), retry_delays = ExponentialBackOff(n = 3))\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.RemoteException",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.RemoteException",
    "category": "type",
    "text": "RemoteException(captured)\n\nExceptions on remote computations are captured and rethrown locally.  A RemoteException wraps the pid of the worker and a captured exception. A CapturedException captures the remote exception and a serializable form of the call stack when the exception was raised.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.Future",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.Future",
    "category": "type",
    "text": "Future(pid::Integer=myid())\n\nCreate a Future on process pid. The default pid is the current process.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.RemoteChannel-Tuple{Integer}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.RemoteChannel",
    "category": "method",
    "text": "RemoteChannel(pid::Integer=myid())\n\nMake a reference to a Channel{Any}(1) on process pid. The default pid is the current process.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.RemoteChannel-Tuple{Function,Integer}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.RemoteChannel",
    "category": "method",
    "text": "RemoteChannel(f::Function, pid::Integer=myid())\n\nCreate references to remote channels of a specific size and type. f() is a function that when executed on pid must return an implementation of an AbstractChannel.\n\nFor example, RemoteChannel(()->Channel{Int}(10), pid), will return a reference to a channel of type Int and size 10 on pid.\n\nThe default pid is the current process.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.wait",
    "page": "Tasks and Parallel Computing",
    "title": "Base.wait",
    "category": "function",
    "text": "wait([x])\n\nBlock the current task until some event occurs, depending on the type of the argument:\n\nRemoteChannel : Wait for a value to become available on the specified remote channel.\nFuture : Wait for a value to become available for the specified future.\nChannel: Wait for a value to be appended to the channel.\nCondition: Wait for notify on a condition.\nProcess: Wait for a process or process chain to exit. The exitcode field of a process can be used to determine success or failure.\nTask: Wait for a Task to finish, returning its result value. If the task fails with an exception, the exception is propagated (re-thrown in the task that called wait).\nRawFD: Wait for changes on a file descriptor (see poll_fd for keyword arguments and return code)\n\nIf no argument is passed, the task blocks for an undefined period. A task can only be restarted by an explicit call to schedule or yieldto.\n\nOften wait is called within a while loop to ensure a waited-for condition is met before proceeding.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.fetch-Tuple{Any}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.fetch",
    "category": "method",
    "text": "fetch(x)\n\nWaits and fetches a value from x depending on the type of x:\n\nFuture: Wait for and get the value of a Future. The fetched value is cached locally. Further calls to fetch on the same reference return the cached value. If the remote value is an exception, throws a RemoteException which captures the remote exception and backtrace.\nRemoteChannel: Wait for and get the value of a remote reference. Exceptions raised are same as for a Future .\n\nDoes not remove the item fetched.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.remotecall-Tuple{Any,Integer,Vararg{Any,N} where N}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.remotecall",
    "category": "method",
    "text": "remotecall(f, id::Integer, args...; kwargs...) -> Future\n\nCall a function f asynchronously on the given arguments on the specified process. Returns a Future. Keyword arguments, if any, are passed through to f.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.remotecall_wait-Tuple{Any,Integer,Vararg{Any,N} where N}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.remotecall_wait",
    "category": "method",
    "text": "remotecall_wait(f, id::Integer, args...; kwargs...)\n\nPerform a faster wait(remotecall(...)) in one message on the Worker specified by worker id id. Keyword arguments, if any, are passed through to f.\n\nSee also wait and remotecall.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.remotecall_fetch-Tuple{Any,Integer,Vararg{Any,N} where N}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.remotecall_fetch",
    "category": "method",
    "text": "remotecall_fetch(f, id::Integer, args...; kwargs...)\n\nPerform fetch(remotecall(...)) in one message. Keyword arguments, if any, are passed through to f. Any remote exceptions are captured in a RemoteException and thrown.\n\nSee also fetch and remotecall.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.remote_do-Tuple{Any,Integer,Vararg{Any,N} where N}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.remote_do",
    "category": "method",
    "text": "remote_do(f, id::Integer, args...; kwargs...) -> nothing\n\nExecutes f on worker id asynchronously. Unlike remotecall, it does not store the result of computation, nor is there a way to wait for its completion.\n\nA successful invocation indicates that the request has been accepted for execution on the remote node.\n\nWhile consecutive remotecalls to the same worker are serialized in the order they are invoked, the order of executions on the remote worker is undetermined. For example, remote_do(f1, 2); remotecall(f2, 2); remote_do(f3, 2) will serialize the call to f1, followed by f2 and f3 in that order. However, it is not guaranteed that f1 is executed before f3 on worker 2.\n\nAny exceptions thrown by f are printed to STDERR on the remote worker.\n\nKeyword arguments, if any, are passed through to f.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.put!-Tuple{RemoteChannel,Vararg{Any,N} where N}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.put!",
    "category": "method",
    "text": "put!(rr::RemoteChannel, args...)\n\nStore a set of values to the RemoteChannel. If the channel is full, blocks until space is available. Returns its first argument.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.put!-Tuple{Future,Any}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.put!",
    "category": "method",
    "text": "put!(rr::Future, v)\n\nStore a value to a Future rr. Futures are write-once remote references. A put! on an already set Future throws an Exception. All asynchronous remote calls return Futures and set the value to the return value of the call upon completion.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.take!-Tuple{RemoteChannel,Vararg{Any,N} where N}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.take!",
    "category": "method",
    "text": "take!(rr::RemoteChannel, args...)\n\nFetch value(s) from a RemoteChannel rr, removing the value(s) in the processs.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.isready-Tuple{RemoteChannel,Vararg{Any,N} where N}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.isready",
    "category": "method",
    "text": "isready(rr::RemoteChannel, args...)\n\nDetermine whether a RemoteChannel has a value stored to it. Note that this function can cause race conditions, since by the time you receive its result it may no longer be true. However, it can be safely used on a Future since they are assigned only once.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.isready-Tuple{Future}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.isready",
    "category": "method",
    "text": "isready(rr::Future)\n\nDetermine whether a Future has a value stored to it.\n\nIf the argument Future is owned by a different node, this call will block to wait for the answer. It is recommended to wait for rr in a separate task instead or to use a local Channel as a proxy:\n\nc = Channel(1)\n@async put!(c, remotecall_fetch(long_computation, p))\nisready(c)  # will not block\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.WorkerPool",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.WorkerPool",
    "category": "type",
    "text": "WorkerPool(workers::Vector{Int})\n\nCreate a WorkerPool from a vector of worker ids.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.CachingPool",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.CachingPool",
    "category": "type",
    "text": "CachingPool(workers::Vector{Int})\n\nAn implementation of an AbstractWorkerPool. remote, remotecall_fetch, pmap (and other remote calls which execute functions remotely) benefit from caching the serialized/deserialized functions on the worker nodes, especially closures (which may capture large amounts of data).\n\nThe remote cache is maintained for the lifetime of the returned CachingPool object. To clear the cache earlier, use clear!(pool).\n\nFor global variables, only the bindings are captured in a closure, not the data. let blocks can be used to capture global data.\n\nFor example:\n\nconst foo=rand(10^8);\nwp=CachingPool(workers())\nlet foo=foo\n    pmap(wp, i->sum(foo)+i, 1:100);\nend\n\nThe above would transfer foo only once to each worker.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.default_worker_pool",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.default_worker_pool",
    "category": "function",
    "text": "default_worker_pool()\n\nWorkerPool containing idle workers() - used by remote(f) and pmap (by default).\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.clear!-Tuple{CachingPool}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.clear!",
    "category": "method",
    "text": "clear!(pool::CachingPool) -> pool\n\nRemoves all cached functions from all participating workers.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.remote",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.remote",
    "category": "function",
    "text": "remote([::AbstractWorkerPool], f) -> Function\n\nReturns an anonymous function that executes function f on an available worker using remotecall_fetch.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.remotecall-Tuple{Any,Base.Distributed.AbstractWorkerPool,Vararg{Any,N} where N}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.remotecall",
    "category": "method",
    "text": "remotecall(f, pool::AbstractWorkerPool, args...; kwargs...) -> Future\n\nWorkerPool variant of remotecall(f, pid, ....). Waits for and takes a free worker from pool and performs a remotecall on it.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.remotecall_wait-Tuple{Any,Base.Distributed.AbstractWorkerPool,Vararg{Any,N} where N}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.remotecall_wait",
    "category": "method",
    "text": "remotecall_wait(f, pool::AbstractWorkerPool, args...; kwargs...) -> Future\n\nWorkerPool variant of remotecall_wait(f, pid, ....). Waits for and takes a free worker from pool and performs a remotecall_wait on it.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.remotecall_fetch-Tuple{Any,Base.Distributed.AbstractWorkerPool,Vararg{Any,N} where N}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.remotecall_fetch",
    "category": "method",
    "text": "remotecall_fetch(f, pool::AbstractWorkerPool, args...; kwargs...) -> result\n\nWorkerPool variant of remotecall_fetch(f, pid, ....). Waits for and takes a free worker from pool and performs a remotecall_fetch on it.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.remote_do-Tuple{Any,Base.Distributed.AbstractWorkerPool,Vararg{Any,N} where N}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.remote_do",
    "category": "method",
    "text": "remote_do(f, pool::AbstractWorkerPool, args...; kwargs...) -> nothing\n\nWorkerPool variant of remote_do(f, pid, ....). Waits for and takes a free worker from pool and performs a remote_do on it.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.timedwait",
    "page": "Tasks and Parallel Computing",
    "title": "Base.timedwait",
    "category": "function",
    "text": "timedwait(testcb::Function, secs::Float64; pollint::Float64=0.1)\n\nWaits until testcb returns true or for secs seconds, whichever is earlier. testcb is polled every pollint seconds.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.@spawn",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.@spawn",
    "category": "macro",
    "text": "@spawn\n\nCreates a closure around an expression and runs it on an automatically-chosen process, returning a Future to the result.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.@spawnat",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.@spawnat",
    "category": "macro",
    "text": "@spawnat\n\nAccepts two arguments, p and an expression. A closure is created around the expression and run asynchronously on process p. Returns a Future to the result.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.@fetch",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.@fetch",
    "category": "macro",
    "text": "@fetch\n\nEquivalent to fetch(@spawn expr). See fetch and @spawn.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.@fetchfrom",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.@fetchfrom",
    "category": "macro",
    "text": "@fetchfrom\n\nEquivalent to fetch(@spawnat p expr). See fetch and @spawnat.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.@async",
    "page": "Tasks and Parallel Computing",
    "title": "Base.@async",
    "category": "macro",
    "text": "@async\n\nLike @schedule, @async wraps an expression in a Task and adds it to the local machine\'s scheduler queue. Additionally it adds the task to the set of items that the nearest enclosing @sync waits for.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.@sync",
    "page": "Tasks and Parallel Computing",
    "title": "Base.@sync",
    "category": "macro",
    "text": "@sync\n\nWait until all dynamically-enclosed uses of @async, @spawn, @spawnat and @parallel are complete. All exceptions thrown by enclosed async operations are collected and thrown as a CompositeException.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.@parallel",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.@parallel",
    "category": "macro",
    "text": "@parallel\n\nA parallel for loop of the form :\n\n@parallel [reducer] for var = range\n    body\nend\n\nThe specified range is partitioned and locally executed across all workers. In case an optional reducer function is specified, @parallel performs local reductions on each worker with a final reduction on the calling process.\n\nNote that without a reducer function, @parallel executes asynchronously, i.e. it spawns independent tasks on all available workers and returns immediately without waiting for completion. To wait for completion, prefix the call with @sync, like :\n\n@sync @parallel for var = range\n    body\nend\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.@everywhere",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.@everywhere",
    "category": "macro",
    "text": "@everywhere expr\n\nExecute an expression under Main everywhere. Equivalent to calling eval(Main, expr) on all processes. Errors on any of the processes are collected into a CompositeException and thrown. For example :\n\n@everywhere bar=1\n\nwill define Main.bar on all processes.\n\nUnlike @spawn and @spawnat, @everywhere does not capture any local variables. Prefixing @everywhere with @eval allows us to broadcast local variables using interpolation :\n\nfoo = 1\n@eval @everywhere bar=$foo\n\nThe expression is evaluated under Main irrespective of where @everywhere is called from. For example :\n\nmodule FooBar\n    foo() = @everywhere bar()=myid()\nend\nFooBar.foo()\n\nwill result in Main.bar being defined on all processes and not FooBar.bar.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.clear!-Tuple{Any,Any}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.clear!",
    "category": "method",
    "text": "clear!(syms, pids=workers(); mod=Main)\n\nClears global bindings in modules by initializing them to nothing. syms should be of type Symbol or a collection of Symbols . pids and mod identify the processes and the module in which global variables are to be reinitialized. Only those names found to be defined under mod are cleared.\n\nAn exception is raised if a global constant is requested to be cleared.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.remoteref_id",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.remoteref_id",
    "category": "function",
    "text": "Base.remoteref_id(r::AbstractRemoteRef) -> RRID\n\nFutures and RemoteChannels are identified by fields:\n\nwhere - refers to the node where the underlying object/storage referred to by the reference actually exists.\nwhence - refers to the node the remote reference was created from. Note that this is different from the node where the underlying object referred to actually exists. For example calling RemoteChannel(2) from the master process would result in a where value of 2 and a whence value of 1.\nid is unique across all references created from the worker specified by whence.\n\nTaken together,  whence and id uniquely identify a reference across all workers.\n\nBase.remoteref_id is a low-level API which returns a Base.RRID object that wraps whence and id values of a remote reference.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.channel_from_id",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.channel_from_id",
    "category": "function",
    "text": "Base.channel_from_id(id) -> c\n\nA low-level API which returns the backing AbstractChannel for an id returned by remoteref_id. The call is valid only on the node where the backing channel exists.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.worker_id_from_socket",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.worker_id_from_socket",
    "category": "function",
    "text": "Base.worker_id_from_socket(s) -> pid\n\nA low-level API which given a IO connection or a Worker, returns the pid of the worker it is connected to. This is useful when writing custom serialize methods for a type, which optimizes the data written out depending on the receiving process id.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.cluster_cookie-Tuple{}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.cluster_cookie",
    "category": "method",
    "text": "Base.cluster_cookie() -> cookie\n\nReturns the cluster cookie.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.cluster_cookie-Tuple{Any}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.cluster_cookie",
    "category": "method",
    "text": "Base.cluster_cookie(cookie) -> cookie\n\nSets the passed cookie as the cluster cookie, then returns it.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#General-Parallel-Computing-Support-1",
    "page": "Tasks and Parallel Computing",
    "title": "General Parallel Computing Support",
    "category": "section",
    "text": "Base.addprocs\nBase.nprocs\nBase.nworkers\nBase.procs()\nBase.procs(::Integer)\nBase.workers\nBase.rmprocs\nBase.interrupt\nBase.myid\nBase.pmap\nBase.RemoteException\nBase.Future\nBase.RemoteChannel(::Integer)\nBase.RemoteChannel(::Function, ::Integer)\nBase.wait\nBase.fetch(::Any)\nBase.remotecall(::Any, ::Integer, ::Any...)\nBase.remotecall_wait(::Any, ::Integer, ::Any...)\nBase.remotecall_fetch(::Any, ::Integer, ::Any...)\nBase.remote_do(::Any, ::Integer, ::Any...)\nBase.put!(::RemoteChannel, ::Any...)\nBase.put!(::Future, ::Any)\nBase.take!(::RemoteChannel, ::Any...)\nBase.isready(::RemoteChannel, ::Any...)\nBase.isready(::Future)\nBase.WorkerPool\nBase.CachingPool\nBase.default_worker_pool\nBase.clear!(::CachingPool)\nBase.remote\nBase.remotecall(::Any, ::Base.Distributed.AbstractWorkerPool, ::Any...)\nBase.remotecall_wait(::Any, ::Base.Distributed.AbstractWorkerPool, ::Any...)\nBase.remotecall_fetch(::Any, ::Base.Distributed.AbstractWorkerPool, ::Any...)\nBase.remote_do(::Any, ::Base.Distributed.AbstractWorkerPool, ::Any...)\nBase.timedwait\nBase.@spawn\nBase.@spawnat\nBase.@fetch\nBase.@fetchfrom\nBase.@async\nBase.@sync\nBase.@parallel\nBase.@everywhere\nBase.clear!(::Any, ::Any; ::Any)\nBase.remoteref_id\nBase.channel_from_id\nBase.worker_id_from_socket\nBase.cluster_cookie()\nBase.cluster_cookie(::Any)"
},

{
    "location": "stdlib/parallel/#Base.SharedArray",
    "page": "Tasks and Parallel Computing",
    "title": "Base.SharedArray",
    "category": "type",
    "text": "SharedArray{T}(dims::NTuple; init=false, pids=Int[])\nSharedArray{T,N}(...)\n\nConstruct a SharedArray of a bits type T and size dims across the processes specified by pids - all of which have to be on the same host.  If N is specified by calling SharedArray{T,N}(dims), then N must match the length of dims.\n\nIf pids is left unspecified, the shared array will be mapped across all processes on the current host, including the master. But, localindexes and indexpids will only refer to worker processes. This facilitates work distribution code to use workers for actual computation with the master process acting as a driver.\n\nIf an init function of the type initfn(S::SharedArray) is specified, it is called on all the participating workers.\n\nThe shared array is valid as long as a reference to the SharedArray object exists on the node which created the mapping.\n\nSharedArray{T}(filename::AbstractString, dims::NTuple, [offset=0]; mode=nothing, init=false, pids=Int[])\nSharedArray{T,N}(...)\n\nConstruct a SharedArray backed by the file filename, with element type T (must be a bits type) and size dims, across the processes specified by pids - all of which have to be on the same host. This file is mmapped into the host memory, with the following consequences:\n\nThe array data must be represented in binary format (e.g., an ASCII format like CSV cannot be supported)\nAny changes you make to the array values (e.g., A[3] = 0) will also change the values on disk\n\nIf pids is left unspecified, the shared array will be mapped across all processes on the current host, including the master. But, localindexes and indexpids will only refer to worker processes. This facilitates work distribution code to use workers for actual computation with the master process acting as a driver.\n\nmode must be one of \"r\", \"r+\", \"w+\", or \"a+\", and defaults to \"r+\" if the file specified by filename already exists, or \"w+\" if not. If an init function of the type initfn(S::SharedArray) is specified, it is called on all the participating workers. You cannot specify an init function if the file is not writable.\n\noffset allows you to skip the specified number of bytes at the beginning of the file.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.procs-Tuple{SharedArray}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.procs",
    "category": "method",
    "text": "procs(S::SharedArray)\n\nGet the vector of processes mapping the shared array.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.sdata",
    "page": "Tasks and Parallel Computing",
    "title": "Base.sdata",
    "category": "function",
    "text": "sdata(S::SharedArray)\n\nReturns the actual Array object backing S.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.indexpids",
    "page": "Tasks and Parallel Computing",
    "title": "Base.indexpids",
    "category": "function",
    "text": "indexpids(S::SharedArray)\n\nReturns the current worker\'s index in the list of workers mapping the SharedArray (i.e. in the same list returned by procs(S)), or 0 if the SharedArray is not mapped locally.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.localindexes",
    "page": "Tasks and Parallel Computing",
    "title": "Base.localindexes",
    "category": "function",
    "text": "localindexes(S::SharedArray)\n\nReturns a range describing the \"default\" indexes to be handled by the current process.  This range should be interpreted in the sense of linear indexing, i.e., as a sub-range of 1:length(S).  In multi-process contexts, returns an empty range in the parent process (or any process for which indexpids returns 0).\n\nIt\'s worth emphasizing that localindexes exists purely as a convenience, and you can partition work on the array among workers any way you wish. For a SharedArray, all indexes should be equally fast for each worker process.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Shared-Arrays-1",
    "page": "Tasks and Parallel Computing",
    "title": "Shared Arrays",
    "category": "section",
    "text": "Base.SharedArray\nBase.procs(::SharedArray)\nBase.sdata\nBase.indexpids\nBase.localindexes"
},

{
    "location": "stdlib/parallel/#Base.Threads.threadid",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Threads.threadid",
    "category": "function",
    "text": "Threads.threadid()\n\nGet the ID number of the current thread of execution. The master thread has ID 1.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Threads.nthreads",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Threads.nthreads",
    "category": "function",
    "text": "Threads.nthreads()\n\nGet the number of threads available to the Julia process. This is the inclusive upper bound on threadid().\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Threads.@threads",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Threads.@threads",
    "category": "macro",
    "text": "Threads.@threads\n\nA macro to parallelize a for-loop to run with multiple threads. This spawns nthreads() number of threads, splits the iteration space amongst them, and iterates in parallel. A barrier is placed at the end of the loop which waits for all the threads to finish execution, and the loop returns.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Threads.Atomic",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Threads.Atomic",
    "category": "type",
    "text": "Threads.Atomic{T}\n\nHolds a reference to an object of type T, ensuring that it is only accessed atomically, i.e. in a thread-safe manner.\n\nOnly certain \"simple\" types can be used atomically, namely the primitive integer and float-point types. These are Int8...Int128, UInt8...UInt128, and Float16...Float64.\n\nNew atomic objects can be created from a non-atomic values; if none is specified, the atomic object is initialized with zero.\n\nAtomic objects can be accessed using the [] notation:\n\njulia> x = Threads.Atomic{Int}(3)\nBase.Threads.Atomic{Int64}(3)\n\njulia> x[] = 1\n1\n\njulia> x[]\n1\n\nAtomic operations use an atomic_ prefix, such as atomic_add!, atomic_xchg!, etc.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Threads.atomic_cas!",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Threads.atomic_cas!",
    "category": "function",
    "text": "Threads.atomic_cas!{T}(x::Atomic{T}, cmp::T, newval::T)\n\nAtomically compare-and-set x\n\nAtomically compares the value in x with cmp. If equal, write newval to x. Otherwise, leaves x unmodified. Returns the old value in x. By comparing the returned value to cmp (via ===) one knows whether x was modified and now holds the new value newval.\n\nFor further details, see LLVM\'s cmpxchg instruction.\n\nThis function can be used to implement transactional semantics. Before the transaction, one records the value in x. After the transaction, the new value is stored only if x has not been modified in the mean time.\n\njulia> x = Threads.Atomic{Int}(3)\nBase.Threads.Atomic{Int64}(3)\n\njulia> Threads.atomic_cas!(x, 4, 2);\n\njulia> x\nBase.Threads.Atomic{Int64}(3)\n\njulia> Threads.atomic_cas!(x, 3, 2);\n\njulia> x\nBase.Threads.Atomic{Int64}(2)\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Threads.atomic_xchg!",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Threads.atomic_xchg!",
    "category": "function",
    "text": "Threads.atomic_xchg!{T}(x::Atomic{T}, newval::T)\n\nAtomically exchange the value in x\n\nAtomically exchanges the value in x with newval. Returns the old value.\n\nFor further details, see LLVM\'s atomicrmw xchg instruction.\n\njulia> x = Threads.Atomic{Int}(3)\nBase.Threads.Atomic{Int64}(3)\n\njulia> Threads.atomic_xchg!(x, 2)\n3\n\njulia> x[]\n2\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Threads.atomic_add!",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Threads.atomic_add!",
    "category": "function",
    "text": "Threads.atomic_add!{T}(x::Atomic{T}, val::T)\n\nAtomically add val to x\n\nPerforms x[] += val atomically. Returns the old value.\n\nFor further details, see LLVM\'s atomicrmw add instruction.\n\njulia> x = Threads.Atomic{Int}(3)\nBase.Threads.Atomic{Int64}(3)\n\njulia> Threads.atomic_add!(x, 2)\n3\n\njulia> x[]\n5\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Threads.atomic_sub!",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Threads.atomic_sub!",
    "category": "function",
    "text": "Threads.atomic_sub!{T}(x::Atomic{T}, val::T)\n\nAtomically subtract val from x\n\nPerforms x[] -= val atomically. Returns the old value.\n\nFor further details, see LLVM\'s atomicrmw sub instruction.\n\njulia> x = Threads.Atomic{Int}(3)\nBase.Threads.Atomic{Int64}(3)\n\njulia> Threads.atomic_sub!(x, 2)\n3\n\njulia> x[]\n1\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Threads.atomic_and!",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Threads.atomic_and!",
    "category": "function",
    "text": "Threads.atomic_and!{T}(x::Atomic{T}, val::T)\n\nAtomically bitwise-and x with val\n\nPerforms x[] &= val atomically. Returns the old value.\n\nFor further details, see LLVM\'s atomicrmw and instruction.\n\njulia> x = Threads.Atomic{Int}(3)\nBase.Threads.Atomic{Int64}(3)\n\njulia> Threads.atomic_and!(x, 2)\n3\n\njulia> x[]\n2\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Threads.atomic_nand!",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Threads.atomic_nand!",
    "category": "function",
    "text": "Threads.atomic_nand!{T}(x::Atomic{T}, val::T)\n\nAtomically bitwise-nand (not-and) x with val\n\nPerforms x[] = ~(x[] & val) atomically. Returns the old value.\n\nFor further details, see LLVM\'s atomicrmw nand instruction.\n\njulia> x = Threads.Atomic{Int}(3)\nBase.Threads.Atomic{Int64}(3)\n\njulia> Threads.atomic_nand!(x, 2)\n3\n\njulia> x[]\n-3\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Threads.atomic_or!",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Threads.atomic_or!",
    "category": "function",
    "text": "Threads.atomic_or!{T}(x::Atomic{T}, val::T)\n\nAtomically bitwise-or x with val\n\nPerforms x[] |= val atomically. Returns the old value.\n\nFor further details, see LLVM\'s atomicrmw or instruction.\n\njulia> x = Threads.Atomic{Int}(5)\nBase.Threads.Atomic{Int64}(5)\n\njulia> Threads.atomic_or!(x, 7)\n5\n\njulia> x[]\n7\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Threads.atomic_xor!",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Threads.atomic_xor!",
    "category": "function",
    "text": "Threads.atomic_xor!{T}(x::Atomic{T}, val::T)\n\nAtomically bitwise-xor (exclusive-or) x with val\n\nPerforms x[] $= val atomically. Returns the old value.\n\nFor further details, see LLVM\'s atomicrmw xor instruction.\n\njulia> x = Threads.Atomic{Int}(5)\nBase.Threads.Atomic{Int64}(5)\n\njulia> Threads.atomic_xor!(x, 7)\n5\n\njulia> x[]\n2\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Threads.atomic_max!",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Threads.atomic_max!",
    "category": "function",
    "text": "Threads.atomic_max!{T}(x::Atomic{T}, val::T)\n\nAtomically store the maximum of x and val in x\n\nPerforms x[] = max(x[], val) atomically. Returns the old value.\n\nFor further details, see LLVM\'s atomicrmw max instruction.\n\njulia> x = Threads.Atomic{Int}(5)\nBase.Threads.Atomic{Int64}(5)\n\njulia> Threads.atomic_max!(x, 7)\n5\n\njulia> x[]\n7\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Threads.atomic_min!",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Threads.atomic_min!",
    "category": "function",
    "text": "Threads.atomic_min!{T}(x::Atomic{T}, val::T)\n\nAtomically store the minimum of x and val in x\n\nPerforms x[] = min(x[], val) atomically. Returns the old value.\n\nFor further details, see LLVM\'s atomicrmw min instruction.\n\njulia> x = Threads.Atomic{Int}(7)\nBase.Threads.Atomic{Int64}(7)\n\njulia> Threads.atomic_min!(x, 5)\n7\n\njulia> x[]\n5\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Threads.atomic_fence",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Threads.atomic_fence",
    "category": "function",
    "text": "Threads.atomic_fence()\n\nInsert a sequential-consistency memory fence\n\nInserts a memory fence with sequentially-consistent ordering semantics. There are algorithms where this is needed, i.e. where an acquire/release ordering is insufficient.\n\nThis is likely a very expensive operation. Given that all other atomic operations in Julia already have acquire/release semantics, explicit fences should not be necessary in most cases.\n\nFor further details, see LLVM\'s fence instruction.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Multi-Threading-1",
    "page": "Tasks and Parallel Computing",
    "title": "Multi-Threading",
    "category": "section",
    "text": "This experimental interface supports Julia\'s multi-threading capabilities. Types and functions described here might (and likely will) change in the future.Base.Threads.threadid\nBase.Threads.nthreads\nBase.Threads.@threads\nBase.Threads.Atomic\nBase.Threads.atomic_cas!\nBase.Threads.atomic_xchg!\nBase.Threads.atomic_add!\nBase.Threads.atomic_sub!\nBase.Threads.atomic_and!\nBase.Threads.atomic_nand!\nBase.Threads.atomic_or!\nBase.Threads.atomic_xor!\nBase.Threads.atomic_max!\nBase.Threads.atomic_min!\nBase.Threads.atomic_fence"
},

{
    "location": "stdlib/parallel/#Base.@threadcall",
    "page": "Tasks and Parallel Computing",
    "title": "Base.@threadcall",
    "category": "macro",
    "text": "@threadcall((cfunc, clib), rettype, (argtypes...), argvals...)\n\nThe @threadcall macro is called in the same way as ccall but does the work in a different thread. This is useful when you want to call a blocking C function without causing the main julia thread to become blocked. Concurrency is limited by size of the libuv thread pool, which defaults to 4 threads but can be increased by setting the UV_THREADPOOL_SIZE environment variable and restarting the julia process.\n\nNote that the called function should never call back into Julia.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#ccall-using-a-threadpool-(Experimental)-1",
    "page": "Tasks and Parallel Computing",
    "title": "ccall using a threadpool (Experimental)",
    "category": "section",
    "text": "Base.@threadcall"
},

{
    "location": "stdlib/parallel/#Base.Threads.AbstractLock",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Threads.AbstractLock",
    "category": "type",
    "text": "AbstractLock\n\nAbstract supertype describing types that implement the thread-safe synchronization primitives: lock, trylock, unlock, and islocked\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.lock",
    "page": "Tasks and Parallel Computing",
    "title": "Base.lock",
    "category": "function",
    "text": "lock(the_lock)\n\nAcquires the lock when it becomes available. If the lock is already locked by a different task/thread, it waits for it to become available.\n\nEach lock must be matched by an unlock.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.unlock",
    "page": "Tasks and Parallel Computing",
    "title": "Base.unlock",
    "category": "function",
    "text": "unlock(the_lock)\n\nReleases ownership of the lock.\n\nIf this is a recursive lock which has been acquired before, it just decrements an internal counter and returns immediately.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.trylock",
    "page": "Tasks and Parallel Computing",
    "title": "Base.trylock",
    "category": "function",
    "text": "trylock(the_lock) -> Success (Boolean)\n\nAcquires the lock if it is available, returning true if successful. If the lock is already locked by a different task/thread, returns false.\n\nEach successful trylock must be matched by an unlock.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.islocked",
    "page": "Tasks and Parallel Computing",
    "title": "Base.islocked",
    "category": "function",
    "text": "islocked(the_lock) -> Status (Boolean)\n\nCheck whether the lock is held by any task/thread. This should not be used for synchronization (see instead trylock).\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.ReentrantLock",
    "page": "Tasks and Parallel Computing",
    "title": "Base.ReentrantLock",
    "category": "type",
    "text": "ReentrantLock()\n\nCreates a reentrant lock for synchronizing Tasks. The same task can acquire the lock as many times as required. Each lock must be matched with an unlock.\n\nThis lock is NOT threadsafe. See Threads.Mutex for a threadsafe lock.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Threads.Mutex",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Threads.Mutex",
    "category": "type",
    "text": "Mutex()\n\nThese are standard system mutexes for locking critical sections of logic.\n\nOn Windows, this is a critical section object, on pthreads, this is a pthread_mutex_t.\n\nSee also SpinLock for a lighter-weight lock.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Threads.SpinLock",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Threads.SpinLock",
    "category": "type",
    "text": "SpinLock()\n\nCreates a non-reentrant lock. Recursive use will result in a deadlock. Each lock must be matched with an unlock.\n\nTest-and-test-and-set spin locks are quickest up to about 30ish contending threads. If you have more contention than that, perhaps a lock is the wrong way to synchronize.\n\nSee also RecursiveSpinLock for a version that permits recursion.\n\nSee also Mutex for a more efficient version on one core or if the lock may be held for a considerable length of time.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Threads.RecursiveSpinLock",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Threads.RecursiveSpinLock",
    "category": "type",
    "text": "RecursiveSpinLock()\n\nCreates a reentrant lock. The same thread can acquire the lock as many times as required. Each lock must be matched with an unlock.\n\nSee also SpinLock for a slightly faster version.\n\nSee also Mutex for a more efficient version on one core or if the lock may be held for a considerable length of time.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Semaphore",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Semaphore",
    "category": "type",
    "text": "Semaphore(sem_size)\n\nCreates a counting semaphore that allows at most sem_size acquires to be in use at any time. Each acquire must be mached with a release.\n\nThis construct is NOT threadsafe.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.acquire",
    "page": "Tasks and Parallel Computing",
    "title": "Base.acquire",
    "category": "function",
    "text": "acquire(s::Semaphore)\n\nWait for one of the sem_size permits to be available, blocking until one can be acquired.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.release",
    "page": "Tasks and Parallel Computing",
    "title": "Base.release",
    "category": "function",
    "text": "release(s::Semaphore)\n\nReturn one permit to the pool, possibly allowing another task to acquire it and resume execution.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Synchronization-Primitives-1",
    "page": "Tasks and Parallel Computing",
    "title": "Synchronization Primitives",
    "category": "section",
    "text": "Base.Threads.AbstractLock\nBase.lock\nBase.unlock\nBase.trylock\nBase.islocked\nBase.ReentrantLock\nBase.Threads.Mutex\nBase.Threads.SpinLock\nBase.Threads.RecursiveSpinLock\nBase.Semaphore\nBase.acquire\nBase.release"
},

{
    "location": "stdlib/parallel/#Base.Distributed.launch",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.launch",
    "category": "function",
    "text": "launch(manager::ClusterManager, params::Dict, launched::Array, launch_ntfy::Condition)\n\nImplemented by cluster managers. For every Julia worker launched by this function, it should append a WorkerConfig entry to launched and notify launch_ntfy. The function MUST exit once all workers, requested by manager have been launched. params is a dictionary of all keyword arguments addprocs was called with.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.manage",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.manage",
    "category": "function",
    "text": "manage(manager::ClusterManager, id::Integer, config::WorkerConfig. op::Symbol)\n\nImplemented by cluster managers. It is called on the master process, during a worker\'s lifetime, with appropriate op values:\n\nwith :register/:deregister when a worker is added / removed from the Julia worker pool.\nwith :interrupt when interrupt(workers) is called. The ClusterManager should signal the appropriate worker with an interrupt signal.\nwith :finalize for cleanup purposes.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.kill-Tuple{ClusterManager,Int64,WorkerConfig}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.kill",
    "category": "method",
    "text": "kill(manager::ClusterManager, pid::Int, config::WorkerConfig)\n\nImplemented by cluster managers. It is called on the master process, by rmprocs. It should cause the remote worker specified by pid to exit. kill(manager::ClusterManager.....) executes a remote exit() on pid.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.init_worker",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.init_worker",
    "category": "function",
    "text": "init_worker(cookie::AbstractString, manager::ClusterManager=DefaultClusterManager())\n\nCalled by cluster managers implementing custom transports. It initializes a newly launched process as a worker. Command line argument --worker has the effect of initializing a process as a worker using TCP/IP sockets for transport. cookie is a cluster_cookie.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.connect-Tuple{ClusterManager,Int64,WorkerConfig}",
    "page": "Tasks and Parallel Computing",
    "title": "Base.connect",
    "category": "method",
    "text": "connect(manager::ClusterManager, pid::Int, config::WorkerConfig) -> (instrm::IO, outstrm::IO)\n\nImplemented by cluster managers using custom transports. It should establish a logical connection to worker with id pid, specified by config and return a pair of IO objects. Messages from pid to current process will be read off instrm, while messages to be sent to pid will be written to outstrm. The custom transport implementation must ensure that messages are delivered and received completely and in order. connect(manager::ClusterManager.....) sets up TCP/IP socket connections in-between workers.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Base.Distributed.process_messages",
    "page": "Tasks and Parallel Computing",
    "title": "Base.Distributed.process_messages",
    "category": "function",
    "text": "Base.process_messages(r_stream::IO, w_stream::IO, incoming::Bool=true)\n\nCalled by cluster managers using custom transports. It should be called when the custom transport implementation receives the first message from a remote worker. The custom transport must manage a logical connection to the remote worker and provide two IO objects, one for incoming messages and the other for messages addressed to the remote worker. If incoming is true, the remote peer initiated the connection. Whichever of the pair initiates the connection sends the cluster cookie and its Julia version number to perform the authentication handshake.\n\nSee also cluster_cookie.\n\n\n\n"
},

{
    "location": "stdlib/parallel/#Cluster-Manager-Interface-1",
    "page": "Tasks and Parallel Computing",
    "title": "Cluster Manager Interface",
    "category": "section",
    "text": "This interface provides a mechanism to launch and manage Julia workers on different cluster environments. There are two types of managers present in Base: LocalManager, for launching additional workers on the same host, and SSHManager, for launching on remote hosts via ssh. TCP/IP sockets are used to connect and transport messages between processes. It is possible for Cluster Managers to provide a different transport.Base.launch\nBase.manage\nBase.kill(::ClusterManager, ::Int, ::WorkerConfig)\nBase.init_worker\nBase.connect(::ClusterManager, ::Int, ::WorkerConfig)\nBase.process_messages"
},

{
    "location": "stdlib/linalg/#",
    "page": "Linear Algebra",
    "title": "Linear Algebra",
    "category": "page",
    "text": ""
},

{
    "location": "stdlib/linalg/#Linear-Algebra-1",
    "page": "Linear Algebra",
    "title": "Linear Algebra",
    "category": "section",
    "text": ""
},

{
    "location": "stdlib/linalg/#Base.:*-Tuple{AbstractArray,AbstractArray}",
    "page": "Linear Algebra",
    "title": "Base.:*",
    "category": "method",
    "text": "*(x, y...)\n\nMultiplication operator. x*y*z*... calls this function with all arguments, i.e. *(x, y, z, ...).\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.:\\-Tuple{AbstractArray,Any}",
    "page": "Linear Algebra",
    "title": "Base.:\\",
    "category": "method",
    "text": "\\(x, y)\n\nLeft division operator: multiplication of y by the inverse of x on the left. Gives floating-point results for integer arguments.\n\njulia> 3 \\ 6\n2.0\n\njulia> inv(3) * 6\n2.0\n\njulia> A = [1 2; 3 4]; x = [5, 6];\n\njulia> A \\ x\n2-element Array{Float64,1}:\n -4.0\n  4.5\n\njulia> inv(A) * x\n2-element Array{Float64,1}:\n -4.0\n  4.5\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.dot",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.dot",
    "category": "function",
    "text": "dot(n, X, incx, Y, incy)\n\nDot product of two vectors consisting of n elements of array X with stride incx and n elements of array Y with stride incy.\n\nExample:\n\njulia> dot(10, ones(10), 1, ones(20), 2)\n10.0\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.vecdot",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.vecdot",
    "category": "function",
    "text": "vecdot(x, y)\n\nFor any iterable containers x and y (including arrays of any dimension) of numbers (or any element type for which dot is defined), compute the Euclidean dot product (the sum of dot(x[i],y[i])) as if they were vectors.\n\nExamples\n\njulia> vecdot(1:5, 2:6)\n70\n\njulia> x = fill(2., (5,5));\n\njulia> y = fill(3., (5,5));\n\njulia> vecdot(x, y)\n150.0\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.cross",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.cross",
    "category": "function",
    "text": "cross(x, y)\n×(x,y)\n\nCompute the cross product of two 3-vectors.\n\nExample\n\njulia> a = [0;1;0]\n3-element Array{Int64,1}:\n 0\n 1\n 0\n\njulia> b = [0;0;1]\n3-element Array{Int64,1}:\n 0\n 0\n 1\n\njulia> cross(a,b)\n3-element Array{Int64,1}:\n 1\n 0\n 0\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.factorize",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.factorize",
    "category": "function",
    "text": "factorize(A)\n\nCompute a convenient factorization of A, based upon the type of the input matrix. factorize checks A to see if it is symmetric/triangular/etc. if A is passed as a generic matrix. factorize checks every element of A to verify/rule out each property. It will short-circuit as soon as it can rule out symmetry/triangular structure. The return value can be reused for efficient solving of multiple systems. For example: A=factorize(A); x=A\\b; y=A\\C.\n\nProperties of A type of factorization\nPositive-definite Cholesky (see cholfact)\nDense Symmetric/Hermitian Bunch-Kaufman (see bkfact)\nSparse Symmetric/Hermitian LDLt (see ldltfact)\nTriangular Triangular\nDiagonal Diagonal\nBidiagonal Bidiagonal\nTridiagonal LU (see lufact)\nSymmetric real tridiagonal LDLt (see ldltfact)\nGeneral square LU (see lufact)\nGeneral non-square QR (see qrfact)\n\nIf factorize is called on a Hermitian positive-definite matrix, for instance, then factorize will return a Cholesky factorization.\n\nExample\n\njulia> A = Array(Bidiagonal(ones(5, 5), true))\n5×5 Array{Float64,2}:\n 1.0  1.0  0.0  0.0  0.0\n 0.0  1.0  1.0  0.0  0.0\n 0.0  0.0  1.0  1.0  0.0\n 0.0  0.0  0.0  1.0  1.0\n 0.0  0.0  0.0  0.0  1.0\n\njulia> factorize(A) # factorize will check to see that A is already factorized\n5×5 Bidiagonal{Float64}:\n 1.0  1.0   ⋅    ⋅    ⋅\n  ⋅   1.0  1.0   ⋅    ⋅\n  ⋅    ⋅   1.0  1.0   ⋅\n  ⋅    ⋅    ⋅   1.0  1.0\n  ⋅    ⋅    ⋅    ⋅   1.0\n\nThis returns a 5×5 Bidiagonal{Float64}, which can now be passed to other linear algebra functions (e.g. eigensolvers) which will use specialized methods for Bidiagonal types.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.Diagonal",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.Diagonal",
    "category": "type",
    "text": "Diagonal(A::AbstractMatrix)\n\nConstructs a matrix from the diagonal of A.\n\nExample\n\njulia> A = [1 2 3; 4 5 6; 7 8 9]\n3×3 Array{Int64,2}:\n 1  2  3\n 4  5  6\n 7  8  9\n\njulia> Diagonal(A)\n3×3 Diagonal{Int64}:\n 1  ⋅  ⋅\n ⋅  5  ⋅\n ⋅  ⋅  9\n\n\n\nDiagonal(V::AbstractVector)\n\nConstructs a matrix with V as its diagonal.\n\nExample\n\njulia> V = [1; 2]\n2-element Array{Int64,1}:\n 1\n 2\n\njulia> Diagonal(V)\n2×2 Diagonal{Int64}:\n 1  ⋅\n ⋅  2\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.Bidiagonal",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.Bidiagonal",
    "category": "type",
    "text": "Bidiagonal(dv, ev, isupper::Bool)\n\nConstructs an upper (isupper=true) or lower (isupper=false) bidiagonal matrix using the given diagonal (dv) and off-diagonal (ev) vectors.  The result is of type Bidiagonal and provides efficient specialized linear solvers, but may be converted into a regular matrix with convert(Array, _) (or Array(_) for short). ev\'s length must be one less than the length of dv.\n\nExample\n\njulia> dv = [1; 2; 3; 4]\n4-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n\njulia> ev = [7; 8; 9]\n3-element Array{Int64,1}:\n 7\n 8\n 9\n\njulia> Bu = Bidiagonal(dv, ev, true) # ev is on the first superdiagonal\n4×4 Bidiagonal{Int64}:\n 1  7  ⋅  ⋅\n ⋅  2  8  ⋅\n ⋅  ⋅  3  9\n ⋅  ⋅  ⋅  4\n\njulia> Bl = Bidiagonal(dv, ev, false) # ev is on the first subdiagonal\n4×4 Bidiagonal{Int64}:\n 1  ⋅  ⋅  ⋅\n 7  2  ⋅  ⋅\n ⋅  8  3  ⋅\n ⋅  ⋅  9  4\n\n\n\nBidiagonal(dv, ev, uplo::Char)\n\nConstructs an upper (uplo=\'U\') or lower (uplo=\'L\') bidiagonal matrix using the given diagonal (dv) and off-diagonal (ev) vectors.  The result is of type Bidiagonal and provides efficient specialized linear solvers, but may be converted into a regular matrix with convert(Array, _) (or Array(_) for short). ev\'s length must be one less than the length of dv.\n\nExample\n\njulia> dv = [1; 2; 3; 4]\n4-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n\njulia> ev = [7; 8; 9]\n3-element Array{Int64,1}:\n 7\n 8\n 9\n\njulia> Bu = Bidiagonal(dv, ev, \'U\') #e is on the first superdiagonal\n4×4 Bidiagonal{Int64}:\n 1  7  ⋅  ⋅\n ⋅  2  8  ⋅\n ⋅  ⋅  3  9\n ⋅  ⋅  ⋅  4\n\njulia> Bl = Bidiagonal(dv, ev, \'L\') #e is on the first subdiagonal\n4×4 Bidiagonal{Int64}:\n 1  ⋅  ⋅  ⋅\n 7  2  ⋅  ⋅\n ⋅  8  3  ⋅\n ⋅  ⋅  9  4\n\n\n\nBidiagonal(A, isupper::Bool)\n\nConstruct a Bidiagonal matrix from the main diagonal of A and its first super- (if isupper=true) or sub-diagonal (if isupper=false).\n\nExample\n\njulia> A = [1 1 1 1; 2 2 2 2; 3 3 3 3; 4 4 4 4]\n4×4 Array{Int64,2}:\n 1  1  1  1\n 2  2  2  2\n 3  3  3  3\n 4  4  4  4\n\njulia> Bidiagonal(A, true) #contains the main diagonal and first superdiagonal of A\n4×4 Bidiagonal{Int64}:\n 1  1  ⋅  ⋅\n ⋅  2  2  ⋅\n ⋅  ⋅  3  3\n ⋅  ⋅  ⋅  4\n\njulia> Bidiagonal(A, false) #contains the main diagonal and first subdiagonal of A\n4×4 Bidiagonal{Int64}:\n 1  ⋅  ⋅  ⋅\n 2  2  ⋅  ⋅\n ⋅  3  3  ⋅\n ⋅  ⋅  4  4\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.SymTridiagonal",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.SymTridiagonal",
    "category": "type",
    "text": "SymTridiagonal(dv, ev)\n\nConstruct a symmetric tridiagonal matrix from the diagonal and first sub/super-diagonal, respectively. The result is of type SymTridiagonal and provides efficient specialized eigensolvers, but may be converted into a regular matrix with convert(Array, _) (or Array(_) for short).\n\nExample\n\njulia> dv = [1; 2; 3; 4]\n4-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n\njulia> ev = [7; 8; 9]\n3-element Array{Int64,1}:\n 7\n 8\n 9\n\njulia> SymTridiagonal(dv, ev)\n4×4 SymTridiagonal{Int64}:\n 1  7  ⋅  ⋅\n 7  2  8  ⋅\n ⋅  8  3  9\n ⋅  ⋅  9  4\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.Tridiagonal",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.Tridiagonal",
    "category": "type",
    "text": "Tridiagonal(dl, d, du)\n\nConstruct a tridiagonal matrix from the first subdiagonal, diagonal, and first superdiagonal, respectively.  The result is of type Tridiagonal and provides efficient specialized linear solvers, but may be converted into a regular matrix with convert(Array, _) (or Array(_) for short). The lengths of dl and du must be one less than the length of d.\n\nExample\n\njulia> dl = [1; 2; 3]\n3-element Array{Int64,1}:\n 1\n 2\n 3\n\njulia> du = [4; 5; 6]\n3-element Array{Int64,1}:\n 4\n 5\n 6\n\njulia> d = [7; 8; 9; 0]\n4-element Array{Int64,1}:\n 7\n 8\n 9\n 0\n\njulia> Tridiagonal(dl, d, du)\n4×4 Tridiagonal{Int64}:\n 7  4  ⋅  ⋅\n 1  8  5  ⋅\n ⋅  2  9  6\n ⋅  ⋅  3  0\n\n\n\nTridiagonal(A)\n\nreturns a Tridiagonal array based on (abstract) matrix A, using its first lower diagonal, main diagonal, and first upper diagonal.\n\nExample\n\njulia> A = [1 2 3 4; 1 2 3 4; 1 2 3 4; 1 2 3 4]\n4×4 Array{Int64,2}:\n 1  2  3  4\n 1  2  3  4\n 1  2  3  4\n 1  2  3  4\n\njulia> Tridiagonal(A)\n4×4 Tridiagonal{Int64}:\n 1  2  ⋅  ⋅\n 1  2  3  ⋅\n ⋅  2  3  4\n ⋅  ⋅  3  4\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.Symmetric",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.Symmetric",
    "category": "type",
    "text": "Symmetric(A, uplo=:U)\n\nConstruct a Symmetric view of the upper (if uplo = :U) or lower (if uplo = :L) triangle of the matrix A.\n\nExample\n\njulia> A = [1 0 2 0 3; 0 4 0 5 0; 6 0 7 0 8; 0 9 0 1 0; 2 0 3 0 4]\n5×5 Array{Int64,2}:\n 1  0  2  0  3\n 0  4  0  5  0\n 6  0  7  0  8\n 0  9  0  1  0\n 2  0  3  0  4\n\njulia> Supper = Symmetric(A)\n5×5 Symmetric{Int64,Array{Int64,2}}:\n 1  0  2  0  3\n 0  4  0  5  0\n 2  0  7  0  8\n 0  5  0  1  0\n 3  0  8  0  4\n\njulia> Slower = Symmetric(A, :L)\n5×5 Symmetric{Int64,Array{Int64,2}}:\n 1  0  6  0  2\n 0  4  0  9  0\n 6  0  7  0  3\n 0  9  0  1  0\n 2  0  3  0  4\n\nNote that Supper will not be equal to Slower unless A is itself symmetric (e.g. if A == A.\').\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.Hermitian",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.Hermitian",
    "category": "type",
    "text": "Hermitian(A, uplo=:U)\n\nConstruct a Hermitian view of the upper (if uplo = :U) or lower (if uplo = :L) triangle of the matrix A.\n\nExample\n\njulia> A = [1 0 2+2im 0 3-3im; 0 4 0 5 0; 6-6im 0 7 0 8+8im; 0 9 0 1 0; 2+2im 0 3-3im 0 4];\n\njulia> Hupper = Hermitian(A)\n5×5 Hermitian{Complex{Int64},Array{Complex{Int64},2}}:\n 1+0im  0+0im  2+2im  0+0im  3-3im\n 0+0im  4+0im  0+0im  5+0im  0+0im\n 2-2im  0+0im  7+0im  0+0im  8+8im\n 0+0im  5+0im  0+0im  1+0im  0+0im\n 3+3im  0+0im  8-8im  0+0im  4+0im\n\njulia> Hlower = Hermitian(A, :L)\n5×5 Hermitian{Complex{Int64},Array{Complex{Int64},2}}:\n 1+0im  0+0im  6+6im  0+0im  2-2im\n 0+0im  4+0im  0+0im  9+0im  0+0im\n 6-6im  0+0im  7+0im  0+0im  3+3im\n 0+0im  9+0im  0+0im  1+0im  0+0im\n 2+2im  0+0im  3-3im  0+0im  4+0im\n\nNote that Hupper will not be equal to Hlower unless A is itself Hermitian (e.g. if A == A\').\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LowerTriangular",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LowerTriangular",
    "category": "type",
    "text": "LowerTriangular(A::AbstractMatrix)\n\nConstruct a LowerTriangular view of the the matrix A.\n\nExample\n\njulia> A = [1.0 2.0 3.0; 4.0 5.0 6.0; 7.0 8.0 9.0]\n3×3 Array{Float64,2}:\n 1.0  2.0  3.0\n 4.0  5.0  6.0\n 7.0  8.0  9.0\n\njulia> LowerTriangular(A)\n3×3 LowerTriangular{Float64,Array{Float64,2}}:\n 1.0   ⋅    ⋅\n 4.0  5.0   ⋅\n 7.0  8.0  9.0\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.UpperTriangular",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.UpperTriangular",
    "category": "type",
    "text": "UpperTriangular(A::AbstractMatrix)\n\nConstruct an UpperTriangular view of the the matrix A.\n\nExample\n\njulia> A = [1.0 2.0 3.0; 4.0 5.0 6.0; 7.0 8.0 9.0]\n3×3 Array{Float64,2}:\n 1.0  2.0  3.0\n 4.0  5.0  6.0\n 7.0  8.0  9.0\n\njulia> UpperTriangular(A)\n3×3 UpperTriangular{Float64,Array{Float64,2}}:\n 1.0  2.0  3.0\n  ⋅   5.0  6.0\n  ⋅    ⋅   9.0\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.lu",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.lu",
    "category": "function",
    "text": "lu(A, pivot=Val{true}) -> L, U, p\n\nCompute the LU factorization of A, such that A[p,:] = L*U. By default, pivoting is used. This can be overridden by passing Val{false} for the second argument.\n\nSee also lufact.\n\nExample\n\njulia> A = [4. 3.; 6. 3.]\n2×2 Array{Float64,2}:\n 4.0  3.0\n 6.0  3.0\n\njulia> L, U, p = lu(A)\n([1.0 0.0; 0.666667 1.0], [6.0 3.0; 0.0 1.0], [2, 1])\n\njulia> A[p, :] == L * U\ntrue\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.lufact",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.lufact",
    "category": "function",
    "text": "lufact(A::SparseMatrixCSC) -> F::UmfpackLU\n\nCompute the LU factorization of a sparse matrix A.\n\nFor sparse A with real or complex element type, the return type of F is UmfpackLU{Tv, Ti}, with Tv = Float64 or Complex128 respectively and Ti is an integer type (Int32 or Int64).\n\nThe individual components of the factorization F can be accessed by indexing:\n\nComponent Description\nF[:L] L (lower triangular) part of LU\nF[:U] U (upper triangular) part of LU\nF[:p] right permutation Vector\nF[:q] left permutation Vector\nF[:Rs] Vector of scaling factors\nF[:(:)] (L,U,p,q,Rs) components\n\nThe relation between F and A is\n\nF[:L]*F[:U] == (F[:Rs] .* A)[F[:p], F[:q]]\n\nF further supports the following functions:\n\n\\\ncond\ndet\n\nnote: Note\nlufact(A::SparseMatrixCSC) uses the UMFPACK library that is part of SuiteSparse. As this library only supports sparse matrices with Float64 or Complex128 elements, lufact converts A into a copy that is of type SparseMatrixCSC{Float64} or SparseMatrixCSC{Complex128} as appropriate.\n\n\n\nlufact(A [,pivot=Val{true}]) -> F::LU\n\nCompute the LU factorization of A.\n\nIn most cases, if A is a subtype S of AbstractMatrix{T} with an element type T supporting +, -, * and /, the return type is LU{T,S{T}}. If pivoting is chosen (default) the element type should also support abs and <.\n\nThe individual components of the factorization F can be accessed by indexing:\n\nComponent Description\nF[:L] L (lower triangular) part of LU\nF[:U] U (upper triangular) part of LU\nF[:p] (right) permutation Vector\nF[:P] (right) permutation Matrix\n\nThe relationship between F and A is\n\nF[:L]*F[:U] == A[F[:p], :]\n\nF further supports the following functions:\n\nSupported function LU LU{T,Tridiagonal{T}}\n/ ✓ \n\\ ✓ ✓\ncond ✓ \ninv ✓ ✓\ndet ✓ ✓\nlogdet ✓ ✓\nlogabsdet ✓ ✓\nsize ✓ ✓\n\nExample\n\njulia> A = [4 3; 6 3]\n2×2 Array{Int64,2}:\n 4  3\n 6  3\n\njulia> F = lufact(A)\nBase.LinAlg.LU{Float64,Array{Float64,2}} with factors L and U:\n[1.0 0.0; 1.5 1.0]\n[4.0 3.0; 0.0 -1.5]\n\njulia> F[:L] * F[:U] == A[F[:p], :]\ntrue\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.lufact!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.lufact!",
    "category": "function",
    "text": "lufact!(A, pivot=Val{true}) -> LU\n\nlufact! is the same as lufact, but saves space by overwriting the input A, instead of creating a copy. An InexactError exception is thrown if the factorization produces a number not representable by the element type of A, e.g. for integer types.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.chol",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.chol",
    "category": "function",
    "text": "chol(A) -> U\n\nCompute the Cholesky factorization of a positive definite matrix A and return the UpperTriangular matrix U such that A = U\'U.\n\nExample\n\njulia> A = [1. 2.; 2. 50.]\n2×2 Array{Float64,2}:\n 1.0   2.0\n 2.0  50.0\n\njulia> U = chol(A)\n2×2 UpperTriangular{Float64,Array{Float64,2}}:\n 1.0  2.0\n  ⋅   6.78233\n\njulia> U\'U\n2×2 Array{Float64,2}:\n 1.0   2.0\n 2.0  50.0\n\n\n\nchol(x::Number) -> y\n\nCompute the square root of a non-negative number x.\n\nExample\n\njulia> chol(16)\n4.0\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.cholfact",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.cholfact",
    "category": "function",
    "text": "cholfact(A; shift = 0.0, perm = Int[]) -> CHOLMOD.Factor\n\nCompute the Cholesky factorization of a sparse positive definite matrix A. A must be a SparseMatrixCSC or a Symmetric/Hermitian view of a SparseMatrixCSC. Note that even if A doesn\'t have the type tag, it must still be symmetric or Hermitian. A fill-reducing permutation is used. F = cholfact(A) is most frequently used to solve systems of equations with F\\b, but also the methods diag, det, and logdet are defined for F. You can also extract individual factors from F, using F[:L]. However, since pivoting is on by default, the factorization is internally represented as A == P\'*L*L\'*P with a permutation matrix P; using just L without accounting for P will give incorrect answers. To include the effects of permutation, it\'s typically preferable to extract \"combined\" factors like PtL = F[:PtL] (the equivalent of P\'*L) and LtP = F[:UP] (the equivalent of L\'*P).\n\nSetting the optional shift keyword argument computes the factorization of A+shift*I instead of A. If the perm argument is nonempty, it should be a permutation of 1:size(A,1) giving the ordering to use (instead of CHOLMOD\'s default AMD ordering).\n\nnote: Note\nThis method uses the CHOLMOD library from SuiteSparse, which only supports doubles or complex doubles. Input matrices not of those element types will be converted to SparseMatrixCSC{Float64} or SparseMatrixCSC{Complex128} as appropriate.Many other functions from CHOLMOD are wrapped but not exported from the Base.SparseArrays.CHOLMOD module.\n\n\n\ncholfact(A, [uplo::Symbol,] Val{false}) -> Cholesky\n\nCompute the Cholesky factorization of a dense symmetric positive definite matrix A and return a Cholesky factorization. The matrix A can either be a Symmetric or Hermitian StridedMatrix or a perfectly symmetric or Hermitian StridedMatrix. In the latter case, the optional argument uplo may be :L for using the lower part or :U for the upper part of A. The default is to use :U. The triangular Cholesky factor can be obtained from the factorization F with: F[:L] and F[:U]. The following functions are available for Cholesky objects: size, \\, inv, and det. A PosDefException exception is thrown in case the matrix is not positive definite.\n\nExample\n\njulia> A = [4. 12. -16.; 12. 37. -43.; -16. -43. 98.]\n3×3 Array{Float64,2}:\n   4.0   12.0  -16.0\n  12.0   37.0  -43.0\n -16.0  -43.0   98.0\n\njulia> C = cholfact(A)\nBase.LinAlg.Cholesky{Float64,Array{Float64,2}} with factor:\n[2.0 6.0 -8.0; 0.0 1.0 5.0; 0.0 0.0 3.0]\n\njulia> C[:U]\n3×3 UpperTriangular{Float64,Array{Float64,2}}:\n 2.0  6.0  -8.0\n  ⋅   1.0   5.0\n  ⋅    ⋅    3.0\n\njulia> C[:L]\n3×3 LowerTriangular{Float64,Array{Float64,2}}:\n  2.0   ⋅    ⋅\n  6.0  1.0   ⋅\n -8.0  5.0  3.0\n\njulia> C[:L] * C[:U] == A\ntrue\n\n\n\ncholfact(A, [uplo::Symbol,] Val{true}; tol = 0.0) -> CholeskyPivoted\n\nCompute the pivoted Cholesky factorization of a dense symmetric positive semi-definite matrix A and return a CholeskyPivoted factorization. The matrix A can either be a Symmetric or Hermitian StridedMatrix or a perfectly symmetric or Hermitian StridedMatrix. In the latter case, the optional argument uplo may be :L for using the lower part or :U for the upper part of A. The default is to use :U. The triangular Cholesky factor can be obtained from the factorization F with: F[:L] and F[:U]. The following functions are available for PivotedCholesky objects: size, \\, inv, det, and rank. The argument tol determines the tolerance for determining the rank. For negative values, the tolerance is the machine precision.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.cholfact!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.cholfact!",
    "category": "function",
    "text": "cholfact!(F::Factor, A; shift = 0.0) -> CHOLMOD.Factor\n\nCompute the Cholesky (LL) factorization of A, reusing the symbolic factorization F. A must be a SparseMatrixCSC or a Symmetric/ Hermitian view of a SparseMatrixCSC. Note that even if A doesn\'t have the type tag, it must still be symmetric or Hermitian.\n\nSee also cholfact.\n\nnote: Note\nThis method uses the CHOLMOD library from SuiteSparse, which only supports doubles or complex doubles. Input matrices not of those element types will be converted to SparseMatrixCSC{Float64} or SparseMatrixCSC{Complex128} as appropriate.\n\n\n\ncholfact!(A, [uplo::Symbol,] Val{false}) -> Cholesky\n\nThe same as cholfact, but saves space by overwriting the input A, instead of creating a copy. An InexactError exception is thrown if the factorization produces a number not representable by the element type of A, e.g. for integer types.\n\nExample\n\njulia> A = [1 2; 2 50]\n2×2 Array{Int64,2}:\n 1   2\n 2  50\n\njulia> cholfact!(A)\nERROR: InexactError()\n\n\n\ncholfact!(A, [uplo::Symbol,] Val{true}; tol = 0.0) -> CholeskyPivoted\n\nThe same as cholfact, but saves space by overwriting the input A, instead of creating a copy. An InexactError exception is thrown if the factorization produces a number not representable by the element type of A, e.g. for integer types.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.lowrankupdate",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.lowrankupdate",
    "category": "function",
    "text": "lowrankupdate(C::Cholesky, v::StridedVector) -> CC::Cholesky\n\nUpdate a Cholesky factorization C with the vector v. If A = C[:U]\'C[:U] then CC = cholfact(C[:U]\'C[:U] + v*v\') but the computation of CC only uses O(n^2) operations.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.lowrankdowndate",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.lowrankdowndate",
    "category": "function",
    "text": "lowrankdowndate(C::Cholesky, v::StridedVector) -> CC::Cholesky\n\nDowndate a Cholesky factorization C with the vector v. If A = C[:U]\'C[:U] then CC = cholfact(C[:U]\'C[:U] - v*v\') but the computation of CC only uses O(n^2) operations.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.lowrankupdate!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.lowrankupdate!",
    "category": "function",
    "text": "lowrankupdate!(C::Cholesky, v::StridedVector) -> CC::Cholesky\n\nUpdate a Cholesky factorization C with the vector v. If A = C[:U]\'C[:U] then CC = cholfact(C[:U]\'C[:U] + v*v\') but the computation of CC only uses O(n^2) operations. The input factorization C is updated in place such that on exit C == CC. The vector v is destroyed during the computation.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.lowrankdowndate!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.lowrankdowndate!",
    "category": "function",
    "text": "lowrankdowndate!(C::Cholesky, v::StridedVector) -> CC::Cholesky\n\nDowndate a Cholesky factorization C with the vector v. If A = C[:U]\'C[:U] then CC = cholfact(C[:U]\'C[:U] - v*v\') but the computation of CC only uses O(n^2) operations. The input factorization C is updated in place such that on exit C == CC. The vector v is destroyed during the computation.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.ldltfact",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.ldltfact",
    "category": "function",
    "text": "ldltfact(A; shift = 0.0, perm=Int[]) -> CHOLMOD.Factor\n\nCompute the LDL factorization of a sparse matrix A. A must be a SparseMatrixCSC or a Symmetric/Hermitian view of a SparseMatrixCSC. Note that even if A doesn\'t have the type tag, it must still be symmetric or Hermitian. A fill-reducing permutation is used. F = ldltfact(A) is most frequently used to solve systems of equations A*x = b with F\\b. The returned factorization object F also supports the methods diag, det, logdet, and inv. You can extract individual factors from F using F[:L]. However, since pivoting is on by default, the factorization is internally represented as A == P\'*L*D*L\'*P with a permutation matrix P; using just L without accounting for P will give incorrect answers. To include the effects of permutation, it is typically preferable to extract \"combined\" factors like PtL = F[:PtL] (the equivalent of P\'*L) and LtP = F[:UP] (the equivalent of L\'*P). The complete list of supported factors is :L, :PtL, :D, :UP, :U, :LD, :DU, :PtLD, :DUP.\n\nSetting the optional shift keyword argument computes the factorization of A+shift*I instead of A. If the perm argument is nonempty, it should be a permutation of 1:size(A,1) giving the ordering to use (instead of CHOLMOD\'s default AMD ordering).\n\nnote: Note\nThis method uses the CHOLMOD library from SuiteSparse, which only supports doubles or complex doubles. Input matrices not of those element types will be converted to SparseMatrixCSC{Float64} or SparseMatrixCSC{Complex128} as appropriate.Many other functions from CHOLMOD are wrapped but not exported from the Base.SparseArrays.CHOLMOD module.\n\n\n\nldltfact(S::SymTridiagonal) -> LDLt\n\nCompute an LDLt factorization of a real symmetric tridiagonal matrix such that A = L*Diagonal(d)*L\' where L is a unit lower triangular matrix and d is a vector. The main use of an LDLt factorization F = ldltfact(A) is to solve the linear system of equations Ax = b with F\\b.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.ldltfact!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.ldltfact!",
    "category": "function",
    "text": "ldltfact!(F::Factor, A; shift = 0.0) -> CHOLMOD.Factor\n\nCompute the LDL factorization of A, reusing the symbolic factorization F. A must be a SparseMatrixCSC or a Symmetric/Hermitian view of a SparseMatrixCSC. Note that even if A doesn\'t have the type tag, it must still be symmetric or Hermitian.\n\nSee also ldltfact.\n\nnote: Note\nThis method uses the CHOLMOD library from SuiteSparse, which only supports doubles or complex doubles. Input matrices not of those element types will be converted to SparseMatrixCSC{Float64} or SparseMatrixCSC{Complex128} as appropriate.\n\n\n\nldltfact!(S::SymTridiagonal) -> LDLt\n\nSame as ldltfact, but saves space by overwriting the input A, instead of creating a copy.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.qr",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.qr",
    "category": "function",
    "text": "qr(A, pivot=Val{false}; thin::Bool=true) -> Q, R, [p]\n\nCompute the (pivoted) QR factorization of A such that either A = Q*R or A[:,p] = Q*R. Also see qrfact. The default is to compute a thin factorization. Note that R is not extended with zeros when the full Q is requested.\n\n\n\nqr(v::AbstractVector) -> w, r\n\nComputes the polar decomposition of a vector. Returns w, a unit vector in the direction of v, and r, the norm of v.\n\nSee also normalize, normalize!, and LinAlg.qr!.\n\nExample\n\njulia> v = [1; 2]\n2-element Array{Int64,1}:\n 1\n 2\n\njulia> w, r = qr(v)\n([0.447214, 0.894427], 2.23606797749979)\n\njulia> w*r == v\ntrue\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.qr!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.qr!",
    "category": "function",
    "text": "LinAlg.qr!(v::AbstractVector) -> w, r\n\nComputes the polar decomposition of a vector. Instead of returning a new vector as qr(v::AbstractVector), this function mutates the input vector v in place. Returns w, a unit vector in the direction of v (this is a mutation of v), and r, the norm of v.\n\nSee also normalize, normalize!, and qr.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.qrfact",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.qrfact",
    "category": "function",
    "text": "qrfact(A, pivot=Val{false}) -> F\n\nCompute the QR factorization of the matrix A: an orthogonal (or unitary if A is complex-valued) matrix Q, and an upper triangular matrix R such that\n\nA = Q R\n\nThe returned object F stores the factorization in a packed format:\n\nif pivot == Val{true} then F is a QRPivoted object,\notherwise if the element type of A is a BLAS type (Float32, Float64, Complex64 or Complex128), then F is a QRCompactWY object,\notherwise F is a QR object.\n\nThe individual components of the factorization F can be accessed by indexing with a symbol:\n\nF[:Q]: the orthogonal/unitary matrix Q\nF[:R]: the upper triangular matrix R\nF[:p]: the permutation vector of the pivot (QRPivoted only)\nF[:P]: the permutation matrix of the pivot (QRPivoted only)\n\nThe following functions are available for the QR objects: inv, size, and \\. When A is rectangular, \\ will return a least squares solution and if the solution is not unique, the one with smallest norm is returned.\n\nMultiplication with respect to either thin or full Q is allowed, i.e. both F[:Q]*F[:R] and F[:Q]*A are supported. A Q matrix can be converted into a regular matrix with full which has a named argument thin.\n\nExample\n\njulia> A = [3.0 -6.0; 4.0 -8.0; 0.0 1.0]\n3×2 Array{Float64,2}:\n 3.0  -6.0\n 4.0  -8.0\n 0.0   1.0\n\njulia> F = qrfact(A)\nBase.LinAlg.QRCompactWY{Float64,Array{Float64,2}} with factors Q and R:\n[-0.6 0.0 0.8; -0.8 0.0 -0.6; 0.0 -1.0 0.0]\n[-5.0 10.0; 0.0 -1.0]\n\njulia> F[:Q] * F[:R] == A\ntrue\n\nnote: Note\nqrfact returns multiple types because LAPACK uses several representations that minimize the memory storage requirements of products of Householder elementary reflectors, so that the Q and R matrices can be stored compactly rather as two separate dense matrices.\n\n\n\nqrfact(A) -> SPQR.Factorization\n\nCompute the QR factorization of a sparse matrix A. A fill-reducing permutation is used. The main application of this type is to solve least squares problems with \\. The function calls the C library SPQR and a few additional functions from the library are wrapped but not exported.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.qrfact!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.qrfact!",
    "category": "function",
    "text": "qrfact!(A, pivot=Val{false})\n\nqrfact! is the same as qrfact when A is a subtype of StridedMatrix, but saves space by overwriting the input A, instead of creating a copy. An InexactError exception is thrown if the factorization produces a number not representable by the element type of A, e.g. for integer types.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.QR",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.QR",
    "category": "type",
    "text": "QR <: Factorization\n\nA QR matrix factorization stored in a packed format, typically obtained from qrfact. If A is an m×n matrix, then\n\nA = Q R\n\nwhere Q is an orthogonal/unitary matrix and R is upper triangular. The matrix Q is stored as a sequence of Householder reflectors v_i and coefficients tau_i where:\n\nQ = prod_i=1^min(mn) (I - tau_i v_i v_i^T)\n\nThe object has two fields:\n\nfactors is an m×n matrix.\nThe upper triangular part contains the elements of R, that is R = triu(F.factors) for a QR object F.\nThe subdiagonal part contains the reflectors v_i stored in a packed format where v_i is the ith column of the matrix V = eye(m,n) + tril(F.factors,-1).\nτ is a vector  of length min(m,n) containing the coefficients au_i.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.QRCompactWY",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.QRCompactWY",
    "category": "type",
    "text": "QRCompactWY <: Factorization\n\nA QR matrix factorization stored in a compact blocked format, typically obtained from qrfact. If A is an m×n matrix, then\n\nA = Q R\n\nwhere Q is an orthogonal/unitary matrix and R is upper triangular. It is similar to the QR format except that the orthogonal/unitary matrix Q is stored in Compact WY format [Schreiber1989], as a lower trapezoidal matrix V and an upper triangular matrix T where\n\nQ = prod_i=1^min(mn) (I - tau_i v_i v_i^T) = I - V T V^T\n\nsuch that v_i is the ith column of V, and au_i is the ith diagonal element of T.\n\nThe object has two fields:\n\nfactors, as in the QR type, is an m×n matrix.\nThe upper triangular part contains the elements of R, that is R = triu(F.factors) for a QR object F.\nThe subdiagonal part contains the reflectors v_i stored in a packed format such that V = eye(m,n) + tril(F.factors,-1).\nT is a square matrix with min(m,n) columns, whose upper triangular part gives the matrix T above (the subdiagonal elements are ignored).\n\nnote: Note\nThis format should not to be confused with the older WY representation [Bischof1987].\n\n[Bischof1987]: C Bischof and C Van Loan, \"The WY representation for products of Householder matrices\", SIAM J Sci Stat Comput 8 (1987), s2-s13. doi:10.1137/0908009\n\n[Schreiber1989]: R Schreiber and C Van Loan, \"A storage-efficient WY representation for products of Householder transformations\", SIAM J Sci Stat Comput 10 (1989), 53-57. doi:10.1137/0910005\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.QRPivoted",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.QRPivoted",
    "category": "type",
    "text": "QRPivoted <: Factorization\n\nA QR matrix factorization with column pivoting in a packed format, typically obtained from qrfact. If A is an m×n matrix, then\n\nA P = Q R\n\nwhere P is a permutation matrix, Q is an orthogonal/unitary matrix and R is upper triangular. The matrix Q is stored as a sequence of Householder reflectors:\n\nQ = prod_i=1^min(mn) (I - tau_i v_i v_i^T)\n\nThe object has three fields:\n\nfactors is an m×n matrix.\nThe upper triangular part contains the elements of R, that is R = triu(F.factors) for a QR object F.\nThe subdiagonal part contains the reflectors v_i stored in a packed format where v_i is the ith column of the matrix V = eye(m,n) + tril(F.factors,-1).\nτ is a vector of length min(m,n) containing the coefficients au_i.\njpvt is an integer vector of length n corresponding to the permutation P.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.lqfact!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.lqfact!",
    "category": "function",
    "text": "lqfact!(A) -> LQ\n\nCompute the LQ factorization of A, using the input matrix as a workspace. See also lq.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.lqfact",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.lqfact",
    "category": "function",
    "text": "lqfact(A) -> LQ\n\nCompute the LQ factorization of A. See also lq.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.lq",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.lq",
    "category": "function",
    "text": "lq(A; [thin=true]) -> L, Q\n\nPerform an LQ factorization of A such that A = L*Q. The default is to compute a thin factorization. The LQ factorization is the QR factorization of A.\'. L is not extended with zeros if the full Q is requested.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.bkfact",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.bkfact",
    "category": "function",
    "text": "bkfact(A, uplo::Symbol=:U, symmetric::Bool=issymmetric(A), rook::Bool=false) -> BunchKaufman\n\nCompute the Bunch-Kaufman [Bunch1977] factorization of a symmetric or Hermitian matrix A and return a BunchKaufman object. uplo indicates which triangle of matrix A to reference. If symmetric is true, A is assumed to be symmetric. If symmetric is false, A is assumed to be Hermitian. If rook is true, rook pivoting is used. If rook is false, rook pivoting is not used. The following functions are available for BunchKaufman objects: size, \\, inv, issymmetric, ishermitian.\n\n[Bunch1977]: J R Bunch and L Kaufman, Some stable methods for calculating inertia and solving symmetric linear systems, Mathematics of Computation 31:137 (1977), 163-179. url.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.bkfact!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.bkfact!",
    "category": "function",
    "text": "bkfact!(A, uplo::Symbol=:U, symmetric::Bool=issymmetric(A), rook::Bool=false) -> BunchKaufman\n\nbkfact! is the same as bkfact, but saves space by overwriting the input A, instead of creating a copy.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.eig",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.eig",
    "category": "function",
    "text": "eig(A::Union{SymTridiagonal, Hermitian, Symmetric}, irange::UnitRange) -> D, V\neig(A::Union{SymTridiagonal, Hermitian, Symmetric}, vl::Real, vu::Real) -> D, V\neig(A, permute::Bool=true, scale::Bool=true) -> D, V\n\nComputes eigenvalues (D) and eigenvectors (V) of A. See eigfact for details on the irange, vl, and vu arguments (for SymTridiagonal, Hermitian, and Symmetric matrices) and the permute and scale keyword arguments. The eigenvectors are returned columnwise.\n\nExample\n\njulia> eig([1.0 0.0 0.0; 0.0 3.0 0.0; 0.0 0.0 18.0])\n([1.0, 3.0, 18.0], [1.0 0.0 0.0; 0.0 1.0 0.0; 0.0 0.0 1.0])\n\neig is a wrapper around eigfact, extracting all parts of the factorization to a tuple; where possible, using eigfact is recommended.\n\n\n\neig(A, B) -> D, V\n\nComputes generalized eigenvalues (D) and vectors (V) of A with respect to B.\n\neig is a wrapper around eigfact, extracting all parts of the factorization to a tuple; where possible, using eigfact is recommended.\n\nExample\n\njulia> A = [1 0; 0 -1]\n2×2 Array{Int64,2}:\n 1   0\n 0  -1\n\njulia> B = [0 1; 1 0]\n2×2 Array{Int64,2}:\n 0  1\n 1  0\n\njulia> eig(A, B)\n(Complex{Float64}[0.0+1.0im, 0.0-1.0im], Complex{Float64}[0.0-1.0im 0.0+1.0im; -1.0-0.0im -1.0+0.0im])\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.eigvals",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.eigvals",
    "category": "function",
    "text": "eigvals(A; permute::Bool=true, scale::Bool=true) -> values\n\nReturns the eigenvalues of A.\n\nFor general non-symmetric matrices it is possible to specify how the matrix is balanced before the eigenvalue calculation. The option permute=true permutes the matrix to become closer to upper triangular, and scale=true scales the matrix by its diagonal elements to make rows and columns more equal in norm. The default is true for both options.\n\n\n\neigvals(A, B) -> values\n\nComputes the generalized eigenvalues of A and B.\n\nExample\n\njulia> A = [1 0; 0 -1]\n2×2 Array{Int64,2}:\n 1   0\n 0  -1\n\njulia> B = [0 1; 1 0]\n2×2 Array{Int64,2}:\n 0  1\n 1  0\n\njulia> eigvals(A,B)\n2-element Array{Complex{Float64},1}:\n 0.0+1.0im\n 0.0-1.0im\n\n\n\neigvals(A::Union{SymTridiagonal, Hermitian, Symmetric}, irange::UnitRange) -> values\n\nReturns the eigenvalues of A. It is possible to calculate only a subset of the eigenvalues by specifying a UnitRange irange covering indices of the sorted eigenvalues, e.g. the 2nd to 8th eigenvalues.\n\njulia> A = SymTridiagonal([1.; 2.; 1.], [2.; 3.])\n3×3 SymTridiagonal{Float64}:\n 1.0  2.0   ⋅\n 2.0  2.0  3.0\n  ⋅   3.0  1.0\n\njulia> eigvals(A, 2:2)\n1-element Array{Float64,1}:\n 1.0\n\njulia> eigvals(A)\n3-element Array{Float64,1}:\n -2.14005\n  1.0\n  5.14005\n\n\n\neigvals(A::Union{SymTridiagonal, Hermitian, Symmetric}, vl::Real, vu::Real) -> values\n\nReturns the eigenvalues of A. It is possible to calculate only a subset of the eigenvalues by specifying a pair vl and vu for the lower and upper boundaries of the eigenvalues.\n\njulia> A = SymTridiagonal([1.; 2.; 1.], [2.; 3.])\n3×3 SymTridiagonal{Float64}:\n 1.0  2.0   ⋅\n 2.0  2.0  3.0\n  ⋅   3.0  1.0\n\njulia> eigvals(A, -1, 2)\n1-element Array{Float64,1}:\n 1.0\n\njulia> eigvals(A)\n3-element Array{Float64,1}:\n -2.14005\n  1.0\n  5.14005\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.eigvals!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.eigvals!",
    "category": "function",
    "text": "eigvals!(A; permute::Bool=true, scale::Bool=true) -> values\n\nSame as eigvals, but saves space by overwriting the input A, instead of creating a copy. The option permute=true permutes the matrix to become closer to upper triangular, and scale=true scales the matrix by its diagonal elements to make rows and columns more equal in norm.\n\n\n\neigvals!(A, B) -> values\n\nSame as eigvals, but saves space by overwriting the input A (and B), instead of creating copies.\n\n\n\neigvals!(A::Union{SymTridiagonal, Hermitian, Symmetric}, irange::UnitRange) -> values\n\nSame as eigvals, but saves space by overwriting the input A, instead of creating a copy. irange is a range of eigenvalue indices to search for - for instance, the 2nd to 8th eigenvalues.\n\n\n\neigvals!(A::Union{SymTridiagonal, Hermitian, Symmetric}, vl::Real, vu::Real) -> values\n\nSame as eigvals, but saves space by overwriting the input A, instead of creating a copy. vl is the lower bound of the interval to search for eigenvalues, and vu is the upper bound.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.eigmax",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.eigmax",
    "category": "function",
    "text": "eigmax(A; permute::Bool=true, scale::Bool=true)\n\nReturns the largest eigenvalue of A. The option permute=true permutes the matrix to become closer to upper triangular, and scale=true scales the matrix by its diagonal elements to make rows and columns more equal in norm. Note that if the eigenvalues of A are complex, this method will fail, since complex numbers cannot be sorted.\n\nExample\n\njulia> A = [0 im; -im 0]\n2×2 Array{Complex{Int64},2}:\n 0+0im  0+1im\n 0-1im  0+0im\n\njulia> eigmax(A)\n1.0\n\njulia> A = [0 im; -1 0]\n2×2 Array{Complex{Int64},2}:\n  0+0im  0+1im\n -1+0im  0+0im\n\njulia> eigmax(A)\nERROR: DomainError:\nStacktrace:\n [1] #eigmax#46(::Bool, ::Bool, ::Function, ::Array{Complex{Int64},2}) at ./linalg/eigen.jl:238\n [2] eigmax(::Array{Complex{Int64},2}) at ./linalg/eigen.jl:236\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.eigmin",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.eigmin",
    "category": "function",
    "text": "eigmin(A; permute::Bool=true, scale::Bool=true)\n\nReturns the smallest eigenvalue of A. The option permute=true permutes the matrix to become closer to upper triangular, and scale=true scales the matrix by its diagonal elements to make rows and columns more equal in norm. Note that if the eigenvalues of A are complex, this method will fail, since complex numbers cannot be sorted.\n\nExample\n\njulia> A = [0 im; -im 0]\n2×2 Array{Complex{Int64},2}:\n 0+0im  0+1im\n 0-1im  0+0im\n\njulia> eigmin(A)\n-1.0\n\njulia> A = [0 im; -1 0]\n2×2 Array{Complex{Int64},2}:\n  0+0im  0+1im\n -1+0im  0+0im\n\njulia> eigmin(A)\nERROR: DomainError:\nStacktrace:\n [1] #eigmin#47(::Bool, ::Bool, ::Function, ::Array{Complex{Int64},2}) at ./linalg/eigen.jl:280\n [2] eigmin(::Array{Complex{Int64},2}) at ./linalg/eigen.jl:278\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.eigvecs",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.eigvecs",
    "category": "function",
    "text": "eigvecs(A::SymTridiagonal[, eigvals]) -> Matrix\n\nReturns a matrix M whose columns are the eigenvectors of A. (The kth eigenvector can be obtained from the slice M[:, k].)\n\nIf the optional vector of eigenvalues eigvals is specified, eigvecs returns the specific corresponding eigenvectors.\n\nExample\n\njulia> A = SymTridiagonal([1.; 2.; 1.], [2.; 3.])\n3×3 SymTridiagonal{Float64}:\n 1.0  2.0   ⋅\n 2.0  2.0  3.0\n  ⋅   3.0  1.0\n\njulia> eigvals(A)\n3-element Array{Float64,1}:\n -2.14005\n  1.0\n  5.14005\n\njulia> eigvecs(A)\n3×3 Array{Float64,2}:\n  0.418304  -0.83205      0.364299\n -0.656749  -7.39009e-16  0.754109\n  0.627457   0.5547       0.546448\n\njulia> eigvecs(A, [1.])\n3×1 Array{Float64,2}:\n  0.83205\n  4.26351e-17\n -0.5547\n\n\n\neigvecs(A; permute::Bool=true, scale::Bool=true) -> Matrix\n\nReturns a matrix M whose columns are the eigenvectors of A. (The kth eigenvector can be obtained from the slice M[:, k].) The permute and scale keywords are the same as for eigfact.\n\nExample\n\njulia> eigvecs([1.0 0.0 0.0; 0.0 3.0 0.0; 0.0 0.0 18.0])\n3×3 Array{Float64,2}:\n 1.0  0.0  0.0\n 0.0  1.0  0.0\n 0.0  0.0  1.0\n\n\n\neigvecs(A, B) -> Matrix\n\nReturns a matrix M whose columns are the generalized eigenvectors of A and B. (The kth eigenvector can be obtained from the slice M[:, k].)\n\nExample\n\njulia> A = [1 0; 0 -1]\n2×2 Array{Int64,2}:\n 1   0\n 0  -1\n\njulia> B = [0 1; 1 0]\n2×2 Array{Int64,2}:\n 0  1\n 1  0\n\njulia> eigvecs(A, B)\n2×2 Array{Complex{Float64},2}:\n  0.0-1.0im   0.0+1.0im\n -1.0-0.0im  -1.0+0.0im\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.eigfact",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.eigfact",
    "category": "function",
    "text": "eigfact(A; permute::Bool=true, scale::Bool=true) -> Eigen\n\nComputes the eigenvalue decomposition of A, returning an Eigen factorization object F which contains the eigenvalues in F[:values] and the eigenvectors in the columns of the matrix F[:vectors]. (The kth eigenvector can be obtained from the slice F[:vectors][:, k].)\n\nThe following functions are available for Eigen objects: inv, det, and isposdef.\n\nFor general nonsymmetric matrices it is possible to specify how the matrix is balanced before the eigenvector calculation. The option permute=true permutes the matrix to become closer to upper triangular, and scale=true scales the matrix by its diagonal elements to make rows and columns more equal in norm. The default is true for both options.\n\nExample\n\njulia> F = eigfact([1.0 0.0 0.0; 0.0 3.0 0.0; 0.0 0.0 18.0])\nBase.LinAlg.Eigen{Float64,Float64,Array{Float64,2},Array{Float64,1}}([1.0, 3.0, 18.0], [1.0 0.0 0.0; 0.0 1.0 0.0; 0.0 0.0 1.0])\n\njulia> F[:values]\n3-element Array{Float64,1}:\n  1.0\n  3.0\n 18.0\n\njulia> F[:vectors]\n3×3 Array{Float64,2}:\n 1.0  0.0  0.0\n 0.0  1.0  0.0\n 0.0  0.0  1.0\n\n\n\neigfact(A, B) -> GeneralizedEigen\n\nComputes the generalized eigenvalue decomposition of A and B, returning a GeneralizedEigen factorization object F which contains the generalized eigenvalues in F[:values] and the generalized eigenvectors in the columns of the matrix F[:vectors]. (The kth generalized eigenvector can be obtained from the slice F[:vectors][:, k].)\n\n\n\neigfact(A::Union{SymTridiagonal, Hermitian, Symmetric}, irange::UnitRange) -> Eigen\n\nComputes the eigenvalue decomposition of A, returning an Eigen factorization object F which contains the eigenvalues in F[:values] and the eigenvectors in the columns of the matrix F[:vectors]. (The kth eigenvector can be obtained from the slice F[:vectors][:, k].)\n\nThe following functions are available for Eigen objects: inv, det, and isposdef.\n\nThe UnitRange irange specifies indices of the sorted eigenvalues to search for.\n\nnote: Note\nIf irange is not 1:n, where n is the dimension of A, then the returned factorization will be a truncated factorization.\n\n\n\neigfact(A::Union{SymTridiagonal, Hermitian, Symmetric}, vl::Real, vu::Real) -> Eigen\n\nComputes the eigenvalue decomposition of A, returning an Eigen factorization object F which contains the eigenvalues in F[:values] and the eigenvectors in the columns of the matrix F[:vectors]. (The kth eigenvector can be obtained from the slice F[:vectors][:, k].)\n\nThe following functions are available for Eigen objects: inv, det, and isposdef.\n\nvl is the lower bound of the window of eigenvalues to search for, and vu is the upper bound.\n\nnote: Note\nIf [vl, vu] does not contain all eigenvalues of A, then the returned factorization will be a truncated factorization.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.eigfact!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.eigfact!",
    "category": "function",
    "text": "eigfact!(A, [B])\n\nSame as eigfact, but saves space by overwriting the input A (and B), instead of creating a copy.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.hessfact",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.hessfact",
    "category": "function",
    "text": "hessfact(A) -> Hessenberg\n\nCompute the Hessenberg decomposition of A and return a Hessenberg object. If F is the factorization object, the unitary matrix can be accessed with F[:Q] and the Hessenberg matrix with F[:H]. When Q is extracted, the resulting type is the HessenbergQ object, and may be converted to a regular matrix with convert(Array, _)  (or Array(_) for short).\n\nExample\n\njulia> A = [4. 9. 7.; 4. 4. 1.; 4. 3. 2.]\n3×3 Array{Float64,2}:\n 4.0  9.0  7.0\n 4.0  4.0  1.0\n 4.0  3.0  2.0\n\njulia> F = hessfact(A);\n\njulia> F[:Q] * F[:H] * F[:Q]\'\n3×3 Array{Float64,2}:\n 4.0  9.0  7.0\n 4.0  4.0  1.0\n 4.0  3.0  2.0\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.hessfact!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.hessfact!",
    "category": "function",
    "text": "hessfact!(A) -> Hessenberg\n\nhessfact! is the same as hessfact, but saves space by overwriting the input A, instead of creating a copy.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.schurfact",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.schurfact",
    "category": "function",
    "text": "schurfact(A::StridedMatrix) -> F::Schur\n\nComputes the Schur factorization of the matrix A. The (quasi) triangular Schur factor can be obtained from the Schur object F with either F[:Schur] or F[:T] and the orthogonal/unitary Schur vectors can be obtained with F[:vectors] or F[:Z] such that A = F[:vectors]*F[:Schur]*F[:vectors]\'. The eigenvalues of A can be obtained with F[:values].\n\nExample\n\njulia> A = [-2. 1. 3.; 2. 1. -1.; -7. 2. 7.]\n3×3 Array{Float64,2}:\n -2.0  1.0   3.0\n  2.0  1.0  -1.0\n -7.0  2.0   7.0\n\njulia> F = schurfact(A)\nBase.LinAlg.Schur{Float64,Array{Float64,2}} with factors T and Z:\n[2.0 0.801792 6.63509; -8.55988e-11 2.0 8.08286; 0.0 0.0 1.99999]\n[0.577351 0.154299 -0.801784; 0.577346 -0.77152 0.267262; 0.577354 0.617211 0.534522]\nand values:\nComplex{Float64}[2.0+8.28447e-6im, 2.0-8.28447e-6im, 1.99999+0.0im]\n\njulia> F[:vectors] * F[:Schur] * F[:vectors]\'\n3×3 Array{Float64,2}:\n -2.0  1.0   3.0\n  2.0  1.0  -1.0\n -7.0  2.0   7.0\n\n\n\nschurfact(A::StridedMatrix, B::StridedMatrix) -> F::GeneralizedSchur\n\nComputes the Generalized Schur (or QZ) factorization of the matrices A and B. The (quasi) triangular Schur factors can be obtained from the Schur object F with F[:S] and F[:T], the left unitary/orthogonal Schur vectors can be obtained with F[:left] or F[:Q] and the right unitary/orthogonal Schur vectors can be obtained with F[:right] or F[:Z] such that A=F[:left]*F[:S]*F[:right]\' and B=F[:left]*F[:T]*F[:right]\'. The generalized eigenvalues of A and B can be obtained with F[:alpha]./F[:beta].\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.schurfact!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.schurfact!",
    "category": "function",
    "text": "schurfact!(A::StridedMatrix) -> F::Schur\n\nSame as schurfact but uses the input argument as workspace.\n\n\n\nschurfact!(A::StridedMatrix, B::StridedMatrix) -> F::GeneralizedSchur\n\nSame as schurfact but uses the input matrices A and B as workspace.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.schur",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.schur",
    "category": "function",
    "text": "schur(A::StridedMatrix) -> T::Matrix, Z::Matrix, λ::Vector\n\nComputes the Schur factorization of the matrix A. The methods return the (quasi) triangular Schur factor T and the orthogonal/unitary Schur vectors Z such that A = Z*T*Z\'. The eigenvalues of A are returned in the vector λ.\n\nSee schurfact.\n\nExample\n\njulia> A = [-2. 1. 3.; 2. 1. -1.; -7. 2. 7.]\n3×3 Array{Float64,2}:\n -2.0  1.0   3.0\n  2.0  1.0  -1.0\n -7.0  2.0   7.0\n\njulia> T, Z, lambda = schur(A)\n([2.0 0.801792 6.63509; -8.55988e-11 2.0 8.08286; 0.0 0.0 1.99999], [0.577351 0.154299 -0.801784; 0.577346 -0.77152 0.267262; 0.577354 0.617211 0.534522], Complex{Float64}[2.0+8.28447e-6im, 2.0-8.28447e-6im, 1.99999+0.0im])\n\njulia> Z * T * Z\'\n3×3 Array{Float64,2}:\n -2.0  1.0   3.0\n  2.0  1.0  -1.0\n -7.0  2.0   7.0\n\n\n\nschur(A::StridedMatrix, B::StridedMatrix) -> S::StridedMatrix, T::StridedMatrix, Q::StridedMatrix, Z::StridedMatrix, α::Vector, β::Vector\n\nSee schurfact.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.ordschur",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.ordschur",
    "category": "function",
    "text": "ordschur(F::Schur, select::Union{Vector{Bool},BitVector}) -> F::Schur\n\nReorders the Schur factorization F of a matrix A = Z*T*Z\' according to the logical array select returning the reordered factorization F object. The selected eigenvalues appear in the leading diagonal of F[:Schur] and the corresponding leading columns of F[:vectors] form an orthogonal/unitary basis of the corresponding right invariant subspace. In the real case, a complex conjugate pair of eigenvalues must be either both included or both excluded via select.\n\n\n\nordschur(T::StridedMatrix, Z::StridedMatrix, select::Union{Vector{Bool},BitVector}) -> T::StridedMatrix, Z::StridedMatrix, λ::Vector\n\nReorders the Schur factorization of a real matrix A = Z*T*Z\' according to the logical array select returning the reordered matrices T and Z as well as the vector of eigenvalues λ. The selected eigenvalues appear in the leading diagonal of T and the corresponding leading columns of Z form an orthogonal/unitary basis of the corresponding right invariant subspace. In the real case, a complex conjugate pair of eigenvalues must be either both included or both excluded via select.\n\n\n\nordschur(F::GeneralizedSchur, select::Union{Vector{Bool},BitVector}) -> F::GeneralizedSchur\n\nReorders the Generalized Schur factorization F of a matrix pair (A, B) = (Q*S*Z\', Q*T*Z\') according to the logical array select and returns a GeneralizedSchur object F. The selected eigenvalues appear in the leading diagonal of both F[:S] and F[:T], and the left and right orthogonal/unitary Schur vectors are also reordered such that (A, B) = F[:Q]*(F[:S], F[:T])*F[:Z]\' still holds and the generalized eigenvalues of A and B can still be obtained with F[:alpha]./F[:beta].\n\n\n\nordschur(S::StridedMatrix, T::StridedMatrix, Q::StridedMatrix, Z::StridedMatrix, select) -> S::StridedMatrix, T::StridedMatrix, Q::StridedMatrix, Z::StridedMatrix, α::Vector, β::Vector\n\nReorders the Generalized Schur factorization of a matrix pair (A, B) = (Q*S*Z\', Q*T*Z\') according to the logical array select and returns the matrices S, T, Q, Z and vectors α and β.  The selected eigenvalues appear in the leading diagonal of both S and T, and the left and right unitary/orthogonal Schur vectors are also reordered such that (A, B) = Q*(S, T)*Z\' still holds and the generalized eigenvalues of A and B can still be obtained with α./β.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.ordschur!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.ordschur!",
    "category": "function",
    "text": "ordschur!(F::Schur, select::Union{Vector{Bool},BitVector}) -> F::Schur\n\nSame as ordschur but overwrites the factorization F.\n\n\n\nordschur!(T::StridedMatrix, Z::StridedMatrix, select::Union{Vector{Bool},BitVector}) -> T::StridedMatrix, Z::StridedMatrix, λ::Vector\n\nSame as ordschur but overwrites the input arguments.\n\n\n\nordschur!(F::GeneralizedSchur, select::Union{Vector{Bool},BitVector}) -> F::GeneralizedSchur\n\nSame as ordschur but overwrites the factorization F.\n\n\n\nordschur!(S::StridedMatrix, T::StridedMatrix, Q::StridedMatrix, Z::StridedMatrix, select) -> S::StridedMatrix, T::StridedMatrix, Q::StridedMatrix, Z::StridedMatrix, α::Vector, β::Vector\n\nSame as ordschur but overwrites the factorization the input arguments.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.svdfact",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.svdfact",
    "category": "function",
    "text": "svdfact(A; thin::Bool=true) -> SVD\n\nCompute the singular value decomposition (SVD) of A and return an SVD object.\n\nU, S, V and Vt can be obtained from the factorization F with F[:U], F[:S], F[:V] and F[:Vt], such that A = U*diagm(S)*Vt. The algorithm produces Vt and hence Vt is more efficient to extract than V. The singular values in S are sorted in descending order.\n\nIf thin=true (default), a thin SVD is returned. For a M times N matrix A, U is M times M for a full SVD (thin=false) and M times min(M N) for a thin SVD.\n\nExample\n\njulia> A = [1. 0. 0. 0. 2.; 0. 0. 3. 0. 0.; 0. 0. 0. 0. 0.; 0. 2. 0. 0. 0.]\n4×5 Array{Float64,2}:\n 1.0  0.0  0.0  0.0  2.0\n 0.0  0.0  3.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0\n 0.0  2.0  0.0  0.0  0.0\n\njulia> F = svdfact(A)\nBase.LinAlg.SVD{Float64,Float64,Array{Float64,2}}([0.0 1.0 0.0 0.0; 1.0 0.0 0.0 0.0; 0.0 0.0 0.0 -1.0; 0.0 0.0 1.0 0.0], [3.0, 2.23607, 2.0, 0.0], [-0.0 0.0 … -0.0 0.0; 0.447214 0.0 … 0.0 0.894427; -0.0 1.0 … -0.0 0.0; 0.0 0.0 … 1.0 0.0])\n\njulia> F[:U] * diagm(F[:S]) * F[:Vt]\n4×5 Array{Float64,2}:\n 1.0  0.0  0.0  0.0  2.0\n 0.0  0.0  3.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0\n 0.0  2.0  0.0  0.0  0.0\n\n\n\nsvdfact(A, B) -> GeneralizedSVD\n\nCompute the generalized SVD of A and B, returning a GeneralizedSVD factorization object F, such that A = F[:U]*F[:D1]*F[:R0]*F[:Q]\' and B = F[:V]*F[:D2]*F[:R0]*F[:Q]\'.\n\nFor an M-by-N matrix A and P-by-N matrix B,\n\nF[:U] is a M-by-M orthogonal matrix,\nF[:V] is a P-by-P orthogonal matrix,\nF[:Q] is a N-by-N orthogonal matrix,\nF[:R0] is a (K+L)-by-N matrix whose rightmost (K+L)-by-(K+L) block is          nonsingular upper block triangular,\nF[:D1] is a M-by-(K+L) diagonal matrix with 1s in the first K entries,\nF[:D2] is a P-by-(K+L) matrix whose top right L-by-L block is diagonal,\n\nK+L is the effective numerical rank of the matrix [A; B].\n\nThe entries of F[:D1] and F[:D2] are related, as explained in the LAPACK documentation for the generalized SVD and the xGGSVD3 routine which is called underneath (in LAPACK 3.6.0 and newer).\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.svdfact!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.svdfact!",
    "category": "function",
    "text": "svdfact!(A, thin::Bool=true) -> SVD\n\nsvdfact! is the same as svdfact, but saves space by overwriting the input A, instead of creating a copy.\n\n\n\nsvdfact!(A, B) -> GeneralizedSVD\n\nsvdfact! is the same as svdfact, but modifies the arguments A and B in-place, instead of making copies.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.svd",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.svd",
    "category": "function",
    "text": "svd(A; thin::Bool=true) -> U, S, V\n\nComputes the SVD of A, returning U, vector S, and V such that A == U*diagm(S)*V\'. The singular values in S are sorted in descending order.\n\nIf thin=true (default), a thin SVD is returned. For a M times N matrix A, U is M times M for a full SVD (thin=false) and M times min(M N) for a thin SVD.\n\nsvd is a wrapper around svdfact, extracting all parts of the SVD factorization to a tuple. Direct use of svdfact is therefore more efficient.\n\nExample\n\njulia> A = [1. 0. 0. 0. 2.; 0. 0. 3. 0. 0.; 0. 0. 0. 0. 0.; 0. 2. 0. 0. 0.]\n4×5 Array{Float64,2}:\n 1.0  0.0  0.0  0.0  2.0\n 0.0  0.0  3.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0\n 0.0  2.0  0.0  0.0  0.0\n\njulia> U, S, V = svd(A)\n([0.0 1.0 0.0 0.0; 1.0 0.0 0.0 0.0; 0.0 0.0 0.0 -1.0; 0.0 0.0 1.0 0.0], [3.0, 2.23607, 2.0, 0.0], [-0.0 0.447214 -0.0 0.0; 0.0 0.0 1.0 0.0; … ; -0.0 0.0 -0.0 1.0; 0.0 0.894427 0.0 0.0])\n\njulia> U*diagm(S)*V\'\n4×5 Array{Float64,2}:\n 1.0  0.0  0.0  0.0  2.0\n 0.0  0.0  3.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0\n 0.0  2.0  0.0  0.0  0.0\n\n\n\nsvd(A, B) -> U, V, Q, D1, D2, R0\n\nWrapper around svdfact extracting all parts of the factorization to a tuple. Direct use of svdfact is therefore generally more efficient. The function returns the generalized SVD of A and B, returning U, V, Q, D1, D2, and R0 such that A = U*D1*R0*Q\' and B = V*D2*R0*Q\'.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.svdvals",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.svdvals",
    "category": "function",
    "text": "svdvals(A)\n\nReturns the singular values of A in descending order.\n\nExample\n\njulia> A = [1. 0. 0. 0. 2.; 0. 0. 3. 0. 0.; 0. 0. 0. 0. 0.; 0. 2. 0. 0. 0.]\n4×5 Array{Float64,2}:\n 1.0  0.0  0.0  0.0  2.0\n 0.0  0.0  3.0  0.0  0.0\n 0.0  0.0  0.0  0.0  0.0\n 0.0  2.0  0.0  0.0  0.0\n\njulia> svdvals(A)\n4-element Array{Float64,1}:\n 3.0\n 2.23607\n 2.0\n 0.0\n\n\n\nsvdvals(A, B)\n\nReturn the generalized singular values from the generalized singular value decomposition of A and B. See also svdfact.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.Givens",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.Givens",
    "category": "type",
    "text": "LinAlg.Givens(i1,i2,c,s) -> G\n\nA Givens rotation linear operator. The fields c and s represent the cosine and sine of the rotation angle, respectively. The Givens type supports left multiplication G*A and conjugated transpose right multiplication A*G\'. The type doesn\'t have a size and can therefore be multiplied with matrices of arbitrary size as long as i2<=size(A,2) for G*A or i2<=size(A,1) for A*G\'.\n\nSee also: givens\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.givens",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.givens",
    "category": "function",
    "text": "givens{T}(f::T, g::T, i1::Integer, i2::Integer) -> (G::Givens, r::T)\n\nComputes the Givens rotation G and scalar r such that for any vector x where\n\nx[i1] = f\nx[i2] = g\n\nthe result of the multiplication\n\ny = G*x\n\nhas the property that\n\ny[i1] = r\ny[i2] = 0\n\nSee also: LinAlg.Givens\n\n\n\ngivens(A::AbstractArray, i1::Integer, i2::Integer, j::Integer) -> (G::Givens, r)\n\nComputes the Givens rotation G and scalar r such that the result of the multiplication\n\nB = G*A\n\nhas the property that\n\nB[i1,j] = r\nB[i2,j] = 0\n\nSee also: LinAlg.Givens\n\n\n\ngivens(x::AbstractVector, i1::Integer, i2::Integer) -> (G::Givens, r)\n\nComputes the Givens rotation G and scalar r such that the result of the multiplication\n\nB = G*x\n\nhas the property that\n\nB[i1] = r\nB[i2] = 0\n\nSee also: LinAlg.Givens\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.triu",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.triu",
    "category": "function",
    "text": "triu(M)\n\nUpper triangle of a matrix.\n\nExample\n\njulia> a = ones(4,4)\n4×4 Array{Float64,2}:\n 1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0\n\njulia> triu(a)\n4×4 Array{Float64,2}:\n 1.0  1.0  1.0  1.0\n 0.0  1.0  1.0  1.0\n 0.0  0.0  1.0  1.0\n 0.0  0.0  0.0  1.0\n\n\n\ntriu(M, k::Integer)\n\nReturns the upper triangle of M starting from the kth superdiagonal.\n\nExample\n\njulia> a = ones(4,4)\n4×4 Array{Float64,2}:\n 1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0\n\njulia> triu(a,3)\n4×4 Array{Float64,2}:\n 0.0  0.0  0.0  1.0\n 0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0\n\njulia> triu(a,-3)\n4×4 Array{Float64,2}:\n 1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.triu!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.triu!",
    "category": "function",
    "text": "triu!(M)\n\nUpper triangle of a matrix, overwriting M in the process. See also triu.\n\n\n\ntriu!(M, k::Integer)\n\nReturns the upper triangle of M starting from the kth superdiagonal, overwriting M in the process.\n\nExample\n\njulia> M = [1 2 3 4 5; 1 2 3 4 5; 1 2 3 4 5; 1 2 3 4 5; 1 2 3 4 5]\n5×5 Array{Int64,2}:\n 1  2  3  4  5\n 1  2  3  4  5\n 1  2  3  4  5\n 1  2  3  4  5\n 1  2  3  4  5\n\njulia> triu!(M, 1)\n5×5 Array{Int64,2}:\n 0  2  3  4  5\n 0  0  3  4  5\n 0  0  0  4  5\n 0  0  0  0  5\n 0  0  0  0  0\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.tril",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.tril",
    "category": "function",
    "text": "tril(M)\n\nLower triangle of a matrix.\n\nExample\n\njulia> a = ones(4,4)\n4×4 Array{Float64,2}:\n 1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0\n\njulia> tril(a)\n4×4 Array{Float64,2}:\n 1.0  0.0  0.0  0.0\n 1.0  1.0  0.0  0.0\n 1.0  1.0  1.0  0.0\n 1.0  1.0  1.0  1.0\n\n\n\ntril(M, k::Integer)\n\nReturns the lower triangle of M starting from the kth superdiagonal.\n\nExample\n\njulia> a = ones(4,4)\n4×4 Array{Float64,2}:\n 1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0\n\njulia> tril(a,3)\n4×4 Array{Float64,2}:\n 1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0\n 1.0  1.0  1.0  1.0\n\njulia> tril(a,-3)\n4×4 Array{Float64,2}:\n 0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0\n 0.0  0.0  0.0  0.0\n 1.0  0.0  0.0  0.0\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.tril!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.tril!",
    "category": "function",
    "text": "tril!(M)\n\nLower triangle of a matrix, overwriting M in the process. See also tril.\n\n\n\ntril!(M, k::Integer)\n\nReturns the lower triangle of M starting from the kth superdiagonal, overwriting M in the process.\n\nExample\n\njulia> M = [1 2 3 4 5; 1 2 3 4 5; 1 2 3 4 5; 1 2 3 4 5; 1 2 3 4 5]\n5×5 Array{Int64,2}:\n 1  2  3  4  5\n 1  2  3  4  5\n 1  2  3  4  5\n 1  2  3  4  5\n 1  2  3  4  5\n\njulia> tril!(M, 2)\n5×5 Array{Int64,2}:\n 1  2  3  0  0\n 1  2  3  4  0\n 1  2  3  4  5\n 1  2  3  4  5\n 1  2  3  4  5\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.diagind",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.diagind",
    "category": "function",
    "text": "diagind(M, k::Integer=0)\n\nA Range giving the indices of the kth diagonal of the matrix M.\n\nExample\n\njulia> A = [1 2 3; 4 5 6; 7 8 9]\n3×3 Array{Int64,2}:\n 1  2  3\n 4  5  6\n 7  8  9\n\njulia> diagind(A,-1)\n2:4:6\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.diag",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.diag",
    "category": "function",
    "text": "diag(M, k::Integer=0)\n\nThe kth diagonal of a matrix, as a vector. Use diagm to construct a diagonal matrix.\n\nExample\n\njulia> A = [1 2 3; 4 5 6; 7 8 9]\n3×3 Array{Int64,2}:\n 1  2  3\n 4  5  6\n 7  8  9\n\njulia> diag(A,1)\n2-element Array{Int64,1}:\n 2\n 6\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.diagm",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.diagm",
    "category": "function",
    "text": "diagm(v, k::Integer=0)\n\nConstruct a matrix by placing v on the kth diagonal.\n\nExample\n\njulia> diagm([1,2,3],1)\n4×4 Array{Int64,2}:\n 0  1  0  0\n 0  0  2  0\n 0  0  0  3\n 0  0  0  0\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.scale!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.scale!",
    "category": "function",
    "text": "scale!(A, b)\nscale!(b, A)\n\nScale an array A by a scalar b overwriting A in-place.\n\nIf A is a matrix and b is a vector, then scale!(A,b) scales each column i of A by b[i] (similar to A*Diagonal(b)), while scale!(b,A) scales each row i of A by b[i] (similar to Diagonal(b)*A), again operating in-place on A. An InexactError exception is thrown if the scaling produces a number not representable by the element type of A, e.g. for integer types.\n\nExample\n\njulia> a = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> b = [1; 2]\n2-element Array{Int64,1}:\n 1\n 2\n\njulia> scale!(a,b)\n2×2 Array{Int64,2}:\n 1  4\n 3  8\n\njulia> a = [1 2; 3 4];\n\njulia> b = [1; 2];\n\njulia> scale!(b,a)\n2×2 Array{Int64,2}:\n 1  2\n 6  8\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.rank",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.rank",
    "category": "function",
    "text": "rank(M[, tol::Real])\n\nCompute the rank of a matrix by counting how many singular values of M have magnitude greater than tol. By default, the value of tol is the largest dimension of M multiplied by the eps of the eltype of M.\n\nExample\n\njulia> rank(eye(3))\n3\n\njulia> rank(diagm([1, 0, 2]))\n2\n\njulia> rank(diagm([1, 0.001, 2]), 0.1)\n2\n\njulia> rank(diagm([1, 0.001, 2]), 0.00001)\n3\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.norm",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.norm",
    "category": "function",
    "text": "norm(A::AbstractArray, p::Real=2)\n\nCompute the p-norm of a vector or the operator norm of a matrix A, defaulting to the 2-norm.\n\nnorm(A::AbstractVector, p::Real=2)\n\nFor vectors, this is equivalent to vecnorm and equal to:\n\nA_p = left( sum_i=1^n  a_i  ^p right)^1p\n\nwith a_i the entries of A and n its length.\n\np can assume any numeric value (even though not all values produce a mathematically valid vector norm). In particular, norm(A, Inf) returns the largest value in abs(A), whereas norm(A, -Inf) returns the smallest.\n\nExample\n\njulia> v = [3, -2, 6]\n3-element Array{Int64,1}:\n  3\n -2\n  6\n\njulia> norm(v)\n7.0\n\njulia> norm(v, Inf)\n6.0\n\n\n\nnorm(A::AbstractMatrix, p::Real=2)\n\nFor matrices, the matrix norm induced by the vector p-norm is used, where valid values of p are 1, 2, or Inf. (Note that for sparse matrices, p=2 is currently not implemented.) Use vecnorm to compute the Frobenius norm.\n\nWhen p=1, the matrix norm is the maximum absolute column sum of A:\n\nA_1 = max_1  j  n sum_i=1^m  a_ij \n\nwith a_ij the entries of A, and m and n its dimensions.\n\nWhen p=2, the matrix norm is the spectral norm, equal to the largest singular value of A.\n\nWhen p=Inf, the matrix norm is the maximum absolute row sum of A:\n\nA_infty = max_1  i  m sum _j=1^n  a_ij \n\nExample\n\njulia> A = [1 -2 -3; 2 3 -1]\n2×3 Array{Int64,2}:\n 1  -2  -3\n 2   3  -1\n\njulia> norm(A, Inf)\n6.0\n\n\n\nnorm(x::Number, p::Real=2)\n\nFor numbers, return left( x^p right)^1p. This is equivalent to vecnorm.\n\n\n\nnorm(A::RowVector, q::Real=2)\n\nFor row vectors, return the q-norm of A, which is equivalent to the p-norm with value p = q/(q-1). They coincide at p = q = 2.\n\nThe difference in norm between a vector space and its dual arises to preserve the relationship between duality and the inner product, and the result is consistent with the p-norm of 1 × n matrix.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.vecnorm",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.vecnorm",
    "category": "function",
    "text": "vecnorm(A, p::Real=2)\n\nFor any iterable container A (including arrays of any dimension) of numbers (or any element type for which norm is defined), compute the p-norm (defaulting to p=2) as if A were a vector of the corresponding length.\n\nThe p-norm is defined as:\n\nA_p = left( sum_i=1^n  a_i  ^p right)^1p\n\nwith a_i the entries of A and n its length.\n\np can assume any numeric value (even though not all values produce a mathematically valid vector norm). In particular, vecnorm(A, Inf) returns the largest value in abs(A), whereas vecnorm(A, -Inf) returns the smallest. If A is a matrix and p=2, then this is equivalent to the Frobenius norm.\n\nExample\n\njulia> vecnorm([1 2 3; 4 5 6; 7 8 9])\n16.881943016134134\n\njulia> vecnorm([1 2 3 4 5 6 7 8 9])\n16.881943016134134\n\n\n\nvecnorm(x::Number, p::Real=2)\n\nFor numbers, return left( x^p right) ^1p.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.normalize!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.normalize!",
    "category": "function",
    "text": "normalize!(v::AbstractVector, p::Real=2)\n\nNormalize the vector v in-place so that its p-norm equals unity, i.e. norm(v, p) == 1. See also normalize and vecnorm.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.normalize",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.normalize",
    "category": "function",
    "text": "normalize(v::AbstractVector, p::Real=2)\n\nNormalize the vector v so that its p-norm equals unity, i.e. norm(v, p) == vecnorm(v, p) == 1. See also normalize! and vecnorm.\n\nExamples\n\njulia> a = [1,2,4];\n\njulia> b = normalize(a)\n3-element Array{Float64,1}:\n 0.218218\n 0.436436\n 0.872872\n\njulia> norm(b)\n1.0\n\njulia> c = normalize(a, 1)\n3-element Array{Float64,1}:\n 0.142857\n 0.285714\n 0.571429\n\njulia> norm(c, 1)\n1.0\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.cond",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.cond",
    "category": "function",
    "text": "cond(M, p::Real=2)\n\nCondition number of the matrix M, computed using the operator p-norm. Valid values for p are 1, 2 (default), or Inf.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.condskeel",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.condskeel",
    "category": "function",
    "text": "condskeel(M, [x, p::Real=Inf])\n\nkappa_S(M p) = leftVert leftvert M rightvert leftvert M^-1 rightvert rightVert_p \nkappa_S(M x p) = leftVert leftvert M rightvert leftvert M^-1 rightvert leftvert x rightvert rightVert_p\n\nSkeel condition number kappa_S of the matrix M, optionally with respect to the vector x, as computed using the operator p-norm. leftvert M rightvert denotes the matrix of (entry wise) absolute values of M; leftvert M rightvert_ij = leftvert M_ij rightvert. Valid values for p are 1, 2 and Inf (default).\n\nThis quantity is also known in the literature as the Bauer condition number, relative condition number, or componentwise relative condition number.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.trace",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.trace",
    "category": "function",
    "text": "trace(M)\n\nMatrix trace. Sums the diagonal elements of M.\n\nExample\n\njulia> A = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> trace(A)\n5\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.det",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.det",
    "category": "function",
    "text": "det(M)\n\nMatrix determinant.\n\nExample\n\njulia> M = [1 0; 2 2]\n2×2 Array{Int64,2}:\n 1  0\n 2  2\n\njulia> det(M)\n2.0\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.logdet",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.logdet",
    "category": "function",
    "text": "logdet(M)\n\nLog of matrix determinant. Equivalent to log(det(M)), but may provide increased accuracy and/or speed.\n\nExamples\n\njulia> M = [1 0; 2 2]\n2×2 Array{Int64,2}:\n 1  0\n 2  2\n\njulia> logdet(M)\n0.6931471805599453\n\njulia> logdet(eye(3))\n0.0\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.logabsdet",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.logabsdet",
    "category": "function",
    "text": "logabsdet(M)\n\nLog of absolute value of matrix determinant. Equivalent to (log(abs(det(M))), sign(det(M))), but may provide increased accuracy and/or speed.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.inv",
    "page": "Linear Algebra",
    "title": "Base.inv",
    "category": "function",
    "text": "inv(M)\n\nMatrix inverse. Computes matrix N such that M * N = I, where I is the identity matrix. Computed by solving the left-division N = M \\ I.\n\nExample\n\njulia> M = [2 5; 1 3]\n2×2 Array{Int64,2}:\n 2  5\n 1  3\n\njulia> N = inv(M)\n2×2 Array{Float64,2}:\n  3.0  -5.0\n -1.0   2.0\n\njulia> M*N == N*M == eye(2)\ntrue\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.pinv",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.pinv",
    "category": "function",
    "text": "pinv(M[, tol::Real])\n\nComputes the Moore-Penrose pseudoinverse.\n\nFor matrices M with floating point elements, it is convenient to compute the pseudoinverse by inverting only singular values above a given threshold, tol.\n\nThe optimal choice of tol varies both with the value of M and the intended application of the pseudoinverse. The default value of tol is eps(real(float(one(eltype(M)))))*maximum(size(A)), which is essentially machine epsilon for the real part of a matrix element multiplied by the larger matrix dimension. For inverting dense ill-conditioned matrices in a least-squares sense, tol = sqrt(eps(real(float(one(eltype(M)))))) is recommended.\n\nFor more information, see [issue8859], [B96], [S84], [KY88].\n\nExample\n\njulia> M = [1.5 1.3; 1.2 1.9]\n2×2 Array{Float64,2}:\n 1.5  1.3\n 1.2  1.9\n\njulia> N = pinv(M)\n2×2 Array{Float64,2}:\n  1.47287   -1.00775\n -0.930233   1.16279\n\njulia> M * N\n2×2 Array{Float64,2}:\n 1.0          -2.22045e-16\n 4.44089e-16   1.0\n\n[issue8859]: Issue 8859, \"Fix least squares\", https://github.com/JuliaLang/julia/pull/8859\n\n[B96]: Åke Björck, \"Numerical Methods for Least Squares Problems\",  SIAM Press, Philadelphia, 1996, \"Other Titles in Applied Mathematics\", Vol. 51. doi:10.1137/1.9781611971484\n\n[S84]: G. W. Stewart, \"Rank Degeneracy\", SIAM Journal on Scientific and Statistical Computing, 5(2), 1984, 403-413. doi:10.1137/0905030\n\n[KY88]: Konstantinos Konstantinides and Kung Yao, \"Statistical analysis of effective singular values in matrix rank determination\", IEEE Transactions on Acoustics, Speech and Signal Processing, 36(5), 1988, 757-763. doi:10.1109/29.1585\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.nullspace",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.nullspace",
    "category": "function",
    "text": "nullspace(M)\n\nBasis for nullspace of M.\n\nExample\n\njulia> M = [1 0 0; 0 1 0; 0 0 0]\n3×3 Array{Int64,2}:\n 1  0  0\n 0  1  0\n 0  0  0\n\njulia> nullspace(M)\n3×1 Array{Float64,2}:\n 0.0\n 0.0\n 1.0\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.repmat",
    "page": "Linear Algebra",
    "title": "Base.repmat",
    "category": "function",
    "text": "repmat(A, m::Integer, n::Integer=1)\n\nConstruct a matrix by repeating the given matrix (or vector) m times in dimension 1 and n times in dimension 2.\n\nExamples\n\njulia> repmat([1, 2, 3], 2)\n6-element Array{Int64,1}:\n 1\n 2\n 3\n 1\n 2\n 3\n\njulia> repmat([1, 2, 3], 2, 3)\n6×3 Array{Int64,2}:\n 1  1  1\n 2  2  2\n 3  3  3\n 1  1  1\n 2  2  2\n 3  3  3\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.repeat",
    "page": "Linear Algebra",
    "title": "Base.repeat",
    "category": "function",
    "text": "repeat(A::AbstractArray; inner=ntuple(x->1, ndims(A)), outer=ntuple(x->1, ndims(A)))\n\nConstruct an array by repeating the entries of A. The i-th element of inner specifies the number of times that the individual entries of the i-th dimension of A should be repeated. The i-th element of outer specifies the number of times that a slice along the i-th dimension of A should be repeated. If inner or outer are omitted, no repetition is performed.\n\nExamples\n\njulia> repeat(1:2, inner=2)\n4-element Array{Int64,1}:\n 1\n 1\n 2\n 2\n\njulia> repeat(1:2, outer=2)\n4-element Array{Int64,1}:\n 1\n 2\n 1\n 2\n\njulia> repeat([1 2; 3 4], inner=(2, 1), outer=(1, 3))\n4×6 Array{Int64,2}:\n 1  2  1  2  1  2\n 1  2  1  2  1  2\n 3  4  3  4  3  4\n 3  4  3  4  3  4\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.kron",
    "page": "Linear Algebra",
    "title": "Base.kron",
    "category": "function",
    "text": "kron(A, B)\n\nKronecker tensor product of two vectors or two matrices.\n\nExample\n\njulia> A = [1 2; 3 4]\n2×2 Array{Int64,2}:\n 1  2\n 3  4\n\njulia> B = [im 1; 1 -im]\n2×2 Array{Complex{Int64},2}:\n 0+1im  1+0im\n 1+0im  0-1im\n\njulia> kron(A, B)\n4×4 Array{Complex{Int64},2}:\n 0+1im  1+0im  0+2im  2+0im\n 1+0im  0-1im  2+0im  0-2im\n 0+3im  3+0im  0+4im  4+0im\n 3+0im  0-3im  4+0im  0-4im\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.SparseArrays.blkdiag",
    "page": "Linear Algebra",
    "title": "Base.SparseArrays.blkdiag",
    "category": "function",
    "text": "blkdiag(A...)\n\nConcatenate matrices block-diagonally. Currently only implemented for sparse matrices.\n\nExample\n\njulia> blkdiag(speye(3), 2*speye(2))\n5×5 SparseMatrixCSC{Float64,Int64} with 5 stored entries:\n  [1, 1]  =  1.0\n  [2, 2]  =  1.0\n  [3, 3]  =  1.0\n  [4, 4]  =  2.0\n  [5, 5]  =  2.0\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.linreg",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.linreg",
    "category": "function",
    "text": "linreg(x, y)\n\nPerform simple linear regression using Ordinary Least Squares. Returns a and b such that a + b*x is the closest straight line to the given points (x, y), i.e., such that the squared error between y and a + b*x is minimized.\n\nExamples:\n\nusing PyPlot\nx = 1.0:12.0\ny = [5.5, 6.3, 7.6, 8.8, 10.9, 11.79, 13.48, 15.02, 17.77, 20.81, 22.0, 22.99]\na, b = linreg(x, y)          # Linear regression\nplot(x, y, \"o\")              # Plot (x, y) points\nplot(x, a + b*x)             # Plot line determined by linear regression\n\nSee also:\n\n\\, cov, std, mean.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.expm",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.expm",
    "category": "function",
    "text": "expm(A)\n\nCompute the matrix exponential of A, defined by\n\ne^A = sum_n=0^infty fracA^nn\n\nFor symmetric or Hermitian A, an eigendecomposition (eigfact) is used, otherwise the scaling and squaring algorithm (see [H05]) is chosen.\n\n[H05]: Nicholas J. Higham, \"The squaring and scaling method for the matrix exponential revisited\", SIAM Journal on Matrix Analysis and Applications, 26(4), 2005, 1179-1193. doi:10.1137/090768539\n\nExample\n\njulia> A = eye(2, 2)\n2×2 Array{Float64,2}:\n 1.0  0.0\n 0.0  1.0\n\njulia> expm(A)\n2×2 Array{Float64,2}:\n 2.71828  0.0\n 0.0      2.71828\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.logm",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.logm",
    "category": "function",
    "text": "logm(A{T}::StridedMatrix{T})\n\nIf A has no negative real eigenvalue, compute the principal matrix logarithm of A, i.e. the unique matrix X such that e^X = A and -pi  Im(lambda)  pi for all the eigenvalues lambda of X. If A has nonpositive eigenvalues, a nonprincipal matrix function is returned whenever possible.\n\nIf A is symmetric or Hermitian, its eigendecomposition (eigfact) is used, if A is triangular an improved version of the inverse scaling and squaring method is employed (see [AH12] and [AHR13]). For general matrices, the complex Schur form (schur) is computed and the triangular algorithm is used on the triangular factor.\n\n[AH12]: Awad H. Al-Mohy and Nicholas J. Higham, \"Improved inverse  scaling and squaring algorithms for the matrix logarithm\", SIAM Journal on Scientific Computing, 34(4), 2012, C153-C169. doi:10.1137/110852553\n\n[AHR13]: Awad H. Al-Mohy, Nicholas J. Higham and Samuel D. Relton, \"Computing the Fréchet derivative of the matrix logarithm and estimating the condition number\", SIAM Journal on Scientific Computing, 35(4), 2013, C394-C410. doi:10.1137/120885991\n\nExample\n\njulia> A = 2.7182818 * eye(2)\n2×2 Array{Float64,2}:\n 2.71828  0.0\n 0.0      2.71828\n\njulia> logm(A)\n2×2 Symmetric{Float64,Array{Float64,2}}:\n 1.0  0.0\n 0.0  1.0\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.sqrtm",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.sqrtm",
    "category": "function",
    "text": "sqrtm(A)\n\nIf A has no negative real eigenvalues, compute the principal matrix square root of A, that is the unique matrix X with eigenvalues having positive real part such that X^2 = A. Otherwise, a nonprincipal square root is returned.\n\nIf A is symmetric or Hermitian, its eigendecomposition (eigfact) is used to compute the square root. Otherwise, the square root is determined by means of the Björck-Hammarling method [BH83], which computes the complex Schur form (schur) and then the complex square root of the triangular factor.\n\n[BH83]: Åke Björck and Sven Hammarling, \"A Schur method for the square root of a matrix\", Linear Algebra and its Applications, 52-53, 1983, 127-140. doi:10.1016/0024-3795(83)80010-X\n\nExample\n\njulia> A = [4 0; 0 4]\n2×2 Array{Int64,2}:\n 4  0\n 0  4\n\njulia> sqrtm(A)\n2×2 Array{Float64,2}:\n 2.0  0.0\n 0.0  2.0\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.lyap",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.lyap",
    "category": "function",
    "text": "lyap(A, C)\n\nComputes the solution X to the continuous Lyapunov equation AX + XA\' + C = 0, where no eigenvalue of A has a zero real part and no two eigenvalues are negative complex conjugates of each other.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.sylvester",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.sylvester",
    "category": "function",
    "text": "sylvester(A, B, C)\n\nComputes the solution X to the Sylvester equation AX + XB + C = 0, where A, B and C have compatible dimensions and A and -B have no eigenvalues with equal real part.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.issymmetric",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.issymmetric",
    "category": "function",
    "text": "issymmetric(A) -> Bool\n\nTest whether a matrix is symmetric.\n\nExamples\n\njulia> a = [1 2; 2 -1]\n2×2 Array{Int64,2}:\n 1   2\n 2  -1\n\njulia> issymmetric(a)\ntrue\n\njulia> b = [1 im; -im 1]\n2×2 Array{Complex{Int64},2}:\n 1+0im  0+1im\n 0-1im  1+0im\n\njulia> issymmetric(b)\nfalse\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.isposdef",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.isposdef",
    "category": "function",
    "text": "isposdef(A) -> Bool\n\nTest whether a matrix is positive definite.\n\nExample\n\njulia> A = [1 2; 2 50]\n2×2 Array{Int64,2}:\n 1   2\n 2  50\n\njulia> isposdef(A)\ntrue\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.isposdef!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.isposdef!",
    "category": "function",
    "text": "isposdef!(A) -> Bool\n\nTest whether a matrix is positive definite, overwriting A in the process.\n\nExample\n\njulia> A = [1. 2.; 2. 50.];\n\njulia> isposdef!(A)\ntrue\n\njulia> A\n2×2 Array{Float64,2}:\n 1.0  2.0\n 2.0  6.78233\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.istril",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.istril",
    "category": "function",
    "text": "istril(A) -> Bool\n\nTest whether a matrix is lower triangular.\n\nExamples\n\njulia> a = [1 2; 2 -1]\n2×2 Array{Int64,2}:\n 1   2\n 2  -1\n\njulia> istril(a)\nfalse\n\njulia> b = [1 0; -im -1]\n2×2 Array{Complex{Int64},2}:\n 1+0im   0+0im\n 0-1im  -1+0im\n\njulia> istril(b)\ntrue\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.istriu",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.istriu",
    "category": "function",
    "text": "istriu(A) -> Bool\n\nTest whether a matrix is upper triangular.\n\nExamples\n\njulia> a = [1 2; 2 -1]\n2×2 Array{Int64,2}:\n 1   2\n 2  -1\n\njulia> istriu(a)\nfalse\n\njulia> b = [1 im; 0 -1]\n2×2 Array{Complex{Int64},2}:\n 1+0im   0+1im\n 0+0im  -1+0im\n\njulia> istriu(b)\ntrue\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.isdiag",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.isdiag",
    "category": "function",
    "text": "isdiag(A) -> Bool\n\nTest whether a matrix is diagonal.\n\nExamples\n\njulia> a = [1 2; 2 -1]\n2×2 Array{Int64,2}:\n 1   2\n 2  -1\n\njulia> isdiag(a)\nfalse\n\njulia> b = [im 0; 0 -im]\n2×2 Array{Complex{Int64},2}:\n 0+1im  0+0im\n 0+0im  0-1im\n\njulia> isdiag(b)\ntrue\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.ishermitian",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.ishermitian",
    "category": "function",
    "text": "ishermitian(A) -> Bool\n\nTest whether a matrix is Hermitian.\n\nExamples\n\njulia> a = [1 2; 2 -1]\n2×2 Array{Int64,2}:\n 1   2\n 2  -1\n\njulia> ishermitian(a)\ntrue\n\njulia> b = [1 im; -im 1]\n2×2 Array{Complex{Int64},2}:\n 1+0im  0+1im\n 0-1im  1+0im\n\njulia> ishermitian(b)\ntrue\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.RowVector",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.RowVector",
    "category": "type",
    "text": "RowVector(vector)\n\nA lazy-view wrapper of an AbstractVector, which turns a length-n vector into a 1×n shaped row vector and represents the transpose of a vector (the elements are also transposed recursively). This type is usually constructed (and unwrapped) via the transpose function or .\' operator (or related ctranspose or \' operator).\n\nBy convention, a vector can be multiplied by a matrix on its left (A * v) whereas a row vector can be multiplied by a matrix on its right (such that v.\' * A = (A.\' * v).\'). It differs from a 1×n-sized matrix by the facts that its transpose returns a vector and the inner product v1.\' * v2 returns a scalar, but will otherwise behave similarly.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.ConjArray",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.ConjArray",
    "category": "type",
    "text": "ConjArray(array)\n\nA lazy-view wrapper of an AbstractArray, taking the elementwise complex conjugate. This type is usually constructed (and unwrapped) via the conj function (or related ctranspose), but currently this is the default behavior for RowVector only. For other arrays, the ConjArray constructor can be used directly.\n\nExamples\n\njulia> [1+im, 1-im]\'\n1×2 RowVector{Complex{Int64},ConjArray{Complex{Int64},1,Array{Complex{Int64},1}}}:\n 1-1im  1+1im\n\njulia> ConjArray([1+im 0; 0 1-im])\n2×2 ConjArray{Complex{Int64},2,Array{Complex{Int64},2}}:\n 1-1im  0+0im\n 0+0im  1+1im\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.transpose",
    "page": "Linear Algebra",
    "title": "Base.transpose",
    "category": "function",
    "text": "transpose(A::AbstractMatrix)\n\nThe transposition operator (.\').\n\nExample\n\njulia> A = [1 2 3; 4 5 6; 7 8 9]\n3×3 Array{Int64,2}:\n 1  2  3\n 4  5  6\n 7  8  9\n\njulia> transpose(A)\n3×3 Array{Int64,2}:\n 1  4  7\n 2  5  8\n 3  6  9\n\n\n\ntranspose(v::AbstractVector)\n\nThe transposition operator (.\').\n\nExample\n\njulia> v = [1,2,3]\n3-element Array{Int64,1}:\n 1\n 2\n 3\n\njulia> transpose(v)\n1×3 RowVector{Int64,Array{Int64,1}}:\n 1  2  3\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.transpose!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.transpose!",
    "category": "function",
    "text": "transpose!(dest,src)\n\nTranspose array src and store the result in the preallocated array dest, which should have a size corresponding to (size(src,2),size(src,1)). No in-place transposition is supported and unexpected results will happen if src and dest have overlapping memory regions.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.ctranspose",
    "page": "Linear Algebra",
    "title": "Base.ctranspose",
    "category": "function",
    "text": "ctranspose(A)\n\nThe conjugate transposition operator (\').\n\nExample\n\njulia> A =  [3+2im 9+2im; 8+7im  4+6im]\n2×2 Array{Complex{Int64},2}:\n 3+2im  9+2im\n 8+7im  4+6im\n\njulia> ctranspose(A)\n2×2 Array{Complex{Int64},2}:\n 3-2im  8-7im\n 9-2im  4-6im\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.ctranspose!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.ctranspose!",
    "category": "function",
    "text": "ctranspose!(dest,src)\n\nConjugate transpose array src and store the result in the preallocated array dest, which should have a size corresponding to (size(src,2),size(src,1)). No in-place transposition is supported and unexpected results will happen if src and dest have overlapping memory regions.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.eigs-Tuple{Any}",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.eigs",
    "category": "method",
    "text": "eigs(A; nev=6, ncv=max(20,2*nev+1), which=:LM, tol=0.0, maxiter=300, sigma=nothing, ritzvec=true, v0=zeros((0,))) -> (d,[v,],nconv,niter,nmult,resid)\n\nComputes eigenvalues d of A using implicitly restarted Lanczos or Arnoldi iterations for real symmetric or general nonsymmetric matrices respectively.\n\nThe following keyword arguments are supported:\n\nnev: Number of eigenvalues\nncv: Number of Krylov vectors used in the computation; should satisfy nev+1 <= ncv <= n for real symmetric problems and nev+2 <= ncv <= n for other problems, where n is the size of the input matrix A. The default is ncv = max(20,2*nev+1). Note that these restrictions limit the input matrix A to be of dimension at least 2.\nwhich: type of eigenvalues to compute. See the note below.\n\nwhich type of eigenvalues\n:LM eigenvalues of largest magnitude (default)\n:SM eigenvalues of smallest magnitude\n:LR eigenvalues of largest real part\n:SR eigenvalues of smallest real part\n:LI eigenvalues of largest imaginary part (nonsymmetric or complex A only)\n:SI eigenvalues of smallest imaginary part (nonsymmetric or complex A only)\n:BE compute half of the eigenvalues from each end of the spectrum, biased in favor of the high end. (real symmetric A only)\n\ntol: parameter defining the relative tolerance for convergence of Ritz values (eigenvalue estimates).    A Ritz value  is considered converged when its associated residual    is less than or equal to the product of tol and max(^23 ),    where ɛ = eps(real(eltype(A)))/2 is LAPACK\'s machine epsilon.    The residual associated with  and its corresponding Ritz vector v    is defined as the norm Av - v.    The specified value of tol should be positive; otherwise, it is ignored    and  is used instead.    Default: .\nmaxiter: Maximum number of iterations (default = 300)\nsigma: Specifies the level shift used in inverse iteration. If nothing (default), defaults to ordinary (forward) iterations. Otherwise, find eigenvalues close to sigma using shift and invert iterations.\nritzvec: Returns the Ritz vectors v (eigenvectors) if true\nv0: starting vector from which to start the iterations\n\neigs returns the nev requested eigenvalues in d, the corresponding Ritz vectors v (only if ritzvec=true), the number of converged eigenvalues nconv, the number of iterations niter and the number of matrix vector multiplications nmult, as well as the final residual vector resid.\n\nExample\n\njulia> A = spdiagm(1:4);\n\njulia> λ, ϕ = eigs(A, nev = 2);\n\njulia> λ\n2-element Array{Float64,1}:\n 4.0\n 3.0\n\nnote: Note\nThe sigma and which keywords interact: the description of eigenvalues searched for by which do not necessarily refer to the eigenvalues of A, but rather the linear operator constructed by the specification of the iteration mode implied by sigma.sigma iteration mode which refers to eigenvalues of\nnothing ordinary (forward) A\nreal or complex inverse with level shift sigma (A - sigma I )^-1\n\nnote: Note\nAlthough tol has a default value, the best choice depends strongly on the matrix A. We recommend that users _always_ specify a value for tol which suits their specific needs.For details of how the errors in the computed eigenvalues are estimated, see:B. N. Parlett, \"The Symmetric Eigenvalue Problem\", SIAM: Philadelphia, 2/e (1998), Ch. 13.2, \"Accessing Accuracy in Lanczos Problems\", pp. 290-292 ff.\nR. B. Lehoucq and D. C. Sorensen, \"Deflation Techniques for an Implicitly Restarted Arnoldi Iteration\", SIAM Journal on Matrix Analysis and Applications (1996), 17(4), 789–821.  doi:10.1137/S0895479895281484\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.eigs-Tuple{Any,Any}",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.eigs",
    "category": "method",
    "text": "eigs(A, B; nev=6, ncv=max(20,2*nev+1), which=:LM, tol=0.0, maxiter=300, sigma=nothing, ritzvec=true, v0=zeros((0,))) -> (d,[v,],nconv,niter,nmult,resid)\n\nComputes generalized eigenvalues d of A and B using implicitly restarted Lanczos or Arnoldi iterations for real symmetric or general nonsymmetric matrices respectively.\n\nThe following keyword arguments are supported:\n\nnev: Number of eigenvalues\nncv: Number of Krylov vectors used in the computation; should satisfy nev+1 <= ncv <= n for real symmetric problems and nev+2 <= ncv <= n for other problems, where n is the size of the input matrices A and B. The default is ncv = max(20,2*nev+1). Note that these restrictions limit the input matrix A to be of dimension at least 2.\nwhich: type of eigenvalues to compute. See the note below.\n\nwhich type of eigenvalues\n:LM eigenvalues of largest magnitude (default)\n:SM eigenvalues of smallest magnitude\n:LR eigenvalues of largest real part\n:SR eigenvalues of smallest real part\n:LI eigenvalues of largest imaginary part (nonsymmetric or complex A only)\n:SI eigenvalues of smallest imaginary part (nonsymmetric or complex A only)\n:BE compute half of the eigenvalues from each end of the spectrum, biased in favor of the high end. (real symmetric A only)\n\ntol: relative tolerance used in the convergence criterion for eigenvalues, similar to    tol in the eigs(A) method for the ordinary eigenvalue    problem, but effectively for the eigenvalues of B^-1 A instead of A.    See the documentation for the ordinary eigenvalue problem in    eigs(A) and the accompanying note about tol.\nmaxiter: Maximum number of iterations (default = 300)\nsigma: Specifies the level shift used in inverse iteration. If nothing (default), defaults to ordinary (forward) iterations. Otherwise, find eigenvalues close to sigma using shift and invert iterations.\nritzvec: Returns the Ritz vectors v (eigenvectors) if true\nv0: starting vector from which to start the iterations\n\neigs returns the nev requested eigenvalues in d, the corresponding Ritz vectors v (only if ritzvec=true), the number of converged eigenvalues nconv, the number of iterations niter and the number of matrix vector multiplications nmult, as well as the final residual vector resid.\n\nExample\n\njulia> A = speye(4, 4); B = spdiagm(1:4);\n\njulia> λ, ϕ = eigs(A, B, nev = 2);\n\njulia> λ\n2-element Array{Float64,1}:\n 1.0\n 0.5\n\nnote: Note\nThe sigma and which keywords interact: the description of eigenvalues searched for by which do not necessarily refer to the eigenvalue problem Av = Bvlambda, but rather the linear operator constructed by the specification of the iteration mode implied by sigma.sigma iteration mode which refers to the problem\nnothing ordinary (forward) Av = Bvlambda\nreal or complex inverse with level shift sigma (A - sigma B )^-1B = vnu\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.svds",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.svds",
    "category": "function",
    "text": "svds(A; nsv=6, ritzvec=true, tol=0.0, maxiter=1000, ncv=2*nsv, u0=zeros((0,)), v0=zeros((0,))) -> (SVD([left_sv,] s, [right_sv,]), nconv, niter, nmult, resid)\n\nComputes the largest singular values s of A using implicitly restarted Lanczos iterations derived from eigs.\n\nInputs\n\nA: Linear operator whose singular values are desired. A may be represented as a subtype of AbstractArray, e.g., a sparse matrix, or any other type supporting the four methods size(A), eltype(A), A * vector, and A\' * vector.\nnsv: Number of singular values. Default: 6.\nritzvec: If true, return the left and right singular vectors left_sv and right_sv.  If false, omit the singular vectors. Default: true.\ntol: tolerance, see eigs.\nmaxiter: Maximum number of iterations, see eigs. Default: 1000.\nncv: Maximum size of the Krylov subspace, see eigs (there called nev). Default: 2*nsv.\nu0: Initial guess for the first left Krylov vector. It may have length m (the first dimension of A), or 0.\nv0: Initial guess for the first right Krylov vector. It may have length n (the second dimension of A), or 0.\n\nOutputs\n\nsvd: An SVD object containing the left singular vectors, the requested values, and the right singular vectors. If ritzvec = false, the left and right singular vectors will be empty.\nnconv: Number of converged singular values.\nniter: Number of iterations.\nnmult: Number of matrix–vector products used.\nresid: Final residual vector.\n\nExample\n\njulia> A = spdiagm(1:4);\n\njulia> s = svds(A, nsv = 2)[1];\n\njulia> s[:S]\n2-element Array{Float64,1}:\n 4.0\n 3.0\n\nnote: Implementation\nsvds(A) is formally equivalent to calling eigs to perform implicitly restarted Lanczos tridiagonalization on the Hermitian matrix beginpmatrix 0  A^prime  A  0 endpmatrix, whose eigenvalues are plus and minus the singular values of A.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.peakflops",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.peakflops",
    "category": "function",
    "text": "peakflops(n::Integer=2000; parallel::Bool=false)\n\npeakflops computes the peak flop rate of the computer by using double precision gemm!. By default, if no arguments are specified, it multiplies a matrix of size n x n, where n = 2000. If the underlying BLAS is using multiple threads, higher flop rates are realized. The number of BLAS threads can be set with BLAS.set_num_threads(n).\n\nIf the keyword argument parallel is set to true, peakflops is run in parallel on all the worker processors. The flop rate of the entire parallel computer is returned. When running in parallel, only 1 BLAS thread is used. The argument n still refers to the size of the problem that is solved on each processor.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Standard-Functions-1",
    "page": "Linear Algebra",
    "title": "Standard Functions",
    "category": "section",
    "text": "Linear algebra functions in Julia are largely implemented by calling functions from LAPACK.  Sparse factorizations call functions from SuiteSparse.Base.:*(::AbstractArray, ::AbstractArray)\nBase.:\\(::AbstractArray, ::Any)\nBase.LinAlg.dot\nBase.LinAlg.vecdot\nBase.LinAlg.cross\nBase.LinAlg.factorize\nBase.LinAlg.Diagonal\nBase.LinAlg.Bidiagonal\nBase.LinAlg.SymTridiagonal\nBase.LinAlg.Tridiagonal\nBase.LinAlg.Symmetric\nBase.LinAlg.Hermitian\nBase.LinAlg.LowerTriangular\nBase.LinAlg.UpperTriangular\nBase.LinAlg.lu\nBase.LinAlg.lufact\nBase.LinAlg.lufact!\nBase.LinAlg.chol\nBase.LinAlg.cholfact\nBase.LinAlg.cholfact!\nBase.LinAlg.lowrankupdate\nBase.LinAlg.lowrankdowndate\nBase.LinAlg.lowrankupdate!\nBase.LinAlg.lowrankdowndate!\nBase.LinAlg.ldltfact\nBase.LinAlg.ldltfact!\nBase.LinAlg.qr\nBase.LinAlg.qr!\nBase.LinAlg.qrfact\nBase.LinAlg.qrfact!\nBase.LinAlg.QR\nBase.LinAlg.QRCompactWY\nBase.LinAlg.QRPivoted\nBase.LinAlg.lqfact!\nBase.LinAlg.lqfact\nBase.LinAlg.lq\nBase.LinAlg.bkfact\nBase.LinAlg.bkfact!\nBase.LinAlg.eig\nBase.LinAlg.eigvals\nBase.LinAlg.eigvals!\nBase.LinAlg.eigmax\nBase.LinAlg.eigmin\nBase.LinAlg.eigvecs\nBase.LinAlg.eigfact\nBase.LinAlg.eigfact!\nBase.LinAlg.hessfact\nBase.LinAlg.hessfact!\nBase.LinAlg.schurfact\nBase.LinAlg.schurfact!\nBase.LinAlg.schur\nBase.LinAlg.ordschur\nBase.LinAlg.ordschur!\nBase.LinAlg.svdfact\nBase.LinAlg.svdfact!\nBase.LinAlg.svd\nBase.LinAlg.svdvals\nBase.LinAlg.Givens\nBase.LinAlg.givens\nBase.LinAlg.triu\nBase.LinAlg.triu!\nBase.LinAlg.tril\nBase.LinAlg.tril!\nBase.LinAlg.diagind\nBase.LinAlg.diag\nBase.LinAlg.diagm\nBase.LinAlg.scale!\nBase.LinAlg.rank\nBase.LinAlg.norm\nBase.LinAlg.vecnorm\nBase.LinAlg.normalize!\nBase.LinAlg.normalize\nBase.LinAlg.cond\nBase.LinAlg.condskeel\nBase.LinAlg.trace\nBase.LinAlg.det\nBase.LinAlg.logdet\nBase.LinAlg.logabsdet\nBase.inv\nBase.LinAlg.pinv\nBase.LinAlg.nullspace\nBase.repmat\nBase.repeat\nBase.kron\nBase.SparseArrays.blkdiag\nBase.LinAlg.linreg\nBase.LinAlg.expm\nBase.LinAlg.logm\nBase.LinAlg.sqrtm\nBase.LinAlg.lyap\nBase.LinAlg.sylvester\nBase.LinAlg.issymmetric\nBase.LinAlg.isposdef\nBase.LinAlg.isposdef!\nBase.LinAlg.istril\nBase.LinAlg.istriu\nBase.LinAlg.isdiag\nBase.LinAlg.ishermitian\nBase.LinAlg.RowVector\nBase.LinAlg.ConjArray\nBase.transpose\nBase.transpose!\nBase.ctranspose\nBase.ctranspose!\nBase.LinAlg.eigs(::Any)\nBase.LinAlg.eigs(::Any, ::Any)\nBase.LinAlg.svds\nBase.LinAlg.peakflops"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.A_ldiv_B!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.A_ldiv_B!",
    "category": "function",
    "text": "A_ldiv_B!([Y,] A, B) -> Y\n\nCompute A \\ B in-place and store the result in Y, returning the result. If only two arguments are passed, then A_ldiv_B!(A, B) overwrites B with the result.\n\nThe argument A should not be a matrix.  Rather, instead of matrices it should be a factorization object (e.g. produced by factorize or cholfact). The reason for this is that factorization itself is both expensive and typically allocates memory (although it can also be done in-place via, e.g., lufact!), and performance-critical situations requiring A_ldiv_B! usually also require fine-grained control over the factorization of A.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.A_ldiv_Bc",
    "page": "Linear Algebra",
    "title": "Base.A_ldiv_Bc",
    "category": "function",
    "text": "A_ldiv_Bc(A, B)\n\nFor matrices or vectors A and B, calculates A \\ B.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.A_ldiv_Bt",
    "page": "Linear Algebra",
    "title": "Base.A_ldiv_Bt",
    "category": "function",
    "text": "A_ldiv_Bt(A, B)\n\nFor matrices or vectors A and B, calculates A \\ B.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.A_mul_B!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.A_mul_B!",
    "category": "function",
    "text": "A_mul_B!(Y, A, B) -> Y\n\nCalculates the matrix-matrix or matrix-vector product AB and stores the result in Y, overwriting the existing value of Y. Note that Y must not be aliased with either A or B.\n\nExample\n\njulia> A=[1.0 2.0; 3.0 4.0]; B=[1.0 1.0; 1.0 1.0]; Y = similar(B); A_mul_B!(Y, A, B);\n\njulia> Y\n2×2 Array{Float64,2}:\n 3.0  3.0\n 7.0  7.0\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.A_mul_Bc",
    "page": "Linear Algebra",
    "title": "Base.A_mul_Bc",
    "category": "function",
    "text": "A_mul_Bc(A, B)\n\nFor matrices or vectors A and B, calculates AB.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.A_mul_Bt",
    "page": "Linear Algebra",
    "title": "Base.A_mul_Bt",
    "category": "function",
    "text": "A_mul_Bt(A, B)\n\nFor matrices or vectors A and B, calculates AB.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.A_rdiv_Bc",
    "page": "Linear Algebra",
    "title": "Base.A_rdiv_Bc",
    "category": "function",
    "text": "A_rdiv_Bc(A, B)\n\nFor matrices or vectors A and B, calculates A  B.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.A_rdiv_Bt",
    "page": "Linear Algebra",
    "title": "Base.A_rdiv_Bt",
    "category": "function",
    "text": "A_rdiv_Bt(A, B)\n\nFor matrices or vectors A and B, calculates A  B.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.Ac_ldiv_B",
    "page": "Linear Algebra",
    "title": "Base.Ac_ldiv_B",
    "category": "function",
    "text": "Ac_ldiv_B(A, B)\n\nFor matrices or vectors A and B, calculates A \\ B.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.Ac_ldiv_B!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.Ac_ldiv_B!",
    "category": "function",
    "text": "Ac_ldiv_B!([Y,] A, B) -> Y\n\nSimilar to A_ldiv_B!, but return A \\ B, computing the result in-place in Y (or overwriting B if Y is not supplied).\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.Ac_ldiv_Bc",
    "page": "Linear Algebra",
    "title": "Base.Ac_ldiv_Bc",
    "category": "function",
    "text": "Ac_ldiv_Bc(A, B)\n\nFor matrices or vectors A and B, calculates A \\ B.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.Ac_mul_B",
    "page": "Linear Algebra",
    "title": "Base.Ac_mul_B",
    "category": "function",
    "text": "Ac_mul_B(A, B)\n\nFor matrices or vectors A and B, calculates AB.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.Ac_mul_Bc",
    "page": "Linear Algebra",
    "title": "Base.Ac_mul_Bc",
    "category": "function",
    "text": "Ac_mul_Bc(A, B)\n\nFor matrices or vectors A and B, calculates A B.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.Ac_rdiv_B",
    "page": "Linear Algebra",
    "title": "Base.Ac_rdiv_B",
    "category": "function",
    "text": "Ac_rdiv_B(A, B)\n\nFor matrices or vectors A and B, calculates A  B.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.Ac_rdiv_Bc",
    "page": "Linear Algebra",
    "title": "Base.Ac_rdiv_Bc",
    "category": "function",
    "text": "Ac_rdiv_Bc(A, B)\n\nFor matrices or vectors A and B, calculates A  B.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.At_ldiv_B",
    "page": "Linear Algebra",
    "title": "Base.At_ldiv_B",
    "category": "function",
    "text": "At_ldiv_B(A, B)\n\nFor matrices or vectors A and B, calculates A \\ B.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.At_ldiv_B!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.At_ldiv_B!",
    "category": "function",
    "text": "At_ldiv_B!([Y,] A, B) -> Y\n\nSimilar to A_ldiv_B!, but return A \\ B, computing the result in-place in Y (or overwriting B if Y is not supplied).\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.At_ldiv_Bt",
    "page": "Linear Algebra",
    "title": "Base.At_ldiv_Bt",
    "category": "function",
    "text": "At_ldiv_Bt(A, B)\n\nFor matrices or vectors A and B, calculates A \\ B.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.At_mul_B",
    "page": "Linear Algebra",
    "title": "Base.At_mul_B",
    "category": "function",
    "text": "At_mul_B(A, B)\n\nFor matrices or vectors A and B, calculates AB.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.At_mul_Bt",
    "page": "Linear Algebra",
    "title": "Base.At_mul_Bt",
    "category": "function",
    "text": "At_mul_Bt(A, B)\n\nFor matrices or vectors A and B, calculates AB.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.At_rdiv_B",
    "page": "Linear Algebra",
    "title": "Base.At_rdiv_B",
    "category": "function",
    "text": "At_rdiv_B(A, B)\n\nFor matrices or vectors A and B, calculates A  B.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.At_rdiv_Bt",
    "page": "Linear Algebra",
    "title": "Base.At_rdiv_Bt",
    "category": "function",
    "text": "At_rdiv_Bt(A, B)\n\nFor matrices or vectors A and B, calculates A  B.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Low-level-matrix-operations-1",
    "page": "Linear Algebra",
    "title": "Low-level matrix operations",
    "category": "section",
    "text": "Matrix operations involving transpositions operations like A\' \\ B are converted by the Julia parser into calls to specially named functions like Ac_ldiv_B. If you want to overload these operations for your own types, then it is useful to know the names of these functions.Also, in many cases there are in-place versions of matrix operations that allow you to supply a pre-allocated output vector or matrix.  This is useful when optimizing critical code in order to avoid the overhead of repeated allocations. These in-place operations are suffixed with ! below (e.g. A_mul_B!) according to the usual Julia convention.Base.LinAlg.A_ldiv_B!\nBase.A_ldiv_Bc\nBase.A_ldiv_Bt\nBase.LinAlg.A_mul_B!\nBase.A_mul_Bc\nBase.A_mul_Bt\nBase.A_rdiv_Bc\nBase.A_rdiv_Bt\nBase.Ac_ldiv_B\nBase.LinAlg.Ac_ldiv_B!\nBase.Ac_ldiv_Bc\nBase.Ac_mul_B\nBase.Ac_mul_Bc\nBase.Ac_rdiv_B\nBase.Ac_rdiv_Bc\nBase.At_ldiv_B\nBase.LinAlg.At_ldiv_B!\nBase.At_ldiv_Bt\nBase.At_mul_B\nBase.At_mul_Bt\nBase.At_rdiv_B\nBase.At_rdiv_Bt"
},

{
    "location": "stdlib/linalg/#BLAS-Functions-1",
    "page": "Linear Algebra",
    "title": "BLAS Functions",
    "category": "section",
    "text": "In Julia (as in much of scientific computation), dense linear-algebra operations are based on the LAPACK library, which in turn is built on top of basic linear-algebra building-blocks known as the BLAS. There are highly optimized implementations of BLAS available for every computer architecture, and sometimes in high-performance linear algebra routines it is useful to call the BLAS functions directly.Base.LinAlg.BLAS provides wrappers for some of the BLAS functions. Those BLAS functions that overwrite one of the input arrays have names ending in \'!\'.  Usually, a BLAS function has four methods defined, for Float64, Float32, Complex128, and Complex64 arrays."
},

{
    "location": "stdlib/linalg/#stdlib-blas-chars-1",
    "page": "Linear Algebra",
    "title": "BLAS Character Arguments",
    "category": "section",
    "text": "Many BLAS functions accept arguments that determine whether to transpose an argument (trans), which triangle of a matrix to reference (uplo or ul), whether the diagonal of a triangular matrix can be assumed to be all ones (dA) or which side of a matrix multiplication the input argument belongs on (side). The possiblities are:"
},

{
    "location": "stdlib/linalg/#stdlib-blas-side-1",
    "page": "Linear Algebra",
    "title": "Multplication Order",
    "category": "section",
    "text": "side Meaning\n\'L\' The argument goes on the left side of a matrix-matrix operation.\n\'R\' The argument goes on the right side of a matrix-matrix operation."
},

{
    "location": "stdlib/linalg/#stdlib-blas-uplo-1",
    "page": "Linear Algebra",
    "title": "Triangle Referencing",
    "category": "section",
    "text": "uplo/ul Meaning\n\'U\' Only the upper triangle of the matrix will be used.\n\'L\' Only the lower triangle of the matrix will be used."
},

{
    "location": "stdlib/linalg/#stdlib-blas-trans-1",
    "page": "Linear Algebra",
    "title": "Transposition Operation",
    "category": "section",
    "text": "trans/tX Meaning\n\'N\' The input matrix X is not transposed or conjugated.\n\'T\' The input matrix X will be transposed.\n\'C\' The input matrix X will be conjugated and transposed."
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.dotu",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.dotu",
    "category": "function",
    "text": "dotu(n, X, incx, Y, incy)\n\nDot function for two complex vectors consisting of n elements of array X with stride incx and n elements of array Y with stride incy.\n\nExample:\n\njulia> Base.BLAS.dotu(10, im*ones(10), 1, complex.(ones(20), ones(20)), 2)\n-10.0 + 10.0im\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.dotc",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.dotc",
    "category": "function",
    "text": "dotc(n, X, incx, U, incy)\n\nDot function for two complex vectors, consisting of n elements of array X with stride incx and n elements of array U with stride incy, conjugating the first vector.\n\nExample:\n\njulia> Base.BLAS.dotc(10, im*ones(10), 1, complex.(ones(20), ones(20)), 2)\n10.0 - 10.0im\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.blascopy!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.blascopy!",
    "category": "function",
    "text": "blascopy!(n, X, incx, Y, incy)\n\nCopy n elements of array X with stride incx to array Y with stride incy. Returns Y.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.nrm2",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.nrm2",
    "category": "function",
    "text": "nrm2(n, X, incx)\n\n2-norm of a vector consisting of n elements of array X with stride incx.\n\nExample:\n\njulia> Base.BLAS.nrm2(4, ones(8), 2)\n2.0\n\njulia> Base.BLAS.nrm2(1, ones(8), 2)\n1.0\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.asum",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.asum",
    "category": "function",
    "text": "asum(n, X, incx)\n\nSum of the absolute values of the first n elements of array X with stride incx.\n\nExample:\n\njulia> Base.BLAS.asum(5, im*ones(10), 2)\n5.0\n\njulia> Base.BLAS.asum(2, im*ones(10), 5)\n2.0\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.axpy!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.axpy!",
    "category": "function",
    "text": "axpy!(a, X, Y)\n\nOverwrite Y with a*X + Y, where a is a scalar. Returns Y.\n\nExample:\n\njulia> x = [1; 2; 3];\n\njulia> y = [4; 5; 6];\n\njulia> Base.BLAS.axpy!(2, x, y)\n3-element Array{Int64,1}:\n  6\n  9\n 12\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.scal!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.scal!",
    "category": "function",
    "text": "scal!(n, a, X, incx)\n\nOverwrite X with a*X for the first n elements of array X with stride incx. Returns X.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.scal",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.scal",
    "category": "function",
    "text": "scal(n, a, X, incx)\n\nReturns X scaled by a for the first n elements of array X with stride incx.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.ger!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.ger!",
    "category": "function",
    "text": "ger!(alpha, x, y, A)\n\nRank-1 update of the matrix A with vectors x and y as alpha*x*y\' + A.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.syr!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.syr!",
    "category": "function",
    "text": "syr!(uplo, alpha, x, A)\n\nRank-1 update of the symmetric matrix A with vector x as alpha*x*x.\' + A. uplo controls which triangle of A is updated. Returns A.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.syrk!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.syrk!",
    "category": "function",
    "text": "syrk!(uplo, trans, alpha, A, beta, C)\n\nRank-k update of the symmetric matrix C as alpha*A*A.\' + beta*C or alpha*A.\'*A + beta*C according to trans. Only the uplo triangle of C is used. Returns C.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.syrk",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.syrk",
    "category": "function",
    "text": "syrk(uplo, trans, alpha, A)\n\nReturns either the upper triangle or the lower triangle of A, according to uplo, of alpha*A*A.\' or alpha*A.\'*A, according to trans.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.her!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.her!",
    "category": "function",
    "text": "her!(uplo, alpha, x, A)\n\nMethods for complex arrays only. Rank-1 update of the Hermitian matrix A with vector x as alpha*x*x\' + A. uplo controls which triangle of A is updated. Returns A.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.herk!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.herk!",
    "category": "function",
    "text": "herk!(uplo, trans, alpha, A, beta, C)\n\nMethods for complex arrays only. Rank-k update of the Hermitian matrix C as alpha*A*A\' + beta*C or alpha*A\'*A + beta*C according to trans. Only the uplo triangle of C is updated. Returns C.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.herk",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.herk",
    "category": "function",
    "text": "herk(uplo, trans, alpha, A)\n\nMethods for complex arrays only. Returns the uplo triangle of alpha*A*A\' or alpha*A\'*A, according to trans.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.gbmv!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.gbmv!",
    "category": "function",
    "text": "gbmv!(trans, m, kl, ku, alpha, A, x, beta, y)\n\nUpdate vector y as alpha*A*x + beta*y or alpha*A\'*x + beta*y according to trans. The matrix A is a general band matrix of dimension m by size(A,2) with kl sub-diagonals and ku super-diagonals. alpha and beta are scalars. Returns the updated y.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.gbmv",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.gbmv",
    "category": "function",
    "text": "gbmv(trans, m, kl, ku, alpha, A, x)\n\nReturns alpha*A*x or alpha*A\'*x according to trans. The matrix A is a general band matrix of dimension m by size(A,2) with kl sub-diagonals and ku super-diagonals, and alpha is a scalar.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.sbmv!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.sbmv!",
    "category": "function",
    "text": "sbmv!(uplo, k, alpha, A, x, beta, y)\n\nUpdate vector y as alpha*A*x + beta*y where A is a a symmetric band matrix of order size(A,2) with k super-diagonals stored in the argument A. The storage layout for A is described the reference BLAS module, level-2 BLAS at http://www.netlib.org/lapack/explore-html/. Only the uplo triangle of A is used.\n\nReturns the updated y.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.sbmv-NTuple{5,Any}",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.sbmv",
    "category": "method",
    "text": "sbmv(uplo, k, alpha, A, x)\n\nReturns alpha*A*x where A is a symmetric band matrix of order size(A,2) with k super-diagonals stored in the argument A. Only the uplo triangle of A is used.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.sbmv-NTuple{4,Any}",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.sbmv",
    "category": "method",
    "text": "sbmv(uplo, k, A, x)\n\nReturns A*x where A is a symmetric band matrix of order size(A,2) with k super-diagonals stored in the argument A. Only the uplo triangle of A is used.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.gemm!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.gemm!",
    "category": "function",
    "text": "gemm!(tA, tB, alpha, A, B, beta, C)\n\nUpdate C as alpha*A*B + beta*C or the other three variants according to tA and tB. Returns the updated C.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.gemm-NTuple{5,Any}",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.gemm",
    "category": "method",
    "text": "gemm(tA, tB, alpha, A, B)\n\nReturns alpha*A*B or the other three variants according to tA and tB.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.gemm-NTuple{4,Any}",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.gemm",
    "category": "method",
    "text": "gemm(tA, tB, A, B)\n\nReturns A*B or the other three variants according to tA and tB.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.gemv!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.gemv!",
    "category": "function",
    "text": "gemv!(tA, alpha, A, x, beta, y)\n\nUpdate the vector y as alpha*A*x + beta*y or alpha*A\'x + beta*y according to tA. alpha and beta are scalars. Returns the updated y.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.gemv-NTuple{4,Any}",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.gemv",
    "category": "method",
    "text": "gemv(tA, alpha, A, x)\n\nReturns alpha*A*x or alpha*A\'x according to tA. alpha is a scalar.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.gemv-Tuple{Any,Any,Any}",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.gemv",
    "category": "method",
    "text": "gemv(tA, A, x)\n\nReturns A*x or A\'x according to tA.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.symm!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.symm!",
    "category": "function",
    "text": "symm!(side, ul, alpha, A, B, beta, C)\n\nUpdate C as alpha*A*B + beta*C or alpha*B*A + beta*C according to side. A is assumed to be symmetric. Only the ul triangle of A is used. Returns the updated C.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.symm-NTuple{5,Any}",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.symm",
    "category": "method",
    "text": "symm(side, ul, alpha, A, B)\n\nReturns alpha*A*B or alpha*B*A according to side. A is assumed to be symmetric. Only the ul triangle of A is used.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.symm-NTuple{4,Any}",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.symm",
    "category": "method",
    "text": "symm(side, ul, A, B)\n\nReturns A*B or B*A according to side. A is assumed to be symmetric. Only the ul triangle of A is used.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.symv!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.symv!",
    "category": "function",
    "text": "symv!(ul, alpha, A, x, beta, y)\n\nUpdate the vector y as alpha*A*x + beta*y. A is assumed to be symmetric. Only the ul triangle of A is used. alpha and beta are scalars. Returns the updated y.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.symv-NTuple{4,Any}",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.symv",
    "category": "method",
    "text": "symv(ul, alpha, A, x)\n\nReturns alpha*A*x. A is assumed to be symmetric. Only the ul triangle of A is used. alpha is a scalar.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.symv-Tuple{Any,Any,Any}",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.symv",
    "category": "method",
    "text": "symv(ul, A, x)\n\nReturns A*x. A is assumed to be symmetric. Only the ul triangle of A is used.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.trmm!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.trmm!",
    "category": "function",
    "text": "trmm!(side, ul, tA, dA, alpha, A, B)\n\nUpdate B as alpha*A*B or one of the other three variants determined by side and tA. Only the ul triangle of A is used. dA determines if the diagonal values are read or are assumed to be all ones. Returns the updated B.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.trmm",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.trmm",
    "category": "function",
    "text": "trmm(side, ul, tA, dA, alpha, A, B)\n\nReturns alpha*A*B or one of the other three variants determined by side and tA. Only the ul triangle of A is used. dA determines if the diagonal values are read or are assumed to be all ones.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.trsm!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.trsm!",
    "category": "function",
    "text": "trsm!(side, ul, tA, dA, alpha, A, B)\n\nOverwrite B with the solution to A*X = alpha*B or one of the other three variants determined by side and tA. Only the ul triangle of A is used. dA determines if the diagonal values are read or are assumed to be all ones. Returns the updated B.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.trsm",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.trsm",
    "category": "function",
    "text": "trsm(side, ul, tA, dA, alpha, A, B)\n\nReturns the solution to A*X = alpha*B or one of the other three variants determined by determined by side and tA. Only the ul triangle of A is used. dA determines if the diagonal values are read or are assumed to be all ones.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.trmv!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.trmv!",
    "category": "function",
    "text": "trmv!(ul, tA, dA, A, b)\n\nReturns op(A)*b, where op is determined by tA. Only the ul triangle of A is used. dA determines if the diagonal values are read or are assumed to be all ones. The multiplication occurs in-place on b.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.trmv",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.trmv",
    "category": "function",
    "text": "trmv(ul, tA, dA, A, b)\n\nReturns op(A)*b, where op is determined by tA. Only the ul triangle of A is used. dA determines if the diagonal values are read or are assumed to be all ones.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.trsv!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.trsv!",
    "category": "function",
    "text": "trsv!(ul, tA, dA, A, b)\n\nOverwrite b with the solution to A*x = b or one of the other two variants determined by tA and ul. dA determines if the diagonal values are read or are assumed to be all ones. Returns the updated b.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.trsv",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.trsv",
    "category": "function",
    "text": "trsv(ul, tA, dA, A, b)\n\nReturns the solution to A*x = b or one of the other two variants determined by tA and ul. dA determines if the diagonal values are read or are assumed to be all ones.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.BLAS.set_num_threads",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.BLAS.set_num_threads",
    "category": "function",
    "text": "set_num_threads(n)\n\nSet the number of threads the BLAS library should use.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.I",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.I",
    "category": "constant",
    "text": "I\n\nAn object of type UniformScaling, representing an identity matrix of any size.\n\nExample\n\njulia> ones(5, 6) * I == ones(5, 6)\ntrue\n\njulia> [1 2im 3; 1im 2 3] * I\n2×3 Array{Complex{Int64},2}:\n 1+0im  0+2im  3+0im\n 0+1im  2+0im  3+0im\n\n\n\n"
},

{
    "location": "stdlib/linalg/#stdlib-blas-diag-1",
    "page": "Linear Algebra",
    "title": "Unit Diagonal",
    "category": "section",
    "text": "diag/dX Meaning\n\'N\' The diagonal values of the matrix X will be read.\n\'U\' The diagonal of the matrix X is assumed to be all ones.Base.LinAlg.BLAS.dotu\nBase.LinAlg.BLAS.dotc\nBase.LinAlg.BLAS.blascopy!\nBase.LinAlg.BLAS.nrm2\nBase.LinAlg.BLAS.asum\nBase.LinAlg.axpy!\nBase.LinAlg.BLAS.scal!\nBase.LinAlg.BLAS.scal\nBase.LinAlg.BLAS.ger!\nBase.LinAlg.BLAS.syr!\nBase.LinAlg.BLAS.syrk!\nBase.LinAlg.BLAS.syrk\nBase.LinAlg.BLAS.her!\nBase.LinAlg.BLAS.herk!\nBase.LinAlg.BLAS.herk\nBase.LinAlg.BLAS.gbmv!\nBase.LinAlg.BLAS.gbmv\nBase.LinAlg.BLAS.sbmv!\nBase.LinAlg.BLAS.sbmv(::Any, ::Any, ::Any, ::Any, ::Any)\nBase.LinAlg.BLAS.sbmv(::Any, ::Any, ::Any, ::Any)\nBase.LinAlg.BLAS.gemm!\nBase.LinAlg.BLAS.gemm(::Any, ::Any, ::Any, ::Any, ::Any)\nBase.LinAlg.BLAS.gemm(::Any, ::Any, ::Any, ::Any)\nBase.LinAlg.BLAS.gemv!\nBase.LinAlg.BLAS.gemv(::Any, ::Any, ::Any, ::Any)\nBase.LinAlg.BLAS.gemv(::Any, ::Any, ::Any)\nBase.LinAlg.BLAS.symm!\nBase.LinAlg.BLAS.symm(::Any, ::Any, ::Any, ::Any, ::Any)\nBase.LinAlg.BLAS.symm(::Any, ::Any, ::Any, ::Any)\nBase.LinAlg.BLAS.symv!\nBase.LinAlg.BLAS.symv(::Any, ::Any, ::Any, ::Any)\nBase.LinAlg.BLAS.symv(::Any, ::Any, ::Any)\nBase.LinAlg.BLAS.trmm!\nBase.LinAlg.BLAS.trmm\nBase.LinAlg.BLAS.trsm!\nBase.LinAlg.BLAS.trsm\nBase.LinAlg.BLAS.trmv!\nBase.LinAlg.BLAS.trmv\nBase.LinAlg.BLAS.trsv!\nBase.LinAlg.BLAS.trsv\nBase.LinAlg.BLAS.set_num_threads\nBase.LinAlg.I"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.gbtrf!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.gbtrf!",
    "category": "function",
    "text": "gbtrf!(kl, ku, m, AB) -> (AB, ipiv)\n\nCompute the LU factorization of a banded matrix AB. kl is the first subdiagonal containing a nonzero band, ku is the last superdiagonal containing one, and m is the first dimension of the matrix AB. Returns the LU factorization in-place and ipiv, the vector of pivots used.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.gbtrs!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.gbtrs!",
    "category": "function",
    "text": "gbtrs!(trans, kl, ku, m, AB, ipiv, B)\n\nSolve the equation AB * X = B. trans determines the orientation of AB. It may be N (no transpose), T (transpose), or C (conjugate transpose). kl is the first subdiagonal containing a nonzero band, ku is the last superdiagonal containing one, and m is the first dimension of the matrix AB. ipiv is the vector of pivots returned from gbtrf!. Returns the vector or matrix X, overwriting B in-place.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.gebal!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.gebal!",
    "category": "function",
    "text": "gebal!(job, A) -> (ilo, ihi, scale)\n\nBalance the matrix A before computing its eigensystem or Schur factorization. job can be one of N (A will not be permuted or scaled), P (A will only be permuted), S (A will only be scaled), or B (A will be both permuted and scaled). Modifies A in-place and returns ilo, ihi, and scale. If permuting was turned on, A[i,j] = 0 if j > i and 1 < j < ilo or j > ihi. scale contains information about the scaling/permutations performed.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.gebak!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.gebak!",
    "category": "function",
    "text": "gebak!(job, side, ilo, ihi, scale, V)\n\nTransform the eigenvectors V of a matrix balanced using gebal! to the unscaled/unpermuted eigenvectors of the original matrix. Modifies V in-place. side can be L (left eigenvectors are transformed) or R (right eigenvectors are transformed).\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.gebrd!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.gebrd!",
    "category": "function",
    "text": "gebrd!(A) -> (A, d, e, tauq, taup)\n\nReduce A in-place to bidiagonal form A = QBP\'. Returns A, containing the bidiagonal matrix B; d, containing the diagonal elements of B; e, containing the off-diagonal elements of B; tauq, containing the elementary reflectors representing Q; and taup, containing the elementary reflectors representing P.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.gelqf!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.gelqf!",
    "category": "function",
    "text": "gelqf!(A, tau)\n\nCompute the LQ factorization of A, A = LQ. tau contains scalars which parameterize the elementary reflectors of the factorization. tau must have length greater than or equal to the smallest dimension of A.\n\nReturns A and tau modified in-place.\n\n\n\ngelqf!(A) -> (A, tau)\n\nCompute the LQ factorization of A, A = LQ.\n\nReturns A, modified in-place, and tau, which contains scalars which parameterize the elementary reflectors of the factorization.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.geqlf!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.geqlf!",
    "category": "function",
    "text": "geqlf!(A, tau)\n\nCompute the QL factorization of A, A = QL. tau contains scalars which parameterize the elementary reflectors of the factorization. tau must have length greater than or equal to the smallest dimension of A.\n\nReturns A and tau modified in-place.\n\n\n\ngeqlf!(A) -> (A, tau)\n\nCompute the QL factorization of A, A = QL.\n\nReturns A, modified in-place, and tau, which contains scalars which parameterize the elementary reflectors of the factorization.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.geqrf!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.geqrf!",
    "category": "function",
    "text": "geqrf!(A, tau)\n\nCompute the QR factorization of A, A = QR. tau contains scalars which parameterize the elementary reflectors of the factorization. tau must have length greater than or equal to the smallest dimension of A.\n\nReturns A and tau modified in-place.\n\n\n\ngeqrf!(A) -> (A, tau)\n\nCompute the QR factorization of A, A = QR.\n\nReturns A, modified in-place, and tau, which contains scalars which parameterize the elementary reflectors of the factorization.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.geqp3!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.geqp3!",
    "category": "function",
    "text": "geqp3!(A, jpvt, tau)\n\nCompute the pivoted QR factorization of A, AP = QR using BLAS level 3. P is a pivoting matrix, represented by jpvt. tau stores the elementary reflectors. jpvt must have length length greater than or equal to n if A is an (m x n) matrix. tau must have length greater than or equal to the smallest dimension of A.\n\nA, jpvt, and tau are modified in-place.\n\n\n\ngeqp3!(A, jpvt) -> (A, jpvt, tau)\n\nCompute the pivoted QR factorization of A, AP = QR using BLAS level 3. P is a pivoting matrix, represented by jpvt. jpvt must have length greater than or equal to n if A is an (m x n) matrix.\n\nReturns A and jpvt, modified in-place, and tau, which stores the elementary reflectors.\n\n\n\ngeqp3!(A) -> (A, jpvt, tau)\n\nCompute the pivoted QR factorization of A, AP = QR using BLAS level 3.\n\nReturns A, modified in-place, jpvt, which represents the pivoting matrix P, and tau, which stores the elementary reflectors.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.gerqf!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.gerqf!",
    "category": "function",
    "text": "gerqf!(A, tau)\n\nCompute the RQ factorization of A, A = RQ. tau contains scalars which parameterize the elementary reflectors of the factorization. tau must have length greater than or equal to the smallest dimension of A.\n\nReturns A and tau modified in-place.\n\n\n\ngerqf!(A) -> (A, tau)\n\nCompute the RQ factorization of A, A = RQ.\n\nReturns A, modified in-place, and tau, which contains scalars which parameterize the elementary reflectors of the factorization.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.geqrt!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.geqrt!",
    "category": "function",
    "text": "geqrt!(A, T)\n\nCompute the blocked QR factorization of A, A = QR. T contains upper triangular block reflectors which parameterize the elementary reflectors of the factorization. The first dimension of T sets the block size and it must be between 1 and n. The second dimension of T must equal the smallest dimension of A.\n\nReturns A and T modified in-place.\n\n\n\ngeqrt!(A, nb) -> (A, T)\n\nCompute the blocked QR factorization of A, A = QR. nb sets the block size and it must be between 1 and n, the second dimension of A.\n\nReturns A, modified in-place, and T, which contains upper triangular block reflectors which parameterize the elementary reflectors of the factorization.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.geqrt3!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.geqrt3!",
    "category": "function",
    "text": "geqrt3!(A, T)\n\nRecursively computes the blocked QR factorization of A, A = QR. T contains upper triangular block reflectors which parameterize the elementary reflectors of the factorization.  The first dimension of T sets the block size and it must be between 1 and n. The second dimension of T must equal the smallest dimension of A.\n\nReturns A and T modified in-place.\n\n\n\ngeqrt3!(A) -> (A, T)\n\nRecursively computes the blocked QR factorization of A, A = QR.\n\nReturns A, modified in-place, and T, which contains upper triangular block reflectors which parameterize the elementary reflectors of the factorization.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.getrf!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.getrf!",
    "category": "function",
    "text": "getrf!(A) -> (A, ipiv, info)\n\nCompute the pivoted LU factorization of A, A = LU.\n\nReturns A, modified in-place, ipiv, the pivoting information, and an info code which indicates success (info = 0), a singular value in U (info = i, in which case U[i,i] is singular), or an error code (info < 0).\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.tzrzf!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.tzrzf!",
    "category": "function",
    "text": "tzrzf!(A) -> (A, tau)\n\nTransforms the upper trapezoidal matrix A to upper triangular form in-place. Returns A and tau, the scalar parameters for the elementary reflectors of the transformation.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.ormrz!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.ormrz!",
    "category": "function",
    "text": "ormrz!(side, trans, A, tau, C)\n\nMultiplies the matrix C by Q from the transformation supplied by tzrzf!. Depending on side or trans the multiplication can be left-sided (side = L, Q*C) or right-sided (side = R, C*Q) and Q can be unmodified (trans = N), transposed (trans = T), or conjugate transposed (trans = C). Returns matrix C which is modified in-place with the result of the multiplication.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.gels!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.gels!",
    "category": "function",
    "text": "gels!(trans, A, B) -> (F, B, ssr)\n\nSolves the linear equation A * X = B, A.\' * X =B, or A\' * X = B using a QR or LQ factorization. Modifies the matrix/vector B in place with the solution. A is overwritten with its QR or LQ factorization. trans may be one of N (no modification), T (transpose), or C (conjugate transpose). gels! searches for the minimum norm/least squares solution. A may be under or over determined. The solution is returned in B.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.gesv!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.gesv!",
    "category": "function",
    "text": "gesv!(A, B) -> (B, A, ipiv)\n\nSolves the linear equation A * X = B where A is a square matrix using the LU factorization of A. A is overwritten with its LU factorization and B is overwritten with the solution X. ipiv contains the pivoting information for the LU factorization of A.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.getrs!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.getrs!",
    "category": "function",
    "text": "getrs!(trans, A, ipiv, B)\n\nSolves the linear equation A * X = B, A.\' * X =B, or A\' * X = B for square A. Modifies the matrix/vector B in place with the solution. A is the LU factorization from getrf!, with ipiv the pivoting information. trans may be one of N (no modification), T (transpose), or C (conjugate transpose).\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.getri!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.getri!",
    "category": "function",
    "text": "getri!(A, ipiv)\n\nComputes the inverse of A, using its LU factorization found by getrf!. ipiv is the pivot information output and A contains the LU factorization of getrf!. A is overwritten with its inverse.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.gesvx!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.gesvx!",
    "category": "function",
    "text": "gesvx!(fact, trans, A, AF, ipiv, equed, R, C, B) -> (X, equed, R, C, B, rcond, ferr, berr, work)\n\nSolves the linear equation A * X = B (trans = N), A.\' * X =B (trans = T), or A\' * X = B (trans = C) using the LU factorization of A. fact may be E, in which case A will be equilibrated and copied to AF; F, in which case AF and ipiv from a previous LU factorization are inputs; or N, in which case A will be copied to AF and then factored. If fact = F, equed may be N, meaning A has not been equilibrated; R, meaning A was multiplied by diagm(R) from the left; C, meaning A was multiplied by diagm(C) from the right; or B, meaning A was multiplied by diagm(R) from the left and diagm(C) from the right. If fact = F and equed = R or B the elements of R must all be positive. If fact = F and equed = C or B the elements of C must all be positive.\n\nReturns the solution X; equed, which is an output if fact is not N, and describes the equilibration that was performed; R, the row equilibration diagonal; C, the column equilibration diagonal; B, which may be overwritten with its equilibrated form diagm(R)*B (if trans = N and equed = R,B) or diagm(C)*B (if trans = T,C and equed = C,B); rcond, the reciprocal condition number of A after equilbrating; ferr, the forward error bound for each solution vector in X; berr, the forward error bound for each solution vector in X; and work, the reciprocal pivot growth factor.\n\n\n\ngesvx!(A, B)\n\nThe no-equilibration, no-transpose simplification of gesvx!.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.gelsd!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.gelsd!",
    "category": "function",
    "text": "gelsd!(A, B, rcond) -> (B, rnk)\n\nComputes the least norm solution of A * X = B by finding the SVD factorization of A, then dividing-and-conquering the problem. B is overwritten with the solution X. Singular values below rcond will be treated as zero. Returns the solution in B and the effective rank of A in rnk.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.gelsy!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.gelsy!",
    "category": "function",
    "text": "gelsy!(A, B, rcond) -> (B, rnk)\n\nComputes the least norm solution of A * X = B by finding the full QR factorization of A, then dividing-and-conquering the problem. B is overwritten with the solution X. Singular values below rcond will be treated as zero. Returns the solution in B and the effective rank of A in rnk.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.gglse!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.gglse!",
    "category": "function",
    "text": "gglse!(A, c, B, d) -> (X,res)\n\nSolves the equation A * x = c where x is subject to the equality constraint B * x = d. Uses the formula ||c - A*x||^2 = 0 to solve. Returns X and the residual sum-of-squares.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.geev!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.geev!",
    "category": "function",
    "text": "geev!(jobvl, jobvr, A) -> (W, VL, VR)\n\nFinds the eigensystem of A. If jobvl = N, the left eigenvectors of A aren\'t computed. If jobvr = N, the right eigenvectors of A aren\'t computed. If jobvl = V or jobvr = V, the corresponding eigenvectors are computed. Returns the eigenvalues in W, the right eigenvectors in VR, and the left eigenvectors in VL.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.gesdd!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.gesdd!",
    "category": "function",
    "text": "gesdd!(job, A) -> (U, S, VT)\n\nFinds the singular value decomposition of A, A = U * S * V\', using a divide and conquer approach. If job = A, all the columns of U and the rows of V\' are computed. If job = N, no columns of U or rows of V\' are computed. If job = O, A is overwritten with the columns of (thin) U and the rows of (thin) V\'. If job = S, the columns of (thin) U and the rows of (thin) V\' are computed and returned separately.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.gesvd!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.gesvd!",
    "category": "function",
    "text": "gesvd!(jobu, jobvt, A) -> (U, S, VT)\n\nFinds the singular value decomposition of A, A = U * S * V\'. If jobu = A, all the columns of U are computed. If jobvt = A all the rows of V\' are computed. If jobu = N, no columns of U are computed. If jobvt = N no rows of V\' are computed. If jobu = O, A is overwritten with the columns of (thin) U. If jobvt = O, A is overwritten with the rows of (thin) V\'. If jobu = S, the columns of (thin) U are computed and returned separately. If jobvt = S the rows of (thin) V\' are computed and returned separately. jobu and jobvt can\'t both be O.\n\nReturns U, S, and Vt, where S are the singular values of A.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.ggsvd!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.ggsvd!",
    "category": "function",
    "text": "ggsvd!(jobu, jobv, jobq, A, B) -> (U, V, Q, alpha, beta, k, l, R)\n\nFinds the generalized singular value decomposition of A and B, U\'*A*Q = D1*R and V\'*B*Q = D2*R. D1 has alpha on its diagonal and D2 has beta on its diagonal. If jobu = U, the orthogonal/unitary matrix U is computed. If jobv = V the orthogonal/unitary matrix V is computed. If jobq = Q, the orthogonal/unitary matrix Q is computed. If jobu, jobv or jobq is N, that matrix is not computed. This function is only available in LAPACK versions prior to 3.6.0.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.ggsvd3!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.ggsvd3!",
    "category": "function",
    "text": "ggsvd3!(jobu, jobv, jobq, A, B) -> (U, V, Q, alpha, beta, k, l, R)\n\nFinds the generalized singular value decomposition of A and B, U\'*A*Q = D1*R and V\'*B*Q = D2*R. D1 has alpha on its diagonal and D2 has beta on its diagonal. If jobu = U, the orthogonal/unitary matrix U is computed. If jobv = V the orthogonal/unitary matrix V is computed. If jobq = Q, the orthogonal/unitary matrix Q is computed. If jobu, jobv, or jobq is N, that matrix is not computed. This function requires LAPACK 3.6.0.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.geevx!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.geevx!",
    "category": "function",
    "text": "geevx!(balanc, jobvl, jobvr, sense, A) -> (A, w, VL, VR, ilo, ihi, scale, abnrm, rconde, rcondv)\n\nFinds the eigensystem of A with matrix balancing. If jobvl = N, the left eigenvectors of A aren\'t computed. If jobvr = N, the right eigenvectors of A aren\'t computed. If jobvl = V or jobvr = V, the corresponding eigenvectors are computed. If balanc = N, no balancing is performed. If balanc = P, A is permuted but not scaled. If balanc = S, A is scaled but not permuted. If balanc = B, A is permuted and scaled. If sense = N, no reciprocal condition numbers are computed. If sense = E, reciprocal condition numbers are computed for the eigenvalues only. If sense = V, reciprocal condition numbers are computed for the right eigenvectors only. If sense = B, reciprocal condition numbers are computed for the right eigenvectors and the eigenvectors. If sense = E,B, the right and left eigenvectors must be computed.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.ggev!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.ggev!",
    "category": "function",
    "text": "ggev!(jobvl, jobvr, A, B) -> (alpha, beta, vl, vr)\n\nFinds the generalized eigendecomposition of A and B. If jobvl = N, the left eigenvectors aren\'t computed. If jobvr = N, the right eigenvectors aren\'t computed. If jobvl = V or jobvr = V, the corresponding eigenvectors are computed.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.gtsv!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.gtsv!",
    "category": "function",
    "text": "gtsv!(dl, d, du, B)\n\nSolves the equation A * X = B where A is a tridiagonal matrix with dl on the subdiagonal, d on the diagonal, and du on the superdiagonal.\n\nOverwrites B with the solution X and returns it.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.gttrf!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.gttrf!",
    "category": "function",
    "text": "gttrf!(dl, d, du) -> (dl, d, du, du2, ipiv)\n\nFinds the LU factorization of a tridiagonal matrix with dl on the subdiagonal, d on the diagonal, and du on the superdiagonal.\n\nModifies dl, d, and du in-place and returns them and the second superdiagonal du2 and the pivoting vector ipiv.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.gttrs!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.gttrs!",
    "category": "function",
    "text": "gttrs!(trans, dl, d, du, du2, ipiv, B)\n\nSolves the equation A * X = B (trans = N), A.\' * X = B (trans = T), or A\' * X = B (trans = C) using the LU factorization computed by gttrf!. B is overwritten with the solution X.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.orglq!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.orglq!",
    "category": "function",
    "text": "orglq!(A, tau, k = length(tau))\n\nExplicitly finds the matrix Q of a LQ factorization after calling gelqf! on A. Uses the output of gelqf!. A is overwritten by Q.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.orgqr!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.orgqr!",
    "category": "function",
    "text": "orgqr!(A, tau, k = length(tau))\n\nExplicitly finds the matrix Q of a QR factorization after calling geqrf! on A. Uses the output of geqrf!. A is overwritten by Q.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.orgql!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.orgql!",
    "category": "function",
    "text": "orgql!(A, tau, k = length(tau))\n\nExplicitly finds the matrix Q of a QL factorization after calling geqlf! on A. Uses the output of geqlf!. A is overwritten by Q.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.orgrq!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.orgrq!",
    "category": "function",
    "text": "orgrq!(A, tau, k = length(tau))\n\nExplicitly finds the matrix Q of a RQ factorization after calling gerqf! on A. Uses the output of gerqf!. A is overwritten by Q.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.ormlq!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.ormlq!",
    "category": "function",
    "text": "ormlq!(side, trans, A, tau, C)\n\nComputes Q * C (trans = N), Q.\' * C (trans = T), Q\' * C (trans = C) for side = L or the equivalent right-sided multiplication for side = R using Q from a LQ factorization of A computed using gelqf!. C is overwritten.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.ormqr!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.ormqr!",
    "category": "function",
    "text": "ormqr!(side, trans, A, tau, C)\n\nComputes Q * C (trans = N), Q.\' * C (trans = T), Q\' * C (trans = C) for side = L or the equivalent right-sided multiplication for side = R using Q from a QR factorization of A computed using geqrf!. C is overwritten.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.ormql!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.ormql!",
    "category": "function",
    "text": "ormql!(side, trans, A, tau, C)\n\nComputes Q * C (trans = N), Q.\' * C (trans = T), Q\' * C (trans = C) for side = L or the equivalent right-sided multiplication for side = R using Q from a QL factorization of A computed using geqlf!. C is overwritten.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.ormrq!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.ormrq!",
    "category": "function",
    "text": "ormrq!(side, trans, A, tau, C)\n\nComputes Q * C (trans = N), Q.\' * C (trans = T), Q\' * C (trans = C) for side = L or the equivalent right-sided multiplication for side = R using Q from a RQ factorization of A computed using gerqf!. C is overwritten.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.gemqrt!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.gemqrt!",
    "category": "function",
    "text": "gemqrt!(side, trans, V, T, C)\n\nComputes Q * C (trans = N), Q.\' * C (trans = T), Q\' * C (trans = C) for side = L or the equivalent right-sided multiplication for side = R using Q from a QR factorization of A computed using geqrt!. C is overwritten.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.posv!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.posv!",
    "category": "function",
    "text": "posv!(uplo, A, B) -> (A, B)\n\nFinds the solution to A * X = B where A is a symmetric or Hermitian positive definite matrix. If uplo = U the upper Cholesky decomposition of A is computed. If uplo = L the lower Cholesky decomposition of A is computed. A is overwritten by its Cholesky decomposition. B is overwritten with the solution X.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.potrf!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.potrf!",
    "category": "function",
    "text": "potrf!(uplo, A)\n\nComputes the Cholesky (upper if uplo = U, lower if uplo = L) decomposition of positive-definite matrix A. A is overwritten and returned with an info code.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.potri!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.potri!",
    "category": "function",
    "text": "potri!(uplo, A)\n\nComputes the inverse of positive-definite matrix A after calling potrf! to find its (upper if uplo = U, lower if uplo = L) Cholesky decomposition.\n\nA is overwritten by its inverse and returned.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.potrs!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.potrs!",
    "category": "function",
    "text": "potrs!(uplo, A, B)\n\nFinds the solution to A * X = B where A is a symmetric or Hermitian positive definite matrix whose Cholesky decomposition was computed by potrf!. If uplo = U the upper Cholesky decomposition of A was computed. If uplo = L the lower Cholesky decomposition of A was computed. B is overwritten with the solution X.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.pstrf!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.pstrf!",
    "category": "function",
    "text": "pstrf!(uplo, A, tol) -> (A, piv, rank, info)\n\nComputes the (upper if uplo = U, lower if uplo = L) pivoted Cholesky decomposition of positive-definite matrix A with a user-set tolerance tol. A is overwritten by its Cholesky decomposition.\n\nReturns A, the pivots piv, the rank of A, and an info code. If info = 0, the factorization succeeded. If info = i > 0, then A is indefinite or rank-deficient.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.ptsv!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.ptsv!",
    "category": "function",
    "text": "ptsv!(D, E, B)\n\nSolves A * X = B for positive-definite tridiagonal A. D is the diagonal of A and E is the off-diagonal. B is overwritten with the solution X and returned.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.pttrf!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.pttrf!",
    "category": "function",
    "text": "pttrf!(D, E)\n\nComputes the LDLt factorization of a positive-definite tridiagonal matrix with D as diagonal and E as off-diagonal. D and E are overwritten and returned.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.pttrs!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.pttrs!",
    "category": "function",
    "text": "pttrs!(D, E, B)\n\nSolves A * X = B for positive-definite tridiagonal A with diagonal D and off-diagonal E after computing A\'s LDLt factorization using pttrf!. B is overwritten with the solution X.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.trtri!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.trtri!",
    "category": "function",
    "text": "trtri!(uplo, diag, A)\n\nFinds the inverse of (upper if uplo = U, lower if uplo = L) triangular matrix A. If diag = N, A has non-unit diagonal elements. If diag = U, all diagonal elements of A are one. A is overwritten with its inverse.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.trtrs!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.trtrs!",
    "category": "function",
    "text": "trtrs!(uplo, trans, diag, A, B)\n\nSolves A * X = B (trans = N), A.\' * X = B (trans = T), or A\' * X = B (trans = C) for (upper if uplo = U, lower if uplo = L) triangular matrix A. If diag = N, A has non-unit diagonal elements. If diag = U, all diagonal elements of A are one. B is overwritten with the solution X.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.trcon!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.trcon!",
    "category": "function",
    "text": "trcon!(norm, uplo, diag, A)\n\nFinds the reciprocal condition number of (upper if uplo = U, lower if uplo = L) triangular matrix A. If diag = N, A has non-unit diagonal elements. If diag = U, all diagonal elements of A are one. If norm = I, the condition number is found in the infinity norm. If norm = O or 1, the condition number is found in the one norm.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.trevc!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.trevc!",
    "category": "function",
    "text": "trevc!(side, howmny, select, T, VL = similar(T), VR = similar(T))\n\nFinds the eigensystem of an upper triangular matrix T. If side = R, the right eigenvectors are computed. If side = L, the left eigenvectors are computed. If side = B, both sets are computed. If howmny = A, all eigenvectors are found. If howmny = B, all eigenvectors are found and backtransformed using VL and VR. If howmny = S, only the eigenvectors corresponding to the values in select are computed.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.trrfs!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.trrfs!",
    "category": "function",
    "text": "trrfs!(uplo, trans, diag, A, B, X, Ferr, Berr) -> (Ferr, Berr)\n\nEstimates the error in the solution to A * X = B (trans = N), A.\' * X = B (trans = T), A\' * X = B (trans = C) for side = L, or the equivalent equations a right-handed side = R X * A after computing X using trtrs!. If uplo = U, A is upper triangular. If uplo = L, A is lower triangular. If diag = N, A has non-unit diagonal elements. If diag = U, all diagonal elements of A are one. Ferr and Berr are optional inputs. Ferr is the forward error and Berr is the backward error, each component-wise.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.stev!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.stev!",
    "category": "function",
    "text": "stev!(job, dv, ev) -> (dv, Zmat)\n\nComputes the eigensystem for a symmetric tridiagonal matrix with dv as diagonal and ev as off-diagonal. If job = N only the eigenvalues are found and returned in dv. If job = V then the eigenvectors are also found and returned in Zmat.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.stebz!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.stebz!",
    "category": "function",
    "text": "stebz!(range, order, vl, vu, il, iu, abstol, dv, ev) -> (dv, iblock, isplit)\n\nComputes the eigenvalues for a symmetric tridiagonal matrix with dv as diagonal and ev as off-diagonal. If range = A, all the eigenvalues are found. If range = V, the eigenvalues in the half-open interval (vl, vu] are found. If range = I, the eigenvalues with indices between il and iu are found. If order = B, eigvalues are ordered within a block. If order = E, they are ordered across all the blocks. abstol can be set as a tolerance for convergence.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.stegr!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.stegr!",
    "category": "function",
    "text": "stegr!(jobz, range, dv, ev, vl, vu, il, iu) -> (w, Z)\n\nComputes the eigenvalues (jobz = N) or eigenvalues and eigenvectors (jobz = V) for a symmetric tridiagonal matrix with dv as diagonal and ev as off-diagonal. If range = A, all the eigenvalues are found. If range = V, the eigenvalues in the half-open interval (vl, vu] are found. If range = I, the eigenvalues with indices between il and iu are found. The eigenvalues are returned in w and the eigenvectors in Z.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.stein!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.stein!",
    "category": "function",
    "text": "stein!(dv, ev_in, w_in, iblock_in, isplit_in)\n\nComputes the eigenvectors for a symmetric tridiagonal matrix with dv as diagonal and ev_in as off-diagonal. w_in specifies the input eigenvalues for which to find corresponding eigenvectors. iblock_in specifies the submatrices corresponding to the eigenvalues in w_in. isplit_in specifies the splitting points between the submatrix blocks.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.syconv!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.syconv!",
    "category": "function",
    "text": "syconv!(uplo, A, ipiv) -> (A, work)\n\nConverts a symmetric matrix A (which has been factorized into a triangular matrix) into two matrices L and D. If uplo = U, A is upper triangular. If uplo = L, it is lower triangular. ipiv is the pivot vector from the triangular factorization. A is overwritten by L and D.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.sysv!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.sysv!",
    "category": "function",
    "text": "sysv!(uplo, A, B) -> (B, A, ipiv)\n\nFinds the solution to A * X = B for symmetric matrix A. If uplo = U, the upper half of A is stored. If uplo = L, the lower half is stored. B is overwritten by the solution X. A is overwritten by its Bunch-Kaufman factorization. ipiv contains pivoting information about the factorization.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.sytrf!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.sytrf!",
    "category": "function",
    "text": "sytrf!(uplo, A) -> (A, ipiv, info)\n\nComputes the Bunch-Kaufman factorization of a symmetric matrix A. If uplo = U, the upper half of A is stored. If uplo = L, the lower half is stored.\n\nReturns A, overwritten by the factorization, a pivot vector ipiv, and the error code info which is a non-negative integer. If info is positive the matrix is singular and the diagonal part of the factorization is exactly zero at position info.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.sytri!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.sytri!",
    "category": "function",
    "text": "sytri!(uplo, A, ipiv)\n\nComputes the inverse of a symmetric matrix A using the results of sytrf!. If uplo = U, the upper half of A is stored. If uplo = L, the lower half is stored. A is overwritten by its inverse.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.sytrs!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.sytrs!",
    "category": "function",
    "text": "sytrs!(uplo, A, ipiv, B)\n\nSolves the equation A * X = B for a symmetric matrix A using the results of sytrf!. If uplo = U, the upper half of A is stored. If uplo = L, the lower half is stored. B is overwritten by the solution X.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.hesv!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.hesv!",
    "category": "function",
    "text": "hesv!(uplo, A, B) -> (B, A, ipiv)\n\nFinds the solution to A * X = B for Hermitian matrix A. If uplo = U, the upper half of A is stored. If uplo = L, the lower half is stored. B is overwritten by the solution X. A is overwritten by its Bunch-Kaufman factorization. ipiv contains pivoting information about the factorization.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.hetrf!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.hetrf!",
    "category": "function",
    "text": "hetrf!(uplo, A) -> (A, ipiv, info)\n\nComputes the Bunch-Kaufman factorization of a Hermitian matrix A. If uplo = U, the upper half of A is stored. If uplo = L, the lower half is stored.\n\nReturns A, overwritten by the factorization, a pivot vector ipiv, and the error code info which is a non-negative integer. If info is positive the matrix is singular and the diagonal part of the factorization is exactly zero at position info.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.hetri!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.hetri!",
    "category": "function",
    "text": "hetri!(uplo, A, ipiv)\n\nComputes the inverse of a Hermitian matrix A using the results of sytrf!. If uplo = U, the upper half of A is stored. If uplo = L, the lower half is stored. A is overwritten by its inverse.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.hetrs!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.hetrs!",
    "category": "function",
    "text": "hetrs!(uplo, A, ipiv, B)\n\nSolves the equation A * X = B for a Hermitian matrix A using the results of sytrf!. If uplo = U, the upper half of A is stored. If uplo = L, the lower half is stored. B is overwritten by the solution X.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.syev!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.syev!",
    "category": "function",
    "text": "syev!(jobz, uplo, A)\n\nFinds the eigenvalues (jobz = N) or eigenvalues and eigenvectors (jobz = V) of a symmetric matrix A. If uplo = U, the upper triangle of A is used. If uplo = L, the lower triangle of A is used.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.syevr!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.syevr!",
    "category": "function",
    "text": "syevr!(jobz, range, uplo, A, vl, vu, il, iu, abstol) -> (W, Z)\n\nFinds the eigenvalues (jobz = N) or eigenvalues and eigenvectors (jobz = V) of a symmetric matrix A. If uplo = U, the upper triangle of A is used. If uplo = L, the lower triangle of A is used. If range = A, all the eigenvalues are found. If range = V, the eigenvalues in the half-open interval (vl, vu] are found. If range = I, the eigenvalues with indices between il and iu are found. abstol can be set as a tolerance for convergence.\n\nThe eigenvalues are returned in W and the eigenvectors in Z.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.sygvd!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.sygvd!",
    "category": "function",
    "text": "sygvd!(itype, jobz, uplo, A, B) -> (w, A, B)\n\nFinds the generalized eigenvalues (jobz = N) or eigenvalues and eigenvectors (jobz = V) of a symmetric matrix A and symmetric positive-definite matrix B. If uplo = U, the upper triangles of A and B are used. If uplo = L, the lower triangles of A and B are used. If itype = 1, the problem to solve is A * x = lambda * B * x. If itype = 2, the problem to solve is A * B * x = lambda * x. If itype = 3, the problem to solve is B * A * x = lambda * x.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.bdsqr!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.bdsqr!",
    "category": "function",
    "text": "bdsqr!(uplo, d, e_, Vt, U, C) -> (d, Vt, U, C)\n\nComputes the singular value decomposition of a bidiagonal matrix with d on the diagonal and e_ on the off-diagonal. If uplo = U, e_ is the superdiagonal. If uplo = L, e_ is the subdiagonal. Can optionally also compute the product Q\' * C.\n\nReturns the singular values in d, and the matrix C overwritten with Q\' * C.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.bdsdc!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.bdsdc!",
    "category": "function",
    "text": "bdsdc!(uplo, compq, d, e_) -> (d, e, u, vt, q, iq)\n\nComputes the singular value decomposition of a bidiagonal matrix with d on the diagonal and e_ on the off-diagonal using a divide and conqueq method. If uplo = U, e_ is the superdiagonal. If uplo = L, e_ is the subdiagonal. If compq = N, only the singular values are found. If compq = I, the singular values and vectors are found. If compq = P, the singular values and vectors are found in compact form. Only works for real types.\n\nReturns the singular values in d, and if compq = P, the compact singular vectors in iq.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.gecon!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.gecon!",
    "category": "function",
    "text": "gecon!(normtype, A, anorm)\n\nFinds the reciprocal condition number of matrix A. If normtype = I, the condition number is found in the infinity norm. If normtype = O or 1, the condition number is found in the one norm. A must be the result of getrf! and anorm is the norm of A in the relevant norm.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.gehrd!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.gehrd!",
    "category": "function",
    "text": "gehrd!(ilo, ihi, A) -> (A, tau)\n\nConverts a matrix A to Hessenberg form. If A is balanced with gebal! then ilo and ihi are the outputs of gebal!. Otherwise they should be ilo = 1 and ihi = size(A,2). tau contains the elementary reflectors of the factorization.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.orghr!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.orghr!",
    "category": "function",
    "text": "orghr!(ilo, ihi, A, tau)\n\nExplicitly finds Q, the orthogonal/unitary matrix from gehrd!. ilo, ihi, A, and tau must correspond to the input/output to gehrd!.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.gees!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.gees!",
    "category": "function",
    "text": "gees!(jobvs, A) -> (A, vs, w)\n\nComputes the eigenvalues (jobvs = N) or the eigenvalues and Schur vectors (jobvs = V) of matrix A. A is overwritten by its Schur form.\n\nReturns A, vs containing the Schur vectors, and w, containing the eigenvalues.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.gges!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.gges!",
    "category": "function",
    "text": "gges!(jobvsl, jobvsr, A, B) -> (A, B, alpha, beta, vsl, vsr)\n\nComputes the generalized eigenvalues, generalized Schur form, left Schur vectors (jobsvl = V), or right Schur vectors (jobvsr = V) of A and B.\n\nThe generalized eigenvalues are returned in alpha and beta. The left Schur vectors are returned in vsl and the right Schur vectors are returned in vsr.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.trexc!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.trexc!",
    "category": "function",
    "text": "trexc!(compq, ifst, ilst, T, Q) -> (T, Q)\n\nReorder the Schur factorization of a matrix. If compq = V, the Schur vectors Q are reordered. If compq = N they are not modified. ifst and ilst specify the reordering of the vectors.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.trsen!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.trsen!",
    "category": "function",
    "text": "trsen!(compq, job, select, T, Q) -> (T, Q, w)\n\nReorder the Schur factorization of a matrix and optionally finds reciprocal condition numbers. If job = N, no condition numbers are found. If job = E, only the condition number for this cluster of eigenvalues is found. If job = V, only the condition number for the invariant subspace is found. If job = B then the condition numbers for the cluster and subspace are found. If compq = V the Schur vectors Q are updated. If compq = N the Schur vectors are not modified. select determines which eigenvalues are in the cluster.\n\nReturns T, Q, and reordered eigenvalues in w.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.tgsen!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.tgsen!",
    "category": "function",
    "text": "tgsen!(select, S, T, Q, Z) -> (S, T, alpha, beta, Q, Z)\n\nReorders the vectors of a generalized Schur decomposition. select specifices the eigenvalues in each cluster.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#Base.LinAlg.LAPACK.trsyl!",
    "page": "Linear Algebra",
    "title": "Base.LinAlg.LAPACK.trsyl!",
    "category": "function",
    "text": "trsyl!(transa, transb, A, B, C, isgn=1) -> (C, scale)\n\nSolves the Sylvester matrix equation A * X +/- X * B = scale*C where A and B are both quasi-upper triangular. If transa = N, A is not modified. If transa = T, A is transposed. If transa = C, A is conjugate transposed. Similarly for transb and B. If isgn = 1, the equation A * X + X * B = scale * C is solved. If isgn = -1, the equation A * X - X * B = scale * C is solved.\n\nReturns X (overwriting C) and scale.\n\n\n\n"
},

{
    "location": "stdlib/linalg/#LAPACK-Functions-1",
    "page": "Linear Algebra",
    "title": "LAPACK Functions",
    "category": "section",
    "text": "Base.LinAlg.LAPACK provides wrappers for some of the LAPACK functions for linear algebra.  Those functions that overwrite one of the input arrays have names ending in \'!\'.Usually a function has 4 methods defined, one each for Float64, Float32, Complex128 and Complex64 arrays.Note that the LAPACK API provided by Julia can and will change in the future. Since this API is not user-facing, there is no commitment to support/deprecate this specific set of functions in future releases.Base.LinAlg.LAPACK.gbtrf!\nBase.LinAlg.LAPACK.gbtrs!\nBase.LinAlg.LAPACK.gebal!\nBase.LinAlg.LAPACK.gebak!\nBase.LinAlg.LAPACK.gebrd!\nBase.LinAlg.LAPACK.gelqf!\nBase.LinAlg.LAPACK.geqlf!\nBase.LinAlg.LAPACK.geqrf!\nBase.LinAlg.LAPACK.geqp3!\nBase.LinAlg.LAPACK.gerqf!\nBase.LinAlg.LAPACK.geqrt!\nBase.LinAlg.LAPACK.geqrt3!\nBase.LinAlg.LAPACK.getrf!\nBase.LinAlg.LAPACK.tzrzf!\nBase.LinAlg.LAPACK.ormrz!\nBase.LinAlg.LAPACK.gels!\nBase.LinAlg.LAPACK.gesv!\nBase.LinAlg.LAPACK.getrs!\nBase.LinAlg.LAPACK.getri!\nBase.LinAlg.LAPACK.gesvx!\nBase.LinAlg.LAPACK.gelsd!\nBase.LinAlg.LAPACK.gelsy!\nBase.LinAlg.LAPACK.gglse!\nBase.LinAlg.LAPACK.geev!\nBase.LinAlg.LAPACK.gesdd!\nBase.LinAlg.LAPACK.gesvd!\nBase.LinAlg.LAPACK.ggsvd!\nBase.LinAlg.LAPACK.ggsvd3!\nBase.LinAlg.LAPACK.geevx!\nBase.LinAlg.LAPACK.ggev!\nBase.LinAlg.LAPACK.gtsv!\nBase.LinAlg.LAPACK.gttrf!\nBase.LinAlg.LAPACK.gttrs!\nBase.LinAlg.LAPACK.orglq!\nBase.LinAlg.LAPACK.orgqr!\nBase.LinAlg.LAPACK.orgql!\nBase.LinAlg.LAPACK.orgrq!\nBase.LinAlg.LAPACK.ormlq!\nBase.LinAlg.LAPACK.ormqr!\nBase.LinAlg.LAPACK.ormql!\nBase.LinAlg.LAPACK.ormrq!\nBase.LinAlg.LAPACK.gemqrt!\nBase.LinAlg.LAPACK.posv!\nBase.LinAlg.LAPACK.potrf!\nBase.LinAlg.LAPACK.potri!\nBase.LinAlg.LAPACK.potrs!\nBase.LinAlg.LAPACK.pstrf!\nBase.LinAlg.LAPACK.ptsv!\nBase.LinAlg.LAPACK.pttrf!\nBase.LinAlg.LAPACK.pttrs!\nBase.LinAlg.LAPACK.trtri!\nBase.LinAlg.LAPACK.trtrs!\nBase.LinAlg.LAPACK.trcon!\nBase.LinAlg.LAPACK.trevc!\nBase.LinAlg.LAPACK.trrfs!\nBase.LinAlg.LAPACK.stev!\nBase.LinAlg.LAPACK.stebz!\nBase.LinAlg.LAPACK.stegr!\nBase.LinAlg.LAPACK.stein!\nBase.LinAlg.LAPACK.syconv!\nBase.LinAlg.LAPACK.sysv!\nBase.LinAlg.LAPACK.sytrf!\nBase.LinAlg.LAPACK.sytri!\nBase.LinAlg.LAPACK.sytrs!\nBase.LinAlg.LAPACK.hesv!\nBase.LinAlg.LAPACK.hetrf!\nBase.LinAlg.LAPACK.hetri!\nBase.LinAlg.LAPACK.hetrs!\nBase.LinAlg.LAPACK.syev!\nBase.LinAlg.LAPACK.syevr!\nBase.LinAlg.LAPACK.sygvd!\nBase.LinAlg.LAPACK.bdsqr!\nBase.LinAlg.LAPACK.bdsdc!\nBase.LinAlg.LAPACK.gecon!\nBase.LinAlg.LAPACK.gehrd!\nBase.LinAlg.LAPACK.orghr!\nBase.LinAlg.LAPACK.gees!\nBase.LinAlg.LAPACK.gges!\nBase.LinAlg.LAPACK.trexc!\nBase.LinAlg.LAPACK.trsen!\nBase.LinAlg.LAPACK.tgsen!\nBase.LinAlg.LAPACK.trsyl!"
},

{
    "location": "stdlib/constants/#",
    "page": "Constants",
    "title": "Constants",
    "category": "page",
    "text": ""
},

{
    "location": "stdlib/constants/#Core.nothing",
    "page": "Constants",
    "title": "Core.nothing",
    "category": "constant",
    "text": "nothing\n\nThe singleton instance of type Void, used by convention when there is no value to return (as in a C void function). Can be converted to an empty Nullable value.\n\n\n\n"
},

{
    "location": "stdlib/constants/#Base.PROGRAM_FILE",
    "page": "Constants",
    "title": "Base.PROGRAM_FILE",
    "category": "constant",
    "text": "PROGRAM_FILE\n\nA string containing the script name passed to Julia from the command line. Note that the script name remains unchanged from within included files. Alternatively see @__FILE__.\n\n\n\n"
},

{
    "location": "stdlib/constants/#Base.ARGS",
    "page": "Constants",
    "title": "Base.ARGS",
    "category": "constant",
    "text": "ARGS\n\nAn array of the command line arguments passed to Julia, as strings.\n\n\n\n"
},

{
    "location": "stdlib/constants/#Base.C_NULL",
    "page": "Constants",
    "title": "Base.C_NULL",
    "category": "constant",
    "text": "C_NULL\n\nThe C null pointer constant, sometimes used when calling external code.\n\n\n\n"
},

{
    "location": "stdlib/constants/#Base.VERSION",
    "page": "Constants",
    "title": "Base.VERSION",
    "category": "constant",
    "text": "VERSION\n\nA VersionNumber object describing which version of Julia is in use. For details see Version Number Literals.\n\n\n\n"
},

{
    "location": "stdlib/constants/#Base.LOAD_PATH",
    "page": "Constants",
    "title": "Base.LOAD_PATH",
    "category": "constant",
    "text": "LOAD_PATH\n\nAn array of paths as strings or custom loader objects for the require function and using and import statements to consider when loading code. To create a custom loader type, define the type and then add appropriate methods to the Base.load_hook function with the following signature:\n\nBase.load_hook(loader::Loader, name::String, found::Any)\n\nThe loader argument is the current value in LOAD_PATH, name is the name of the module to load, and found is the path of any previously found code to provide name. If no provider has been found earlier in LOAD_PATH then the value of found will be nothing. Custom loader functionality is experimental and may break or change in Julia 1.0.\n\n\n\n"
},

{
    "location": "stdlib/constants/#Base.JULIA_HOME",
    "page": "Constants",
    "title": "Base.JULIA_HOME",
    "category": "constant",
    "text": "JULIA_HOME\n\nA string containing the full path to the directory containing the julia executable.\n\n\n\n"
},

{
    "location": "stdlib/constants/#Core.ANY",
    "page": "Constants",
    "title": "Core.ANY",
    "category": "constant",
    "text": "ANY\n\nEquivalent to Any for dispatch purposes, but signals the compiler to skip code generation specialization for that field.\n\n\n\n"
},

{
    "location": "stdlib/constants/#Base.Sys.CPU_CORES",
    "page": "Constants",
    "title": "Base.Sys.CPU_CORES",
    "category": "constant",
    "text": "Sys.CPU_CORES\n\nThe number of logical CPU cores available in the system.\n\nSee the Hwloc.jl package for extended information, including number of physical cores.\n\n\n\n"
},

{
    "location": "stdlib/constants/#Base.Sys.WORD_SIZE",
    "page": "Constants",
    "title": "Base.Sys.WORD_SIZE",
    "category": "constant",
    "text": "Sys.WORD_SIZE\n\nStandard word size on the current machine, in bits.\n\n\n\n"
},

{
    "location": "stdlib/constants/#Base.Sys.KERNEL",
    "page": "Constants",
    "title": "Base.Sys.KERNEL",
    "category": "constant",
    "text": "Sys.KERNEL\n\nA symbol representing the name of the operating system, as returned by uname of the build configuration.\n\n\n\n"
},

{
    "location": "stdlib/constants/#Base.Sys.ARCH",
    "page": "Constants",
    "title": "Base.Sys.ARCH",
    "category": "constant",
    "text": "Sys.ARCH\n\nA symbol representing the architecture of the build configuration.\n\n\n\n"
},

{
    "location": "stdlib/constants/#Base.Sys.MACHINE",
    "page": "Constants",
    "title": "Base.Sys.MACHINE",
    "category": "constant",
    "text": "Sys.MACHINE\n\nA string containing the build triple.\n\n\n\n"
},

{
    "location": "stdlib/constants/#lib-constants-1",
    "page": "Constants",
    "title": "Constants",
    "category": "section",
    "text": "Core.nothing\nBase.PROGRAM_FILE\nBase.ARGS\nBase.C_NULL\nBase.VERSION\nBase.LOAD_PATH\nBase.JULIA_HOME\nCore.ANY\nBase.Sys.CPU_CORES\nBase.Sys.WORD_SIZE\nBase.Sys.KERNEL\nBase.Sys.ARCH\nBase.Sys.MACHINESee also:STDIN\nSTDOUT\nSTDERR\nENV\nENDIAN_BOM\nLibc.MS_ASYNC\nLibc.MS_INVALIDATE\nLibc.MS_SYNC\nLibdl.DL_LOAD_PATH\nLibdl.RTLD_DEEPBIND\nLibdl.RTLD_LOCAL\nLibdl.RTLD_NOLOAD\nLibdl.RTLD_LAZY\nLibdl.RTLD_NOW\nLibdl.RTLD_GLOBAL\nLibdl.RTLD_NODELETE\nLibdl.RTLD_FIRST"
},

{
    "location": "stdlib/file/#",
    "page": "Filesystem",
    "title": "Filesystem",
    "category": "page",
    "text": ""
},

{
    "location": "stdlib/file/#Base.Filesystem.pwd",
    "page": "Filesystem",
    "title": "Base.Filesystem.pwd",
    "category": "function",
    "text": "pwd() -> AbstractString\n\nGet the current working directory.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.cd-Tuple{AbstractString}",
    "page": "Filesystem",
    "title": "Base.Filesystem.cd",
    "category": "method",
    "text": "cd(dir::AbstractString=homedir())\n\nSet the current working directory.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.cd-Tuple{Function}",
    "page": "Filesystem",
    "title": "Base.Filesystem.cd",
    "category": "method",
    "text": "cd(f::Function, dir::AbstractString=homedir())\n\nTemporarily changes the current working directory and applies function f before returning.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.readdir",
    "page": "Filesystem",
    "title": "Base.Filesystem.readdir",
    "category": "function",
    "text": "readdir(dir::AbstractString=\".\") -> Vector{String}\n\nReturns the files and directories in the directory dir (or the current working directory if not given).\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.walkdir",
    "page": "Filesystem",
    "title": "Base.Filesystem.walkdir",
    "category": "function",
    "text": "walkdir(dir; topdown=true, follow_symlinks=false, onerror=throw)\n\nThe walkdir method returns an iterator that walks the directory tree of a directory. The iterator returns a tuple containing (rootpath, dirs, files). The directory tree can be traversed top-down or bottom-up. If walkdir encounters a SystemError it will rethrow the error by default. A custom error handling function can be provided through onerror keyword argument. onerror is called with a SystemError as argument.\n\nfor (root, dirs, files) in walkdir(\".\")\n    println(\"Directories in $root\")\n    for dir in dirs\n        println(joinpath(root, dir)) # path to directories\n    end\n    println(\"Files in $root\")\n    for file in files\n        println(joinpath(root, file)) # path to files\n    end\nend\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.mkdir",
    "page": "Filesystem",
    "title": "Base.Filesystem.mkdir",
    "category": "function",
    "text": "mkdir(path::AbstractString, mode::Unsigned=0o777)\n\nMake a new directory with name path and permissions mode. mode defaults to 0o777, modified by the current file creation mask. This function never creates more than one directory. If the directory already exists, or some intermediate directories do not exist, this function throws an error. See mkpath for a function which creates all required intermediate directories.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.mkpath",
    "page": "Filesystem",
    "title": "Base.Filesystem.mkpath",
    "category": "function",
    "text": "mkpath(path::AbstractString, mode::Unsigned=0o777)\n\nCreate all directories in the given path, with permissions mode. mode defaults to 0o777, modified by the current file creation mask.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.symlink",
    "page": "Filesystem",
    "title": "Base.Filesystem.symlink",
    "category": "function",
    "text": "symlink(target::AbstractString, link::AbstractString)\n\nCreates a symbolic link to target with the name link.\n\nnote: Note\nThis function raises an error under operating systems that do not support soft symbolic links, such as Windows XP.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.readlink",
    "page": "Filesystem",
    "title": "Base.Filesystem.readlink",
    "category": "function",
    "text": "readlink(path::AbstractString) -> AbstractString\n\nReturns the target location a symbolic link path points to.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.chmod",
    "page": "Filesystem",
    "title": "Base.Filesystem.chmod",
    "category": "function",
    "text": "chmod(path::AbstractString, mode::Integer; recursive::Bool=false)\n\nChange the permissions mode of path to mode. Only integer modes (e.g. 0o777) are currently supported. If recursive=true and the path is a directory all permissions in that directory will be recursively changed.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.chown",
    "page": "Filesystem",
    "title": "Base.Filesystem.chown",
    "category": "function",
    "text": "chown(path::AbstractString, owner::Integer, group::Integer=-1)\n\nChange the owner and/or group of path to owner and/or group. If the value entered for owner or group is -1 the corresponding ID will not change. Only integer owners and groups are currently supported.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.stat",
    "page": "Filesystem",
    "title": "Base.stat",
    "category": "function",
    "text": "stat(file)\n\nReturns a structure whose fields contain information about the file. The fields of the structure are:\n\nName Description\nsize The size (in bytes) of the file\ndevice ID of the device that contains the file\ninode The inode number of the file\nmode The protection mode of the file\nnlink The number of hard links to the file\nuid The user id of the owner of the file\ngid The group id of the file owner\nrdev If this file refers to a device, the ID of the device it refers to\nblksize The file-system preferred block size for the file\nblocks The number of such blocks allocated\nmtime Unix timestamp of when the file was last modified\nctime Unix timestamp of when the file was created\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.lstat",
    "page": "Filesystem",
    "title": "Base.Filesystem.lstat",
    "category": "function",
    "text": "lstat(file)\n\nLike stat, but for symbolic links gets the info for the link itself rather than the file it refers to. This function must be called on a file path rather than a file object or a file descriptor.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.ctime",
    "page": "Filesystem",
    "title": "Base.Filesystem.ctime",
    "category": "function",
    "text": "ctime(file)\n\nEquivalent to stat(file).ctime\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.mtime",
    "page": "Filesystem",
    "title": "Base.Filesystem.mtime",
    "category": "function",
    "text": "mtime(file)\n\nEquivalent to stat(file).mtime.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.filemode",
    "page": "Filesystem",
    "title": "Base.Filesystem.filemode",
    "category": "function",
    "text": "filemode(file)\n\nEquivalent to stat(file).mode\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.filesize",
    "page": "Filesystem",
    "title": "Base.Filesystem.filesize",
    "category": "function",
    "text": "filesize(path...)\n\nEquivalent to stat(file).size.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.uperm",
    "page": "Filesystem",
    "title": "Base.Filesystem.uperm",
    "category": "function",
    "text": "uperm(file)\n\nGets the permissions of the owner of the file as a bitfield of\n\nValue Description\n01 Execute Permission\n02 Write Permission\n04 Read Permission\n\nFor allowed arguments, see stat.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.gperm",
    "page": "Filesystem",
    "title": "Base.Filesystem.gperm",
    "category": "function",
    "text": "gperm(file)\n\nLike uperm but gets the permissions of the group owning the file.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.operm",
    "page": "Filesystem",
    "title": "Base.Filesystem.operm",
    "category": "function",
    "text": "operm(file)\n\nLike uperm but gets the permissions for people who neither own the file nor are a member of the group owning the file\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.cp",
    "page": "Filesystem",
    "title": "Base.Filesystem.cp",
    "category": "function",
    "text": "cp(src::AbstractString, dst::AbstractString; remove_destination::Bool=false, follow_symlinks::Bool=false)\n\nCopy the file, link, or directory from src to dest. remove_destination=true will first remove an existing dst.\n\nIf follow_symlinks=false, and src is a symbolic link, dst will be created as a symbolic link. If follow_symlinks=true and src is a symbolic link, dst will be a copy of the file or directory src refers to.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.download",
    "page": "Filesystem",
    "title": "Base.download",
    "category": "function",
    "text": "download(url::AbstractString, [localfile::AbstractString])\n\nDownload a file from the given url, optionally renaming it to the given local file name. Note that this function relies on the availability of external tools such as curl, wget or fetch to download the file and is provided for convenience. For production use or situations in which more options are needed, please use a package that provides the desired functionality instead.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.mv",
    "page": "Filesystem",
    "title": "Base.Filesystem.mv",
    "category": "function",
    "text": "mv(src::AbstractString, dst::AbstractString; remove_destination::Bool=false)\n\nMove the file, link, or directory from src to dst. remove_destination=true will first remove an existing dst.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.rm",
    "page": "Filesystem",
    "title": "Base.Filesystem.rm",
    "category": "function",
    "text": "rm(path::AbstractString; force::Bool=false, recursive::Bool=false)\n\nDelete the file, link, or empty directory at the given path. If force=true is passed, a non-existing path is not treated as error. If recursive=true is passed and the path is a directory, then all contents are removed recursively.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.touch",
    "page": "Filesystem",
    "title": "Base.Filesystem.touch",
    "category": "function",
    "text": "touch(path::AbstractString)\n\nUpdate the last-modified timestamp on a file to the current time.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.tempname",
    "page": "Filesystem",
    "title": "Base.Filesystem.tempname",
    "category": "function",
    "text": "tempname()\n\nGenerate a unique temporary file path.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.tempdir",
    "page": "Filesystem",
    "title": "Base.Filesystem.tempdir",
    "category": "function",
    "text": "tempdir()\n\nObtain the path of a temporary directory (possibly shared with other processes).\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.mktemp-Tuple{Any}",
    "page": "Filesystem",
    "title": "Base.Filesystem.mktemp",
    "category": "method",
    "text": "mktemp(parent=tempdir())\n\nReturns (path, io), where path is the path of a new temporary file in parent and io is an open file object for this path.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.mktemp-Tuple{Function,Any}",
    "page": "Filesystem",
    "title": "Base.Filesystem.mktemp",
    "category": "method",
    "text": "mktemp(f::Function, parent=tempdir())\n\nApply the function f to the result of mktemp(parent) and remove the temporary file upon completion.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.mktempdir-Tuple{Any}",
    "page": "Filesystem",
    "title": "Base.Filesystem.mktempdir",
    "category": "method",
    "text": "mktempdir(parent=tempdir())\n\nCreate a temporary directory in the parent directory and return its path. If parent does not exist, throw an error.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.mktempdir-Tuple{Function,Any}",
    "page": "Filesystem",
    "title": "Base.Filesystem.mktempdir",
    "category": "method",
    "text": "mktempdir(f::Function, parent=tempdir())\n\nApply the function f to the result of mktempdir(parent) and remove the temporary directory upon completion.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.isblockdev",
    "page": "Filesystem",
    "title": "Base.Filesystem.isblockdev",
    "category": "function",
    "text": "isblockdev(path) -> Bool\n\nReturns true if path is a block device, false otherwise.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.ischardev",
    "page": "Filesystem",
    "title": "Base.Filesystem.ischardev",
    "category": "function",
    "text": "ischardev(path) -> Bool\n\nReturns true if path is a character device, false otherwise.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.isdir",
    "page": "Filesystem",
    "title": "Base.Filesystem.isdir",
    "category": "function",
    "text": "isdir(path) -> Bool\n\nReturns true if path is a directory, false otherwise.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.isfifo",
    "page": "Filesystem",
    "title": "Base.Filesystem.isfifo",
    "category": "function",
    "text": "isfifo(path) -> Bool\n\nReturns true if path is a FIFO, false otherwise.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.isfile",
    "page": "Filesystem",
    "title": "Base.Filesystem.isfile",
    "category": "function",
    "text": "isfile(path) -> Bool\n\nReturns true if path is a regular file, false otherwise.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.islink",
    "page": "Filesystem",
    "title": "Base.Filesystem.islink",
    "category": "function",
    "text": "islink(path) -> Bool\n\nReturns true if path is a symbolic link, false otherwise.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.ismount",
    "page": "Filesystem",
    "title": "Base.Filesystem.ismount",
    "category": "function",
    "text": "ismount(path) -> Bool\n\nReturns true if path is a mount point, false otherwise.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.ispath",
    "page": "Filesystem",
    "title": "Base.Filesystem.ispath",
    "category": "function",
    "text": "ispath(path) -> Bool\n\nReturns true if path is a valid filesystem path, false otherwise.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.issetgid",
    "page": "Filesystem",
    "title": "Base.Filesystem.issetgid",
    "category": "function",
    "text": "issetgid(path) -> Bool\n\nReturns true if path has the setgid flag set, false otherwise.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.issetuid",
    "page": "Filesystem",
    "title": "Base.Filesystem.issetuid",
    "category": "function",
    "text": "issetuid(path) -> Bool\n\nReturns true if path has the setuid flag set, false otherwise.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.issocket",
    "page": "Filesystem",
    "title": "Base.Filesystem.issocket",
    "category": "function",
    "text": "issocket(path) -> Bool\n\nReturns true if path is a socket, false otherwise.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.issticky",
    "page": "Filesystem",
    "title": "Base.Filesystem.issticky",
    "category": "function",
    "text": "issticky(path) -> Bool\n\nReturns true if path has the sticky bit set, false otherwise.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.homedir",
    "page": "Filesystem",
    "title": "Base.Filesystem.homedir",
    "category": "function",
    "text": "homedir() -> AbstractString\n\nReturn the current user\'s home directory.\n\nnote: Note\nhomedir determines the home directory via libuv\'s uv_os_homedir. For details (for example on how to specify the home directory via environment variables), see the uv_os_homedir documentation.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.dirname",
    "page": "Filesystem",
    "title": "Base.Filesystem.dirname",
    "category": "function",
    "text": "dirname(path::AbstractString) -> AbstractString\n\nGet the directory part of a path.\n\njulia> dirname(\"/home/myuser\")\n\"/home\"\n\nSee also: basename\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.basename",
    "page": "Filesystem",
    "title": "Base.Filesystem.basename",
    "category": "function",
    "text": "basename(path::AbstractString) -> AbstractString\n\nGet the file name part of a path.\n\njulia> basename(\"/home/myuser/example.jl\")\n\"example.jl\"\n\nSee also: dirname\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.@__FILE__",
    "page": "Filesystem",
    "title": "Base.@__FILE__",
    "category": "macro",
    "text": "@__FILE__ -> AbstractString\n\n@__FILE__ expands to a string with the absolute file path of the file containing the macro. Returns nothing if run from a REPL or an empty string if evaluated by julia -e <expr>. Alternatively see PROGRAM_FILE.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.@__DIR__",
    "page": "Filesystem",
    "title": "Base.@__DIR__",
    "category": "macro",
    "text": "@__DIR__ -> AbstractString\n\n@__DIR__ expands to a string with the directory part of the absolute path of the file containing the macro. Returns nothing if run from a REPL or an empty string if evaluated by julia -e <expr>.\n\n\n\n"
},

{
    "location": "stdlib/file/#@__LINE__",
    "page": "Filesystem",
    "title": "@__LINE__",
    "category": "macro",
    "text": "@__LINE__ -> Int\n\n@__LINE__ expands to the line number of the call-site.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.isabspath",
    "page": "Filesystem",
    "title": "Base.Filesystem.isabspath",
    "category": "function",
    "text": "isabspath(path::AbstractString) -> Bool\n\nDetermines whether a path is absolute (begins at the root directory).\n\njulia> isabspath(\"/home\")\ntrue\n\njulia> isabspath(\"home\")\nfalse\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.isdirpath",
    "page": "Filesystem",
    "title": "Base.Filesystem.isdirpath",
    "category": "function",
    "text": "isdirpath(path::AbstractString) -> Bool\n\nDetermines whether a path refers to a directory (for example, ends with a path separator).\n\njulia> isdirpath(\"/home\")\nfalse\n\njulia> isdirpath(\"/home/\")\ntrue\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.joinpath",
    "page": "Filesystem",
    "title": "Base.Filesystem.joinpath",
    "category": "function",
    "text": "joinpath(parts...) -> AbstractString\n\nJoin path components into a full path. If some argument is an absolute path, then prior components are dropped.\n\njulia> joinpath(\"/home/myuser\",\"example.jl\")\n\"/home/myuser/example.jl\"\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.abspath",
    "page": "Filesystem",
    "title": "Base.Filesystem.abspath",
    "category": "function",
    "text": "abspath(path::AbstractString) -> AbstractString\n\nConvert a path to an absolute path by adding the current directory if necessary.\n\n\n\nabspath(path::AbstractString, paths::AbstractString...) -> AbstractString\n\nConvert a set of paths to an absolute path by joining them together and adding the current directory if necessary. Equivalent to abspath(joinpath(path, paths...)).\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.normpath",
    "page": "Filesystem",
    "title": "Base.Filesystem.normpath",
    "category": "function",
    "text": "normpath(path::AbstractString) -> AbstractString\n\nNormalize a path, removing \".\" and \"..\" entries.\n\njulia> normpath(\"/home/myuser/../example.jl\")\n\"/home/example.jl\"\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.realpath",
    "page": "Filesystem",
    "title": "Base.Filesystem.realpath",
    "category": "function",
    "text": "realpath(path::AbstractString) -> AbstractString\n\nCanonicalize a path by expanding symbolic links and removing \".\" and \"..\" entries.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.relpath",
    "page": "Filesystem",
    "title": "Base.Filesystem.relpath",
    "category": "function",
    "text": "relpath(path::AbstractString, startpath::AbstractString = \".\") -> AbstractString\n\nReturn a relative filepath to path either from the current directory or from an optional start directory. This is a path computation: the filesystem is not accessed to confirm the existence or nature of path or startpath.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.expanduser",
    "page": "Filesystem",
    "title": "Base.Filesystem.expanduser",
    "category": "function",
    "text": "expanduser(path::AbstractString) -> AbstractString\n\nOn Unix systems, replace a tilde character at the start of a path with the current user\'s home directory.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.splitdir",
    "page": "Filesystem",
    "title": "Base.Filesystem.splitdir",
    "category": "function",
    "text": "splitdir(path::AbstractString) -> (AbstractString, AbstractString)\n\nSplit a path into a tuple of the directory name and file name.\n\njulia> splitdir(\"/home/myuser\")\n(\"/home\", \"myuser\")\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.splitdrive",
    "page": "Filesystem",
    "title": "Base.Filesystem.splitdrive",
    "category": "function",
    "text": "splitdrive(path::AbstractString) -> (AbstractString, AbstractString)\n\nOn Windows, split a path into the drive letter part and the path part. On Unix systems, the first component is always the empty string.\n\n\n\n"
},

{
    "location": "stdlib/file/#Base.Filesystem.splitext",
    "page": "Filesystem",
    "title": "Base.Filesystem.splitext",
    "category": "function",
    "text": "splitext(path::AbstractString) -> (AbstractString, AbstractString)\n\nIf the last component of a path contains a dot, split the path into everything before the dot and everything including and after the dot. Otherwise, return a tuple of the argument unmodified and the empty string.\n\njulia> splitext(\"/home/myuser/example.jl\")\n(\"/home/myuser/example\", \".jl\")\n\njulia> splitext(\"/home/myuser/example\")\n(\"/home/myuser/example\", \"\")\n\n\n\n"
},

{
    "location": "stdlib/file/#Filesystem-1",
    "page": "Filesystem",
    "title": "Filesystem",
    "category": "section",
    "text": "Base.Filesystem.pwd\nBase.Filesystem.cd(::AbstractString)\nBase.Filesystem.cd(::Function)\nBase.Filesystem.readdir\nBase.Filesystem.walkdir\nBase.Filesystem.mkdir\nBase.Filesystem.mkpath\nBase.Filesystem.symlink\nBase.Filesystem.readlink\nBase.Filesystem.chmod\nBase.Filesystem.chown\nBase.stat\nBase.Filesystem.lstat\nBase.Filesystem.ctime\nBase.Filesystem.mtime\nBase.Filesystem.filemode\nBase.Filesystem.filesize\nBase.Filesystem.uperm\nBase.Filesystem.gperm\nBase.Filesystem.operm\nBase.Filesystem.cp\nBase.download\nBase.Filesystem.mv\nBase.Filesystem.rm\nBase.Filesystem.touch\nBase.Filesystem.tempname\nBase.Filesystem.tempdir\nBase.Filesystem.mktemp(::Any)\nBase.Filesystem.mktemp(::Function, ::Any)\nBase.Filesystem.mktempdir(::Any)\nBase.Filesystem.mktempdir(::Function, ::Any)\nBase.Filesystem.isblockdev\nBase.Filesystem.ischardev\nBase.Filesystem.isdir\nBase.Filesystem.isfifo\nBase.Filesystem.isfile\nBase.Filesystem.islink\nBase.Filesystem.ismount\nBase.Filesystem.ispath\nBase.Filesystem.issetgid\nBase.Filesystem.issetuid\nBase.Filesystem.issocket\nBase.Filesystem.issticky\nBase.Filesystem.homedir\nBase.Filesystem.dirname\nBase.Filesystem.basename\nBase.@__FILE__\nBase.@__DIR__\n@__LINE__\nBase.Filesystem.isabspath\nBase.Filesystem.isdirpath\nBase.Filesystem.joinpath\nBase.Filesystem.abspath\nBase.Filesystem.normpath\nBase.Filesystem.realpath\nBase.Filesystem.relpath\nBase.Filesystem.expanduser\nBase.Filesystem.splitdir\nBase.Filesystem.splitdrive\nBase.Filesystem.splitext"
},

{
    "location": "stdlib/io-network/#",
    "page": "I/O and Network",
    "title": "I/O and Network",
    "category": "page",
    "text": ""
},

{
    "location": "stdlib/io-network/#I/O-and-Network-1",
    "page": "I/O and Network",
    "title": "I/O and Network",
    "category": "section",
    "text": ""
},

{
    "location": "stdlib/io-network/#Base.STDOUT",
    "page": "I/O and Network",
    "title": "Base.STDOUT",
    "category": "constant",
    "text": "STDOUT\n\nGlobal variable referring to the standard out stream.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.STDERR",
    "page": "I/O and Network",
    "title": "Base.STDERR",
    "category": "constant",
    "text": "STDERR\n\nGlobal variable referring to the standard error stream.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.STDIN",
    "page": "I/O and Network",
    "title": "Base.STDIN",
    "category": "constant",
    "text": "STDIN\n\nGlobal variable referring to the standard input stream.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.open",
    "page": "I/O and Network",
    "title": "Base.open",
    "category": "function",
    "text": "open(filename::AbstractString, [read::Bool, write::Bool, create::Bool, truncate::Bool, append::Bool]) -> IOStream\n\nOpen a file in a mode specified by five boolean arguments. The default is to open files for reading only. Returns a stream for accessing the file.\n\n\n\nopen(filename::AbstractString, [mode::AbstractString]) -> IOStream\n\nAlternate syntax for open, where a string-based mode specifier is used instead of the five booleans. The values of mode correspond to those from fopen(3) or Perl open, and are equivalent to setting the following boolean groups:\n\nMode Description\nr read\nr+ read, write\nw write, create, truncate\nw+ read, write, create, truncate\na write, create, append\na+ read, write, create, append\n\n\n\nopen(f::Function, args...)\n\nApply the function f to the result of open(args...) and close the resulting file descriptor upon completion.\n\nExample: open(readstring, \"file.txt\")\n\n\n\nopen(command, mode::AbstractString=\"r\", stdio=DevNull)\n\nStart running command asynchronously, and return a tuple (stream,process).  If mode is \"r\", then stream reads from the process\'s standard output and stdio optionally specifies the process\'s standard input stream.  If mode is \"w\", then stream writes to the process\'s standard input and stdio optionally specifies the process\'s standard output stream.\n\n\n\nopen(f::Function, command, mode::AbstractString=\"r\", stdio=DevNull)\n\nSimilar to open(command, mode, stdio), but calls f(stream) on the resulting read or write stream, then closes the stream and waits for the process to complete.  Returns the value returned by f.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.IOBuffer",
    "page": "I/O and Network",
    "title": "Base.IOBuffer",
    "category": "type",
    "text": "IOBuffer([data,],[readable::Bool=true, writable::Bool=true, [maxsize::Int=typemax(Int)]])\n\nCreate an IOBuffer, which may optionally operate on a pre-existing array. If the readable/writable arguments are given, they restrict whether or not the buffer may be read from or written to respectively. The last argument optionally specifies a size beyond which the buffer may not be grown.\n\n\n\nIOBuffer() -> IOBuffer\n\nCreate an in-memory I/O stream.\n\n\n\nIOBuffer(size::Int)\n\nCreate a fixed size IOBuffer. The buffer will not grow dynamically.\n\n\n\nIOBuffer(string::String)\n\nCreate a read-only IOBuffer on the data underlying the given string.\n\njulia> io = IOBuffer(\"Haho\");\n\njulia> String(take!(io))\n\"Haho\"\n\njulia> String(take!(io))\n\"Haho\"\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.take!-Tuple{Base.AbstractIOBuffer}",
    "page": "I/O and Network",
    "title": "Base.take!",
    "category": "method",
    "text": "take!(b::IOBuffer)\n\nObtain the contents of an IOBuffer as an array, without copying. Afterwards, the IOBuffer is reset to its initial state.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.fdio",
    "page": "I/O and Network",
    "title": "Base.fdio",
    "category": "function",
    "text": "fdio([name::AbstractString, ]fd::Integer[, own::Bool=false]) -> IOStream\n\nCreate an IOStream object from an integer file descriptor. If own is true, closing this object will close the underlying descriptor. By default, an IOStream is closed when it is garbage collected. name allows you to associate the descriptor with a named file.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.flush",
    "page": "I/O and Network",
    "title": "Base.flush",
    "category": "function",
    "text": "flush(stream)\n\nCommit all currently buffered writes to the given stream.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.close",
    "page": "I/O and Network",
    "title": "Base.close",
    "category": "function",
    "text": "close(stream)\n\nClose an I/O stream. Performs a flush first.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.write",
    "page": "I/O and Network",
    "title": "Base.write",
    "category": "function",
    "text": "write(stream::IO, x)\nwrite(filename::AbstractString, x)\n\nWrite the canonical binary representation of a value to the given I/O stream or file. Returns the number of bytes written into the stream.\n\nYou can write multiple values with the same write call. i.e. the following are equivalent:\n\nwrite(stream, x, y...)\nwrite(stream, x) + write(stream, y...)\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.read",
    "page": "I/O and Network",
    "title": "Base.read",
    "category": "function",
    "text": "read(filename::AbstractString, args...)\n\nOpen a file and read its contents. args is passed to read: this is equivalent to open(io->read(io, args...), filename).\n\n\n\nread(stream::IO, T, dims)\n\nRead a series of values of type T from stream, in canonical binary representation. dims is either a tuple or a series of integer arguments specifying the size of the Array{T} to return.\n\n\n\nread(s::IO, nb=typemax(Int))\n\nRead at most nb bytes from s, returning a Vector{UInt8} of the bytes read.\n\n\n\nread(s::IOStream, nb::Integer; all=true)\n\nRead at most nb bytes from s, returning a Vector{UInt8} of the bytes read.\n\nIf all is true (the default), this function will block repeatedly trying to read all requested bytes, until an error or end-of-file occurs. If all is false, at most one read call is performed, and the amount of data returned is device-dependent. Note that not all stream types support the all option.\n\n\n\nread(stream::IO, T)\n\nRead a single value of type T from stream, in canonical binary representation.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.read!",
    "page": "I/O and Network",
    "title": "Base.read!",
    "category": "function",
    "text": "read!(stream::IO, array::Union{Array, BitArray})\nread!(filename::AbstractString, array::Union{Array, BitArray})\n\nRead binary data from an I/O stream or file, filling in array.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.readbytes!",
    "page": "I/O and Network",
    "title": "Base.readbytes!",
    "category": "function",
    "text": "readbytes!(stream::IO, b::AbstractVector{UInt8}, nb=length(b))\n\nRead at most nb bytes from stream into b, returning the number of bytes read. The size of b will be increased if needed (i.e. if nb is greater than length(b) and enough bytes could be read), but it will never be decreased.\n\n\n\nreadbytes!(stream::IOStream, b::AbstractVector{UInt8}, nb=length(b); all::Bool=true)\n\nRead at most nb bytes from stream into b, returning the number of bytes read. The size of b will be increased if needed (i.e. if nb is greater than length(b) and enough bytes could be read), but it will never be decreased.\n\nSee read for a description of the all option.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.unsafe_read",
    "page": "I/O and Network",
    "title": "Base.unsafe_read",
    "category": "function",
    "text": "unsafe_read(io::IO, ref, nbytes::UInt)\n\nCopy nbytes from the IO stream object into ref (converted to a pointer).\n\nIt is recommended that subtypes T<:IO override the following method signature to provide more efficient implementations: unsafe_read(s::T, p::Ptr{UInt8}, n::UInt)\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.unsafe_write",
    "page": "I/O and Network",
    "title": "Base.unsafe_write",
    "category": "function",
    "text": "unsafe_write(io::IO, ref, nbytes::UInt)\n\nCopy nbytes from ref (converted to a pointer) into the IO object.\n\nIt is recommended that subtypes T<:IO override the following method signature to provide more efficient implementations: unsafe_write(s::T, p::Ptr{UInt8}, n::UInt)\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.position",
    "page": "I/O and Network",
    "title": "Base.position",
    "category": "function",
    "text": "position(s)\n\nGet the current position of a stream.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.seek",
    "page": "I/O and Network",
    "title": "Base.seek",
    "category": "function",
    "text": "seek(s, pos)\n\nSeek a stream to the given position.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.seekstart",
    "page": "I/O and Network",
    "title": "Base.seekstart",
    "category": "function",
    "text": "seekstart(s)\n\nSeek a stream to its beginning.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.seekend",
    "page": "I/O and Network",
    "title": "Base.seekend",
    "category": "function",
    "text": "seekend(s)\n\nSeek a stream to its end.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.skip",
    "page": "I/O and Network",
    "title": "Base.skip",
    "category": "function",
    "text": "skip(s, offset)\n\nSeek a stream relative to the current position.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.mark",
    "page": "I/O and Network",
    "title": "Base.mark",
    "category": "function",
    "text": "mark(s)\n\nAdd a mark at the current position of stream s. Returns the marked position.\n\nSee also unmark, reset, ismarked.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.unmark",
    "page": "I/O and Network",
    "title": "Base.unmark",
    "category": "function",
    "text": "unmark(s)\n\nRemove a mark from stream s. Returns true if the stream was marked, false otherwise.\n\nSee also mark, reset, ismarked.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.reset",
    "page": "I/O and Network",
    "title": "Base.reset",
    "category": "function",
    "text": "reset(s)\n\nReset a stream s to a previously marked position, and remove the mark. Returns the previously marked position. Throws an error if the stream is not marked.\n\nSee also mark, unmark, ismarked.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.ismarked",
    "page": "I/O and Network",
    "title": "Base.ismarked",
    "category": "function",
    "text": "ismarked(s)\n\nReturns true if stream s is marked.\n\nSee also mark, unmark, reset.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.eof",
    "page": "I/O and Network",
    "title": "Base.eof",
    "category": "function",
    "text": "eof(stream) -> Bool\n\nTests whether an I/O stream is at end-of-file. If the stream is not yet exhausted, this function will block to wait for more data if necessary, and then return false. Therefore it is always safe to read one byte after seeing eof return false. eof will return false as long as buffered data is still available, even if the remote end of a connection is closed.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.isreadonly",
    "page": "I/O and Network",
    "title": "Base.isreadonly",
    "category": "function",
    "text": "isreadonly(stream) -> Bool\n\nDetermine whether a stream is read-only.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.iswritable",
    "page": "I/O and Network",
    "title": "Base.iswritable",
    "category": "function",
    "text": "iswritable(io) -> Bool\n\nReturns true if the specified IO object is writable (if that can be determined).\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.isreadable",
    "page": "I/O and Network",
    "title": "Base.isreadable",
    "category": "function",
    "text": "isreadable(io) -> Bool\n\nReturns true if the specified IO object is readable (if that can be determined).\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.isopen",
    "page": "I/O and Network",
    "title": "Base.isopen",
    "category": "function",
    "text": "isopen(object) -> Bool\n\nDetermine whether an object - such as a stream, timer, or mmap – is not yet closed. Once an object is closed, it will never produce a new event. However, a closed stream may still have data to read in its buffer, use eof to check for the ability to read data. Use poll_fd to be notified when a stream might be writable or readable.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.Serializer.serialize",
    "page": "I/O and Network",
    "title": "Base.Serializer.serialize",
    "category": "function",
    "text": "serialize(stream, value)\n\nWrite an arbitrary value to a stream in an opaque format, such that it can be read back by deserialize. The read-back value will be as identical as possible to the original. In general, this process will not work if the reading and writing are done by different versions of Julia, or an instance of Julia with a different system image. Ptr values are serialized as all-zero bit patterns (NULL).\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.Serializer.deserialize",
    "page": "I/O and Network",
    "title": "Base.Serializer.deserialize",
    "category": "function",
    "text": "deserialize(stream)\n\nRead a value written by serialize. deserialize assumes the binary data read from stream is correct and has been serialized by a compatible implementation of serialize. It has been designed with simplicity and performance as a goal and does not validate the data read. Malformed data can result in process termination. The caller has to ensure the integrity and correctness of data read from stream.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.Grisu.print_shortest",
    "page": "I/O and Network",
    "title": "Base.Grisu.print_shortest",
    "category": "function",
    "text": "print_shortest(io, x)\n\nPrint the shortest possible representation, with the minimum number of consecutive non-zero digits, of number x, ensuring that it would parse to the exact same number.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.fd",
    "page": "I/O and Network",
    "title": "Base.fd",
    "category": "function",
    "text": "fd(stream)\n\nReturns the file descriptor backing the stream or file. Note that this function only applies to synchronous File\'s and IOStream\'s not to any of the asynchronous streams.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.redirect_stdout",
    "page": "I/O and Network",
    "title": "Base.redirect_stdout",
    "category": "function",
    "text": "redirect_stdout([stream]) -> (rd, wr)\n\nCreate a pipe to which all C and Julia level STDOUT output will be redirected. Returns a tuple (rd, wr) representing the pipe ends. Data written to STDOUT may now be read from the rd end of the pipe. The wr end is given for convenience in case the old STDOUT object was cached by the user and needs to be replaced elsewhere.\n\nnote: Note\nstream must be a TTY, a Pipe, or a TCPSocket.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.redirect_stdout-Tuple{Function,Any}",
    "page": "I/O and Network",
    "title": "Base.redirect_stdout",
    "category": "method",
    "text": "redirect_stdout(f::Function, stream)\n\nRun the function f while redirecting STDOUT to stream. Upon completion, STDOUT is restored to its prior setting.\n\nnote: Note\nstream must be a TTY, a Pipe, or a TCPSocket.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.redirect_stderr",
    "page": "I/O and Network",
    "title": "Base.redirect_stderr",
    "category": "function",
    "text": "redirect_stderr([stream]) -> (rd, wr)\n\nLike redirect_stdout, but for STDERR.\n\nnote: Note\nstream must be a TTY, a Pipe, or a TCPSocket.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.redirect_stderr-Tuple{Function,Any}",
    "page": "I/O and Network",
    "title": "Base.redirect_stderr",
    "category": "method",
    "text": "redirect_stderr(f::Function, stream)\n\nRun the function f while redirecting STDERR to stream. Upon completion, STDERR is restored to its prior setting.\n\nnote: Note\nstream must be a TTY, a Pipe, or a TCPSocket.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.redirect_stdin",
    "page": "I/O and Network",
    "title": "Base.redirect_stdin",
    "category": "function",
    "text": "redirect_stdin([stream]) -> (rd, wr)\n\nLike redirect_stdout, but for STDIN. Note that the order of the return tuple is still (rd, wr), i.e. data to be read from STDIN may be written to wr.\n\nnote: Note\nstream must be a TTY, a Pipe, or a TCPSocket.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.redirect_stdin-Tuple{Function,Any}",
    "page": "I/O and Network",
    "title": "Base.redirect_stdin",
    "category": "method",
    "text": "redirect_stdin(f::Function, stream)\n\nRun the function f while redirecting STDIN to stream. Upon completion, STDIN is restored to its prior setting.\n\nnote: Note\nstream must be a TTY, a Pipe, or a TCPSocket.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.readchomp",
    "page": "I/O and Network",
    "title": "Base.readchomp",
    "category": "function",
    "text": "readchomp(x)\n\nRead the entirety of x as a string and remove a single trailing newline. Equivalent to chomp!(readstring(x)).\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.truncate",
    "page": "I/O and Network",
    "title": "Base.truncate",
    "category": "function",
    "text": "truncate(file,n)\n\nResize the file or buffer given by the first argument to exactly n bytes, filling previously unallocated space with \'\\0\' if the file or buffer is grown.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.skipchars",
    "page": "I/O and Network",
    "title": "Base.skipchars",
    "category": "function",
    "text": "skipchars(stream, predicate; linecomment::Char)\n\nAdvance the stream until before the first character for which predicate returns false. For example skipchars(stream, isspace) will skip all whitespace. If keyword argument linecomment is specified, characters from that character through the end of a line will also be skipped.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.DataFmt.countlines",
    "page": "I/O and Network",
    "title": "Base.DataFmt.countlines",
    "category": "function",
    "text": "countlines(io::IO, eol::Char=\'\\n\')\n\nRead io until the end of the stream/file and count the number of lines. To specify a file pass the filename as the first argument. EOL markers other than \'\\n\' are supported by passing them as the second argument.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.PipeBuffer",
    "page": "I/O and Network",
    "title": "Base.PipeBuffer",
    "category": "function",
    "text": "PipeBuffer(data::Vector{UInt8}=UInt8[],[maxsize::Int=typemax(Int)])\n\nAn IOBuffer that allows reading and performs writes by appending. Seeking and truncating are not supported. See IOBuffer for the available constructors. If data is given, creates a PipeBuffer to operate on a data vector, optionally specifying a size beyond which the underlying Array may not be grown.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.readavailable",
    "page": "I/O and Network",
    "title": "Base.readavailable",
    "category": "function",
    "text": "readavailable(stream)\n\nRead all available data on the stream, blocking the task only if no data is available. The result is a Vector{UInt8,1}.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.IOContext",
    "page": "I/O and Network",
    "title": "Base.IOContext",
    "category": "type",
    "text": "IOContext\n\nIOContext provides a mechanism for passing output configuration settings among show methods.\n\nIn short, it is an immutable dictionary that is a subclass of IO. It supports standard dictionary operations such as getindex, and can also be used as an I/O stream.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.IOContext-Tuple{IO,Pair}",
    "page": "I/O and Network",
    "title": "Base.IOContext",
    "category": "method",
    "text": "IOContext(io::IO, KV::Pair)\n\nCreate an IOContext that wraps a given stream, adding the specified key=>value pair to the properties of that stream (note that io can itself be an IOContext).\n\nuse (key => value) in dict to see if this particular combination is in the properties set\nuse get(dict, key, default) to retrieve the most recent value for a particular key\n\nThe following properties are in common use:\n\n:compact: Boolean specifying that small values should be printed more compactly, e.g. that numbers should be printed with fewer digits. This is set when printing array elements.\n:limit: Boolean specifying that containers should be truncated, e.g. showing … in place of most elements.\n:displaysize: A Tuple{Int,Int} giving the size in rows and columns to use for text output. This can be used to override the display size for called functions, but to get the size of the screen use the displaysize function.\n\njulia> function f(io::IO)\n           if get(io, :short, false)\n               print(io, \"short\")\n           else\n               print(io, \"loooooong\")\n           end\n       end\nf (generic function with 1 method)\n\njulia> f(STDOUT)\nloooooong\njulia> f(IOContext(STDOUT, :short => true))\nshort\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.IOContext-Tuple{IO,IOContext}",
    "page": "I/O and Network",
    "title": "Base.IOContext",
    "category": "method",
    "text": "IOContext(io::IO, context::IOContext)\n\nCreate an IOContext that wraps an alternate IO but inherits the properties of context.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#General-I/O-1",
    "page": "I/O and Network",
    "title": "General I/O",
    "category": "section",
    "text": "Base.STDOUT\nBase.STDERR\nBase.STDIN\nBase.open\nBase.IOBuffer\nBase.take!(::Base.AbstractIOBuffer)\nBase.fdio\nBase.flush\nBase.close\nBase.write\nBase.read\nBase.read!\nBase.readbytes!\nBase.unsafe_read\nBase.unsafe_write\nBase.position\nBase.seek\nBase.seekstart\nBase.seekend\nBase.skip\nBase.mark\nBase.unmark\nBase.reset\nBase.ismarked\nBase.eof\nBase.isreadonly\nBase.iswritable\nBase.isreadable\nBase.isopen\nBase.Serializer.serialize\nBase.Serializer.deserialize\nBase.Grisu.print_shortest\nBase.fd\nBase.redirect_stdout\nBase.redirect_stdout(::Function, ::Any)\nBase.redirect_stderr\nBase.redirect_stderr(::Function, ::Any)\nBase.redirect_stdin\nBase.redirect_stdin(::Function, ::Any)\nBase.readchomp\nBase.truncate\nBase.skipchars\nBase.DataFmt.countlines\nBase.PipeBuffer\nBase.readavailable\nBase.IOContext\nBase.IOContext(::IO, ::Pair)\nBase.IOContext(::IO, ::IOContext)"
},

{
    "location": "stdlib/io-network/#Base.show-Tuple{Any}",
    "page": "I/O and Network",
    "title": "Base.show",
    "category": "method",
    "text": "show(x)\n\nWrite an informative text representation of a value to the current output stream. New types should overload show(io, x) where the first argument is a stream. The representation used by show generally includes Julia-specific formatting and type information.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.showcompact",
    "page": "I/O and Network",
    "title": "Base.showcompact",
    "category": "function",
    "text": "showcompact(x)\n\nShow a compact representation of a value.\n\nThis is used for printing array elements without repeating type information (which would be redundant with that printed once for the whole array), and without line breaks inside the representation of an element.\n\nTo offer a compact representation different from its standard one, a custom type should test get(io, :compact, false) in its normal show method.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.showall",
    "page": "I/O and Network",
    "title": "Base.showall",
    "category": "function",
    "text": "showall(x)\n\nSimilar to show, except shows all elements of arrays.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.summary",
    "page": "I/O and Network",
    "title": "Base.summary",
    "category": "function",
    "text": "summary(x)\n\nReturn a string giving a brief description of a value. By default returns string(typeof(x)), e.g. Int64.\n\nFor arrays, returns a string of size and type info, e.g. 10-element Array{Int64,1}.\n\njulia> summary(1)\n\"Int64\"\n\njulia> summary(zeros(2))\n\"2-element Array{Float64,1}\"\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.print",
    "page": "I/O and Network",
    "title": "Base.print",
    "category": "function",
    "text": "print(io::IO, x)\n\nWrite to io (or to the default output stream STDOUT if io is not given) a canonical (un-decorated) text representation of a value if there is one, otherwise call show. The representation used by print includes minimal formatting and tries to avoid Julia-specific details.\n\njulia> print(\"Hello World!\")\nHello World!\njulia> io = IOBuffer();\n\njulia> print(io, \"Hello World!\")\n\njulia> String(take!(io))\n\"Hello World!\"\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.println",
    "page": "I/O and Network",
    "title": "Base.println",
    "category": "function",
    "text": "println(io::IO, xs...)\n\nPrint (using print) xs followed by a newline. If io is not supplied, prints to STDOUT.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.print_with_color",
    "page": "I/O and Network",
    "title": "Base.print_with_color",
    "category": "function",
    "text": "print_with_color(color::Union{Symbol, Int}, [io], xs...; bold::Bool = false)\n\nPrint xs in a color specified as a symbol.\n\ncolor may take any of the values :normal, :default, :bold, :black, :blue, :cyan, :green, :light_black, :light_blue, :light_cyan, :light_green, :light_magenta, :light_red, :light_yellow, :magenta, :nothing, :red, :white, or  :yellow or an integer between 0 and 255 inclusive. Note that not all terminals support 256 colors. If the keyword bold is given as true, the result will be printed in bold.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.info",
    "page": "I/O and Network",
    "title": "Base.info",
    "category": "function",
    "text": "info([io, ] msg..., [prefix=\"INFO: \"])\n\nDisplay an informational message. Argument msg is a string describing the information to be displayed. The prefix keyword argument can be used to override the default prepending of msg.\n\njulia> info(\"hello world\")\nINFO: hello world\n\njulia> info(\"hello world\"; prefix=\"MY INFO: \")\nMY INFO: hello world\n\nSee also logging.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.warn",
    "page": "I/O and Network",
    "title": "Base.warn",
    "category": "function",
    "text": "warn([io, ] msg..., [prefix=\"WARNING: \", once=false, key=nothing, bt=nothing, filename=nothing, lineno::Int=0])\n\nDisplay a warning. Argument msg is a string describing the warning to be displayed.  Set once to true and specify a key to only display msg the first time warn is called.  If bt is not nothing a backtrace is displayed. If filename is not nothing both it and lineno are displayed.\n\nSee also logging.\n\n\n\nwarn(msg)\n\nDisplay a warning. Argument msg is a string describing the warning to be displayed.\n\njulia> warn(\"Beep Beep\")\nWARNING: Beep Beep\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.logging",
    "page": "I/O and Network",
    "title": "Base.logging",
    "category": "function",
    "text": "logging(io [, m [, f]][; kind=:all])\nlogging([; kind=:all])\n\nStream output of informational, warning, and/or error messages to io, overriding what was otherwise specified.  Optionally, divert stream only for module m, or specifically function f within m.  kind can be :all (the default), :info, :warn, or :error.  See Base.log_{info,warn,error}_to for the current set of redirections.  Call logging with no arguments (or just the kind) to reset everything.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.Printf.@printf",
    "page": "I/O and Network",
    "title": "Base.Printf.@printf",
    "category": "macro",
    "text": "@printf([io::IOStream], \"%Fmt\", args...)\n\nPrint args using C printf() style format specification string, with some caveats: Inf and NaN are printed consistently as Inf and NaN for flags %a, %A, %e, %E, %f, %F, %g, and %G. Furthermore, if a floating point number is equally close to the numeric values of two possible output strings, the output string further away from zero is chosen.\n\nOptionally, an IOStream may be passed as the first argument to redirect output.\n\nExamples\n\njulia> @printf(\"%f %F %f %F\\n\", Inf, Inf, NaN, NaN)\nInf Inf NaN NaN\n\n\njulia> @printf \"%.0f %.1f %f\\n\" 0.5 0.025 -0.0078125\n1 0.0 -0.007813\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.Printf.@sprintf",
    "page": "I/O and Network",
    "title": "Base.Printf.@sprintf",
    "category": "macro",
    "text": "@sprintf(\"%Fmt\", args...)\n\nReturn @printf formatted output as string.\n\nExamples\n\njulia> s = @sprintf \"this is a %s %15.1f\" \"test\" 34.567;\n\njulia> println(s)\nthis is a test            34.6\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.sprint",
    "page": "I/O and Network",
    "title": "Base.sprint",
    "category": "function",
    "text": "sprint(f::Function, args...)\n\nCall the given function with an I/O stream and the supplied extra arguments. Everything written to this I/O stream is returned as a string.\n\njulia> sprint(showcompact, 66.66666)\n\"66.6667\"\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.showerror",
    "page": "I/O and Network",
    "title": "Base.showerror",
    "category": "function",
    "text": "showerror(io, e)\n\nShow a descriptive representation of an exception object.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.dump",
    "page": "I/O and Network",
    "title": "Base.dump",
    "category": "function",
    "text": "dump(x)\n\nShow every part of the representation of a value.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.readstring",
    "page": "I/O and Network",
    "title": "Base.readstring",
    "category": "function",
    "text": "readstring(stream::IO)\nreadstring(filename::AbstractString)\n\nRead the entire contents of an I/O stream or a file as a string. The text is assumed to be encoded in UTF-8.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.readline",
    "page": "I/O and Network",
    "title": "Base.readline",
    "category": "function",
    "text": "readline(stream::IO=STDIN; chomp::Bool=true)\nreadline(filename::AbstractString; chomp::Bool=true)\n\nRead a single line of text from the given I/O stream or file (defaults to STDIN). When reading from a file, the text is assumed to be encoded in UTF-8. Lines in the input end with \'\\n\' or \"\\r\\n\" or the end of an input stream. When chomp is true (as it is by default), these trailing newline characters are removed from the line before it is returned. When chomp is false, they are returned as part of the line.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.readuntil",
    "page": "I/O and Network",
    "title": "Base.readuntil",
    "category": "function",
    "text": "readuntil(stream::IO, delim)\nreaduntil(filename::AbstractString, delim)\n\nRead a string from an I/O stream or a file, up to and including the given delimiter byte. The text is assumed to be encoded in UTF-8.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.readlines",
    "page": "I/O and Network",
    "title": "Base.readlines",
    "category": "function",
    "text": "readlines(stream::IO=STDIN; chomp::Bool=true)\nreadlines(filename::AbstractString; chomp::Bool=true)\n\nRead all lines of an I/O stream or a file as a vector of strings. Behavior is equivalent to saving the result of reading readline repeatedly with the same arguments and saving the resulting lines as a vector of strings.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.eachline",
    "page": "I/O and Network",
    "title": "Base.eachline",
    "category": "function",
    "text": "eachline(stream::IO=STDIN; chomp::Bool=true)\neachline(filename::AbstractString; chomp::Bool=true)\n\nCreate an iterable EachLine object that will yield each line from an I/O stream or a file. Iteration calls readline on the stream argument repeatedly with chomp passed through, determining whether trailing end-of-line characters are removed. When called with a file name, the file is opened once at the beginning of iteration and closed at the end. If iteration is interrupted, the file will be closed when the EachLine object is garbage collected.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.DataFmt.readdlm-Tuple{Any,Char,Type,Char}",
    "page": "I/O and Network",
    "title": "Base.DataFmt.readdlm",
    "category": "method",
    "text": "readdlm(source, delim::Char, T::Type, eol::Char; header=false, skipstart=0, skipblanks=true, use_mmap, quotes=true, dims, comments=true, comment_char=\'#\')\n\nRead a matrix from the source where each line (separated by eol) gives one row, with elements separated by the given delimiter. The source can be a text file, stream or byte array. Memory mapped files can be used by passing the byte array representation of the mapped segment as source.\n\nIf T is a numeric type, the result is an array of that type, with any non-numeric elements as NaN for floating-point types, or zero. Other useful values of T include String, AbstractString, and Any.\n\nIf header is true, the first row of data will be read as header and the tuple (data_cells, header_cells) is returned instead of only data_cells.\n\nSpecifying skipstart will ignore the corresponding number of initial lines from the input.\n\nIf skipblanks is true, blank lines in the input will be ignored.\n\nIf use_mmap is true, the file specified by source is memory mapped for potential speedups. Default is true except on Windows. On Windows, you may want to specify true if the file is large, and is only read once and not written to.\n\nIf quotes is true, columns enclosed within double-quote (\") characters are allowed to contain new lines and column delimiters. Double-quote characters within a quoted field must be escaped with another double-quote.  Specifying dims as a tuple of the expected rows and columns (including header, if any) may speed up reading of large files.  If comments is true, lines beginning with comment_char and text following comment_char in any line are ignored.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.DataFmt.readdlm-Tuple{Any,Char,Char}",
    "page": "I/O and Network",
    "title": "Base.DataFmt.readdlm",
    "category": "method",
    "text": "readdlm(source, delim::Char, eol::Char; options...)\n\nIf all data is numeric, the result will be a numeric array. If some elements cannot be parsed as numbers, a heterogeneous array of numbers and strings is returned.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.DataFmt.readdlm-Tuple{Any,Char,Type}",
    "page": "I/O and Network",
    "title": "Base.DataFmt.readdlm",
    "category": "method",
    "text": "readdlm(source, delim::Char, T::Type; options...)\n\nThe end of line delimiter is taken as \\n.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.DataFmt.readdlm-Tuple{Any,Char}",
    "page": "I/O and Network",
    "title": "Base.DataFmt.readdlm",
    "category": "method",
    "text": "readdlm(source, delim::Char; options...)\n\nThe end of line delimiter is taken as \\n. If all data is numeric, the result will be a numeric array. If some elements cannot be parsed as numbers, a heterogeneous array of numbers and strings is returned.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.DataFmt.readdlm-Tuple{Any,Type}",
    "page": "I/O and Network",
    "title": "Base.DataFmt.readdlm",
    "category": "method",
    "text": "readdlm(source, T::Type; options...)\n\nThe columns are assumed to be separated by one or more whitespaces. The end of line delimiter is taken as \\n.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.DataFmt.readdlm-Tuple{Any}",
    "page": "I/O and Network",
    "title": "Base.DataFmt.readdlm",
    "category": "method",
    "text": "readdlm(source; options...)\n\nThe columns are assumed to be separated by one or more whitespaces. The end of line delimiter is taken as \\n. If all data is numeric, the result will be a numeric array. If some elements cannot be parsed as numbers, a heterogeneous array of numbers and strings is returned.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.DataFmt.writedlm",
    "page": "I/O and Network",
    "title": "Base.DataFmt.writedlm",
    "category": "function",
    "text": "writedlm(f, A, delim=\'\\t\'; opts)\n\nWrite A (a vector, matrix, or an iterable collection of iterable rows) as text to f (either a filename string or an IO stream) using the given delimiter delim (which defaults to tab, but can be any printable Julia object, typically a Char or AbstractString).\n\nFor example, two vectors x and y of the same length can be written as two columns of tab-delimited text to f by either writedlm(f, [x y]) or by writedlm(f, zip(x, y)).\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.DataFmt.readcsv",
    "page": "I/O and Network",
    "title": "Base.DataFmt.readcsv",
    "category": "function",
    "text": "readcsv(source, [T::Type]; options...)\n\nEquivalent to readdlm with delim set to comma, and type optionally defined by T.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.DataFmt.writecsv",
    "page": "I/O and Network",
    "title": "Base.DataFmt.writecsv",
    "category": "function",
    "text": "writecsv(filename, A; opts)\n\nEquivalent to writedlm with delim set to comma.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.Base64.Base64EncodePipe",
    "page": "I/O and Network",
    "title": "Base.Base64.Base64EncodePipe",
    "category": "type",
    "text": "Base64EncodePipe(ostream)\n\nReturns a new write-only I/O stream, which converts any bytes written to it into base64-encoded ASCII bytes written to ostream. Calling close on the Base64EncodePipe stream is necessary to complete the encoding (but does not close ostream).\n\njulia> io = IOBuffer();\n\njulia> iob64_encode = Base64EncodePipe(io);\n\njulia> write(iob64_encode, \"Hello!\")\n6\n\njulia> close(iob64_encode);\n\njulia> str = String(take!(io))\n\"SGVsbG8h\"\n\njulia> String(base64decode(str))\n\"Hello!\"\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.Base64.Base64DecodePipe",
    "page": "I/O and Network",
    "title": "Base.Base64.Base64DecodePipe",
    "category": "type",
    "text": "Base64DecodePipe(istream)\n\nReturns a new read-only I/O stream, which decodes base64-encoded data read from istream.\n\njulia> io = IOBuffer();\n\njulia> iob64_decode = Base64DecodePipe(io);\n\njulia> write(io, \"SGVsbG8h\")\n8\n\njulia> seekstart(io);\n\njulia> String(read(iob64_decode))\n\"Hello!\"\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.Base64.base64encode",
    "page": "I/O and Network",
    "title": "Base.Base64.base64encode",
    "category": "function",
    "text": "base64encode(writefunc, args...)\nbase64encode(args...)\n\nGiven a write-like function writefunc, which takes an I/O stream as its first argument, base64encode(writefunc, args...) calls writefunc to write args... to a base64-encoded string, and returns the string. base64encode(args...) is equivalent to base64encode(write, args...): it converts its arguments into bytes using the standard write functions and returns the base64-encoded string.\n\nSee also base64decode.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.Base64.base64decode",
    "page": "I/O and Network",
    "title": "Base.Base64.base64decode",
    "category": "function",
    "text": "base64decode(string)\n\nDecodes the base64-encoded string and returns a Vector{UInt8} of the decoded bytes.\n\nSee also base64encode\n\njulia> b = base64decode(\"SGVsbG8h\")\n6-element Array{UInt8,1}:\n 0x48\n 0x65\n 0x6c\n 0x6c\n 0x6f\n 0x21\n\njulia> String(b)\n\"Hello!\"\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.displaysize",
    "page": "I/O and Network",
    "title": "Base.displaysize",
    "category": "function",
    "text": "displaysize(io) -> (lines, columns)\n\nReturn the nominal size of the screen that may be used for rendering output to this io object\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Text-I/O-1",
    "page": "I/O and Network",
    "title": "Text I/O",
    "category": "section",
    "text": "Base.show(::Any)\nBase.showcompact\nBase.showall\nBase.summary\nBase.print\nBase.println\nBase.print_with_color\nBase.info\nBase.warn\nBase.logging\nBase.Printf.@printf\nBase.Printf.@sprintf\nBase.sprint\nBase.showerror\nBase.dump\nBase.readstring\nBase.readline\nBase.readuntil\nBase.readlines\nBase.eachline\nBase.DataFmt.readdlm(::Any, ::Char, ::Type, ::Char)\nBase.DataFmt.readdlm(::Any, ::Char, ::Char)\nBase.DataFmt.readdlm(::Any, ::Char, ::Type)\nBase.DataFmt.readdlm(::Any, ::Char)\nBase.DataFmt.readdlm(::Any, ::Type)\nBase.DataFmt.readdlm(::Any)\nBase.DataFmt.writedlm\nBase.DataFmt.readcsv\nBase.DataFmt.writecsv\nBase.Base64.Base64EncodePipe\nBase.Base64.Base64DecodePipe\nBase.Base64.base64encode\nBase.Base64.base64decode\nBase.displaysize"
},

{
    "location": "stdlib/io-network/#Base.Multimedia.display",
    "page": "I/O and Network",
    "title": "Base.Multimedia.display",
    "category": "function",
    "text": "display(x)\ndisplay(d::Display, x)\ndisplay(mime, x)\ndisplay(d::Display, mime, x)\n\nDisplay x using the topmost applicable display in the display stack, typically using the richest supported multimedia output for x, with plain-text STDOUT output as a fallback. The display(d, x) variant attempts to display x on the given display d only, throwing a MethodError if d cannot display objects of this type.\n\nThere are also two variants with a mime argument (a MIME type string, such as \"image/png\"), which attempt to display x using the requested MIME type only, throwing a MethodError if this type is not supported by either the display(s) or by x. With these variants, one can also supply the \"raw\" data in the requested MIME type by passing x::AbstractString (for MIME types with text-based storage, such as text/html or application/postscript) or x::Vector{UInt8} (for binary MIME types).\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.Multimedia.redisplay",
    "page": "I/O and Network",
    "title": "Base.Multimedia.redisplay",
    "category": "function",
    "text": "redisplay(x)\nredisplay(d::Display, x)\nredisplay(mime, x)\nredisplay(d::Display, mime, x)\n\nBy default, the redisplay functions simply call display. However, some display backends may override redisplay to modify an existing display of x (if any). Using redisplay is also a hint to the backend that x may be redisplayed several times, and the backend may choose to defer the display until (for example) the next interactive prompt.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.Multimedia.displayable",
    "page": "I/O and Network",
    "title": "Base.Multimedia.displayable",
    "category": "function",
    "text": "displayable(mime) -> Bool\ndisplayable(d::Display, mime) -> Bool\n\nReturns a boolean value indicating whether the given mime type (string) is displayable by any of the displays in the current display stack, or specifically by the display d in the second variant.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.show-Tuple{Any,Any,Any}",
    "page": "I/O and Network",
    "title": "Base.show",
    "category": "method",
    "text": "show(stream, mime, x)\n\nThe display functions ultimately call show in order to write an object x as a given mime type to a given I/O stream (usually a memory buffer), if possible. In order to provide a rich multimedia representation of a user-defined type T, it is only necessary to define a new show method for T, via: show(stream, ::MIME\"mime\", x::T) = ..., where mime is a MIME-type string and the function body calls write (or similar) to write that representation of x to stream. (Note that the MIME\"\" notation only supports literal strings; to construct MIME types in a more flexible manner use MIME{Symbol(\"\")}.)\n\nFor example, if you define a MyImage type and know how to write it to a PNG file, you could define a function show(stream, ::MIME\"image/png\", x::MyImage) = ... to allow your images to be displayed on any PNG-capable Display (such as IJulia). As usual, be sure to import Base.show in order to add new methods to the built-in Julia function show.\n\nThe default MIME type is MIME\"text/plain\". There is a fallback definition for text/plain output that calls show with 2 arguments. Therefore, this case should be handled by defining a 2-argument show(stream::IO, x::MyType) method.\n\nTechnically, the MIME\"mime\" macro defines a singleton type for the given mime string, which allows us to exploit Julia\'s dispatch mechanisms in determining how to display objects of any given type.\n\nThe first argument to show can be an IOContext specifying output format properties. See IOContext for details.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.Multimedia.mimewritable",
    "page": "I/O and Network",
    "title": "Base.Multimedia.mimewritable",
    "category": "function",
    "text": "mimewritable(mime, x)\n\nReturns a boolean value indicating whether or not the object x can be written as the given mime type. (By default, this is determined automatically by the existence of the corresponding show method for typeof(x).)\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.Multimedia.reprmime",
    "page": "I/O and Network",
    "title": "Base.Multimedia.reprmime",
    "category": "function",
    "text": "reprmime(mime, x)\n\nReturns an AbstractString or Vector{UInt8} containing the representation of x in the requested mime type, as written by show (throwing a MethodError if no appropriate show is available). An AbstractString is returned for MIME types with textual representations (such as \"text/html\" or \"application/postscript\"), whereas binary data is returned as Vector{UInt8}. (The function istextmime(mime) returns whether or not Julia treats a given mime type as text.)\n\nAs a special case, if x is an AbstractString (for textual MIME types) or a Vector{UInt8} (for binary MIME types), the reprmime function assumes that x is already in the requested mime format and simply returns x. This special case does not apply to the \"text/plain\" MIME type. This is useful so that raw data can be passed to display(m::MIME, x).\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.Multimedia.stringmime",
    "page": "I/O and Network",
    "title": "Base.Multimedia.stringmime",
    "category": "function",
    "text": "stringmime(mime, x)\n\nReturns an AbstractString containing the representation of x in the requested mime type. This is similar to reprmime except that binary data is base64-encoded as an ASCII string.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.Multimedia.pushdisplay",
    "page": "I/O and Network",
    "title": "Base.Multimedia.pushdisplay",
    "category": "function",
    "text": "pushdisplay(d::Display)\n\nPushes a new display d on top of the global display-backend stack. Calling display(x) or display(mime, x) will display x on the topmost compatible backend in the stack (i.e., the topmost backend that does not throw a MethodError).\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.Multimedia.popdisplay",
    "page": "I/O and Network",
    "title": "Base.Multimedia.popdisplay",
    "category": "function",
    "text": "popdisplay()\npopdisplay(d::Display)\n\nPop the topmost backend off of the display-backend stack, or the topmost copy of d in the second variant.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.Multimedia.TextDisplay",
    "page": "I/O and Network",
    "title": "Base.Multimedia.TextDisplay",
    "category": "type",
    "text": "TextDisplay(io::IO)\n\nReturns a TextDisplay <: Display, which displays any object as the text/plain MIME type (by default), writing the text representation to the given I/O stream. (This is how objects are printed in the Julia REPL.)\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.Multimedia.istextmime",
    "page": "I/O and Network",
    "title": "Base.Multimedia.istextmime",
    "category": "function",
    "text": "istextmime(m::MIME)\n\nDetermine whether a MIME type is text data. MIME types are assumed to be binary data except for a set of types known to be text data (possibly Unicode).\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Multimedia-I/O-1",
    "page": "I/O and Network",
    "title": "Multimedia I/O",
    "category": "section",
    "text": "Just as text output is performed by print and user-defined types can indicate their textual representation by overloading show, Julia provides a standardized mechanism for rich multimedia output (such as images, formatted text, or even audio and video), consisting of three parts:A function display(x) to request the richest available multimedia display of a Julia object x (with a plain-text fallback).\nOverloading show allows one to indicate arbitrary multimedia representations (keyed by standard MIME types) of user-defined types.\nMultimedia-capable display backends may be registered by subclassing a generic Display type and pushing them onto a stack of display backends via pushdisplay.The base Julia runtime provides only plain-text display, but richer displays may be enabled by loading external modules or by using graphical Julia environments (such as the IPython-based IJulia notebook).Base.Multimedia.display\nBase.Multimedia.redisplay\nBase.Multimedia.displayable\nBase.show(::Any, ::Any, ::Any)\nBase.Multimedia.mimewritable\nBase.Multimedia.reprmime\nBase.Multimedia.stringmimeAs mentioned above, one can also define new display backends. For example, a module that can display PNG images in a window can register this capability with Julia, so that calling display(x) on types with PNG representations will automatically display the image using the module\'s window.In order to define a new display backend, one should first create a subtype D of the abstract class Display.  Then, for each MIME type (mime string) that can be displayed on D, one should define a function display(d::D, ::MIME\"mime\", x) = ... that displays x as that MIME type, usually by calling reprmime(mime, x).  A MethodError should be thrown if x cannot be displayed as that MIME type; this is automatic if one calls reprmime. Finally, one should define a function display(d::D, x) that queries mimewritable(mime, x) for the mime types supported by D and displays the \"best\" one; a MethodError should be thrown if no supported MIME types are found for x.  Similarly, some subtypes may wish to override redisplay(d::D, ...). (Again, one should import Base.display to add new methods to display.) The return values of these functions are up to the implementation (since in some cases it may be useful to return a display \"handle\" of some type).  The display functions for D can then be called directly, but they can also be invoked automatically from display(x) simply by pushing a new display onto the display-backend stack with:Base.Multimedia.pushdisplay\nBase.Multimedia.popdisplay\nBase.Multimedia.TextDisplay\nBase.Multimedia.istextmime"
},

{
    "location": "stdlib/io-network/#Base.Mmap.Anonymous",
    "page": "I/O and Network",
    "title": "Base.Mmap.Anonymous",
    "category": "type",
    "text": "Mmap.Anonymous(name, readonly, create)\n\nCreate an IO-like object for creating zeroed-out mmapped-memory that is not tied to a file for use in Mmap.mmap. Used by SharedArray for creating shared memory arrays.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.Mmap.mmap-Tuple{Any,Type,Any,Any}",
    "page": "I/O and Network",
    "title": "Base.Mmap.mmap",
    "category": "method",
    "text": "Mmap.mmap(io::Union{IOStream,AbstractString,Mmap.AnonymousMmap}[, type::Type{Array{T,N}}, dims, offset]; grow::Bool=true, shared::Bool=true)\n       Mmap.mmap(type::Type{Array{T,N}}, dims)\n\nCreate an Array whose values are linked to a file, using memory-mapping. This provides a convenient way of working with data too large to fit in the computer\'s memory.\n\nThe type is an Array{T,N} with a bits-type element of T and dimension N that determines how the bytes of the array are interpreted. Note that the file must be stored in binary format, and no format conversions are possible (this is a limitation of operating systems, not Julia).\n\ndims is a tuple or single Integer specifying the size or length of the array.\n\nThe file is passed via the stream argument, either as an open IOStream or filename string. When you initialize the stream, use \"r\" for a \"read-only\" array, and \"w+\" to create a new array used to write values to disk.\n\nIf no type argument is specified, the default is Vector{UInt8}.\n\nOptionally, you can specify an offset (in bytes) if, for example, you want to skip over a header in the file. The default value for the offset is the current stream position for an IOStream.\n\nThe grow keyword argument specifies whether the disk file should be grown to accommodate the requested size of array (if the total file size is < requested array size). Write privileges are required to grow the file.\n\nThe shared keyword argument specifies whether the resulting Array and changes made to it will be visible to other processes mapping the same file.\n\nFor example, the following code\n\n# Create a file for mmapping\n# (you could alternatively use mmap to do this step, too)\nA = rand(1:20, 5, 30)\ns = open(\"/tmp/mmap.bin\", \"w+\")\n# We\'ll write the dimensions of the array as the first two Ints in the file\nwrite(s, size(A,1))\nwrite(s, size(A,2))\n# Now write the data\nwrite(s, A)\nclose(s)\n\n# Test by reading it back in\ns = open(\"/tmp/mmap.bin\")   # default is read-only\nm = read(s, Int)\nn = read(s, Int)\nA2 = Mmap.mmap(s, Matrix{Int}, (m,n))\n\ncreates a m-by-n Matrix{Int}, linked to the file associated with stream s.\n\nA more portable file would need to encode the word size – 32 bit or 64 bit – and endianness information in the header. In practice, consider encoding binary data using standard formats like HDF5 (which can be used with memory-mapping).\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.Mmap.mmap-Tuple{Any,BitArray,Any,Any}",
    "page": "I/O and Network",
    "title": "Base.Mmap.mmap",
    "category": "method",
    "text": "Mmap.mmap(io, BitArray, [dims, offset])\n\nCreate a BitArray whose values are linked to a file, using memory-mapping; it has the same purpose, works in the same way, and has the same arguments, as mmap, but the byte representation is different.\n\nExample: B = Mmap.mmap(s, BitArray, (25,30000))\n\nThis would create a 25-by-30000 BitArray, linked to the file associated with stream s.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.Mmap.sync!",
    "page": "I/O and Network",
    "title": "Base.Mmap.sync!",
    "category": "function",
    "text": "Mmap.sync!(array)\n\nForces synchronization between the in-memory version of a memory-mapped Array or BitArray and the on-disk version.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Memory-mapped-I/O-1",
    "page": "I/O and Network",
    "title": "Memory-mapped I/O",
    "category": "section",
    "text": "Base.Mmap.Anonymous\nBase.Mmap.mmap(::Any, ::Type, ::Any, ::Any)\nBase.Mmap.mmap(::Any, ::BitArray, ::Any, ::Any)\nBase.Mmap.sync!"
},

{
    "location": "stdlib/io-network/#Base.connect-Tuple{TCPSocket,Integer}",
    "page": "I/O and Network",
    "title": "Base.connect",
    "category": "method",
    "text": "connect([host], port::Integer) -> TCPSocket\n\nConnect to the host host on port port.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.connect-Tuple{AbstractString}",
    "page": "I/O and Network",
    "title": "Base.connect",
    "category": "method",
    "text": "connect(path::AbstractString) -> PipeEndpoint\n\nConnect to the named pipe / UNIX domain socket at path.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.listen-Tuple{Any}",
    "page": "I/O and Network",
    "title": "Base.listen",
    "category": "method",
    "text": "listen([addr, ]port::Integer; backlog::Integer=BACKLOG_DEFAULT) -> TCPServer\n\nListen on port on the address specified by addr. By default this listens on localhost only. To listen on all interfaces pass IPv4(0) or IPv6(0) as appropriate. backlog determines how many connections can be pending (not having called accept) before the server will begin to reject them. The default value of backlog is 511.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.listen-Tuple{AbstractString}",
    "page": "I/O and Network",
    "title": "Base.listen",
    "category": "method",
    "text": "listen(path::AbstractString) -> PipeServer\n\nCreate and listen on a named pipe / UNIX domain socket.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.getaddrinfo",
    "page": "I/O and Network",
    "title": "Base.getaddrinfo",
    "category": "function",
    "text": "getaddrinfo(host::AbstractString) -> IPAddr\n\nGets the IP address of the host (may have to do a DNS lookup)\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.getsockname",
    "page": "I/O and Network",
    "title": "Base.getsockname",
    "category": "function",
    "text": "getsockname(sock::Union{TCPServer, TCPSocket}) -> (IPAddr, UInt16)\n\nGet the IP address and the port that the given TCPSocket is connected to (or bound to, in the case of TCPServer).\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.IPv4",
    "page": "I/O and Network",
    "title": "Base.IPv4",
    "category": "type",
    "text": "IPv4(host::Integer) -> IPv4\n\nReturns an IPv4 object from ip address host formatted as an Integer.\n\njulia> IPv4(3223256218)\nip\"192.30.252.154\"\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.IPv6",
    "page": "I/O and Network",
    "title": "Base.IPv6",
    "category": "type",
    "text": "IPv6(host::Integer) -> IPv6\n\nReturns an IPv6 object from ip address host formatted as an Integer.\n\njulia> IPv6(3223256218)\nip\"::c01e:fc9a\"\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.nb_available",
    "page": "I/O and Network",
    "title": "Base.nb_available",
    "category": "function",
    "text": "nb_available(stream)\n\nReturns the number of bytes available for reading before a read from this stream or buffer will block.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.accept",
    "page": "I/O and Network",
    "title": "Base.accept",
    "category": "function",
    "text": "accept(server[,client])\n\nAccepts a connection on the given server and returns a connection to the client. An uninitialized client stream may be provided, in which case it will be used instead of creating a new stream.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.listenany",
    "page": "I/O and Network",
    "title": "Base.listenany",
    "category": "function",
    "text": "listenany([host::IPAddr,] port_hint) -> (UInt16, TCPServer)\n\nCreate a TCPServer on any port, using hint as a starting point. Returns a tuple of the actual port that the server was created on and the server itself.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.Filesystem.poll_fd",
    "page": "I/O and Network",
    "title": "Base.Filesystem.poll_fd",
    "category": "function",
    "text": "poll_fd(fd, timeout_s::Real=-1; readable=false, writable=false)\n\nMonitor a file descriptor fd for changes in the read or write availability, and with a timeout given by timeout_s seconds.\n\nThe keyword arguments determine which of read and/or write status should be monitored; at least one of them must be set to true.\n\nThe returned value is an object with boolean fields readable, writable, and timedout, giving the result of the polling.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.Filesystem.poll_file",
    "page": "I/O and Network",
    "title": "Base.Filesystem.poll_file",
    "category": "function",
    "text": "poll_file(path::AbstractString, interval_s::Real=5.007, timeout_s::Real=-1) -> (previous::StatStruct, current::StatStruct)\n\nMonitor a file for changes by polling every interval_s seconds until a change occurs or timeout_s seconds have elapsed. The interval_s should be a long period; the default is 5.007 seconds.\n\nReturns a pair of StatStruct objects (previous, current) when a change is detected.\n\nTo determine when a file was modified, compare mtime(prev) != mtime(current) to detect notification of changes. However, using watch_file for this operation is preferred, since it is more reliable and efficient, although in some situations it may not be available.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.Filesystem.watch_file",
    "page": "I/O and Network",
    "title": "Base.Filesystem.watch_file",
    "category": "function",
    "text": "watch_file(path::AbstractString, timeout_s::Real=-1)\n\nWatch file or directory path for changes until a change occurs or timeout_s seconds have elapsed.\n\nThe returned value is an object with boolean fields changed, renamed, and timedout, giving the result of watching the file.\n\nThis behavior of this function varies slightly across platforms. See https://nodejs.org/api/fs.html#fs_caveats for more detailed information.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.bind",
    "page": "I/O and Network",
    "title": "Base.bind",
    "category": "function",
    "text": "bind(socket::Union{UDPSocket, TCPSocket}, host::IPAddr, port::Integer; ipv6only=false, reuseaddr=false, kws...)\n\nBind socket to the given host:port. Note that 0.0.0.0 will listen on all devices.\n\nThe ipv6only parameter disables dual stack mode. If ipv6only=true, only an IPv6 stack is created.\nIf reuseaddr=true, multiple threads or processes can bind to the same address without error if they all set reuseaddr=true, but only the last to bind will receive any traffic.\n\n\n\nbind(chnl::Channel, task::Task)\n\nAssociates the lifetime of chnl with a task. Channel chnl is automatically closed when the task terminates. Any uncaught exception in the task is propagated to all waiters on chnl.\n\nThe chnl object can be explicitly closed independent of task termination. Terminating tasks have no effect on already closed Channel objects.\n\nWhen a channel is bound to multiple tasks, the first task to terminate will close the channel. When multiple channels are bound to the same task, termination of the task will close all of the bound channels.\n\njulia> c = Channel(0);\n\njulia> task = @schedule foreach(i->put!(c, i), 1:4);\n\njulia> bind(c,task);\n\njulia> for i in c\n           @show i\n       end;\ni = 1\ni = 2\ni = 3\ni = 4\n\njulia> isopen(c)\nfalse\n\njulia> c = Channel(0);\n\njulia> task = @schedule (put!(c,1);error(\"foo\"));\n\njulia> bind(c,task);\n\njulia> take!(c)\n1\n\njulia> put!(c,1);\nERROR: foo\nStacktrace:\n [1] check_channel_state(::Channel{Any}) at ./channels.jl:131\n [2] put!(::Channel{Any}, ::Int64) at ./channels.jl:261\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.send",
    "page": "I/O and Network",
    "title": "Base.send",
    "category": "function",
    "text": "send(socket::UDPSocket, host, port::Integer, msg)\n\nSend msg over socket to host:port.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.recv",
    "page": "I/O and Network",
    "title": "Base.recv",
    "category": "function",
    "text": "recv(socket::UDPSocket)\n\nRead a UDP packet from the specified socket, and return the bytes received. This call blocks.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.recvfrom",
    "page": "I/O and Network",
    "title": "Base.recvfrom",
    "category": "function",
    "text": "recvfrom(socket::UDPSocket) -> (address, data)\n\nRead a UDP packet from the specified socket, returning a tuple of (address, data), where address will be either IPv4 or IPv6 as appropriate.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.setopt",
    "page": "I/O and Network",
    "title": "Base.setopt",
    "category": "function",
    "text": "setopt(sock::UDPSocket; multicast_loop = nothing, multicast_ttl=nothing, enable_broadcast=nothing, ttl=nothing)\n\nSet UDP socket options.\n\nmulticast_loop: loopback for multicast packets (default: true).\nmulticast_ttl: TTL for multicast packets (default: nothing).\nenable_broadcast: flag must be set to true if socket will be used for broadcast messages, or else the UDP system will return an access error (default: false).\nttl: Time-to-live of packets sent on the socket (default: nothing).\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.ntoh",
    "page": "I/O and Network",
    "title": "Base.ntoh",
    "category": "function",
    "text": "ntoh(x)\n\nConverts the endianness of a value from Network byte order (big-endian) to that used by the Host.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.hton",
    "page": "I/O and Network",
    "title": "Base.hton",
    "category": "function",
    "text": "hton(x)\n\nConverts the endianness of a value from that used by the Host to Network byte order (big-endian).\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.ltoh",
    "page": "I/O and Network",
    "title": "Base.ltoh",
    "category": "function",
    "text": "ltoh(x)\n\nConverts the endianness of a value from Little-endian to that used by the Host.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.htol",
    "page": "I/O and Network",
    "title": "Base.htol",
    "category": "function",
    "text": "htol(x)\n\nConverts the endianness of a value from that used by the Host to Little-endian.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Base.ENDIAN_BOM",
    "page": "I/O and Network",
    "title": "Base.ENDIAN_BOM",
    "category": "constant",
    "text": "ENDIAN_BOM\n\nThe 32-bit byte-order-mark indicates the native byte order of the host machine. Little-endian machines will contain the value 0x04030201. Big-endian machines will contain the value 0x01020304.\n\n\n\n"
},

{
    "location": "stdlib/io-network/#Network-I/O-1",
    "page": "I/O and Network",
    "title": "Network I/O",
    "category": "section",
    "text": "Base.connect(::TCPSocket, ::Integer)\nBase.connect(::AbstractString)\nBase.listen(::Any)\nBase.listen(::AbstractString)\nBase.getaddrinfo\nBase.getsockname\nBase.IPv4\nBase.IPv6\nBase.nb_available\nBase.accept\nBase.listenany\nBase.Filesystem.poll_fd\nBase.Filesystem.poll_file\nBase.Filesystem.watch_file\nBase.bind\nBase.send\nBase.recv\nBase.recvfrom\nBase.setopt\nBase.ntoh\nBase.hton\nBase.ltoh\nBase.htol\nBase.ENDIAN_BOM"
},

{
    "location": "stdlib/punctuation/#",
    "page": "Punctuation",
    "title": "Punctuation",
    "category": "page",
    "text": ""
},

{
    "location": "stdlib/punctuation/#Punctuation-1",
    "page": "Punctuation",
    "title": "Punctuation",
    "category": "section",
    "text": "Extended documentation for mathematical symbols & functions is here.symbol meaning\n@m invoke macro m; followed by space-separated expressions\n! prefix \"not\" operator\na!( ) at the end of a function name, ! indicates that a function modifies its argument(s)\n# begin single line comment\n#= begin multi-line comment (these are nestable)\n=# end multi-line comment\n$ string and expression interpolation\n% remainder operator\n^ exponent operator\n& bitwise and\n&& short-circuiting boolean and\n| bitwise or\n|| short-circuiting boolean or\n⊻ bitwise xor operator\n* multiply, or matrix multiply\n() the empty tuple\n~ bitwise not operator\n\\ backslash operator\n\' complex transpose operator Aᴴ\na[] array indexing\n[,] vertical concatenation\n[;] also vertical concatenation\n[    ] with space-separated expressions, horizontal concatenation\nT{ } parametric type instantiation\n; statement separator\n, separate function arguments or tuple components\n? 3-argument conditional operator (conditional ? if_true : if_false)\n\"\" delimit string literals\n\'\' delimit character literals\n` ` delimit external process (command) specifications\n... splice arguments into a function call or declare a varargs function or type\n. access named fields in objects/modules, also prefixes elementwise operator/function calls\na:b range a, a+1, a+2, ..., b\na:s:b range a, a+s, a+2s, ..., b\n: index an entire dimension (1:end)\n:: type annotation, depending on context\n:( ) quoted expression\n:a symbol a\n<: subtype operator\n>: supertype operator (reverse of subtype operator)\n=== egal comparison operator"
},

{
    "location": "stdlib/sort/#",
    "page": "Sorting and Related Functions",
    "title": "Sorting and Related Functions",
    "category": "page",
    "text": ""
},

{
    "location": "stdlib/sort/#Sorting-and-Related-Functions-1",
    "page": "Sorting and Related Functions",
    "title": "Sorting and Related Functions",
    "category": "section",
    "text": "Julia has an extensive, flexible API for sorting and interacting with already-sorted arrays of values. By default, Julia picks reasonable algorithms and sorts in standard ascending order:julia> sort([2,3,1])\n3-element Array{Int64,1}:\n 1\n 2\n 3You can easily sort in reverse order as well:julia> sort([2,3,1], rev=true)\n3-element Array{Int64,1}:\n 3\n 2\n 1To sort an array in-place, use the \"bang\" version of the sort function:julia> a = [2,3,1];\n\njulia> sort!(a);\n\njulia> a\n3-element Array{Int64,1}:\n 1\n 2\n 3Instead of directly sorting an array, you can compute a permutation of the array\'s indices that puts the array into sorted order:julia> v = randn(5)\n5-element Array{Float64,1}:\n  0.297288\n  0.382396\n -0.597634\n -0.0104452\n -0.839027\n\njulia> p = sortperm(v)\n5-element Array{Int64,1}:\n 5\n 3\n 4\n 1\n 2\n\njulia> v[p]\n5-element Array{Float64,1}:\n -0.839027\n -0.597634\n -0.0104452\n  0.297288\n  0.382396Arrays can easily be sorted according to an arbitrary transformation of their values:julia> sort(v, by=abs)\n5-element Array{Float64,1}:\n -0.0104452\n  0.297288\n  0.382396\n -0.597634\n -0.839027Or in reverse order by a transformation:julia> sort(v, by=abs, rev=true)\n5-element Array{Float64,1}:\n -0.839027\n -0.597634\n  0.382396\n  0.297288\n -0.0104452If needed, the sorting algorithm can be chosen:julia> sort(v, alg=InsertionSort)\n5-element Array{Float64,1}:\n -0.839027\n -0.597634\n -0.0104452\n  0.297288\n  0.382396All the sorting and order related functions rely on a \"less than\" relation defining a total order on the values to be manipulated. The isless function is invoked by default, but the relation can be specified via the lt keyword."
},

{
    "location": "stdlib/sort/#Base.sort!",
    "page": "Sorting and Related Functions",
    "title": "Base.sort!",
    "category": "function",
    "text": "sort!(v; alg::Algorithm=defalg(v), lt=isless, by=identity, rev::Bool=false, order::Ordering=Forward)\n\nSort the vector v in place. QuickSort is used by default for numeric arrays while MergeSort is used for other arrays. You can specify an algorithm to use via the alg keyword (see Sorting Algorithms for available algorithms). The by keyword lets you provide a function that will be applied to each element before comparison; the lt keyword allows providing a custom \"less than\" function; use rev=true to reverse the sorting order. These options are independent and can be used together in all possible combinations: if both by and lt are specified, the lt function is applied to the result of the by function; rev=true reverses whatever ordering specified via the by and lt keywords.\n\nExamples\n\njulia> v = [3, 1, 2]; sort!(v); v\n3-element Array{Int64,1}:\n 1\n 2\n 3\n\njulia> v = [3, 1, 2]; sort!(v, rev = true); v\n3-element Array{Int64,1}:\n 3\n 2\n 1\n\njulia> v = [(1, \"c\"), (3, \"a\"), (2, \"b\")]; sort!(v, by = x -> x[1]); v\n3-element Array{Tuple{Int64,String},1}:\n (1, \"c\")\n (2, \"b\")\n (3, \"a\")\n\njulia> v = [(1, \"c\"), (3, \"a\"), (2, \"b\")]; sort!(v, by = x -> x[2]); v\n3-element Array{Tuple{Int64,String},1}:\n (3, \"a\")\n (2, \"b\")\n (1, \"c\")\n\n\n\n"
},

{
    "location": "stdlib/sort/#Base.sort",
    "page": "Sorting and Related Functions",
    "title": "Base.sort",
    "category": "function",
    "text": "sort(v; alg::Algorithm=defalg(v), lt=isless, by=identity, rev::Bool=false, order::Ordering=Forward)\n\nVariant of sort! that returns a sorted copy of v leaving v itself unmodified.\n\nExamples\n\njulia> v = [3, 1, 2];\n\njulia> sort(v)\n3-element Array{Int64,1}:\n 1\n 2\n 3\n\njulia> v\n3-element Array{Int64,1}:\n 3\n 1\n 2\n\n\n\nsort(A, dim::Integer; alg::Algorithm=DEFAULT_UNSTABLE, lt=isless, by=identity, rev::Bool=false, order::Ordering=Forward, initialized::Bool=false)\n\nSort a multidimensional array A along the given dimension. See sort! for a description of possible keyword arguments.\n\nExamples\n\njulia> A = [4 3; 1 2]\n2×2 Array{Int64,2}:\n 4  3\n 1  2\n\njulia> sort(A, 1)\n2×2 Array{Int64,2}:\n 1  2\n 4  3\n\njulia> sort(A, 2)\n2×2 Array{Int64,2}:\n 3  4\n 1  2\n\n\n\n"
},

{
    "location": "stdlib/sort/#Base.sortperm",
    "page": "Sorting and Related Functions",
    "title": "Base.sortperm",
    "category": "function",
    "text": "sortperm(v; alg::Algorithm=DEFAULT_UNSTABLE, lt=isless, by=identity, rev::Bool=false, order::Ordering=Forward)\n\nReturn a permutation vector of indices of v that puts it in sorted order. Specify alg to choose a particular sorting algorithm (see Sorting Algorithms). MergeSort is used by default, and since it is stable, the resulting permutation will be the lexicographically first one that puts the input array into sorted order – i.e. indices of equal elements appear in ascending order. If you choose a non-stable sorting algorithm such as QuickSort, a different permutation that puts the array into order may be returned. The order is specified using the same keywords as sort!.\n\nSee also sortperm!.\n\nExamples\n\njulia> v = [3, 1, 2];\n\njulia> p = sortperm(v)\n3-element Array{Int64,1}:\n 2\n 3\n 1\n\njulia> v[p]\n3-element Array{Int64,1}:\n 1\n 2\n 3\n\n\n\n"
},

{
    "location": "stdlib/sort/#Base.Sort.sortperm!",
    "page": "Sorting and Related Functions",
    "title": "Base.Sort.sortperm!",
    "category": "function",
    "text": "sortperm!(ix, v; alg::Algorithm=DEFAULT_UNSTABLE, lt=isless, by=identity, rev::Bool=false, order::Ordering=Forward, initialized::Bool=false)\n\nLike sortperm, but accepts a preallocated index vector ix.  If initialized is false (the default), ix is initialized to contain the values 1:length(v).\n\nExamples\n\njulia> v = [3, 1, 2]; p = zeros(Int, 3);\n\njulia> sortperm!(p, v); p\n3-element Array{Int64,1}:\n 2\n 3\n 1\n\njulia> v[p]\n3-element Array{Int64,1}:\n 1\n 2\n 3\n\n\n\n"
},

{
    "location": "stdlib/sort/#Base.Sort.sortrows",
    "page": "Sorting and Related Functions",
    "title": "Base.Sort.sortrows",
    "category": "function",
    "text": "sortrows(A; alg::Algorithm=DEFAULT_UNSTABLE, lt=isless, by=identity, rev::Bool=false, order::Ordering=Forward)\n\nSort the rows of matrix A lexicographically. See sort! for a description of possible keyword arguments.\n\nExamples\n\njulia> sortrows([7 3 5; -1 6 4; 9 -2 8])\n3×3 Array{Int64,2}:\n -1   6  4\n  7   3  5\n  9  -2  8\n\njulia> sortrows([7 3 5; -1 6 4; 9 -2 8], lt=(x,y)->isless(x[2],y[2]))\n3×3 Array{Int64,2}:\n  9  -2  8\n  7   3  5\n -1   6  4\n\njulia> sortrows([7 3 5; -1 6 4; 9 -2 8], rev=true)\n3×3 Array{Int64,2}:\n  9  -2  8\n  7   3  5\n -1   6  4\n\n\n\n"
},

{
    "location": "stdlib/sort/#Base.Sort.sortcols",
    "page": "Sorting and Related Functions",
    "title": "Base.Sort.sortcols",
    "category": "function",
    "text": "sortcols(A; alg::Algorithm=DEFAULT_UNSTABLE, lt=isless, by=identity, rev::Bool=false, order::Ordering=Forward)\n\nSort the columns of matrix A lexicographically. See sort! for a description of possible keyword arguments.\n\nExamples\n\njulia> sortcols([7 3 5; 6 -1 -4; 9 -2 8])\n3×3 Array{Int64,2}:\n  3   5  7\n -1  -4  6\n -2   8  9\n\njulia> sortcols([7 3 5; 6 -1 -4; 9 -2 8], alg=InsertionSort, lt=(x,y)->isless(x[2],y[2]))\n3×3 Array{Int64,2}:\n  5   3  7\n -4  -1  6\n  8  -2  9\n\njulia> sortcols([7 3 5; 6 -1 -4; 9 -2 8], rev=true)\n3×3 Array{Int64,2}:\n 7   5   3\n 6  -4  -1\n 9   8  -2\n\n\n\n"
},

{
    "location": "stdlib/sort/#Sorting-Functions-1",
    "page": "Sorting and Related Functions",
    "title": "Sorting Functions",
    "category": "section",
    "text": "Base.sort!\nBase.sort\nBase.sortperm\nBase.Sort.sortperm!\nBase.Sort.sortrows\nBase.Sort.sortcols"
},

{
    "location": "stdlib/sort/#Base.issorted",
    "page": "Sorting and Related Functions",
    "title": "Base.issorted",
    "category": "function",
    "text": "issorted(v, lt=isless, by=identity, rev:Bool=false, order::Ordering=Forward)\n\nTest whether a vector is in sorted order. The lt, by and rev keywords modify what order is considered to be sorted just as they do for sort.\n\nExamples\n\njulia> issorted([1, 2, 3])\ntrue\n\njulia> issorted([(1, \"b\"), (2, \"a\")], by = x -> x[1])\ntrue\n\njulia> issorted([(1, \"b\"), (2, \"a\")], by = x -> x[2])\nfalse\n\njulia> issorted([(1, \"b\"), (2, \"a\")], by = x -> x[2], rev=true)\ntrue\n\n\n\n"
},

{
    "location": "stdlib/sort/#Base.Sort.searchsorted",
    "page": "Sorting and Related Functions",
    "title": "Base.Sort.searchsorted",
    "category": "function",
    "text": "searchsorted(a, x, [by=<transform>,] [lt=<comparison>,] [rev=false])\n\nReturns the range of indices of a which compare as equal to x (using binary search) according to the order specified by the by, lt and rev keywords, assuming that a is already sorted in that order. Returns an empty range located at the insertion point if a does not contain values equal to x.\n\nExamples\n\njulia> a = [4, 3, 2, 1]\n4-element Array{Int64,1}:\n 4\n 3\n 2\n 1\n\njulia> searchsorted(a, 4)\n5:4\n\njulia> searchsorted(a, 4, rev=true)\n1:1\n\n\n\n"
},

{
    "location": "stdlib/sort/#Base.Sort.searchsortedfirst",
    "page": "Sorting and Related Functions",
    "title": "Base.Sort.searchsortedfirst",
    "category": "function",
    "text": "searchsortedfirst(a, x, [by=<transform>,] [lt=<comparison>,] [rev=false])\n\nReturns the index of the first value in a greater than or equal to x, according to the specified order. Returns length(a)+1 if x is greater than all values in a. a is assumed to be sorted.\n\nExamples\n\njulia> searchsortedfirst([1, 2, 4, 5, 14], 4)\n3\n\njulia> searchsortedfirst([1, 2, 4, 5, 14], 4, rev=true)\n1\n\njulia> searchsortedfirst([1, 2, 4, 5, 14], 15)\n6\n\n\n\n"
},

{
    "location": "stdlib/sort/#Base.Sort.searchsortedlast",
    "page": "Sorting and Related Functions",
    "title": "Base.Sort.searchsortedlast",
    "category": "function",
    "text": "searchsortedlast(a, x, [by=<transform>,] [lt=<comparison>,] [rev=false])\n\nReturns the index of the last value in a less than or equal to x, according to the specified order. Returns 0 if x is less than all values in a. a is assumed to be sorted.\n\nExamples\n\njulia> searchsortedlast([1, 2, 4, 5, 14], 4)\n3\n\njulia> searchsortedlast([1, 2, 4, 5, 14], 4, rev=true)\n5\n\njulia> searchsortedlast([1, 2, 4, 5, 14], -1)\n0\n\n\n\n"
},

{
    "location": "stdlib/sort/#Base.Sort.select!",
    "page": "Sorting and Related Functions",
    "title": "Base.Sort.select!",
    "category": "function",
    "text": "select!(v, k, [by=<transform>,] [lt=<comparison>,] [rev=false])\n\nPartially sort the vector v in place, according to the order specified by by, lt and rev so that the value at index k (or range of adjacent values if k is a range) occurs at the position where it would appear if the array were fully sorted via a non-stable algorithm. If k is a single index, that value is returned; if k is a range, an array of values at those indices is returned. Note that select! does not fully sort the input array.\n\nExamples\n\njulia> a = [1, 2, 4, 3, 4]\n5-element Array{Int64,1}:\n 1\n 2\n 4\n 3\n 4\n\njulia> select!(a, 4)\n4\n\njulia> a\n5-element Array{Int64,1}:\n 1\n 2\n 3\n 4\n 4\n\njulia> a = [1, 2, 4, 3, 4]\n5-element Array{Int64,1}:\n 1\n 2\n 4\n 3\n 4\n\njulia> select!(a, 4, rev=true)\n2\n\njulia> a\n5-element Array{Int64,1}:\n 4\n 4\n 3\n 2\n 1\n\n\n\n"
},

{
    "location": "stdlib/sort/#Base.Sort.select",
    "page": "Sorting and Related Functions",
    "title": "Base.Sort.select",
    "category": "function",
    "text": "select(v, k, [by=<transform>,] [lt=<comparison>,] [rev=false])\n\nVariant of select! which copies v before partially sorting it, thereby returning the same thing as select! but leaving v unmodified.\n\n\n\n"
},

{
    "location": "stdlib/sort/#Base.Sort.selectperm",
    "page": "Sorting and Related Functions",
    "title": "Base.Sort.selectperm",
    "category": "function",
    "text": "selectperm(v, k, [alg=<algorithm>,] [by=<transform>,] [lt=<comparison>,] [rev=false])\n\nReturn a partial permutation of the vector v, according to the order specified by by, lt and rev, so that v[output] returns the first k (or range of adjacent values if k is a range) values of a fully sorted version of v. If k is a single index (Integer), an array of the first k indices is returned; if k is a range, an array of those indices is returned. Note that the handling of integer values for k is different from select in that it returns a vector of k elements instead of just the k th element. Also note that this is equivalent to, but more efficient than, calling sortperm(...)[k].\n\n\n\n"
},

{
    "location": "stdlib/sort/#Base.Sort.selectperm!",
    "page": "Sorting and Related Functions",
    "title": "Base.Sort.selectperm!",
    "category": "function",
    "text": "selectperm!(ix, v, k, [alg=<algorithm>,] [by=<transform>,] [lt=<comparison>,] [rev=false,] [initialized=false])\n\nLike selectperm, but accepts a preallocated index vector ix. If initialized is false (the default), ix is initialized to contain the values 1:length(ix).\n\n\n\n"
},

{
    "location": "stdlib/sort/#Order-Related-Functions-1",
    "page": "Sorting and Related Functions",
    "title": "Order-Related Functions",
    "category": "section",
    "text": "Base.issorted\nBase.Sort.searchsorted\nBase.Sort.searchsortedfirst\nBase.Sort.searchsortedlast\nBase.Sort.select!\nBase.Sort.select\nBase.Sort.selectperm\nBase.Sort.selectperm!"
},

{
    "location": "stdlib/sort/#Sorting-Algorithms-1",
    "page": "Sorting and Related Functions",
    "title": "Sorting Algorithms",
    "category": "section",
    "text": "There are currently four sorting algorithms available in base Julia:InsertionSort\nQuickSort\nPartialQuickSort(k)\nMergeSortInsertionSort is an O(n^2) stable sorting algorithm. It is efficient for very small n, and is used internally by QuickSort.QuickSort is an O(n log n) sorting algorithm which is in-place, very fast, but not stable – i.e. elements which are considered equal will not remain in the same order in which they originally appeared in the array to be sorted. QuickSort is the default algorithm for numeric values, including integers and floats.PartialQuickSort(k) is similar to QuickSort, but the output array is only sorted up to index k if k is an integer, or in the range of k if k is an OrdinalRange. For example:x = rand(1:500, 100)\nk = 50\nk2 = 50:100\ns = sort(x; alg=QuickSort)\nps = sort(x; alg=PartialQuickSort(k))\nqs = sort(x; alg=PartialQuickSort(k2))\nmap(issorted, (s, ps, qs))             # => (true, false, false)\nmap(x->issorted(x[1:k]), (s, ps, qs))  # => (true, true, false)\nmap(x->issorted(x[k2]), (s, ps, qs))   # => (true, false, true)\ns[1:k] == ps[1:k]                      # => true\ns[k2] == qs[k2]                        # => trueMergeSort is an O(n log n) stable sorting algorithm but is not in-place – it requires a temporary array of half the size of the input array – and is typically not quite as fast as QuickSort. It is the default algorithm for non-numeric data.The default sorting algorithms are chosen on the basis that they are fast and stable, or appear to be so. For numeric types indeed, QuickSort is selected as it is faster and indistinguishable in this case from a stable sort (unless the array records its mutations in some way). The stability property comes at a non-negligible cost, so if you don\'t need it, you may want to explicitly specify your preferred algorithm, e.g. sort!(v, alg=QuickSort).The mechanism by which Julia picks default sorting algorithms is implemented via the Base.Sort.defalg function. It allows a particular algorithm to be registered as the default in all sorting functions for specific arrays. For example, here are the two default methods from sort.jl:defalg(v::AbstractArray) = MergeSort\ndefalg{T<:Number}(v::AbstractArray{T}) = QuickSortAs for numeric arrays, choosing a non-stable default algorithm for array types for which the notion of a stable sort is meaningless (i.e. when two values comparing equal can not be distinguished) may make sense."
},

{
    "location": "stdlib/pkg/#",
    "page": "Package Manager Functions",
    "title": "Package Manager Functions",
    "category": "page",
    "text": ""
},

{
    "location": "stdlib/pkg/#Base.Pkg.dir",
    "page": "Package Manager Functions",
    "title": "Base.Pkg.dir",
    "category": "function",
    "text": "dir() -> AbstractString\n\nReturns the absolute path of the package directory. This defaults to joinpath(homedir(),\".julia\",\"v$(VERSION.major).$(VERSION.minor)\") on all platforms (i.e. ~/.julia/v0.6 in UNIX shell syntax). If the JULIA_PKGDIR environment variable is set, then that path is used in the returned value as joinpath(ENV[\"JULIA_PKGDIR\"],\"v$(VERSION.major).$(VERSION.minor)\"). If JULIA_PKGDIR is a relative path, it is interpreted relative to whatever the current working directory is.\n\n\n\ndir(names...) -> AbstractString\n\nEquivalent to normpath(Pkg.dir(),names...) – i.e. it appends path components to the package directory and normalizes the resulting path. In particular, Pkg.dir(pkg) returns the path to the package pkg.\n\n\n\n"
},

{
    "location": "stdlib/pkg/#Base.Pkg.init",
    "page": "Package Manager Functions",
    "title": "Base.Pkg.init",
    "category": "function",
    "text": "init(meta::AbstractString=DEFAULT_META, branch::AbstractString=META_BRANCH)\n\nInitialize Pkg.dir() as a package directory. This will be done automatically when the JULIA_PKGDIR is not set and Pkg.dir() uses its default value. As part of this process, clones a local METADATA git repository from the site and branch specified by its arguments, which are typically not provided. Explicit (non-default) arguments can be used to support a custom METADATA setup.\n\n\n\n"
},

{
    "location": "stdlib/pkg/#Base.Pkg.resolve",
    "page": "Package Manager Functions",
    "title": "Base.Pkg.resolve",
    "category": "function",
    "text": "resolve()\n\nDetermines an optimal, consistent set of package versions to install or upgrade to. The optimal set of package versions is based on the contents of Pkg.dir(\"REQUIRE\") and the state of installed packages in Pkg.dir(), Packages that are no longer required are moved into Pkg.dir(\".trash\").\n\n\n\n"
},

{
    "location": "stdlib/pkg/#Base.Pkg.edit",
    "page": "Package Manager Functions",
    "title": "Base.Pkg.edit",
    "category": "function",
    "text": "edit()\n\nOpens Pkg.dir(\"REQUIRE\") in the editor specified by the VISUAL or EDITOR environment variables; when the editor command returns, it runs Pkg.resolve() to determine and install a new optimal set of installed package versions.\n\n\n\n"
},

{
    "location": "stdlib/pkg/#Base.Pkg.add",
    "page": "Package Manager Functions",
    "title": "Base.Pkg.add",
    "category": "function",
    "text": "add(pkg, vers...)\n\nAdd a requirement entry for pkg to Pkg.dir(\"REQUIRE\") and call Pkg.resolve(). If vers are given, they must be VersionNumber objects and they specify acceptable version intervals for pkg.\n\n\n\n"
},

{
    "location": "stdlib/pkg/#Base.Pkg.rm",
    "page": "Package Manager Functions",
    "title": "Base.Pkg.rm",
    "category": "function",
    "text": "rm(pkg)\n\nRemove all requirement entries for pkg from Pkg.dir(\"REQUIRE\") and call Pkg.resolve().\n\n\n\n"
},

{
    "location": "stdlib/pkg/#Base.Pkg.clone",
    "page": "Package Manager Functions",
    "title": "Base.Pkg.clone",
    "category": "function",
    "text": "clone(pkg)\n\nIf pkg has a URL registered in Pkg.dir(\"METADATA\"), clone it from that URL on the default branch. The package does not need to have any registered versions.\n\n\n\nclone(url, [pkg])\n\nClone a package directly from the git URL url. The package does not need to be registered in Pkg.dir(\"METADATA\"). The package repo is cloned by the name pkg if provided; if not provided, pkg is determined automatically from url.\n\n\n\n"
},

{
    "location": "stdlib/pkg/#Base.Pkg.setprotocol!",
    "page": "Package Manager Functions",
    "title": "Base.Pkg.setprotocol!",
    "category": "function",
    "text": "setprotocol!(proto)\n\nSet the protocol used to access GitHub-hosted packages. Defaults to \'https\', with a blank proto delegating the choice to the package developer.\n\n\n\n"
},

{
    "location": "stdlib/pkg/#Base.Pkg.available",
    "page": "Package Manager Functions",
    "title": "Base.Pkg.available",
    "category": "function",
    "text": "available() -> Vector{String}\n\nReturns the names of available packages.\n\n\n\navailable(pkg) -> Vector{VersionNumber}\n\nReturns the version numbers available for package pkg.\n\n\n\n"
},

{
    "location": "stdlib/pkg/#Base.Pkg.installed",
    "page": "Package Manager Functions",
    "title": "Base.Pkg.installed",
    "category": "function",
    "text": "installed() -> Dict{String,VersionNumber}\n\nReturns a dictionary mapping installed package names to the installed version number of each package.\n\n\n\ninstalled(pkg) -> Void | VersionNumber\n\nIf pkg is installed, return the installed version number. If pkg is registered, but not installed, return nothing.\n\n\n\n"
},

{
    "location": "stdlib/pkg/#Base.Pkg.status",
    "page": "Package Manager Functions",
    "title": "Base.Pkg.status",
    "category": "function",
    "text": "status()\n\nPrints out a summary of what packages are installed and what version and state they\'re in.\n\n\n\nstatus(pkg)\n\nPrints out a summary of what version and state pkg, specifically, is in.\n\n\n\n"
},

{
    "location": "stdlib/pkg/#Base.Pkg.update",
    "page": "Package Manager Functions",
    "title": "Base.Pkg.update",
    "category": "function",
    "text": "update(pkgs...)\n\nUpdate the metadata repo – kept in Pkg.dir(\"METADATA\") – then update any fixed packages that can safely be pulled from their origin; then call Pkg.resolve() to determine a new optimal set of packages versions.\n\nWithout arguments, updates all installed packages. When one or more package names are provided as arguments, only those packages and their dependencies are updated.\n\n\n\n"
},

{
    "location": "stdlib/pkg/#Base.Pkg.checkout",
    "page": "Package Manager Functions",
    "title": "Base.Pkg.checkout",
    "category": "function",
    "text": "checkout(pkg, [branch=\"master\"]; merge=true, pull=true)\n\nCheckout the Pkg.dir(pkg) repo to the branch branch. Defaults to checking out the \"master\" branch. To go back to using the newest compatible released version, use Pkg.free(pkg). Changes are merged (fast-forward only) if the keyword argument merge == true, and the latest version is pulled from the upstream repo if pull == true.\n\n\n\n"
},

{
    "location": "stdlib/pkg/#Base.Pkg.pin",
    "page": "Package Manager Functions",
    "title": "Base.Pkg.pin",
    "category": "function",
    "text": "pin(pkg)\n\nPin pkg at the current version. To go back to using the newest compatible released version, use Pkg.free(pkg)\n\n\n\npin(pkg, version)\n\nPin pkg at registered version version.\n\n\n\n"
},

{
    "location": "stdlib/pkg/#Base.Pkg.free",
    "page": "Package Manager Functions",
    "title": "Base.Pkg.free",
    "category": "function",
    "text": "free(pkg)\n\nFree the package pkg to be managed by the package manager again. It calls Pkg.resolve() to determine optimal package versions after. This is an inverse for both Pkg.checkout and Pkg.pin.\n\nYou can also supply an iterable collection of package names, e.g., Pkg.free((\"Pkg1\", \"Pkg2\")) to free multiple packages at once.\n\n\n\n"
},

{
    "location": "stdlib/pkg/#Base.Pkg.build",
    "page": "Package Manager Functions",
    "title": "Base.Pkg.build",
    "category": "function",
    "text": "build()\n\nRun the build scripts for all installed packages in depth-first recursive order.\n\n\n\nbuild(pkgs...)\n\nRun the build script in deps/build.jl for each package in pkgs and all of their dependencies in depth-first recursive order. This is called automatically by Pkg.resolve() on all installed or updated packages.\n\n\n\n"
},

{
    "location": "stdlib/pkg/#Base.Pkg.test",
    "page": "Package Manager Functions",
    "title": "Base.Pkg.test",
    "category": "function",
    "text": "test(; coverage=false)\n\nRun the tests for all installed packages ensuring that each package\'s test dependencies are installed for the duration of the test. A package is tested by running its test/runtests.jl file and test dependencies are specified in test/REQUIRE. Coverage statistics for the packages may be generated by passing coverage=true. The default behavior is not to run coverage.\n\n\n\ntest(pkgs...; coverage=false)\n\nRun the tests for each package in pkgs ensuring that each package\'s test dependencies are installed for the duration of the test. A package is tested by running its test/runtests.jl file and test dependencies are specified in test/REQUIRE. Coverage statistics for the packages may be generated by passing coverage=true. The default behavior is not to run coverage.\n\n\n\n"
},

{
    "location": "stdlib/pkg/#Base.Pkg.dependents",
    "page": "Package Manager Functions",
    "title": "Base.Pkg.dependents",
    "category": "function",
    "text": "dependents(pkg)\n\nList the packages that have pkg as a dependency.\n\n\n\n"
},

{
    "location": "stdlib/pkg/#Package-Manager-Functions-1",
    "page": "Package Manager Functions",
    "title": "Package Manager Functions",
    "category": "section",
    "text": "All package manager functions are defined in the Pkg module. None of the Pkg module\'s functions are exported; to use them, you\'ll need to prefix each function call with an explicit Pkg., e.g. Pkg.status() or Pkg.dir().Functions for package development (e.g. tag, publish, etc.) have been moved to the PkgDev package. See PkgDev README for the documentation of those functions.Base.Pkg.dir\nBase.Pkg.init\nBase.Pkg.resolve\nBase.Pkg.edit\nBase.Pkg.add\nBase.Pkg.rm\nBase.Pkg.clone\nBase.Pkg.setprotocol!\nBase.Pkg.available\nBase.Pkg.installed\nBase.Pkg.status\nBase.Pkg.update\nBase.Pkg.checkout\nBase.Pkg.pin\nBase.Pkg.free\nBase.Pkg.build\nBase.Pkg.test\nBase.Pkg.dependents"
},

{
    "location": "stdlib/dates/#",
    "page": "Dates and Time",
    "title": "Dates and Time",
    "category": "page",
    "text": ""
},

{
    "location": "stdlib/dates/#stdlib-dates-1",
    "page": "Dates and Time",
    "title": "Dates and Time",
    "category": "section",
    "text": ""
},

{
    "location": "stdlib/dates/#Base.Dates.Period",
    "page": "Dates and Time",
    "title": "Base.Dates.Period",
    "category": "type",
    "text": "Period\nYear\nMonth\nWeek\nDay\nHour\nMinute\nSecond\nMillisecond\nMicrosecond\nNanosecond\n\nPeriod types represent discrete, human representations of time.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.CompoundPeriod",
    "page": "Dates and Time",
    "title": "Base.Dates.CompoundPeriod",
    "category": "type",
    "text": "CompoundPeriod\n\nA CompoundPeriod is useful for expressing time periods that are not a fixed multiple of smaller periods. For example, \"a year and a  day\" is not a fixed number of days, but can be expressed using a CompoundPeriod. In fact, a CompoundPeriod is automatically generated by addition of different period types, e.g. Year(1) + Day(1) produces a CompoundPeriod result.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.Instant",
    "page": "Dates and Time",
    "title": "Base.Dates.Instant",
    "category": "type",
    "text": "Instant\n\nInstant types represent integer-based, machine representations of time as continuous timelines starting from an epoch.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.UTInstant",
    "page": "Dates and Time",
    "title": "Base.Dates.UTInstant",
    "category": "type",
    "text": "UTInstant{T}\n\nThe UTInstant represents a machine timeline based on UT time (1 day = one revolution of the earth). The T is a Period parameter that indicates the resolution or precision of the instant.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.TimeType",
    "page": "Dates and Time",
    "title": "Base.Dates.TimeType",
    "category": "type",
    "text": "TimeType\n\nTimeType types wrap Instant machine instances to provide human representations of the machine instant. Time, DateTime and Date are subtypes of TimeType.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.DateTime",
    "page": "Dates and Time",
    "title": "Base.Dates.DateTime",
    "category": "type",
    "text": "DateTime\n\nDateTime wraps a UTInstant{Millisecond} and interprets it according to the proleptic Gregorian calendar.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.Date",
    "page": "Dates and Time",
    "title": "Base.Dates.Date",
    "category": "type",
    "text": "Date\n\nDate wraps a UTInstant{Day} and interprets it according to the proleptic Gregorian calendar.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.Time",
    "page": "Dates and Time",
    "title": "Base.Dates.Time",
    "category": "type",
    "text": "Time\n\nTime wraps a Nanosecond and represents a specific moment in a 24-hour day.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Dates-and-Time-Types-1",
    "page": "Dates and Time",
    "title": "Dates and Time Types",
    "category": "section",
    "text": "Base.Dates.Period\nBase.Dates.CompoundPeriod\nBase.Dates.Instant\nBase.Dates.UTInstant\nBase.Dates.TimeType\nBase.Dates.DateTime\nBase.Dates.Date\nBase.Dates.Time"
},

{
    "location": "stdlib/dates/#Base.Dates.DateTime-NTuple{7,Int64}",
    "page": "Dates and Time",
    "title": "Base.Dates.DateTime",
    "category": "method",
    "text": "DateTime(y, [m, d, h, mi, s, ms]) -> DateTime\n\nConstruct a DateTime type by parts. Arguments must be convertible to Int64.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.DateTime-Tuple{Vararg{Base.Dates.Period,N} where N}",
    "page": "Dates and Time",
    "title": "Base.Dates.DateTime",
    "category": "method",
    "text": "DateTime(periods::Period...) -> DateTime\n\nConstruct a DateTime type by Period type parts. Arguments may be in any order. DateTime parts not provided will default to the value of Dates.default(period).\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.DateTime-Tuple{Function,Vararg{Any,N} where N}",
    "page": "Dates and Time",
    "title": "Base.Dates.DateTime",
    "category": "method",
    "text": "DateTime(f::Function, y[, m, d, h, mi, s]; step=Day(1), limit=10000) -> DateTime\n\nCreate a DateTime through the adjuster API. The starting point will be constructed from the provided y, m, d... arguments, and will be adjusted until f::Function returns true. The step size in adjusting can be provided manually through the step keyword. limit provides a limit to the max number of iterations the adjustment API will pursue before throwing an error (in the case that f::Function is never satisfied).\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.DateTime-Tuple{Base.Dates.TimeType}",
    "page": "Dates and Time",
    "title": "Base.Dates.DateTime",
    "category": "method",
    "text": "DateTime(dt::Date) -> DateTime\n\nConverts a Date to a DateTime. The hour, minute, second, and millisecond parts of the new DateTime are assumed to be zero.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.DateTime-Tuple{AbstractString,AbstractString}",
    "page": "Dates and Time",
    "title": "Base.Dates.DateTime",
    "category": "method",
    "text": "DateTime(dt::AbstractString, format::AbstractString; locale=\"english\") -> DateTime\n\nConstruct a DateTime by parsing the dt date string following the pattern given in the format string.\n\nThis method creates a DateFormat object each time it is called. If you are parsing many date strings of the same format, consider creating a DateFormat object once and using that as the second argument instead.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.format-Tuple{Base.Dates.TimeType,AbstractString}",
    "page": "Dates and Time",
    "title": "Base.Dates.format",
    "category": "method",
    "text": "format(dt::TimeType, format::AbstractString; locale=\"english\") -> AbstractString\n\nConstruct a string by using a TimeType object and applying the provided format. The following character codes can be used to construct the format string:\n\nCode Examples Comment\ny 6 Numeric year with a fixed width\nY 1996 Numeric year with a minimum width\nm 1, 12 Numeric month with a minimum width\nu Jan Month name shortened to 3-chars according to the locale\nU January Full month name according to the locale keyword\nd 1, 31 Day of the month with a minimum width\nH 0, 23 Hour (24-hour clock) with a minimum width\nM 0, 59 Minute with a minimum width\nS 0, 59 Second with a minimum width\ns 000, 500 Millisecond with a minimum width of 3\ne Mon, Tue Abbreviated days of the week\nE Monday Full day of week name\n\nThe number of sequential code characters indicate the width of the code. A format of yyyy-mm specifies that the code y should have a width of four while m a width of two. Codes that yield numeric digits have an associated mode: fixed-width or minimum-width. The fixed-width mode left-pads the value with zeros when it is shorter than the specified width and truncates the value when longer. Minimum-width mode works the same as fixed-width except that it does not truncate values longer than the width.\n\nWhen creating a format you can use any non-code characters as a separator. For example to generate the string \"1996-01-15T00:00:00\" you could use format: \"yyyy-mm-ddTHH:MM:SS\". Note that if you need to use a code character as a literal you can use the escape character backslash. The string \"1996y01m\" can be produced with the format \"yyyy\\ymm\\m\".\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.DateFormat",
    "page": "Dates and Time",
    "title": "Base.Dates.DateFormat",
    "category": "type",
    "text": "DateFormat(format::AbstractString, locale=\"english\") -> DateFormat\n\nConstruct a date formatting object that can be used for parsing date strings or formatting a date object as a string. The following character codes can be used to construct the format string:\n\nCode Matches Comment\ny 1996, 96 Returns year of 1996, 0096\nY 1996, 96 Returns year of 1996, 0096. Equivalent to y\nm 1, 01 Matches 1 or 2-digit months\nu Jan Matches abbreviated months according to the locale keyword\nU January Matches full month names according to the locale keyword\nd 1, 01 Matches 1 or 2-digit days\nH 00 Matches hours\nM 00 Matches minutes\nS 00 Matches seconds\ns .500 Matches milliseconds\ne Mon, Tues Matches abbreviated days of the week\nE Monday Matches full name days of the week\nyyyymmdd 19960101 Matches fixed-width year, month, and day\n\nCharacters not listed above are normally treated as delimiters between date and time slots. For example a dt string of \"1996-01-15T00:00:00.0\" would have a format string like \"y-m-dTH:M:S.s\". If you need to use a code character as a delimiter you can escape it using backslash. The date \"1995y01m\" would have the format \"y\\ym\\m\".\n\nCreating a DateFormat object is expensive. Whenever possible, create it once and use it many times or try the dateformat\"\" string macro. Using this macro creates the DateFormat object once at macro expansion time and reuses it later. see @dateformat_str.\n\nSee DateTime and format for how to use a DateFormat object to parse and write Date strings respectively.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.@dateformat_str",
    "page": "Dates and Time",
    "title": "Base.Dates.@dateformat_str",
    "category": "macro",
    "text": "dateformat\"Y-m-d H:M:S\"\n\nCreate a DateFormat object. Similar to DateFormat(\"Y-m-d H:M:S\") but creates the DateFormat object once during macro expansion.\n\nSee DateFormat for details about format specifiers.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.DateTime-Tuple{AbstractString,DateFormat}",
    "page": "Dates and Time",
    "title": "Base.Dates.DateTime",
    "category": "method",
    "text": "DateTime(dt::AbstractString, df::DateFormat) -> DateTime\n\nConstruct a DateTime by parsing the dt date string following the pattern given in the DateFormat object. Similar to DateTime(::AbstractString, ::AbstractString) but more efficient when repeatedly parsing similarly formatted date strings with a pre-created DateFormat object.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.Date-Tuple{Int64,Int64,Int64}",
    "page": "Dates and Time",
    "title": "Base.Dates.Date",
    "category": "method",
    "text": "Date(y, [m, d]) -> Date\n\nConstruct a Date type by parts. Arguments must be convertible to Int64.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.Date-Tuple{Vararg{Base.Dates.Period,N} where N}",
    "page": "Dates and Time",
    "title": "Base.Dates.Date",
    "category": "method",
    "text": "Date(period::Period...) -> Date\n\nConstruct a Date type by Period type parts. Arguments may be in any order. Date parts not provided will default to the value of Dates.default(period).\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.Date-Tuple{Function,Any,Any,Any}",
    "page": "Dates and Time",
    "title": "Base.Dates.Date",
    "category": "method",
    "text": "Date(f::Function, y[, m, d]; step=Day(1), limit=10000) -> Date\n\nCreate a Date through the adjuster API. The starting point will be constructed from the provided y, m, d arguments, and will be adjusted until f::Function returns true. The step size in adjusting can be provided manually through the step keyword. limit provides a limit to the max number of iterations the adjustment API will pursue before throwing an error (given that f::Function is never satisfied).\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.Date-Tuple{Base.Dates.TimeType}",
    "page": "Dates and Time",
    "title": "Base.Dates.Date",
    "category": "method",
    "text": "Date(dt::DateTime) -> Date\n\nConverts a DateTime to a Date. The hour, minute, second, and millisecond parts of the DateTime are truncated, so only the year, month and day parts are used in construction.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.Date-Tuple{AbstractString,AbstractString}",
    "page": "Dates and Time",
    "title": "Base.Dates.Date",
    "category": "method",
    "text": "Date(dt::AbstractString, format::AbstractString; locale=\"english\") -> Date\n\nConstruct a Date object by parsing a dt date string following the pattern given in the format string. Follows the same conventions as DateTime(::AbstractString, ::AbstractString).\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.Date-Tuple{AbstractString,DateFormat}",
    "page": "Dates and Time",
    "title": "Base.Dates.Date",
    "category": "method",
    "text": "Date(dt::AbstractString, df::DateFormat) -> Date\n\nParse a date from a date string dt using a DateFormat object df.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.Time-NTuple{5,Int64}",
    "page": "Dates and Time",
    "title": "Base.Dates.Time",
    "category": "method",
    "text": "Time(h, [mi, s, ms, us, ns]) -> Time\n\nConstruct a Time type by parts. Arguments must be convertible to Int64.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.Time-Tuple{Vararg{Base.Dates.TimePeriod,N} where N}",
    "page": "Dates and Time",
    "title": "Base.Dates.Time",
    "category": "method",
    "text": "Time(period::TimePeriod...) -> Time\n\nConstruct a Time type by Period type parts. Arguments may be in any order. Time parts not provided will default to the value of Dates.default(period).\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.Time-Tuple{Function,Vararg{Any,N} where N}",
    "page": "Dates and Time",
    "title": "Base.Dates.Time",
    "category": "method",
    "text": "Time(f::Function, h, mi=0; step::Period=Second(1), limit::Int=10000)\nTime(f::Function, h, mi, s; step::Period=Millisecond(1), limit::Int=10000)\nTime(f::Function, h, mi, s, ms; step::Period=Microsecond(1), limit::Int=10000)\nTime(f::Function, h, mi, s, ms, us; step::Period=Nanosecond(1), limit::Int=10000)\n\nCreate a Time through the adjuster API. The starting point will be constructed from the provided h, mi, s, ms, us arguments, and will be adjusted until f::Function returns true. The step size in adjusting can be provided manually through the step keyword. limit provides a limit to the max number of iterations the adjustment API will pursue before throwing an error (in the case that f::Function is never satisfied). Note that the default step will adjust to allow for greater precision for the given arguments; i.e. if hour, minute, and second arguments are provided, the default step will be Millisecond(1) instead of Second(1).\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.Time-Tuple{DateTime}",
    "page": "Dates and Time",
    "title": "Base.Dates.Time",
    "category": "method",
    "text": "Time(dt::DateTime) -> Time\n\nConverts a DateTime to a Time. The hour, minute, second, and millisecond parts of the DateTime are used to create the new Time. Microsecond and nanoseconds are zero by default.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.now-Tuple{}",
    "page": "Dates and Time",
    "title": "Base.Dates.now",
    "category": "method",
    "text": "now() -> DateTime\n\nReturns a DateTime corresponding to the user\'s system time including the system timezone locale.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.now-Tuple{Type{Base.Dates.UTC}}",
    "page": "Dates and Time",
    "title": "Base.Dates.now",
    "category": "method",
    "text": "now(::Type{UTC}) -> DateTime\n\nReturns a DateTime corresponding to the user\'s system time as UTC/GMT.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.eps",
    "page": "Dates and Time",
    "title": "Base.eps",
    "category": "function",
    "text": "eps(::DateTime) -> Millisecond\neps(::Date) -> Day\neps(::Time) -> Nanosecond\n\nReturns Millisecond(1) for DateTime values, Day(1) for Date values, and Nanosecond(1) for Time values.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Dates-Functions-1",
    "page": "Dates and Time",
    "title": "Dates Functions",
    "category": "section",
    "text": "All Dates functions are defined in the Dates module; note that only the Date, DateTime, and now functions are exported; to use all other Dates functions, you\'ll need to prefix each function call with an explicit Dates., e.g. Dates.dayofweek(dt). Alternatively, you can write using Base.Dates to bring all exported functions into Main to be used without the Dates. prefix.Base.Dates.DateTime(::Int64, ::Int64, ::Int64, ::Int64, ::Int64, ::Int64, ::Int64)\nBase.Dates.DateTime(::Base.Dates.Period...)\nBase.Dates.DateTime(::Function, ::Any...)\nBase.Dates.DateTime(::Base.Dates.TimeType)\nBase.Dates.DateTime(::AbstractString, ::AbstractString)\nBase.Dates.format(::Base.Dates.TimeType, ::AbstractString)\nBase.Dates.DateFormat\nBase.Dates.@dateformat_str\nBase.Dates.DateTime(::AbstractString, ::Base.Dates.DateFormat)\nBase.Dates.Date(::Int64, ::Int64, ::Int64)\nBase.Dates.Date(::Base.Dates.Period...)\nBase.Dates.Date(::Function, ::Any, ::Any, ::Any)\nBase.Dates.Date(::Base.Dates.TimeType)\nBase.Dates.Date(::AbstractString, ::AbstractString)\nBase.Dates.Date(::AbstractString, ::Base.Dates.DateFormat)\nBase.Dates.Time(::Int64::Int64, ::Int64, ::Int64, ::Int64, ::Int64)\nBase.Dates.Time(::Base.Dates.TimePeriod...)\nBase.Dates.Time(::Function, ::Any...)\nBase.Dates.Time(::Base.Dates.DateTime)\nBase.Dates.now()\nBase.Dates.now(::Type{Base.Dates.UTC})\nBase.eps"
},

{
    "location": "stdlib/dates/#Base.Dates.year",
    "page": "Dates and Time",
    "title": "Base.Dates.year",
    "category": "function",
    "text": "year(dt::TimeType) -> Int64\n\nThe year of a Date or DateTime as an Int64.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.month",
    "page": "Dates and Time",
    "title": "Base.Dates.month",
    "category": "function",
    "text": "month(dt::TimeType) -> Int64\n\nThe month of a Date or DateTime as an Int64.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.week",
    "page": "Dates and Time",
    "title": "Base.Dates.week",
    "category": "function",
    "text": "week(dt::TimeType) -> Int64\n\nReturn the ISO week date of a Date or DateTime as an Int64. Note that the first week of a year is the week that contains the first Thursday of the year which can result in dates prior to January 4th being in the last week of the previous year. For example week(Date(2005,1,1)) is the 53rd week of 2004.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.day",
    "page": "Dates and Time",
    "title": "Base.Dates.day",
    "category": "function",
    "text": "day(dt::TimeType) -> Int64\n\nThe day of month of a Date or DateTime as an Int64.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.hour",
    "page": "Dates and Time",
    "title": "Base.Dates.hour",
    "category": "function",
    "text": "hour(dt::DateTime) -> Int64\n\nThe hour of day of a DateTime as an Int64.\n\n\n\nhour(t::Time) -> Int64\n\nThe hour of a Time as an Int64.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.minute",
    "page": "Dates and Time",
    "title": "Base.Dates.minute",
    "category": "function",
    "text": "minute(dt::DateTime) -> Int64\n\nThe minute of a DateTime as an Int64.\n\n\n\nminute(t::Time) -> Int64\n\nThe minute of a Time as an Int64.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.second",
    "page": "Dates and Time",
    "title": "Base.Dates.second",
    "category": "function",
    "text": "second(dt::DateTime) -> Int64\n\nThe second of a DateTime as an Int64.\n\n\n\nsecond(t::Time) -> Int64\n\nThe second of a Time as an Int64.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.millisecond",
    "page": "Dates and Time",
    "title": "Base.Dates.millisecond",
    "category": "function",
    "text": "millisecond(dt::DateTime) -> Int64\n\nThe millisecond of a DateTime as an Int64.\n\n\n\nmillisecond(t::Time) -> Int64\n\nThe millisecond of a Time as an Int64.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.microsecond",
    "page": "Dates and Time",
    "title": "Base.Dates.microsecond",
    "category": "function",
    "text": "microsecond(t::Time) -> Int64\n\nThe microsecond of a Time as an Int64.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.nanosecond",
    "page": "Dates and Time",
    "title": "Base.Dates.nanosecond",
    "category": "function",
    "text": "nanosecond(t::Time) -> Int64\n\nThe nanosecond of a Time as an Int64.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.Year-Tuple{Base.Dates.TimeType}",
    "page": "Dates and Time",
    "title": "Base.Dates.Year",
    "category": "method",
    "text": "Year(v)\n\nConstruct a Year object with the given v value. Input must be losslessly convertible to an Int64.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.Month-Tuple{Base.Dates.TimeType}",
    "page": "Dates and Time",
    "title": "Base.Dates.Month",
    "category": "method",
    "text": "Month(v)\n\nConstruct a Month object with the given v value. Input must be losslessly convertible to an Int64.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.Week-Tuple{Base.Dates.TimeType}",
    "page": "Dates and Time",
    "title": "Base.Dates.Week",
    "category": "method",
    "text": "Week(v)\n\nConstruct a Week object with the given v value. Input must be losslessly convertible to an Int64.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.Day-Tuple{Base.Dates.TimeType}",
    "page": "Dates and Time",
    "title": "Base.Dates.Day",
    "category": "method",
    "text": "Day(v)\n\nConstruct a Day object with the given v value. Input must be losslessly convertible to an Int64.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.Hour-Tuple{DateTime}",
    "page": "Dates and Time",
    "title": "Base.Dates.Hour",
    "category": "method",
    "text": "Hour(dt::DateTime) -> Hour\n\nThe hour part of a DateTime as a Hour.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.Minute-Tuple{DateTime}",
    "page": "Dates and Time",
    "title": "Base.Dates.Minute",
    "category": "method",
    "text": "Minute(dt::DateTime) -> Minute\n\nThe minute part of a DateTime as a Minute.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.Second-Tuple{DateTime}",
    "page": "Dates and Time",
    "title": "Base.Dates.Second",
    "category": "method",
    "text": "Second(dt::DateTime) -> Second\n\nThe second part of a DateTime as a Second.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.Millisecond-Tuple{DateTime}",
    "page": "Dates and Time",
    "title": "Base.Dates.Millisecond",
    "category": "method",
    "text": "Millisecond(dt::DateTime) -> Millisecond\n\nThe millisecond part of a DateTime as a Millisecond.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.Microsecond-Tuple{Base.Dates.Time}",
    "page": "Dates and Time",
    "title": "Base.Dates.Microsecond",
    "category": "method",
    "text": "Microsecond(dt::Time) -> Microsecond\n\nThe microsecond part of a Time as a Microsecond.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.Nanosecond-Tuple{Base.Dates.Time}",
    "page": "Dates and Time",
    "title": "Base.Dates.Nanosecond",
    "category": "method",
    "text": "Nanosecond(dt::Time) -> Nanosecond\n\nThe nanosecond part of a Time as a Nanosecond.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.yearmonth",
    "page": "Dates and Time",
    "title": "Base.Dates.yearmonth",
    "category": "function",
    "text": "yearmonth(dt::TimeType) -> (Int64, Int64)\n\nSimultaneously return the year and month parts of a Date or DateTime.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.monthday",
    "page": "Dates and Time",
    "title": "Base.Dates.monthday",
    "category": "function",
    "text": "monthday(dt::TimeType) -> (Int64, Int64)\n\nSimultaneously return the month and day parts of a Date or DateTime.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.yearmonthday",
    "page": "Dates and Time",
    "title": "Base.Dates.yearmonthday",
    "category": "function",
    "text": "yearmonthday(dt::TimeType) -> (Int64, Int64, Int64)\n\nSimultaneously return the year, month and day parts of a Date or DateTime.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Accessor-Functions-1",
    "page": "Dates and Time",
    "title": "Accessor Functions",
    "category": "section",
    "text": "Base.Dates.year\nBase.Dates.month\nBase.Dates.week\nBase.Dates.day\nBase.Dates.hour\nBase.Dates.minute\nBase.Dates.second\nBase.Dates.millisecond\nBase.Dates.microsecond\nBase.Dates.nanosecond\nBase.Dates.Year(::Base.Dates.TimeType)\nBase.Dates.Month(::Base.Dates.TimeType)\nBase.Dates.Week(::Base.Dates.TimeType)\nBase.Dates.Day(::Base.Dates.TimeType)\nBase.Dates.Hour(::DateTime)\nBase.Dates.Minute(::DateTime)\nBase.Dates.Second(::DateTime)\nBase.Dates.Millisecond(::DateTime)\nBase.Dates.Microsecond(::Dates.Time)\nBase.Dates.Nanosecond(::Dates.Time)\nBase.Dates.yearmonth\nBase.Dates.monthday\nBase.Dates.yearmonthday"
},

{
    "location": "stdlib/dates/#Base.Dates.dayname",
    "page": "Dates and Time",
    "title": "Base.Dates.dayname",
    "category": "function",
    "text": "dayname(dt::TimeType; locale=\"english\") -> AbstractString\n\nReturn the full day name corresponding to the day of the week of the Date or DateTime in the given locale.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.dayabbr",
    "page": "Dates and Time",
    "title": "Base.Dates.dayabbr",
    "category": "function",
    "text": "dayabbr(dt::TimeType; locale=\"english\") -> AbstractString\n\nReturn the abbreviated name corresponding to the day of the week of the Date or DateTime in the given locale.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.dayofweek",
    "page": "Dates and Time",
    "title": "Base.Dates.dayofweek",
    "category": "function",
    "text": "dayofweek(dt::TimeType) -> Int64\n\nReturns the day of the week as an Int64 with 1 = Monday, 2 = Tuesday, etc..\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.dayofmonth",
    "page": "Dates and Time",
    "title": "Base.Dates.dayofmonth",
    "category": "function",
    "text": "dayofmonth(dt::TimeType) -> Int64\n\nThe day of month of a Date or DateTime as an Int64.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.dayofweekofmonth",
    "page": "Dates and Time",
    "title": "Base.Dates.dayofweekofmonth",
    "category": "function",
    "text": "dayofweekofmonth(dt::TimeType) -> Int\n\nFor the day of week of dt, returns which number it is in dt\'s month. So if the day of the week of dt is Monday, then 1 = First Monday of the month, 2 = Second Monday of the month, etc. In the range 1:5.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.daysofweekinmonth",
    "page": "Dates and Time",
    "title": "Base.Dates.daysofweekinmonth",
    "category": "function",
    "text": "daysofweekinmonth(dt::TimeType) -> Int\n\nFor the day of week of dt, returns the total number of that day of the week in dt\'s month. Returns 4 or 5. Useful in temporal expressions for specifying the last day of a week in a month by including dayofweekofmonth(dt) == daysofweekinmonth(dt) in the adjuster function.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.monthname",
    "page": "Dates and Time",
    "title": "Base.Dates.monthname",
    "category": "function",
    "text": "monthname(dt::TimeType; locale=\"english\") -> AbstractString\n\nReturn the full name of the month of the Date or DateTime in the given locale.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.monthabbr",
    "page": "Dates and Time",
    "title": "Base.Dates.monthabbr",
    "category": "function",
    "text": "monthabbr(dt::TimeType; locale=\"english\") -> AbstractString\n\nReturn the abbreviated month name of the Date or DateTime in the given locale.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.daysinmonth",
    "page": "Dates and Time",
    "title": "Base.Dates.daysinmonth",
    "category": "function",
    "text": "daysinmonth(dt::TimeType) -> Int\n\nReturns the number of days in the month of dt. Value will be 28, 29, 30, or 31.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.isleapyear",
    "page": "Dates and Time",
    "title": "Base.Dates.isleapyear",
    "category": "function",
    "text": "isleapyear(dt::TimeType) -> Bool\n\nReturns true if the year of dt is a leap year.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.dayofyear",
    "page": "Dates and Time",
    "title": "Base.Dates.dayofyear",
    "category": "function",
    "text": "dayofyear(dt::TimeType) -> Int\n\nReturns the day of the year for dt with January 1st being day 1.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.daysinyear",
    "page": "Dates and Time",
    "title": "Base.Dates.daysinyear",
    "category": "function",
    "text": "daysinyear(dt::TimeType) -> Int\n\nReturns 366 if the year of dt is a leap year, otherwise returns 365.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.quarterofyear",
    "page": "Dates and Time",
    "title": "Base.Dates.quarterofyear",
    "category": "function",
    "text": "quarterofyear(dt::TimeType) -> Int\n\nReturns the quarter that dt resides in. Range of value is 1:4.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.dayofquarter",
    "page": "Dates and Time",
    "title": "Base.Dates.dayofquarter",
    "category": "function",
    "text": "dayofquarter(dt::TimeType) -> Int\n\nReturns the day of the current quarter of dt. Range of value is 1:92.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Query-Functions-1",
    "page": "Dates and Time",
    "title": "Query Functions",
    "category": "section",
    "text": "Base.Dates.dayname\nBase.Dates.dayabbr\nBase.Dates.dayofweek\nBase.Dates.dayofmonth\nBase.Dates.dayofweekofmonth\nBase.Dates.daysofweekinmonth\nBase.Dates.monthname\nBase.Dates.monthabbr\nBase.Dates.daysinmonth\nBase.Dates.isleapyear\nBase.Dates.dayofyear\nBase.Dates.daysinyear\nBase.Dates.quarterofyear\nBase.Dates.dayofquarter"
},

{
    "location": "stdlib/dates/#Base.trunc-Tuple{Base.Dates.TimeType,Type{Base.Dates.Period}}",
    "page": "Dates and Time",
    "title": "Base.trunc",
    "category": "method",
    "text": "trunc(dt::TimeType, ::Type{Period}) -> TimeType\n\nTruncates the value of dt according to the provided Period type. E.g. if dt is 1996-01-01T12:30:00, then trunc(dt,Day) == 1996-01-01T00:00:00.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.firstdayofweek",
    "page": "Dates and Time",
    "title": "Base.Dates.firstdayofweek",
    "category": "function",
    "text": "firstdayofweek(dt::TimeType) -> TimeType\n\nAdjusts dt to the Monday of its week.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.lastdayofweek",
    "page": "Dates and Time",
    "title": "Base.Dates.lastdayofweek",
    "category": "function",
    "text": "lastdayofweek(dt::TimeType) -> TimeType\n\nAdjusts dt to the Sunday of its week.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.firstdayofmonth",
    "page": "Dates and Time",
    "title": "Base.Dates.firstdayofmonth",
    "category": "function",
    "text": "firstdayofmonth(dt::TimeType) -> TimeType\n\nAdjusts dt to the first day of its month.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.lastdayofmonth",
    "page": "Dates and Time",
    "title": "Base.Dates.lastdayofmonth",
    "category": "function",
    "text": "lastdayofmonth(dt::TimeType) -> TimeType\n\nAdjusts dt to the last day of its month.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.firstdayofyear",
    "page": "Dates and Time",
    "title": "Base.Dates.firstdayofyear",
    "category": "function",
    "text": "firstdayofyear(dt::TimeType) -> TimeType\n\nAdjusts dt to the first day of its year.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.lastdayofyear",
    "page": "Dates and Time",
    "title": "Base.Dates.lastdayofyear",
    "category": "function",
    "text": "lastdayofyear(dt::TimeType) -> TimeType\n\nAdjusts dt to the last day of its year.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.firstdayofquarter",
    "page": "Dates and Time",
    "title": "Base.Dates.firstdayofquarter",
    "category": "function",
    "text": "firstdayofquarter(dt::TimeType) -> TimeType\n\nAdjusts dt to the first day of its quarter.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.lastdayofquarter",
    "page": "Dates and Time",
    "title": "Base.Dates.lastdayofquarter",
    "category": "function",
    "text": "lastdayofquarter(dt::TimeType) -> TimeType\n\nAdjusts dt to the last day of its quarter.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.tonext-Tuple{Base.Dates.TimeType,Int64}",
    "page": "Dates and Time",
    "title": "Base.Dates.tonext",
    "category": "method",
    "text": "tonext(dt::TimeType, dow::Int; same::Bool=false) -> TimeType\n\nAdjusts dt to the next day of week corresponding to dow with 1 = Monday, 2 = Tuesday, etc. Setting same=true allows the current dt to be considered as the next dow, allowing for no adjustment to occur.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.toprev-Tuple{Base.Dates.TimeType,Int64}",
    "page": "Dates and Time",
    "title": "Base.Dates.toprev",
    "category": "method",
    "text": "toprev(dt::TimeType, dow::Int; same::Bool=false) -> TimeType\n\nAdjusts dt to the previous day of week corresponding to dow with 1 = Monday, 2 = Tuesday, etc. Setting same=true allows the current dt to be considered as the previous dow, allowing for no adjustment to occur.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.tofirst",
    "page": "Dates and Time",
    "title": "Base.Dates.tofirst",
    "category": "function",
    "text": "tofirst(dt::TimeType, dow::Int; of=Month) -> TimeType\n\nAdjusts dt to the first dow of its month. Alternatively, of=Year will adjust to the first dow of the year.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.tolast",
    "page": "Dates and Time",
    "title": "Base.Dates.tolast",
    "category": "function",
    "text": "tolast(dt::TimeType, dow::Int; of=Month) -> TimeType\n\nAdjusts dt to the last dow of its month. Alternatively, of=Year will adjust to the last dow of the year.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.tonext-Tuple{Function,Base.Dates.TimeType}",
    "page": "Dates and Time",
    "title": "Base.Dates.tonext",
    "category": "method",
    "text": "tonext(func::Function, dt::TimeType; step=Day(1), limit=10000, same=false) -> TimeType\n\nAdjusts dt by iterating at most limit iterations by step increments until func returns true. func must take a single TimeType argument and return a Bool. same allows dt to be considered in satisfying func.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.toprev-Tuple{Function,Base.Dates.TimeType}",
    "page": "Dates and Time",
    "title": "Base.Dates.toprev",
    "category": "method",
    "text": "toprev(func::Function, dt::TimeType; step=Day(-1), limit=10000, same=false) -> TimeType\n\nAdjusts dt by iterating at most limit iterations by step increments until func returns true. func must take a single TimeType argument and return a Bool. same allows dt to be considered in satisfying func.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Adjuster-Functions-1",
    "page": "Dates and Time",
    "title": "Adjuster Functions",
    "category": "section",
    "text": "Base.trunc(::Base.Dates.TimeType, ::Type{Base.Dates.Period})\nBase.Dates.firstdayofweek\nBase.Dates.lastdayofweek\nBase.Dates.firstdayofmonth\nBase.Dates.lastdayofmonth\nBase.Dates.firstdayofyear\nBase.Dates.lastdayofyear\nBase.Dates.firstdayofquarter\nBase.Dates.lastdayofquarter\nBase.Dates.tonext(::Base.Dates.TimeType, ::Int)\nBase.Dates.toprev(::Base.Dates.TimeType, ::Int)\nBase.Dates.tofirst\nBase.Dates.tolast\nBase.Dates.tonext(::Function, ::Base.Dates.TimeType)\nBase.Dates.toprev(::Function, ::Base.Dates.TimeType)"
},

{
    "location": "stdlib/dates/#Base.Dates.Period-Tuple{Any}",
    "page": "Dates and Time",
    "title": "Base.Dates.Period",
    "category": "method",
    "text": "Year(v)\nMonth(v)\nWeek(v)\nDay(v)\nHour(v)\nMinute(v)\nSecond(v)\nMillisecond(v)\nMicrosecond(v)\nNanosecond(v)\n\nConstruct a Period type with the given v value. Input must be losslessly convertible to an Int64.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.CompoundPeriod-Tuple{Array{#s27,1} where #s27<:Base.Dates.Period}",
    "page": "Dates and Time",
    "title": "Base.Dates.CompoundPeriod",
    "category": "method",
    "text": "CompoundPeriod(periods) -> CompoundPeriod\n\nConstruct a CompoundPeriod from a Vector of Periods. All Periods of the same type will be added together.\n\nExamples\n\njulia> Dates.CompoundPeriod(Dates.Hour(12), Dates.Hour(13))\n25 hours\n\njulia> Dates.CompoundPeriod(Dates.Hour(-1), Dates.Minute(1))\n-1 hour, 1 minute\n\njulia> Dates.CompoundPeriod(Dates.Month(1), Dates.Week(-2))\n1 month, -2 weeks\n\njulia> Dates.CompoundPeriod(Dates.Minute(50000))\n50000 minutes\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.default",
    "page": "Dates and Time",
    "title": "Base.Dates.default",
    "category": "function",
    "text": "default(p::Period) -> Period\n\nReturns a sensible \"default\" value for the input Period by returning T(1) for Year, Month, and Day, and T(0) for Hour, Minute, Second, and Millisecond.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Periods-1",
    "page": "Dates and Time",
    "title": "Periods",
    "category": "section",
    "text": "Base.Dates.Period(::Any)\nBase.Dates.CompoundPeriod(::Vector{<:Base.Dates.Period})\nBase.Dates.default"
},

{
    "location": "stdlib/dates/#Base.floor-Tuple{Base.Dates.TimeType,Base.Dates.Period}",
    "page": "Dates and Time",
    "title": "Base.floor",
    "category": "method",
    "text": "floor(dt::TimeType, p::Period) -> TimeType\n\nReturns the nearest Date or DateTime less than or equal to dt at resolution p.\n\nFor convenience, p may be a type instead of a value: floor(dt, Dates.Hour) is a shortcut for floor(dt, Dates.Hour(1)).\n\njulia> floor(Date(1985, 8, 16), Dates.Month)\n1985-08-01\n\njulia> floor(DateTime(2013, 2, 13, 0, 31, 20), Dates.Minute(15))\n2013-02-13T00:30:00\n\njulia> floor(DateTime(2016, 8, 6, 12, 0, 0), Dates.Day)\n2016-08-06T00:00:00\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.ceil-Tuple{Base.Dates.TimeType,Base.Dates.Period}",
    "page": "Dates and Time",
    "title": "Base.ceil",
    "category": "method",
    "text": "ceil(dt::TimeType, p::Period) -> TimeType\n\nReturns the nearest Date or DateTime greater than or equal to dt at resolution p.\n\nFor convenience, p may be a type instead of a value: ceil(dt, Dates.Hour) is a shortcut for ceil(dt, Dates.Hour(1)).\n\njulia> ceil(Date(1985, 8, 16), Dates.Month)\n1985-09-01\n\njulia> ceil(DateTime(2013, 2, 13, 0, 31, 20), Dates.Minute(15))\n2013-02-13T00:45:00\n\njulia> ceil(DateTime(2016, 8, 6, 12, 0, 0), Dates.Day)\n2016-08-07T00:00:00\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.round-Tuple{Base.Dates.TimeType,Base.Dates.Period,RoundingMode{:NearestTiesUp}}",
    "page": "Dates and Time",
    "title": "Base.round",
    "category": "method",
    "text": "round(dt::TimeType, p::Period, [r::RoundingMode]) -> TimeType\n\nReturns the Date or DateTime nearest to dt at resolution p. By default (RoundNearestTiesUp), ties (e.g., rounding 9:30 to the nearest hour) will be rounded up.\n\nFor convenience, p may be a type instead of a value: round(dt, Dates.Hour) is a shortcut for round(dt, Dates.Hour(1)).\n\njulia> round(Date(1985, 8, 16), Dates.Month)\n1985-08-01\n\njulia> round(DateTime(2013, 2, 13, 0, 31, 20), Dates.Minute(15))\n2013-02-13T00:30:00\n\njulia> round(DateTime(2016, 8, 6, 12, 0, 0), Dates.Day)\n2016-08-07T00:00:00\n\nValid rounding modes for round(::TimeType, ::Period, ::RoundingMode) are RoundNearestTiesUp (default), RoundDown (floor), and RoundUp (ceil).\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.floorceil",
    "page": "Dates and Time",
    "title": "Base.Dates.floorceil",
    "category": "function",
    "text": "floorceil(dt::TimeType, p::Period) -> (TimeType, TimeType)\n\nSimultaneously return the floor and ceil of a Date or DateTime at resolution p. More efficient than calling both floor and ceil individually.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.epochdays2date",
    "page": "Dates and Time",
    "title": "Base.Dates.epochdays2date",
    "category": "function",
    "text": "epochdays2date(days) -> Date\n\nTakes the number of days since the rounding epoch (0000-01-01T00:00:00) and returns the corresponding Date.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.epochms2datetime",
    "page": "Dates and Time",
    "title": "Base.Dates.epochms2datetime",
    "category": "function",
    "text": "epochms2datetime(milliseconds) -> DateTime\n\nTakes the number of milliseconds since the rounding epoch (0000-01-01T00:00:00) and returns the corresponding DateTime.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.date2epochdays",
    "page": "Dates and Time",
    "title": "Base.Dates.date2epochdays",
    "category": "function",
    "text": "date2epochdays(dt::Date) -> Int64\n\nTakes the given Date and returns the number of days since the rounding epoch (0000-01-01T00:00:00) as an Int64.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.datetime2epochms",
    "page": "Dates and Time",
    "title": "Base.Dates.datetime2epochms",
    "category": "function",
    "text": "datetime2epochms(dt::DateTime) -> Int64\n\nTakes the given DateTime and returns the number of milliseconds since the rounding epoch (0000-01-01T00:00:00) as an Int64.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Rounding-Functions-1",
    "page": "Dates and Time",
    "title": "Rounding Functions",
    "category": "section",
    "text": "Date and DateTime values can be rounded to a specified resolution (e.g., 1 month or 15 minutes) with floor, ceil, or round.Base.floor(::Base.Dates.TimeType, ::Base.Dates.Period)\nBase.ceil(::Base.Dates.TimeType, ::Base.Dates.Period)\nBase.round(::Base.Dates.TimeType, ::Base.Dates.Period, ::RoundingMode{:NearestTiesUp})The following functions are not exported:Base.Dates.floorceil\nBase.Dates.epochdays2date\nBase.Dates.epochms2datetime\nBase.Dates.date2epochdays\nBase.Dates.datetime2epochms"
},

{
    "location": "stdlib/dates/#Base.Dates.today",
    "page": "Dates and Time",
    "title": "Base.Dates.today",
    "category": "function",
    "text": "today() -> Date\n\nReturns the date portion of now().\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.unix2datetime",
    "page": "Dates and Time",
    "title": "Base.Dates.unix2datetime",
    "category": "function",
    "text": "unix2datetime(x) -> DateTime\n\nTakes the number of seconds since unix epoch 1970-01-01T00:00:00 and converts to the corresponding DateTime.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.datetime2unix",
    "page": "Dates and Time",
    "title": "Base.Dates.datetime2unix",
    "category": "function",
    "text": "datetime2unix(dt::DateTime) -> Float64\n\nTakes the given DateTime and returns the number of seconds since the unix epoch 1970-01-01T00:00:00 as a Float64.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.julian2datetime",
    "page": "Dates and Time",
    "title": "Base.Dates.julian2datetime",
    "category": "function",
    "text": "julian2datetime(julian_days) -> DateTime\n\nTakes the number of Julian calendar days since epoch -4713-11-24T12:00:00 and returns the corresponding DateTime.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.datetime2julian",
    "page": "Dates and Time",
    "title": "Base.Dates.datetime2julian",
    "category": "function",
    "text": "datetime2julian(dt::DateTime) -> Float64\n\nTakes the given DateTime and returns the number of Julian calendar days since the julian epoch -4713-11-24T12:00:00 as a Float64.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.rata2datetime",
    "page": "Dates and Time",
    "title": "Base.Dates.rata2datetime",
    "category": "function",
    "text": "rata2datetime(days) -> DateTime\n\nTakes the number of Rata Die days since epoch 0000-12-31T00:00:00 and returns the corresponding DateTime.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Base.Dates.datetime2rata",
    "page": "Dates and Time",
    "title": "Base.Dates.datetime2rata",
    "category": "function",
    "text": "datetime2rata(dt::TimeType) -> Int64\n\nReturns the number of Rata Die days since epoch from the given Date or DateTime.\n\n\n\n"
},

{
    "location": "stdlib/dates/#Conversion-Functions-1",
    "page": "Dates and Time",
    "title": "Conversion Functions",
    "category": "section",
    "text": "Base.Dates.today\nBase.Dates.unix2datetime\nBase.Dates.datetime2unix\nBase.Dates.julian2datetime\nBase.Dates.datetime2julian\nBase.Dates.rata2datetime\nBase.Dates.datetime2rata"
},

{
    "location": "stdlib/dates/#Constants-1",
    "page": "Dates and Time",
    "title": "Constants",
    "category": "section",
    "text": "Days of the Week:Variable Abbr. Value (Int)\nMonday Mon 1\nTuesday Tue 2\nWednesday Wed 3\nThursday Thu 4\nFriday Fri 5\nSaturday Sat 6\nSunday Sun 7Months of the Year:Variable Abbr. Value (Int)\nJanuary Jan 1\nFebruary Feb 2\nMarch Mar 3\nApril Apr 4\nMay May 5\nJune Jun 6\nJuly Jul 7\nAugust Aug 8\nSeptember Sep 9\nOctober Oct 10\nNovember Nov 11\nDecember Dec 12"
},

{
    "location": "stdlib/iterators/#",
    "page": "Iteration utilities",
    "title": "Iteration utilities",
    "category": "page",
    "text": ""
},

{
    "location": "stdlib/iterators/#Base.Iterators.zip",
    "page": "Iteration utilities",
    "title": "Base.Iterators.zip",
    "category": "function",
    "text": "zip(iters...)\n\nFor a set of iterable objects, returns an iterable of tuples, where the ith tuple contains the ith component of each input iterable.\n\nNote that zip is its own inverse: collect(zip(zip(a...)...)) == collect(a).\n\nExample\n\njulia> a = 1:5\n1:5\n\njulia> b = [\"e\",\"d\",\"b\",\"c\",\"a\"]\n5-element Array{String,1}:\n \"e\"\n \"d\"\n \"b\"\n \"c\"\n \"a\"\n\njulia> c = zip(a,b)\nBase.Iterators.Zip2{UnitRange{Int64},Array{String,1}}(1:5, String[\"e\", \"d\", \"b\", \"c\", \"a\"])\n\njulia> length(c)\n5\n\njulia> first(c)\n(1, \"e\")\n\n\n\n"
},

{
    "location": "stdlib/iterators/#Base.Iterators.enumerate",
    "page": "Iteration utilities",
    "title": "Base.Iterators.enumerate",
    "category": "function",
    "text": "enumerate(iter)\n\nAn iterator that yields (i, x) where i is a counter starting at 1, and x is the ith value from the given iterator. It\'s useful when you need not only the values x over which you are iterating, but also the number of iterations so far. Note that i may not be valid for indexing iter; it\'s also possible that x != iter[i], if iter has indices that do not start at 1. See the enumerate(IndexLinear(), iter) method if you want to ensure that i is an index.\n\nExample\n\njulia> a = [\"a\", \"b\", \"c\"];\n\njulia> for (index, value) in enumerate(a)\n           println(\"$index $value\")\n       end\n1 a\n2 b\n3 c\n\n\n\nenumerate(IndexLinear(), A)\nenumerate(IndexCartesian(), A)\nenumerate(IndexStyle(A), A)\n\nAn iterator that accesses each element of the array A, returning (i, x), where i is the index for the element and x = A[i].  This is similar to enumerate(A), except i will always be a valid index for A.\n\nSpecifying IndexLinear() ensures that i will be an integer; specifying IndexCartesian() ensures that i will be a CartesianIndex; specifying IndexStyle(A) chooses whichever has been defined as the native indexing style for array A.\n\nExamples\n\njulia> A = [\"a\" \"d\"; \"b\" \"e\"; \"c\" \"f\"];\n\njulia> for (index, value) in enumerate(IndexStyle(A), A)\n           println(\"$index $value\")\n       end\n1 a\n2 b\n3 c\n4 d\n5 e\n6 f\n\njulia> S = view(A, 1:2, :);\n\njulia> for (index, value) in enumerate(IndexStyle(S), S)\n           println(\"$index $value\")\n       end\nCartesianIndex{2}((1, 1)) a\nCartesianIndex{2}((2, 1)) b\nCartesianIndex{2}((1, 2)) d\nCartesianIndex{2}((2, 2)) e\n\nNote that enumerate(A) returns i as a counter (always starting at 1), whereas enumerate(IndexLinear(), A) returns i as an index (starting at the first linear index of A, which may or may not be 1).\n\nSee also: IndexStyle, indices.\n\n\n\n"
},

{
    "location": "stdlib/iterators/#Base.Iterators.rest",
    "page": "Iteration utilities",
    "title": "Base.Iterators.rest",
    "category": "function",
    "text": "rest(iter, state)\n\nAn iterator that yields the same elements as iter, but starting at the given state.\n\n\n\n"
},

{
    "location": "stdlib/iterators/#Base.Iterators.countfrom",
    "page": "Iteration utilities",
    "title": "Base.Iterators.countfrom",
    "category": "function",
    "text": "countfrom(start=1, step=1)\n\nAn iterator that counts forever, starting at start and incrementing by step.\n\n\n\n"
},

{
    "location": "stdlib/iterators/#Base.Iterators.take",
    "page": "Iteration utilities",
    "title": "Base.Iterators.take",
    "category": "function",
    "text": "take(iter, n)\n\nAn iterator that generates at most the first n elements of iter.\n\nExample\n\njulia> a = 1:2:11\n1:2:11\n\njulia> collect(a)\n6-element Array{Int64,1}:\n  1\n  3\n  5\n  7\n  9\n 11\n\njulia> collect(Iterators.take(a,3))\n3-element Array{Int64,1}:\n 1\n 3\n 5\n\n\n\n"
},

{
    "location": "stdlib/iterators/#Base.Iterators.drop",
    "page": "Iteration utilities",
    "title": "Base.Iterators.drop",
    "category": "function",
    "text": "drop(iter, n)\n\nAn iterator that generates all but the first n elements of iter.\n\nExample\n\njulia> a = 1:2:11\n1:2:11\n\njulia> collect(a)\n6-element Array{Int64,1}:\n  1\n  3\n  5\n  7\n  9\n 11\n\njulia> collect(Iterators.drop(a,4))\n2-element Array{Int64,1}:\n  9\n 11\n\n\n\n"
},

{
    "location": "stdlib/iterators/#Base.Iterators.cycle",
    "page": "Iteration utilities",
    "title": "Base.Iterators.cycle",
    "category": "function",
    "text": "cycle(iter)\n\nAn iterator that cycles through iter forever.\n\n\n\n"
},

{
    "location": "stdlib/iterators/#Base.Iterators.repeated",
    "page": "Iteration utilities",
    "title": "Base.Iterators.repeated",
    "category": "function",
    "text": "repeated(x[, n::Int])\n\nAn iterator that generates the value x forever. If n is specified, generates x that many times (equivalent to take(repeated(x), n)).\n\nExample\n\njulia> a = Iterators.repeated([1 2], 4);\n\njulia> collect(a)\n4-element Array{Array{Int64,2},1}:\n [1 2]\n [1 2]\n [1 2]\n [1 2]\n\n\n\n"
},

{
    "location": "stdlib/iterators/#Base.Iterators.product",
    "page": "Iteration utilities",
    "title": "Base.Iterators.product",
    "category": "function",
    "text": "product(iters...)\n\nReturns an iterator over the product of several iterators. Each generated element is a tuple whose ith element comes from the ith argument iterator. The first iterator changes the fastest. Example:\n\nExample\n\njulia> collect(Iterators.product(1:2,3:5))\n2×3 Array{Tuple{Int64,Int64},2}:\n (1, 3)  (1, 4)  (1, 5)\n (2, 3)  (2, 4)  (2, 5)\n\n\n\n"
},

{
    "location": "stdlib/iterators/#Base.Iterators.flatten",
    "page": "Iteration utilities",
    "title": "Base.Iterators.flatten",
    "category": "function",
    "text": "flatten(iter)\n\nGiven an iterator that yields iterators, return an iterator that yields the elements of those iterators. Put differently, the elements of the argument iterator are concatenated.\n\nExample\n\njulia> collect(Iterators.flatten((1:2, 8:9)))\n4-element Array{Int64,1}:\n 1\n 2\n 8\n 9\n\n\n\n"
},

{
    "location": "stdlib/iterators/#Base.Iterators.partition",
    "page": "Iteration utilities",
    "title": "Base.Iterators.partition",
    "category": "function",
    "text": "partition(collection, n)\n\nIterate over a collection n elements at a time.\n\nExample\n\njulia> collect(Iterators.partition([1,2,3,4,5], 2))\n3-element Array{Array{Int64,1},1}:\n [1, 2]\n [3, 4]\n [5]\n\n\n\n"
},

{
    "location": "stdlib/iterators/#Iteration-utilities-1",
    "page": "Iteration utilities",
    "title": "Iteration utilities",
    "category": "section",
    "text": "Base.Iterators.zip\nBase.Iterators.enumerate\nBase.Iterators.rest\nBase.Iterators.countfrom\nBase.Iterators.take\nBase.Iterators.drop\nBase.Iterators.cycle\nBase.Iterators.repeated\nBase.Iterators.product\nBase.Iterators.flatten\nBase.Iterators.partition"
},

{
    "location": "stdlib/test/#",
    "page": "Unit Testing",
    "title": "Unit Testing",
    "category": "page",
    "text": ""
},

{
    "location": "stdlib/test/#Unit-Testing-1",
    "page": "Unit Testing",
    "title": "Unit Testing",
    "category": "section",
    "text": "DocTestSetup = quote\n    using Base.Test\nend"
},

{
    "location": "stdlib/test/#Base.runtests",
    "page": "Unit Testing",
    "title": "Base.runtests",
    "category": "function",
    "text": "runtests([tests=[\"all\"] [, numcores=ceil(Int, Sys.CPU_CORES / 2) ]])\n\nRun the Julia unit tests listed in tests, which can be either a string or an array of strings, using numcores processors. (not exported)\n\n\n\n"
},

{
    "location": "stdlib/test/#Testing-Base-Julia-1",
    "page": "Unit Testing",
    "title": "Testing Base Julia",
    "category": "section",
    "text": "Julia is under rapid development and has an extensive test suite to verify functionality across multiple platforms. If you build Julia from source, you can run this test suite with make test. In a binary install, you can run the test suite using Base.runtests().Base.runtests"
},

{
    "location": "stdlib/test/#Base.Test.@test",
    "page": "Unit Testing",
    "title": "Base.Test.@test",
    "category": "macro",
    "text": "@test ex\n@test f(args...) key=val ...\n\nTests that the expression ex evaluates to true. Returns a Pass Result if it does, a Fail Result if it is false, and an Error Result if it could not be evaluated.\n\nThe @test f(args...) key=val... form is equivalent to writing @test f(args..., key=val...) which can be useful when the expression is a call using infix syntax such as approximate comparisons:\n\n@test a ≈ b atol=ε\n\nThis is equivalent to the uglier test @test ≈(a, b, atol=ε). It is an error to supply more than one expression unless the first is a call expression and the rest are assignments (k=v).\n\n\n\n"
},

{
    "location": "stdlib/test/#Base.Test.@test_throws",
    "page": "Unit Testing",
    "title": "Base.Test.@test_throws",
    "category": "macro",
    "text": "@test_throws extype ex\n\nTests that the expression ex throws an exception of type extype. Note that @test_throws does not support a trailing keyword form.\n\n\n\n"
},

{
    "location": "stdlib/test/#Basic-Unit-Tests-1",
    "page": "Unit Testing",
    "title": "Basic Unit Tests",
    "category": "section",
    "text": "The Base.Test module provides simple unit testing functionality. Unit testing is a way to see if your code is correct by checking that the results are what you expect. It can be helpful to ensure your code still works after you make changes, and can be used when developing as a way of specifying the behaviors your code should have when complete.Simple unit testing can be performed with the @test() and @test_throws() macros:Base.Test.@test\nBase.Test.@test_throwsFor example, suppose we want to check our new function foo(x) works as expected:julia> using Base.Test\n\njulia> foo(x) = length(x)^2\nfoo (generic function with 1 method)If the condition is true, a Pass is returned:julia> @test foo(\"bar\") == 9\nTest Passed\n\njulia> @test foo(\"fizz\") >= 10\nTest PassedIf the condition is false, then a Fail is returned and an exception is thrown:julia> @test foo(\"f\") == 20\nTest Failed\n  Expression: foo(\"f\") == 20\n   Evaluated: 1 == 20\nERROR: There was an error during testingIf the condition could not be evaluated because an exception was thrown, which occurs in this case because length() is not defined for symbols, an Error object is returned and an exception is thrown:julia> @test foo(:cat) == 1\nError During Test\n  Test threw an exception of type MethodError\n  Expression: foo(:cat) == 1\n  MethodError: no method matching length(::Symbol)\n  Closest candidates are:\n    length(::SimpleVector) at essentials.jl:256\n    length(::Base.MethodList) at reflection.jl:521\n    length(::MethodTable) at reflection.jl:597\n    ...\n  Stacktrace:\n   [...]\nERROR: There was an error during testingIf we expect that evaluating an expression should throw an exception, then we can use @test_throws() to check that this occurs:julia> @test_throws MethodError foo(:cat)\nTest Passed\n      Thrown: MethodError"
},

{
    "location": "stdlib/test/#Base.Test.@testset",
    "page": "Unit Testing",
    "title": "Base.Test.@testset",
    "category": "macro",
    "text": "@testset [CustomTestSet] [option=val  ...] [\"description\"] begin ... end\n@testset [CustomTestSet] [option=val  ...] [\"description $v\"] for v in (...) ... end\n@testset [CustomTestSet] [option=val  ...] [\"description $v, $w\"] for v in (...), w in (...) ... end\n\nStarts a new test set, or multiple test sets if a for loop is provided.\n\nIf no custom testset type is given it defaults to creating a DefaultTestSet. DefaultTestSet records all the results and, if there are any Fails or Errors, throws an exception at the end of the top-level (non-nested) test set, along with a summary of the test results.\n\nAny custom testset type (subtype of AbstractTestSet) can be given and it will also be used for any nested @testset invocations. The given options are only applied to the test set where they are given. The default test set type does not take any options.\n\nThe description string accepts interpolation from the loop indices. If no description is provided, one is constructed based on the variables.\n\nBy default the @testset macro will return the testset object itself, though this behavior can be customized in other testset types. If a for loop is used then the macro collects and returns a list of the return values of the finish method, which by default will return a list of the testset objects used in each iteration.\n\n\n\n"
},

{
    "location": "stdlib/test/#Working-with-Test-Sets-1",
    "page": "Unit Testing",
    "title": "Working with Test Sets",
    "category": "section",
    "text": "Typically a large number of tests are used to make sure functions work correctly over a range of inputs. In the event a test fails, the default behavior is to throw an exception immediately. However, it is normally preferable to run the rest of the tests first to get a better picture of how many errors there are in the code being tested.The @testset() macro can be used to group tests into sets. All the tests in a test set will be run, and at the end of the test set a summary will be printed. If any of the tests failed, or could not be evaluated due to an error, the test set will then throw a TestSetException.Base.Test.@testsetWe can put our tests for the foo(x) function in a test set:julia> @testset \"Foo Tests\" begin\n           @test foo(\"a\")   == 1\n           @test foo(\"ab\")  == 4\n           @test foo(\"abc\") == 9\n       end;\nTest Summary: | Pass  Total\nFoo Tests     |    3      3Test sets can also be nested:julia> @testset \"Foo Tests\" begin\n           @testset \"Animals\" begin\n               @test foo(\"cat\") == 9\n               @test foo(\"dog\") == foo(\"cat\")\n           end\n           @testset \"Arrays $i\" for i in 1:3\n               @test foo(zeros(i)) == i^2\n               @test foo(ones(i)) == i^2\n           end\n       end;\nTest Summary: | Pass  Total\nFoo Tests     |    8      8In the event that a nested test set has no failures, as happened here, it will be hidden in the summary. If we do have a test failure, only the details for the failed test sets will be shown:julia> @testset \"Foo Tests\" begin\n           @testset \"Animals\" begin\n               @testset \"Felines\" begin\n                   @test foo(\"cat\") == 9\n               end\n               @testset \"Canines\" begin\n                   @test foo(\"dog\") == 9\n               end\n           end\n           @testset \"Arrays\" begin\n               @test foo(zeros(2)) == 4\n               @test foo(ones(4)) == 15\n           end\n       end\n\nArrays: Test Failed\n  Expression: foo(ones(4)) == 15\n   Evaluated: 16 == 15\nStacktrace:\n    [...]\nTest Summary: | Pass  Fail  Total\nFoo Tests     |    3     1      4\n  Animals     |    2            2\n  Arrays      |    1     1      2\nERROR: Some tests did not pass: 3 passed, 1 failed, 0 errored, 0 broken."
},

{
    "location": "stdlib/test/#Base.Test.@inferred",
    "page": "Unit Testing",
    "title": "Base.Test.@inferred",
    "category": "macro",
    "text": "@inferred f(x)\n\nTests that the call expression f(x) returns a value of the same type inferred by the compiler. It is useful to check for type stability.\n\nf(x) can be any call expression. Returns the result of f(x) if the types match, and an Error Result if it finds different types.\n\njulia> using Base.Test\n\njulia> f(a,b,c) = b > 1 ? 1 : 1.0\nf (generic function with 1 method)\n\njulia> typeof(f(1,2,3))\nInt64\n\njulia> @code_warntype f(1,2,3)\nVariables:\n  #self# <optimized out>\n  a <optimized out>\n  b::Int64\n  c <optimized out>\n\nBody:\n  begin\n      unless (Base.slt_int)(1, b::Int64)::Bool goto 3\n      return 1\n      3:\n      return 1.0\n  end::UNION{FLOAT64, INT64}\n\njulia> @inferred f(1,2,3)\nERROR: return type Int64 does not match inferred return type Union{Float64, Int64}\nStacktrace:\n [1] error(::String) at ./error.jl:21\n\njulia> @inferred max(1,2)\n2\n\n\n\n"
},

{
    "location": "stdlib/test/#Base.Test.@test_warn",
    "page": "Unit Testing",
    "title": "Base.Test.@test_warn",
    "category": "macro",
    "text": "@test_warn msg expr\n\nTest whether evaluating expr results in STDERR output that contains the msg string or matches the msg regular expression.  If msg is a boolean function, tests whether msg(output) returns true.  If msg is a tuple or array, checks that the error output contains/matches each item in msg. Returns the result of evaluating expr.\n\nSee also @test_nowarn to check for the absence of error output.\n\n\n\n"
},

{
    "location": "stdlib/test/#Base.Test.@test_nowarn",
    "page": "Unit Testing",
    "title": "Base.Test.@test_nowarn",
    "category": "macro",
    "text": "@test_nowarn expr\n\nTest whether evaluating expr results in empty STDERR output (no warnings or other messages).  Returns the result of evaluating expr.\n\n\n\n"
},

{
    "location": "stdlib/test/#Other-Test-Macros-1",
    "page": "Unit Testing",
    "title": "Other Test Macros",
    "category": "section",
    "text": "As calculations on floating-point values can be imprecise, you can perform approximate equality checks using either @test a ≈ b (where ≈, typed via tab completion of \\approx, is the isapprox() function) or use isapprox() directly.julia> @test 1 ≈ 0.999999999\nTest Passed\n\njulia> @test 1 ≈ 0.999999\nTest Failed\n  Expression: 1 ≈ 0.999999\n   Evaluated: 1 ≈ 0.999999\nERROR: There was an error during testingBase.Test.@inferred\nBase.Test.@test_warn\nBase.Test.@test_nowarn"
},

{
    "location": "stdlib/test/#Base.Test.@test_broken",
    "page": "Unit Testing",
    "title": "Base.Test.@test_broken",
    "category": "macro",
    "text": "@test_broken ex\n@test_broken f(args...) key=val ...\n\nIndicates a test that should pass but currently consistently fails. Tests that the expression ex evaluates to false or causes an exception. Returns a Broken Result if it does, or an Error Result if the expression evaluates to true.\n\nThe @test_broken f(args...) key=val... form works as for the @test macro.\n\n\n\n"
},

{
    "location": "stdlib/test/#Base.Test.@test_skip",
    "page": "Unit Testing",
    "title": "Base.Test.@test_skip",
    "category": "macro",
    "text": "@test_skip ex\n@test_skip f(args...) key=val ...\n\nMarks a test that should not be executed but should be included in test summary reporting as Broken. This can be useful for tests that intermittently fail, or tests of not-yet-implemented functionality.\n\nThe @test_skip f(args...) key=val... form works as for the @test macro.\n\n\n\n"
},

{
    "location": "stdlib/test/#Broken-Tests-1",
    "page": "Unit Testing",
    "title": "Broken Tests",
    "category": "section",
    "text": "If a test fails consistently it can be changed to use the @test_broken() macro. This will denote the test as Broken if the test continues to fail and alerts the user via an Error if the test succeeds.Base.Test.@test_broken@test_skip() is also available to skip a test without evaluation, but counting the skipped test in the test set reporting. The test will not run but gives a Broken Result.Base.Test.@test_skip"
},

{
    "location": "stdlib/test/#Base.Test.record",
    "page": "Unit Testing",
    "title": "Base.Test.record",
    "category": "function",
    "text": "record(ts::AbstractTestSet, res::Result)\n\nRecord a result to a testset. This function is called by the @testset infrastructure each time a contained @test macro completes, and is given the test result (which could be an Error). This will also be called with an Error if an exception is thrown inside the test block but outside of a @test context.\n\n\n\n"
},

{
    "location": "stdlib/test/#Base.Test.finish",
    "page": "Unit Testing",
    "title": "Base.Test.finish",
    "category": "function",
    "text": "finish(ts::AbstractTestSet)\n\nDo any final processing necessary for the given testset. This is called by the @testset infrastructure after a test block executes. One common use for this function is to record the testset to the parent\'s results list, using get_testset.\n\n\n\n"
},

{
    "location": "stdlib/test/#Base.Test.get_testset",
    "page": "Unit Testing",
    "title": "Base.Test.get_testset",
    "category": "function",
    "text": "get_testset()\n\nRetrieve the active test set from the task\'s local storage. If no test set is active, use the fallback default test set.\n\n\n\n"
},

{
    "location": "stdlib/test/#Base.Test.get_testset_depth",
    "page": "Unit Testing",
    "title": "Base.Test.get_testset_depth",
    "category": "function",
    "text": "get_testset_depth()\n\nReturns the number of active test sets, not including the defaut test set\n\n\n\n"
},

{
    "location": "stdlib/test/#Creating-Custom-AbstractTestSet-Types-1",
    "page": "Unit Testing",
    "title": "Creating Custom AbstractTestSet Types",
    "category": "section",
    "text": "Packages can create their own AbstractTestSet subtypes by implementing the record and finish methods. The subtype should have a one-argument constructor taking a description string, with any options passed in as keyword arguments.Base.Test.record\nBase.Test.finishBase.Test takes responsibility for maintaining a stack of nested testsets as they are executed, but any result accumulation is the responsibility of the AbstractTestSet subtype. You can access this stack with the get_testset and get_testset_depth methods. Note that these functions are not exported.Base.Test.get_testset\nBase.Test.get_testset_depthBase.Test also makes sure that nested @testset invocations use the same AbstractTestSet subtype as their parent unless it is set explicitly. It does not propagate any properties of the testset. Option inheritance behavior can be implemented by packages using the stack infrastructure that Base.Test provides.Defining a basic AbstractTestSet subtype might look like:import Base.Test: record, finish\nusing Base.Test: AbstractTestSet, Result, Pass, Fail, Error\nusing Base.Test: get_testset_depth, get_testset\nstruct CustomTestSet <: Base.Test.AbstractTestSet\n    description::AbstractString\n    foo::Int\n    results::Vector\n    # constructor takes a description string and options keyword arguments\n    CustomTestSet(desc; foo=1) = new(desc, foo, [])\nend\n\nrecord(ts::CustomTestSet, child::AbstractTestSet) = push!(ts.results, child)\nrecord(ts::CustomTestSet, res::Result) = push!(ts.results, res)\nfunction finish(ts::CustomTestSet)\n    # just record if we\'re not the top-level parent\n    if get_testset_depth() > 0\n        record(get_testset(), ts)\n    end\n    ts\nendAnd using that testset looks like:@testset CustomTestSet foo=4 \"custom testset inner 2\" begin\n    # this testset should inherit the type, but not the argument.\n    @testset \"custom testset inner\" begin\n        @test true\n    end\nendDocTestSetup = nothing"
},

{
    "location": "stdlib/c/#",
    "page": "C Interface",
    "title": "C Interface",
    "category": "page",
    "text": ""
},

{
    "location": "stdlib/c/#ccall",
    "page": "C Interface",
    "title": "ccall",
    "category": "keyword",
    "text": "ccall((symbol, library) or function_pointer, ReturnType, (ArgumentType1, ...), ArgumentValue1, ...)\n\nCall function in C-exported shared library, specified by (function name, library) tuple, where each component is a string or symbol.\n\nNote that the argument type tuple must be a literal tuple, and not a tuple-valued variable or expression. Alternatively, ccall may also be used to call a function pointer, such as one returned by dlsym.\n\nEach ArgumentValue to the ccall will be converted to the corresponding ArgumentType, by automatic insertion of calls to unsafe_convert(ArgumentType, cconvert(ArgumentType, ArgumentValue)). (See also the documentation for each of these functions for further details.) In most cases, this simply results in a call to convert(ArgumentType, ArgumentValue).\n\n\n\n"
},

{
    "location": "stdlib/c/#Core.Intrinsics.cglobal",
    "page": "C Interface",
    "title": "Core.Intrinsics.cglobal",
    "category": "function",
    "text": "cglobal((symbol, library) [, type=Void])\n\nObtain a pointer to a global variable in a C-exported shared library, specified exactly as in ccall. Returns a Ptr{Type}, defaulting to Ptr{Void} if no Type argument is supplied. The values can be read or written by unsafe_load or unsafe_store!, respectively.\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.cfunction",
    "page": "C Interface",
    "title": "Base.cfunction",
    "category": "function",
    "text": "cfunction(function::Function, ReturnType::Type, ArgumentTypes::Type)\n\nGenerate C-callable function pointer from Julia function. Type annotation of the return value in the callback function is a must for situations where Julia cannot infer the return type automatically.\n\nExamples\n\njulia> function foo(x::Int, y::Int)\n           return x + y\n       end\n\njulia> cfunction(foo, Int, Tuple{Int,Int})\nPtr{Void} @0x000000001b82fcd0\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.unsafe_convert",
    "page": "C Interface",
    "title": "Base.unsafe_convert",
    "category": "function",
    "text": "unsafe_convert(T,x)\n\nConvert x to a value of type T\n\nIn cases where convert would need to take a Julia object and turn it into a Ptr, this function should be used to define and perform that conversion.\n\nBe careful to ensure that a Julia reference to x exists as long as the result of this function will be used. Accordingly, the argument x to this function should never be an expression, only a variable name or field reference. For example, x=a.b.c is acceptable, but x=[a,b,c] is not.\n\nThe unsafe prefix on this function indicates that using the result of this function after the x argument to this function is no longer accessible to the program may cause undefined behavior, including program corruption or segfaults, at any later time.\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.cconvert",
    "page": "C Interface",
    "title": "Base.cconvert",
    "category": "function",
    "text": "cconvert(T,x)\n\nConvert x to a value of type T, typically by calling convert(T,x)\n\nIn cases where x cannot be safely converted to T, unlike convert, cconvert may return an object of a type different from T, which however is suitable for unsafe_convert to handle.\n\nNeither convert nor cconvert should take a Julia object and turn it into a Ptr.\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.unsafe_load",
    "page": "C Interface",
    "title": "Base.unsafe_load",
    "category": "function",
    "text": "unsafe_load(p::Ptr{T}, i::Integer=1)\n\nLoad a value of type T from the address of the ith element (1-indexed) starting at p. This is equivalent to the C expression p[i-1].\n\nThe unsafe prefix on this function indicates that no validation is performed on the pointer p to ensure that it is valid. Incorrect usage may segfault your program or return garbage answers, in the same manner as C.\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.unsafe_store!",
    "page": "C Interface",
    "title": "Base.unsafe_store!",
    "category": "function",
    "text": "unsafe_store!(p::Ptr{T}, x, i::Integer=1)\n\nStore a value of type T to the address of the ith element (1-indexed) starting at p. This is equivalent to the C expression p[i-1] = x.\n\nThe unsafe prefix on this function indicates that no validation is performed on the pointer p to ensure that it is valid. Incorrect usage may corrupt or segfault your program, in the same manner as C.\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.unsafe_copy!-Union{Tuple{Ptr{T},Ptr{T},Any}, Tuple{T}} where T",
    "page": "C Interface",
    "title": "Base.unsafe_copy!",
    "category": "method",
    "text": "unsafe_copy!(dest::Ptr{T}, src::Ptr{T}, N)\n\nCopy N elements from a source pointer to a destination, with no checking. The size of an element is determined by the type of the pointers.\n\nThe unsafe prefix on this function indicates that no validation is performed on the pointers dest and src to ensure that they are valid. Incorrect usage may corrupt or segfault your program, in the same manner as C.\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.unsafe_copy!-Tuple{Array,Any,Array,Any,Any}",
    "page": "C Interface",
    "title": "Base.unsafe_copy!",
    "category": "method",
    "text": "unsafe_copy!(dest::Array, do, src::Array, so, N)\n\nCopy N elements from a source array to a destination, starting at offset so in the source and do in the destination (1-indexed).\n\nThe unsafe prefix on this function indicates that no validation is performed to ensure that N is inbounds on either array. Incorrect usage may corrupt or segfault your program, in the same manner as C.\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.copy!-Tuple{Any,Any}",
    "page": "C Interface",
    "title": "Base.copy!",
    "category": "method",
    "text": "copy!(dest, src) -> dest\n\nCopy all elements from collection src to array dest.\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.copy!-NTuple{5,Any}",
    "page": "C Interface",
    "title": "Base.copy!",
    "category": "method",
    "text": "copy!(dest, do, src, so, N)\n\nCopy N elements from collection src starting at offset so, to array dest starting at offset do. Returns dest.\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.pointer",
    "page": "C Interface",
    "title": "Base.pointer",
    "category": "function",
    "text": "pointer(array [, index])\n\nGet the native address of an array or string element. Be careful to ensure that a Julia reference to a exists as long as this pointer will be used. This function is \"unsafe\" like unsafe_convert.\n\nCalling Ref(array[, index]) is generally preferable to this function.\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.unsafe_wrap-Union{Tuple{N}, Tuple{T}, Tuple{Union{Type{Array{T,N} where N}, Type{Array{T,N}}, Type{Array}},Ptr{T},Tuple{Vararg{Int64,N}}}} where N where T",
    "page": "C Interface",
    "title": "Base.unsafe_wrap",
    "category": "method",
    "text": "unsafe_wrap(Array, pointer::Ptr{T}, dims, own=false)\n\nWrap a Julia Array object around the data at the address given by pointer, without making a copy.  The pointer element type T determines the array element type. dims is either an integer (for a 1d array) or a tuple of the array dimensions. own optionally specifies whether Julia should take ownership of the memory, calling free on the pointer when the array is no longer referenced.\n\nThis function is labelled \"unsafe\" because it will crash if pointer is not a valid memory address to data of the requested length.\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.pointer_from_objref",
    "page": "C Interface",
    "title": "Base.pointer_from_objref",
    "category": "function",
    "text": "pointer_from_objref(x)\n\nGet the memory address of a Julia object as a Ptr. The existence of the resulting Ptr will not protect the object from garbage collection, so you must ensure that the object remains referenced for the whole time that the Ptr will be used.\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.unsafe_pointer_to_objref",
    "page": "C Interface",
    "title": "Base.unsafe_pointer_to_objref",
    "category": "function",
    "text": "unsafe_pointer_to_objref(p::Ptr)\n\nConvert a Ptr to an object reference. Assumes the pointer refers to a valid heap-allocated Julia object. If this is not the case, undefined behavior results, hence this function is considered \"unsafe\" and should be used with care.\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.disable_sigint",
    "page": "C Interface",
    "title": "Base.disable_sigint",
    "category": "function",
    "text": "disable_sigint(f::Function)\n\nDisable Ctrl-C handler during execution of a function on the current task, for calling external code that may call julia code that is not interrupt safe. Intended to be called using do block syntax as follows:\n\ndisable_sigint() do\n    # interrupt-unsafe code\n    ...\nend\n\nThis is not needed on worker threads (Threads.threadid() != 1) since the InterruptException will only be delivered to the master thread. External functions that do not call julia code or julia runtime automatically disable sigint during their execution.\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.reenable_sigint",
    "page": "C Interface",
    "title": "Base.reenable_sigint",
    "category": "function",
    "text": "reenable_sigint(f::Function)\n\nRe-enable Ctrl-C handler during execution of a function. Temporarily reverses the effect of disable_sigint.\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.systemerror",
    "page": "C Interface",
    "title": "Base.systemerror",
    "category": "function",
    "text": "systemerror(sysfunc, iftrue)\n\nRaises a SystemError for errno with the descriptive string sysfunc if iftrue is true\n\n\n\n"
},

{
    "location": "stdlib/c/#Core.Ptr",
    "page": "C Interface",
    "title": "Core.Ptr",
    "category": "type",
    "text": "Ptr{T}\n\nA memory address referring to data of type T.  However, there is no guarantee that the memory is actually valid, or that it actually represents data of the specified type.\n\n\n\n"
},

{
    "location": "stdlib/c/#Core.Ref",
    "page": "C Interface",
    "title": "Core.Ref",
    "category": "type",
    "text": "Ref{T}\n\nAn object that safely references data of type T. This type is guaranteed to point to valid, Julia-allocated memory of the correct type. The underlying data is protected from freeing by the garbage collector as long as the Ref itself is referenced.\n\nWhen passed as a ccall argument (either as a Ptr or Ref type), a Ref object will be converted to a native pointer to the data it references.\n\nThere is no invalid (NULL) Ref.\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.Cchar",
    "page": "C Interface",
    "title": "Base.Cchar",
    "category": "type",
    "text": "Cchar\n\nEquivalent to the native char c-type.\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.Cuchar",
    "page": "C Interface",
    "title": "Base.Cuchar",
    "category": "type",
    "text": "Cuchar\n\nEquivalent to the native unsigned char c-type (UInt8).\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.Cshort",
    "page": "C Interface",
    "title": "Base.Cshort",
    "category": "type",
    "text": "Cshort\n\nEquivalent to the native signed short c-type (Int16).\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.Cushort",
    "page": "C Interface",
    "title": "Base.Cushort",
    "category": "type",
    "text": "Cushort\n\nEquivalent to the native unsigned short c-type (UInt16).\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.Cint",
    "page": "C Interface",
    "title": "Base.Cint",
    "category": "type",
    "text": "Cint\n\nEquivalent to the native signed int c-type (Int32).\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.Cuint",
    "page": "C Interface",
    "title": "Base.Cuint",
    "category": "type",
    "text": "Cuint\n\nEquivalent to the native unsigned int c-type (UInt32).\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.Clong",
    "page": "C Interface",
    "title": "Base.Clong",
    "category": "type",
    "text": "Clong\n\nEquivalent to the native signed long c-type.\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.Culong",
    "page": "C Interface",
    "title": "Base.Culong",
    "category": "type",
    "text": "Culong\n\nEquivalent to the native unsigned long c-type.\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.Clonglong",
    "page": "C Interface",
    "title": "Base.Clonglong",
    "category": "type",
    "text": "Clonglong\n\nEquivalent to the native signed long long c-type (Int64).\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.Culonglong",
    "page": "C Interface",
    "title": "Base.Culonglong",
    "category": "type",
    "text": "Culonglong\n\nEquivalent to the native unsigned long long c-type (UInt64).\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.Cintmax_t",
    "page": "C Interface",
    "title": "Base.Cintmax_t",
    "category": "type",
    "text": "Cintmax_t\n\nEquivalent to the native intmax_t c-type (Int64).\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.Cuintmax_t",
    "page": "C Interface",
    "title": "Base.Cuintmax_t",
    "category": "type",
    "text": "Cuintmax_t\n\nEquivalent to the native uintmax_t c-type (UInt64).\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.Csize_t",
    "page": "C Interface",
    "title": "Base.Csize_t",
    "category": "type",
    "text": "Csize_t\n\nEquivalent to the native size_t c-type (UInt).\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.Cssize_t",
    "page": "C Interface",
    "title": "Base.Cssize_t",
    "category": "type",
    "text": "Cssize_t\n\nEquivalent to the native ssize_t c-type.\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.Cptrdiff_t",
    "page": "C Interface",
    "title": "Base.Cptrdiff_t",
    "category": "type",
    "text": "Cptrdiff_t\n\nEquivalent to the native ptrdiff_t c-type (Int).\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.Cwchar_t",
    "page": "C Interface",
    "title": "Base.Cwchar_t",
    "category": "type",
    "text": "Cwchar_t\n\nEquivalent to the native wchar_t c-type (Int32).\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.Cfloat",
    "page": "C Interface",
    "title": "Base.Cfloat",
    "category": "type",
    "text": "Cfloat\n\nEquivalent to the native float c-type (Float32).\n\n\n\n"
},

{
    "location": "stdlib/c/#Base.Cdouble",
    "page": "C Interface",
    "title": "Base.Cdouble",
    "category": "type",
    "text": "Cdouble\n\nEquivalent to the native double c-type (Float64).\n\n\n\n"
},

{
    "location": "stdlib/c/#C-Interface-1",
    "page": "C Interface",
    "title": "C Interface",
    "category": "section",
    "text": "ccall\nCore.Intrinsics.cglobal\nBase.cfunction\nBase.unsafe_convert\nBase.cconvert\nBase.unsafe_load\nBase.unsafe_store!\nBase.unsafe_copy!{T}(::Ptr{T}, ::Ptr{T}, ::Any)\nBase.unsafe_copy!(::Array, ::Any, ::Array, ::Any, ::Any)\nBase.copy!(::Any, ::Any)\nBase.copy!(::Any, ::Any, ::Any, ::Any, ::Any)\nBase.pointer\nBase.unsafe_wrap{T,N}(::Union{Type{Array},Type{Array{T}},Type{Array{T,N}}}, ::Ptr{T}, ::NTuple{N,Int})\nBase.pointer_from_objref\nBase.unsafe_pointer_to_objref\nBase.disable_sigint\nBase.reenable_sigint\nBase.systemerror\nCore.Ptr\nCore.Ref\nBase.Cchar\nBase.Cuchar\nBase.Cshort\nBase.Cushort\nBase.Cint\nBase.Cuint\nBase.Clong\nBase.Culong\nBase.Clonglong\nBase.Culonglong\nBase.Cintmax_t\nBase.Cuintmax_t\nBase.Csize_t\nBase.Cssize_t\nBase.Cptrdiff_t\nBase.Cwchar_t\nBase.Cfloat\nBase.Cdouble"
},

{
    "location": "stdlib/c/#Core.Intrinsics.llvmcall",
    "page": "C Interface",
    "title": "Core.Intrinsics.llvmcall",
    "category": "function",
    "text": "llvmcall(IR::String, ReturnType, (ArgumentType1, ...), ArgumentValue1, ...)\nllvmcall((declarations::String, IR::String), ReturnType, (ArgumentType1, ...), ArgumentValue1, ...)\n\nCall LLVM IR string in the first argument. Similar to an LLVM function define block, arguments are available as consecutive unnamed SSA variables (%0, %1, etc.).\n\nThe optional declarations string contains external functions declarations that are necessary for llvm to compile the IR string. Multiple declarations can be passed in by separating them with line breaks.\n\nNote that the argument type tuple must be a literal tuple, and not a tuple-valued variable or expression.\n\nEach ArgumentValue to llvmcall will be converted to the corresponding ArgumentType, by automatic insertion of calls to unsafe_convert(ArgumentType, cconvert(ArgumentType, ArgumentValue)). (see also the documentation for each of these functions for further details). In most cases, this simply results in a call to convert(ArgumentType, ArgumentValue).\n\nSee test/llvmcall.jl for usage examples.\n\n\n\n"
},

{
    "location": "stdlib/c/#LLVM-Interface-1",
    "page": "C Interface",
    "title": "LLVM Interface",
    "category": "section",
    "text": "Core.Intrinsics.llvmcall"
},

{
    "location": "stdlib/libc/#",
    "page": "C Standard Library",
    "title": "C Standard Library",
    "category": "page",
    "text": ""
},

{
    "location": "stdlib/libc/#Base.Libc.malloc",
    "page": "C Standard Library",
    "title": "Base.Libc.malloc",
    "category": "function",
    "text": "malloc(size::Integer) -> Ptr{Void}\n\nCall malloc from the C standard library.\n\n\n\n"
},

{
    "location": "stdlib/libc/#Base.Libc.calloc",
    "page": "C Standard Library",
    "title": "Base.Libc.calloc",
    "category": "function",
    "text": "calloc(num::Integer, size::Integer) -> Ptr{Void}\n\nCall calloc from the C standard library.\n\n\n\n"
},

{
    "location": "stdlib/libc/#Base.Libc.realloc",
    "page": "C Standard Library",
    "title": "Base.Libc.realloc",
    "category": "function",
    "text": "realloc(addr::Ptr, size::Integer) -> Ptr{Void}\n\nCall realloc from the C standard library.\n\nSee warning in the documentation for free regarding only using this on memory originally obtained from malloc.\n\n\n\n"
},

{
    "location": "stdlib/libc/#Base.Libc.free",
    "page": "C Standard Library",
    "title": "Base.Libc.free",
    "category": "function",
    "text": "free(addr::Ptr)\n\nCall free from the C standard library. Only use this on memory obtained from malloc, not on pointers retrieved from other C libraries. Ptr objects obtained from C libraries should be freed by the free functions defined in that library, to avoid assertion failures if multiple libc libraries exist on the system.\n\n\n\n"
},

{
    "location": "stdlib/libc/#Base.Libc.errno",
    "page": "C Standard Library",
    "title": "Base.Libc.errno",
    "category": "function",
    "text": "errno([code])\n\nGet the value of the C library\'s errno. If an argument is specified, it is used to set the value of errno.\n\nThe value of errno is only valid immediately after a ccall to a C library routine that sets it. Specifically, you cannot call errno at the next prompt in a REPL, because lots of code is executed between prompts.\n\n\n\n"
},

{
    "location": "stdlib/libc/#Base.Libc.strerror",
    "page": "C Standard Library",
    "title": "Base.Libc.strerror",
    "category": "function",
    "text": "strerror(n=errno())\n\nConvert a system call error code to a descriptive string\n\n\n\n"
},

{
    "location": "stdlib/libc/#Base.Libc.GetLastError",
    "page": "C Standard Library",
    "title": "Base.Libc.GetLastError",
    "category": "function",
    "text": "GetLastError()\n\nCall the Win32 GetLastError function [only available on Windows].\n\n\n\n"
},

{
    "location": "stdlib/libc/#Base.Libc.FormatMessage",
    "page": "C Standard Library",
    "title": "Base.Libc.FormatMessage",
    "category": "function",
    "text": "FormatMessage(n=GetLastError())\n\nConvert a Win32 system call error code to a descriptive string [only available on Windows].\n\n\n\n"
},

{
    "location": "stdlib/libc/#Base.Libc.time-Tuple{Base.Libc.TmStruct}",
    "page": "C Standard Library",
    "title": "Base.Libc.time",
    "category": "method",
    "text": "time(t::TmStruct)\n\nConverts a TmStruct struct to a number of seconds since the epoch.\n\n\n\n"
},

{
    "location": "stdlib/libc/#Base.Libc.strftime",
    "page": "C Standard Library",
    "title": "Base.Libc.strftime",
    "category": "function",
    "text": "strftime([format], time)\n\nConvert time, given as a number of seconds since the epoch or a TmStruct, to a formatted string using the given format. Supported formats are the same as those in the standard C library.\n\n\n\n"
},

{
    "location": "stdlib/libc/#Base.Libc.strptime",
    "page": "C Standard Library",
    "title": "Base.Libc.strptime",
    "category": "function",
    "text": "strptime([format], timestr)\n\nParse a formatted time string into a TmStruct giving the seconds, minute, hour, date, etc. Supported formats are the same as those in the standard C library. On some platforms, timezones will not be parsed correctly. If the result of this function will be passed to time to convert it to seconds since the epoch, the isdst field should be filled in manually. Setting it to -1 will tell the C library to use the current system settings to determine the timezone.\n\n\n\n"
},

{
    "location": "stdlib/libc/#Base.Libc.TmStruct",
    "page": "C Standard Library",
    "title": "Base.Libc.TmStruct",
    "category": "type",
    "text": "TmStruct([seconds])\n\nConvert a number of seconds since the epoch to broken-down format, with fields sec, min, hour, mday, month, year, wday, yday, and isdst.\n\n\n\n"
},

{
    "location": "stdlib/libc/#Base.Libc.flush_cstdio",
    "page": "C Standard Library",
    "title": "Base.Libc.flush_cstdio",
    "category": "function",
    "text": "flush_cstdio()\n\nFlushes the C stdout and stderr streams (which may have been written to by external C code).\n\n\n\n"
},

{
    "location": "stdlib/libc/#C-Standard-Library-1",
    "page": "C Standard Library",
    "title": "C Standard Library",
    "category": "section",
    "text": "Base.Libc.malloc\nBase.Libc.calloc\nBase.Libc.realloc\nBase.Libc.free\nBase.Libc.errno\nBase.Libc.strerror\nBase.Libc.GetLastError\nBase.Libc.FormatMessage\nBase.Libc.time(::Base.Libc.TmStruct)\nBase.Libc.strftime\nBase.Libc.strptime\nBase.Libc.TmStruct\nBase.Libc.flush_cstdio"
},

{
    "location": "stdlib/libdl/#",
    "page": "Dynamic Linker",
    "title": "Dynamic Linker",
    "category": "page",
    "text": ""
},

{
    "location": "stdlib/libdl/#Base.Libdl.dlopen",
    "page": "Dynamic Linker",
    "title": "Base.Libdl.dlopen",
    "category": "function",
    "text": "dlopen(libfile::AbstractString [, flags::Integer])\n\nLoad a shared library, returning an opaque handle.\n\nThe extension given by the constant dlext (.so, .dll, or .dylib) can be omitted from the libfile string, as it is automatically appended if needed.   If libfile is not an absolute path name, then the paths in the array DL_LOAD_PATH are searched for libfile, followed by the system load path.\n\nThe optional flags argument is a bitwise-or of zero or more of RTLD_LOCAL, RTLD_GLOBAL, RTLD_LAZY, RTLD_NOW, RTLD_NODELETE, RTLD_NOLOAD, RTLD_DEEPBIND, and RTLD_FIRST. These are converted to the corresponding flags of the POSIX (and/or GNU libc and/or MacOS) dlopen command, if possible, or are ignored if the specified functionality is not available on the current platform. The default flags are platform specific. On MacOS the default dlopen flags are RTLD_LAZY|RTLD_DEEPBIND|RTLD_GLOBAL while on other platforms the defaults are RTLD_LAZY|RTLD_DEEPBIND|RTLD_LOCAL. An important usage of these flags is to specify non default behavior for when the dynamic library loader binds library references to exported symbols and if the bound references are put into process local or global scope. For instance RTLD_LAZY|RTLD_DEEPBIND|RTLD_GLOBAL allows the library\'s symbols to be available for usage in other shared libraries, addressing situations where there are dependencies between shared libraries.\n\n\n\n"
},

{
    "location": "stdlib/libdl/#Base.Libdl.dlopen_e",
    "page": "Dynamic Linker",
    "title": "Base.Libdl.dlopen_e",
    "category": "function",
    "text": "dlopen_e(libfile::AbstractString [, flags::Integer])\n\nSimilar to dlopen, except returns a NULL pointer instead of raising errors.\n\n\n\n"
},

{
    "location": "stdlib/libdl/#Base.Libdl.RTLD_NOW",
    "page": "Dynamic Linker",
    "title": "Base.Libdl.RTLD_NOW",
    "category": "constant",
    "text": "RTLD_DEEPBIND\nRTLD_FIRST\nRTLD_GLOBAL\nRTLD_LAZY\nRTLD_LOCAL\nRTLD_NODELETE\nRTLD_NOLOAD\nRTLD_NOW\n\nEnum constant for dlopen. See your platform man page for details, if applicable.\n\n\n\n"
},

{
    "location": "stdlib/libdl/#Base.Libdl.dlsym",
    "page": "Dynamic Linker",
    "title": "Base.Libdl.dlsym",
    "category": "function",
    "text": "dlsym(handle, sym)\n\nLook up a symbol from a shared library handle, return callable function pointer on success.\n\n\n\n"
},

{
    "location": "stdlib/libdl/#Base.Libdl.dlsym_e",
    "page": "Dynamic Linker",
    "title": "Base.Libdl.dlsym_e",
    "category": "function",
    "text": "dlsym_e(handle, sym)\n\nLook up a symbol from a shared library handle, silently return NULL pointer on lookup failure.\n\n\n\n"
},

{
    "location": "stdlib/libdl/#Base.Libdl.dlclose",
    "page": "Dynamic Linker",
    "title": "Base.Libdl.dlclose",
    "category": "function",
    "text": "dlclose(handle)\n\nClose shared library referenced by handle.\n\n\n\n"
},

{
    "location": "stdlib/libdl/#Base.Libdl.dlext",
    "page": "Dynamic Linker",
    "title": "Base.Libdl.dlext",
    "category": "constant",
    "text": "dlext\n\nFile extension for dynamic libraries (e.g. dll, dylib, so) on the current platform.\n\n\n\n"
},

{
    "location": "stdlib/libdl/#Base.Libdl.find_library",
    "page": "Dynamic Linker",
    "title": "Base.Libdl.find_library",
    "category": "function",
    "text": "find_library(names, locations)\n\nSearches for the first library in names in the paths in the locations list, DL_LOAD_PATH, or system library paths (in that order) which can successfully be dlopen\'d. On success, the return value will be one of the names (potentially prefixed by one of the paths in locations). This string can be assigned to a global const and used as the library name in future ccall\'s. On failure, it returns the empty string.\n\n\n\n"
},

{
    "location": "stdlib/libdl/#Base.Libdl.DL_LOAD_PATH",
    "page": "Dynamic Linker",
    "title": "Base.Libdl.DL_LOAD_PATH",
    "category": "constant",
    "text": "DL_LOAD_PATH\n\nWhen calling dlopen, the paths in this list will be searched first, in order, before searching the system locations for a valid library handle.\n\n\n\n"
},

{
    "location": "stdlib/libdl/#Dynamic-Linker-1",
    "page": "Dynamic Linker",
    "title": "Dynamic Linker",
    "category": "section",
    "text": "The names in Base.Libdl are not exported and need to be called e.g. as Libdl.dlopen().Base.Libdl.dlopen\nBase.Libdl.dlopen_e\nBase.Libdl.RTLD_NOW\nBase.Libdl.dlsym\nBase.Libdl.dlsym_e\nBase.Libdl.dlclose\nBase.Libdl.dlext\nBase.Libdl.find_library\nBase.Libdl.DL_LOAD_PATH"
},

{
    "location": "stdlib/profile/#",
    "page": "Profiling",
    "title": "Profiling",
    "category": "page",
    "text": ""
},

{
    "location": "stdlib/profile/#Base.Profile.@profile",
    "page": "Profiling",
    "title": "Base.Profile.@profile",
    "category": "macro",
    "text": "@profile\n\n@profile <expression> runs your expression while taking periodic backtraces. These are appended to an internal buffer of backtraces.\n\n\n\n"
},

{
    "location": "stdlib/profile/#Base.Profile.clear",
    "page": "Profiling",
    "title": "Base.Profile.clear",
    "category": "function",
    "text": "clear()\n\nClear any existing backtraces from the internal buffer.\n\n\n\n"
},

{
    "location": "stdlib/profile/#Base.Profile.print",
    "page": "Profiling",
    "title": "Base.Profile.print",
    "category": "function",
    "text": "print([io::IO = STDOUT,] [data::Vector]; kwargs...)\n\nPrints profiling results to io (by default, STDOUT). If you do not supply a data vector, the internal buffer of accumulated backtraces will be used.\n\nThe keyword arguments can be any combination of:\n\nformat – Determines whether backtraces are printed with (default, :tree) or without (:flat) indentation indicating tree structure.\nC – If true, backtraces from C and Fortran code are shown (normally they are excluded).\ncombine – If true (default), instruction pointers are merged that correspond to the same line of code.\nmaxdepth – Limits the depth higher than maxdepth in the :tree format.\nsortedby – Controls the order in :flat format. :filefuncline (default) sorts by the source  line, whereas :count sorts in order of number of collected samples.\nnoisefloor – Limits frames that exceed the heuristic noise floor of the sample (only applies to format :tree).  A suggested value to try for this is 2.0 (the default is 0). This parameter hides samples for which n <= noisefloor * √N,  where n is the number of samples on this line, and N is the number of samples for the callee.\nmincount – Limits the printout to only those lines with at least mincount occurrences.\n\n\n\nprint([io::IO = STDOUT,] data::Vector, lidict::LineInfoDict; kwargs...)\n\nPrints profiling results to io. This variant is used to examine results exported by a previous call to retrieve. Supply the vector data of backtraces and a dictionary lidict of line information.\n\nSee Profile.print([io], data) for an explanation of the valid keyword arguments.\n\n\n\n"
},

{
    "location": "stdlib/profile/#Base.Profile.init",
    "page": "Profiling",
    "title": "Base.Profile.init",
    "category": "function",
    "text": "init(; n::Integer, delay::Float64)\n\nConfigure the delay between backtraces (measured in seconds), and the number n of instruction pointers that may be stored. Each instruction pointer corresponds to a single line of code; backtraces generally consist of a long list of instruction pointers. Default settings can be obtained by calling this function with no arguments, and each can be set independently using keywords or in the order (n, delay).\n\n\n\n"
},

{
    "location": "stdlib/profile/#Base.Profile.fetch",
    "page": "Profiling",
    "title": "Base.Profile.fetch",
    "category": "function",
    "text": "fetch() -> data\n\nReturns a reference to the internal buffer of backtraces. Note that subsequent operations, like clear, can affect data unless you first make a copy. Note that the values in data have meaning only on this machine in the current session, because it depends on the exact memory addresses used in JIT-compiling. This function is primarily for internal use; retrieve may be a better choice for most users.\n\n\n\n"
},

{
    "location": "stdlib/profile/#Base.Profile.retrieve",
    "page": "Profiling",
    "title": "Base.Profile.retrieve",
    "category": "function",
    "text": "retrieve() -> data, lidict\n\n\"Exports\" profiling results in a portable format, returning the set of all backtraces (data) and a dictionary that maps the (session-specific) instruction pointers in data to LineInfo values that store the file name, function name, and line number. This function allows you to save profiling results for future analysis.\n\n\n\n"
},

{
    "location": "stdlib/profile/#Base.Profile.callers",
    "page": "Profiling",
    "title": "Base.Profile.callers",
    "category": "function",
    "text": "callers(funcname, [data, lidict], [filename=<filename>], [linerange=<start:stop>]) -> Vector{Tuple{count, lineinfo}}\n\nGiven a previous profiling run, determine who called a particular function. Supplying the filename (and optionally, range of line numbers over which the function is defined) allows you to disambiguate an overloaded method. The returned value is a vector containing a count of the number of calls and line information about the caller. One can optionally supply backtrace data obtained from retrieve; otherwise, the current internal profile buffer is used.\n\n\n\n"
},

{
    "location": "stdlib/profile/#Base.Profile.clear_malloc_data",
    "page": "Profiling",
    "title": "Base.Profile.clear_malloc_data",
    "category": "function",
    "text": "clear_malloc_data()\n\nClears any stored memory allocation data when running julia with --track-allocation. Execute the command(s) you want to test (to force JIT-compilation), then call clear_malloc_data. Then execute your command(s) again, quit Julia, and examine the resulting *.mem files.\n\n\n\n"
},

{
    "location": "stdlib/profile/#lib-profiling-1",
    "page": "Profiling",
    "title": "Profiling",
    "category": "section",
    "text": "Base.Profile.@profileThe methods in Base.Profile are not exported and need to be called e.g. as Profile.print().Base.Profile.clear\nBase.Profile.print\nBase.Profile.init\nBase.Profile.fetch\nBase.Profile.retrieve\nBase.Profile.callers\nBase.Profile.clear_malloc_data"
},

{
    "location": "stdlib/stacktraces/#",
    "page": "StackTraces",
    "title": "StackTraces",
    "category": "page",
    "text": ""
},

{
    "location": "stdlib/stacktraces/#Base.StackTraces.StackFrame",
    "page": "StackTraces",
    "title": "Base.StackTraces.StackFrame",
    "category": "type",
    "text": "StackFrame\n\nStack information representing execution context, with the following fields:\n\nfunc::Symbol\nThe name of the function containing the execution context.\nlinfo::Nullable{Core.MethodInstance}\nThe MethodInstance containing the execution context (if it could be found).\nfile::Symbol\nThe path to the file containing the execution context.\nline::Int\nThe line number in the file containing the execution context.\nfrom_c::Bool\nTrue if the code is from C.\ninlined::Bool\nTrue if the code is from an inlined frame.\npointer::UInt64\nRepresentation of the pointer to the execution context as returned by backtrace.\n\n\n\n"
},

{
    "location": "stdlib/stacktraces/#Base.StackTraces.StackTrace",
    "page": "StackTraces",
    "title": "Base.StackTraces.StackTrace",
    "category": "type",
    "text": "StackTrace\n\nAn alias for Vector{StackFrame} provided for convenience; returned by calls to stacktrace and catch_stacktrace.\n\n\n\n"
},

{
    "location": "stdlib/stacktraces/#Base.StackTraces.stacktrace",
    "page": "StackTraces",
    "title": "Base.StackTraces.stacktrace",
    "category": "function",
    "text": "stacktrace([trace::Vector{Ptr{Void}},] [c_funcs::Bool=false]) -> StackTrace\n\nReturns a stack trace in the form of a vector of StackFrames. (By default stacktrace doesn\'t return C functions, but this can be enabled.) When called without specifying a trace, stacktrace first calls backtrace.\n\n\n\n"
},

{
    "location": "stdlib/stacktraces/#Base.StackTraces.catch_stacktrace",
    "page": "StackTraces",
    "title": "Base.StackTraces.catch_stacktrace",
    "category": "function",
    "text": "catch_stacktrace([c_funcs::Bool=false]) -> StackTrace\n\nReturns the stack trace for the most recent error thrown, rather than the current execution context.\n\n\n\n"
},

{
    "location": "stdlib/stacktraces/#Base.StackTraces.lookup",
    "page": "StackTraces",
    "title": "Base.StackTraces.lookup",
    "category": "function",
    "text": "lookup(pointer::Union{Ptr{Void}, UInt}) -> Vector{StackFrame}\n\nGiven a pointer to an execution context (usually generated by a call to backtrace), looks up stack frame context information. Returns an array of frame information for all functions inlined at that point, innermost function first.\n\n\n\n"
},

{
    "location": "stdlib/stacktraces/#Base.StackTraces.remove_frames!",
    "page": "StackTraces",
    "title": "Base.StackTraces.remove_frames!",
    "category": "function",
    "text": "remove_frames!(stack::StackTrace, name::Symbol)\n\nTakes a StackTrace (a vector of StackFrames) and a function name (a Symbol) and removes the StackFrame specified by the function name from the StackTrace (also removing all frames above the specified function). Primarily used to remove StackTraces functions from the StackTrace prior to returning it.\n\n\n\nremove_frames!(stack::StackTrace, m::Module)\n\nReturns the StackTrace with all StackFrames from the provided Module removed.\n\n\n\n"
},

{
    "location": "stdlib/stacktraces/#StackTraces-1",
    "page": "StackTraces",
    "title": "StackTraces",
    "category": "section",
    "text": "Base.StackTraces.StackFrame\nBase.StackTraces.StackTrace\nBase.StackTraces.stacktrace\nBase.StackTraces.catch_stacktraceThe following methods and types in Base.StackTraces are not exported and need to be called e.g. as StackTraces.lookup(ptr).Base.StackTraces.lookup\nBase.StackTraces.remove_frames!"
},

{
    "location": "stdlib/simd-types/#",
    "page": "SIMD Support",
    "title": "SIMD Support",
    "category": "page",
    "text": ""
},

{
    "location": "stdlib/simd-types/#SIMD-Support-1",
    "page": "SIMD Support",
    "title": "SIMD Support",
    "category": "section",
    "text": "Type VecElement{T} is intended for building libraries of SIMD operations. Practical use of it requires using llvmcall. The type is defined as:struct VecElement{T}\n    value::T\nendIt has a special compilation rule: a homogeneous tuple of VecElement{T} maps to an LLVM vector type when T is a primitive bits type and the tuple length is in the set {2-6,8-10,16}.At -O3, the compiler might automatically vectorize operations on such tuples. For example, the following program, when compiled with julia -O3 generates two SIMD addition instructions (addps) on x86 systems:const m128 = NTuple{4,VecElement{Float32}}\n\nfunction add(a::m128, b::m128)\n    (VecElement(a[1].value+b[1].value),\n     VecElement(a[2].value+b[2].value),\n     VecElement(a[3].value+b[3].value),\n     VecElement(a[4].value+b[4].value))\nend\n\ntriple(c::m128) = add(add(c,c),c)\n\ncode_native(triple,(m128,))However, since the automatic vectorization cannot be relied upon, future use will mostly be via libraries that use llvmcall."
},

{
    "location": "devdocs/reflection/#",
    "page": "Reflection and introspection",
    "title": "Reflection and introspection",
    "category": "page",
    "text": ""
},

{
    "location": "devdocs/reflection/#Reflection-and-introspection-1",
    "page": "Reflection and introspection",
    "title": "Reflection and introspection",
    "category": "section",
    "text": "Julia provides a variety of runtime reflection capabilities."
},

{
    "location": "devdocs/reflection/#Module-bindings-1",
    "page": "Reflection and introspection",
    "title": "Module bindings",
    "category": "section",
    "text": "The exported names for a Module are available using names(m::Module), which will return an array of Symbol elements representing the exported bindings. names(m::Module, true) returns symbols for all bindings in m, regardless of export status."
},

{
    "location": "devdocs/reflection/#DataType-fields-1",
    "page": "Reflection and introspection",
    "title": "DataType fields",
    "category": "section",
    "text": "The names of DataType fields may be interrogated using fieldnames(). For example, given the following type, fieldnames(Point) returns an arrays of Symbol elements representing the field names:julia> struct Point\n           x::Int\n           y\n       end\n\njulia> fieldnames(Point)\n2-element Array{Symbol,1}:\n :x\n :yThe type of each field in a Point object is stored in the types field of the Point variable itself:julia> Point.types\nsvec(Int64, Any)While x is annotated as an Int, y was unannotated in the type definition, therefore y defaults to the Any type.Types are themselves represented as a structure called DataType:julia> typeof(Point)\nDataTypeNote that fieldnames(DataType) gives the names for each field of DataType itself, and one of these fields is the types field observed in the example above."
},

{
    "location": "devdocs/reflection/#Subtypes-1",
    "page": "Reflection and introspection",
    "title": "Subtypes",
    "category": "section",
    "text": "The direct subtypes of any DataType may be listed using subtypes(). For example, the abstract DataType AbstractFloat has four (concrete) subtypes:julia> subtypes(AbstractFloat)\n4-element Array{Union{DataType, UnionAll},1}:\n BigFloat\n Float16\n Float32\n Float64Any abstract subtype will also be included in this list, but further subtypes thereof will not; recursive application of subtypes() may be used to inspect the full type tree."
},

{
    "location": "devdocs/reflection/#DataType-layout-1",
    "page": "Reflection and introspection",
    "title": "DataType layout",
    "category": "section",
    "text": "The internal representation of a DataType is critically important when interfacing with C code and several functions are available to inspect these details. isbits(T::DataType) returns true if T is stored with C-compatible alignment. fieldoffset(T::DataType, i::Integer) returns the (byte) offset for field i relative to the start of the type."
},

{
    "location": "devdocs/reflection/#Function-methods-1",
    "page": "Reflection and introspection",
    "title": "Function methods",
    "category": "section",
    "text": "The methods of any generic function may be listed using methods(). The method dispatch table may be searched for methods accepting a given type using methodswith()."
},

{
    "location": "devdocs/reflection/#Expansion-and-lowering-1",
    "page": "Reflection and introspection",
    "title": "Expansion and lowering",
    "category": "section",
    "text": "As discussed in the Metaprogramming section, the macroexpand() function gives the unquoted and interpolated expression (Expr) form for a given macro. To use macroexpand, quote the expression block itself (otherwise, the macro will be evaluated and the result will be passed instead!). For example:julia> macroexpand( :(@edit println(\"\")) )\n:((Base.edit)(println, (Base.typesof)(\"\")))The functions Base.Meta.show_sexpr() and dump() are used to display S-expr style views and depth-nested detail views for any expression.Finally, the expand() function gives the lowered form of any expression and is of particular interest for understanding both macros and top-level statements such as function declarations and variable assignments:julia> expand( :(f() = 1) )\n:(begin\n        $(Expr(:method, :f))\n        $(Expr(:method, :f, :((Core.svec)((Core.svec)((Core.Typeof)(f)), (Core.svec)())), CodeInfo(:(begin  # none, line 1:\n        return 1\n    end)), false))\n        return f\n    end)"
},

{
    "location": "devdocs/reflection/#Intermediate-and-compiled-representations-1",
    "page": "Reflection and introspection",
    "title": "Intermediate and compiled representations",
    "category": "section",
    "text": "Inspecting the lowered form for functions requires selection of the specific method to display, because generic functions may have many methods with different type signatures. For this purpose, method-specific code-lowering is available using code_lowered(f::Function, (Argtypes...)), and the type-inferred form is available using code_typed(f::Function, (Argtypes...)). code_warntype(f::Function, (Argtypes...)) adds highlighting to the output of code_typed() (see @code_warntype).Closer to the machine, the LLVM intermediate representation of a function may be printed using by code_llvm(f::Function, (Argtypes...)), and finally the compiled machine code is available using code_native(f::Function, (Argtypes...)) (this will trigger JIT compilation/code generation for any function which has not previously been called).For convenience, there are macro versions of the above functions which take standard function calls and expand argument types automatically:julia> @code_llvm +(1,1)\n\n; Function Attrs: sspreq\ndefine i64 @\"julia_+_130862\"(i64, i64) #0 {\ntop:\n    %2 = add i64 %1, %0, !dbg !8\n    ret i64 %2, !dbg !8\n}(likewise @code_typed, @code_warntype, @code_lowered, and @code_native)"
},

{
    "location": "devdocs/init/#",
    "page": "Initialization of the Julia runtime",
    "title": "Initialization of the Julia runtime",
    "category": "page",
    "text": ""
},

{
    "location": "devdocs/init/#Initialization-of-the-Julia-runtime-1",
    "page": "Initialization of the Julia runtime",
    "title": "Initialization of the Julia runtime",
    "category": "section",
    "text": "How does the Julia runtime execute julia -e \'println(\"Hello World!\")\' ?"
},

{
    "location": "devdocs/init/#main()-1",
    "page": "Initialization of the Julia runtime",
    "title": "main()",
    "category": "section",
    "text": "Execution starts at main() in ui/repl.c.main() calls libsupport_init() to set the C library locale and to initialize the \"ios\" library (see ios_init_stdstreams() and Legacy ios.c library).Next parse_opts() is called to process command line options. Note that parse_opts() only deals with options that affect code generation or early initialization. Other options are handled later by process_options() in base/client.jl.parse_opts() stores command line options in the global jl_options struct."
},

{
    "location": "devdocs/init/#julia_init()-1",
    "page": "Initialization of the Julia runtime",
    "title": "julia_init()",
    "category": "section",
    "text": "julia_init() in task.c is called by main() and calls _julia_init() in init.c._julia_init() begins by calling libsupport_init() again (it does nothing the second time).restore_signals() is called to zero the signal handler mask.jl_resolve_sysimg_location() searches configured paths for the base system image. See Building the Julia system image.jl_gc_init() sets up allocation pools and lists for weak refs, preserved values and finalization.jl_init_frontend() loads and initializes a pre-compiled femtolisp image containing the scanner/parser.jl_init_types() creates jl_datatype_t type description objects for the built-in types defined in julia.h. e.g.jl_any_type = jl_new_abstracttype(jl_symbol(\"Any\"), NULL, jl_null);\njl_any_type->super = jl_any_type;\n\njl_type_type = jl_new_abstracttype(jl_symbol(\"Type\"), jl_any_type, jl_null);\n\njl_int32_type = jl_new_bitstype(jl_symbol(\"Int32\"),\n                                jl_any_type, jl_null, 32);jl_init_tasks() creates the jl_datatype_t* jl_task_type object; initializes the global jl_root_task struct; and sets jl_current_task to the root task.jl_init_codegen() initializes the LLVM library.jl_init_serializer() initializes 8-bit serialization tags for 256 frequently used jl_value_t values. The serialization mechanism uses these tags as shorthand (in lieu of storing whole objects) to save storage space.If there is no sysimg file (!jl_options.image_file) then the Core and Main modules are created and boot.jl is evaluated:jl_core_module = jl_new_module(jl_symbol(\"Core\")) creates the Julia Core module.jl_init_intrinsic_functions() creates a new Julia module Intrinsics containing constant jl_intrinsic_type symbols. These define an integer code for each intrinsic function. emit_intrinsic() translates these symbols into LLVM instructions during code generation.jl_init_primitives() hooks C functions up to Julia function symbols. e.g. the symbol Base.is() is bound to C function pointer jl_f_is() by calling add_builtin_func(\"eval\", jl_f_top_eval).jl_new_main_module() creates the global \"Main\" module and sets jl_current_task->current_module = jl_main_module.Note: _julia_init() then sets jl_root_task->current_module = jl_core_module. jl_root_task is an alias of jl_current_task at this point, so the current_module set by jl_new_main_module() above is overwritten.jl_load(\"boot.jl\", sizeof(\"boot.jl\")) calls jl_parse_eval_all which repeatedly calls jl_toplevel_eval_flex() to execute boot.jl. <!– TODO – drill down into eval? –>jl_get_builtin_hooks() initializes global C pointers to Julia globals defined in boot.jl.jl_init_box_caches() pre-allocates global boxed integer value objects for values up to 1024. This speeds up allocation of boxed ints later on. e.g.:jl_value_t *jl_box_uint8(uint32_t x)\n{\n    return boxed_uint8_cache[(uint8_t)x];\n}_julia_init() iterates over the jl_core_module->bindings.table looking for jl_datatype_t values and sets the type name\'s module prefix to jl_core_module.jl_add_standard_imports(jl_main_module) does \"using Base\" in the \"Main\" module.Note: _julia_init() now reverts to jl_root_task->current_module = jl_main_module as it was before being set to jl_core_module above.Platform specific signal handlers are initialized for SIGSEGV (OSX, Linux), and SIGFPE (Windows).Other signals (SIGINFO, SIGBUS, SIGILL, SIGTERM, SIGABRT, SIGQUIT, SIGSYS and SIGPIPE) are hooked up to sigdie_handler() which prints a backtrace.jl_init_restored_modules() calls jl_module_run_initializer() for each deserialized module to run the __init__() function.Finally sigint_handler() is hooked up to SIGINT and calls jl_throw(jl_interrupt_exception)._julia_init() then returns back to main() in ui/repl.c and main() calls true_main(argc, (char**)argv).sidebar: sysimg\nIf there is a sysimg file, it contains a pre-cooked image of the Core and Main modules (and whatever else is created by boot.jl). See Building the Julia system image.jl_restore_system_image() deserializes the saved sysimg into the current Julia runtime environment and initialization continues after jl_init_box_caches() below...Note: jl_restore_system_image() (and dump.c in general) uses the Legacy ios.c library."
},

{
    "location": "devdocs/init/#true_main()-1",
    "page": "Initialization of the Julia runtime",
    "title": "true_main()",
    "category": "section",
    "text": "true_main() loads the contents of argv[] into Base.ARGS.If a .jl \"program\" file was supplied on the command line, then exec_program() calls jl_load(program,len) which calls jl_parse_eval_all which repeatedly calls jl_toplevel_eval_flex() to execute the program.However, in our example (julia -e \'println(\"Hello World!\")\'), jl_get_global(jl_base_module, jl_symbol(\"_start\")) looks up Base._start and jl_apply() executes it."
},

{
    "location": "devdocs/init/#Base._start-1",
    "page": "Initialization of the Julia runtime",
    "title": "Base._start",
    "category": "section",
    "text": "Base._start calls Base.process_options which calls jl_parse_input_line(\"println(\"Hello World!\")\") to create an expression object and Base.eval() to execute it."
},

{
    "location": "devdocs/init/#Base.eval-1",
    "page": "Initialization of the Julia runtime",
    "title": "Base.eval",
    "category": "section",
    "text": "Base.eval() was mapped to jl_f_top_eval by jl_init_primitives().jl_f_top_eval() calls jl_toplevel_eval_in(jl_main_module, ex), where ex is the parsed expression println(\"Hello World!\").jl_toplevel_eval_in() calls jl_toplevel_eval_flex() which calls eval() in interpreter.c.The stack dump below shows how the interpreter works its way through various methods of Base.println() and Base.print() before arriving at write(s::IO, a::Array{T}) where T  which does ccall(jl_uv_write()).jl_uv_write() calls uv_write() to write \"Hello World!\" to JL_STDOUT. See Libuv wrappers for stdio.:Hello World!Stack frame Source code Notes\njl_uv_write() jl_uv.c called though ccall\njulia_write_282942 stream.jl function write!(s::IO, a::Array{T}) where T\njulia_print_284639 ascii.jl print(io::IO, s::String) = (write(io, s); nothing)\njlcall_print_284639    \njl_apply() julia.h  \njl_trampoline() builtins.c  \njl_apply() julia.h  \njl_apply_generic() gf.c Base.print(Base.TTY, String)\njl_apply() julia.h  \njl_trampoline() builtins.c  \njl_apply() julia.h  \njl_apply_generic() gf.c Base.print(Base.TTY, String, Char, Char...)\njl_apply() julia.h  \njl_f_apply() builtins.c  \njl_apply() julia.h  \njl_trampoline() builtins.c  \njl_apply() julia.h  \njl_apply_generic() gf.c Base.println(Base.TTY, String, String...)\njl_apply() julia.h  \njl_trampoline() builtins.c  \njl_apply() julia.h  \njl_apply_generic() gf.c Base.println(String,)\njl_apply() julia.h  \ndo_call() interpreter.c  \neval() interpreter.c  \njl_interpret_toplevel_expr() interpreter.c  \njl_toplevel_eval_flex() toplevel.c  \njl_toplevel_eval() toplevel.c  \njl_toplevel_eval_in() builtins.c  \njl_f_top_eval() builtins.c  Since our example has just one function call, which has done its job of printing \"Hello World!\", the stack now rapidly unwinds back to main()."
},

{
    "location": "devdocs/init/#jl_atexit_hook()-1",
    "page": "Initialization of the Julia runtime",
    "title": "jl_atexit_hook()",
    "category": "section",
    "text": "main() calls jl_atexit_hook(). This calls _atexit for each module, then calls jl_gc_run_all_finalizers() and cleans up libuv handles."
},

{
    "location": "devdocs/init/#julia_save()-1",
    "page": "Initialization of the Julia runtime",
    "title": "julia_save()",
    "category": "section",
    "text": "Finally, main() calls julia_save(), which if requested on the command line, saves the runtime state to a new system image. See jl_compile_all() and jl_save_system_image()."
},

{
    "location": "devdocs/ast/#",
    "page": "Julia ASTs",
    "title": "Julia ASTs",
    "category": "page",
    "text": ""
},

{
    "location": "devdocs/ast/#Julia-ASTs-1",
    "page": "Julia ASTs",
    "title": "Julia ASTs",
    "category": "section",
    "text": "Julia has two representations of code. First there is a surface syntax AST returned by the parser (e.g. the parse() function), and manipulated by macros. It is a structured representation of code as it is written, constructed by julia-parser.scm from a character stream. Next there is a lowered form, or IR (intermediate representation), which is used by type inference and code generation. In the lowered form there are fewer types of nodes, all macros are expanded, and all control flow is converted to explicit branches and sequences of statements. The lowered form is constructed by julia-syntax.scm.First we will focus on the lowered form, since it is more important to the compiler. It is also less obvious to the human, since it results from a significant rearrangement of the input syntax."
},

{
    "location": "devdocs/ast/#Lowered-form-1",
    "page": "Julia ASTs",
    "title": "Lowered form",
    "category": "section",
    "text": "The following data types exist in lowered form:Expr\nHas a node type indicated by the head field, and an args field which is a Vector{Any} of subexpressions.\nSlot\nIdentifies arguments and local variables by consecutive numbering. Slot is an abstract type with subtypes SlotNumber and TypedSlot. Both types have an integer-valued id field giving the slot index. Most slots have the same type at all uses, and so are represented with SlotNumber. The types of these slots are found in the slottypes field of their MethodInstance object. Slots that require per-use type annotations are represented with TypedSlot, which has a typ field.\nCodeInfo\nWraps the IR of a method.\nLineNumberNode\nContains a single number, specifying the line number the next statement came from.\nLabelNode\nBranch target, a consecutively-numbered integer starting at 0.\nGotoNode\nUnconditional branch.\nQuoteNode\nWraps an arbitrary value to reference as data. For example, the function f() = :a contains a QuoteNode whose value field is the symbol a, in order to return the symbol itself instead of evaluating it.\nGlobalRef\nRefers to global variable name in module mod.\nSSAValue\nRefers to a consecutively-numbered (starting at 0) static single assignment (SSA) variable inserted by the compiler.\nNewvarNode\nMarks a point where a variable is created. This has the effect of resetting a variable to undefined."
},

{
    "location": "devdocs/ast/#Expr-types-1",
    "page": "Julia ASTs",
    "title": "Expr types",
    "category": "section",
    "text": "These symbols appear in the head field of Exprs in lowered form.call\nFunction call (dynamic dispatch). args[1] is the function to call, args[2:end] are the arguments.\ninvoke\nFunction call (static dispatch). args[1] is the MethodInstance to call, args[2:end] are the arguments (including the function that is being called, at args[2]).\nstatic_parameter\nReference a static parameter by index.\nline\nLine number and file name metadata. Unlike a LineNumberNode, can also contain a file name.\ngotoifnot\nConditional branch. If args[1] is false, goes to label identified in args[2].\n=\nAssignment.\nmethod\nAdds a method to a generic function and assigns the result if necessary.\nHas a 1-argument form and a 4-argument form. The 1-argument form arises from the syntax function foo end. In the 1-argument form, the argument is a symbol. If this symbol already names a function in the current scope, nothing happens. If the symbol is undefined, a new function is created and assigned to the identifier specified by the symbol. If the symbol is defined but names a non-function, an error is raised. The definition of \"names a function\" is that the binding is constant, and refers to an object of singleton type. The rationale for this is that an instance of a singleton type uniquely identifies the type to add the method to. When the type has fields, it wouldn\'t be clear whether the method was being added to the instance or its type.\nThe 4-argument form has the following arguments:\nargs[1]\nA function name, or false if unknown. If a symbol, then the expression first behaves like the 1-argument form above. This argument is ignored from then on. When this is false, it means a method is being added strictly by type, (::T)(x) = x.\nargs[2]\nA SimpleVector of argument type data. args[2][1] is a SimpleVector of the argument types, and args[2][2] is a SimpleVector of type variables corresponding to the method\'s static parameters.\nargs[3]\nA CodeInfo of the method itself. For \"out of scope\" method definitions (adding a method to a function that also has methods defined in different scopes) this is an expression that evaluates to a :lambda expression.\nargs[4]\ntrue or false, identifying whether the method is staged (@generated function).\nconst\nDeclares a (global) variable as constant.\nnull\nHas no arguments; simply yields the value nothing.\nnew\nAllocates a new struct-like object. First argument is the type. The new pseudo-function is lowered to this, and the type is always inserted by the compiler.  This is very much an internal-only feature, and does no checking. Evaluating arbitrary new expressions can easily segfault.\nreturn\nReturns its argument as the value of the enclosing function.\nthe_exception\nYields the caught exception inside a catch block. This is the value of the run time system variable jl_exception_in_transit.\nenter\nEnters an exception handler (setjmp). args[1] is the label of the catch block to jump to on error.\nleave\nPop exception handlers. args[1] is the number of handlers to pop.\ninbounds\nControls turning bounds checks on or off. A stack is maintained; if the first argument of this expression is true or false (true means bounds checks are disabled), it is pushed onto the stack. If the first argument is :pop, the stack is popped.\nboundscheck\nIndicates the beginning or end of a section of code that performs a bounds check. Like inbounds, a stack is maintained, and the second argument can be one of: true, false, or :pop.\ncopyast\nPart of the implementation of quasi-quote. The argument is a surface syntax AST that is simply copied recursively and returned at run time.\nmeta\nMetadata. args[1] is typically a symbol specifying the kind of metadata, and the rest of the arguments are free-form. The following kinds of metadata are commonly used:\n:inline and :noinline: Inlining hints.\n:push_loc: enters a sequence of statements from a specified source location.\nargs[2] specifies a filename, as a symbol.\nargs[3] optionally specifies the name of an (inlined) function that originally contained the code.\n:pop_loc: returns to the source location before the matching :push_loc."
},

{
    "location": "devdocs/ast/#Method-1",
    "page": "Julia ASTs",
    "title": "Method",
    "category": "section",
    "text": "A unique\'d container describing the shared metadata for a single method.name, module, file, line, sig\nMetadata to uniquely identify the method for the computer and the human.\nambig\nCache of other methods that may be ambiguous with this one.\nspecializations\nCache of all MethodInstance ever created for this Method, used to ensure uniqueness. Uniqueness is required for efficiency, especially for incremental precompile and tracking of method invalidation.\nsource\nThe original source code (usually compressed).\nroots\nPointers to non-AST things that have been interpolated into the AST, required by compression of the AST, type-inference, or the generation of native code.\nnargs, isva, called, isstaged, pure\nDescriptive bit-fields for the source code of this Method.\nmin_world / max_world\nThe range of world ages for which this method is visible to dispatch."
},

{
    "location": "devdocs/ast/#MethodInstance-1",
    "page": "Julia ASTs",
    "title": "MethodInstance",
    "category": "section",
    "text": "A unique\'d container describing a single callable signature for a Method. See especially Proper maintenance and care of multi-threading locks for important details on how to modify these fields safely.specTypes\nThe primary key for this MethodInstance. Uniqueness is guaranteed through a def.specializations lookup.\ndef\nThe Method that this function describes a specialization of. Or #undef, if this is a top-level Lambda that is not part of a Method.\nsparam_vals\nThe values of the static parameters in specTypes indexed by def.sparam_syms. For the MethodInstance at Method.unspecialized, this is the empty SimpleVector. But for a runtime MethodInstance from the MethodTable cache, this will always be defined and indexable.\nrettype\nThe inferred return type for the specFunctionObject field, which (in most cases) is also the computed return type for the function in general.\ninferred\nMay contain a cache of the inferred source for this function, or other information about the inference result such as a constant return value may be put here (if jlcall_api == 2), or it could be set to nothing to just indicate rettype is inferred.\nftpr\nThe generic jlcall entry point.\njlcall_api\nThe ABI to use when calling fptr. Some significant ones include:\n0 - Not compiled yet\n1 - JL_CALLABLE jl_value_t *(*)(jl_function_t *f, jl_value_t *args[nargs], uint32_t nargs)\n2 - Constant (value stored in inferred)\n3 - With Static-parameters forwarded jl_value_t *(*)(jl_svec_t *sparams, jl_function_t *f, jl_value_t *args[nargs], uint32_t nargs)\n4 - Run in interpreter jl_value_t *(*)(jl_method_instance_t *meth, jl_function_t *f, jl_value_t *args[nargs], uint32_t nargs)\nmin_world / max_world\nThe range of world ages for which this method instance is valid to be called."
},

{
    "location": "devdocs/ast/#CodeInfo-1",
    "page": "Julia ASTs",
    "title": "CodeInfo",
    "category": "section",
    "text": "A temporary container for holding lowered source code.code\nAn Any array of statements\nslotnames\nAn array of symbols giving the name of each slot (argument or local variable).\nslottypes\nAn array of types for the slots.\nslotflags\nA UInt8 array of slot properties, represented as bit flags:\n2  - assigned (only false if there are no assignment statements with this var on the left)\n8  - const (currently unused for local variables)\n16 - statically assigned once\n32 - might be used before assigned. This flag is only valid after type inference.\nssavaluetypes\nEither an array or an Int.\nIf an Int, it gives the number of compiler-inserted temporary locations in the function. If an array, specifies a type for each location.Boolean properties:inferred\nWhether this has been produced by type inference.\ninlineable\nWhether this should be inlined.\npropagate_inbounds\nWhether this should should propagate @inbounds when inlined for the purpose of eliding @boundscheck blocks.\npure\nWhether this is known to be a pure function of its arguments, without respect to the state of the method caches or other mutable global state."
},

{
    "location": "devdocs/ast/#Surface-syntax-AST-1",
    "page": "Julia ASTs",
    "title": "Surface syntax AST",
    "category": "section",
    "text": "Front end ASTs consist entirely of Exprs and atoms (e.g. symbols, numbers). There is generally a different expression head for each visually distinct syntactic form. Examples will be given in s-expression syntax. Each parenthesized list corresponds to an Expr, where the first element is the head. For example (call f x) corresponds to Expr(:call, :f, :x) in Julia."
},

{
    "location": "devdocs/ast/#Calls-1",
    "page": "Julia ASTs",
    "title": "Calls",
    "category": "section",
    "text": "Input AST\nf(x) (call f x)\nf(x, y=1, z=2) (call f x (kw y 1) (kw z 2))\nf(x; y=1) (call f (parameters (kw y 1)) x)\nf(x...) (call f (... x))do syntax:f(x) do a,b\n    body\nendparses as (call f (-> (tuple a b) (block body)) x)."
},

{
    "location": "devdocs/ast/#Operators-1",
    "page": "Julia ASTs",
    "title": "Operators",
    "category": "section",
    "text": "Most uses of operators are just function calls, so they are parsed with the head call. However some operators are special forms (not necessarily function calls), and in those cases the operator itself is the expression head. In julia-parser.scm these are referred to as \"syntactic operators\". Some operators (+ and *) use N-ary parsing; chained calls are parsed as a single N-argument call. Finally, chains of comparisons have their own special expression structure.Input AST\nx+y (call + x y)\na+b+c+d (call + a b c d)\n2x (call * 2 x)\na&&b (&& a b)\nx += 1 (+= x 1)\na ? 1 : 2 (if a 1 2)\na:b (: a b)\na:b:c (: a b c)\na,b (tuple a b)\na==b (call == a b)\n1<i<=n (comparison 1 < i <= n)\na.b (. a (quote b))\na.(b) (. a b)"
},

{
    "location": "devdocs/ast/#Bracketed-forms-1",
    "page": "Julia ASTs",
    "title": "Bracketed forms",
    "category": "section",
    "text": "Input AST\na[i] (ref a i)\nt[i;j] (typed_vcat t i j)\nt[i j] (typed_hcat t i j)\nt[a b; c d] (typed_vcat t (row a b) (row c d))\na{b} (curly a b)\na{b;c} (curly a (parameters c) b)\n[x] (vect x)\n[x,y] (vect x y)\n[x;y] (vcat x y)\n[x y] (hcat x y)\n[x y; z t] (vcat (row x y) (row z t))\n[x for y in z, a in b] (comprehension x (= y z) (= a b))\nT[x for y in z] (typed_comprehension T x (= y z))\n(a, b, c) (tuple a b c)\n(a; b; c) (block a (block b c))"
},

{
    "location": "devdocs/ast/#Macros-1",
    "page": "Julia ASTs",
    "title": "Macros",
    "category": "section",
    "text": "Input AST\n@m x y (macrocall @m x y)\nBase.@m x y (macrocall (. Base (quote @m)) x y)\n@Base.m x y (macrocall (. Base (quote @m)) x y)"
},

{
    "location": "devdocs/ast/#Strings-1",
    "page": "Julia ASTs",
    "title": "Strings",
    "category": "section",
    "text": "Input AST\n\"a\" \"a\"\nx\"y\" (macrocall @x_str \"y\")\nx\"y\"z (macrocall @x_str \"y\" \"z\")\n\"x = $x\" (string \"x = \" x)\n`a b c` (macrocall @cmd \"a b c\")Doc string syntax:\"some docs\"\nf(x) = xparses as (macrocall (|.| Core \'@doc) \"some docs\" (= (call f x) (block x)))."
},

{
    "location": "devdocs/ast/#Imports-and-such-1",
    "page": "Julia ASTs",
    "title": "Imports and such",
    "category": "section",
    "text": "Input AST\nimport a (import a)\nimport a.b.c (import a b c)\nimport ...a (import . . . a)\nimport a.b, c.d (toplevel (import a b) (import c d))\nimport Base: x (import Base x)\nimport Base: x, y (toplevel (import Base x) (import Base y))\nexport a, b (export a b)"
},

{
    "location": "devdocs/ast/#Numbers-1",
    "page": "Julia ASTs",
    "title": "Numbers",
    "category": "section",
    "text": "Julia supports more number types than many scheme implementations, so not all numbers are represented directly as scheme numbers in the AST.Input AST\n11111111111111111111 (macrocall @int128_str \"11111111111111111111\")\n0xfffffffffffffffff (macrocall @uint128_str \"0xfffffffffffffffff\")\n1111...many digits... (macrocall @big_str \"1111....\")"
},

{
    "location": "devdocs/ast/#Block-forms-1",
    "page": "Julia ASTs",
    "title": "Block forms",
    "category": "section",
    "text": "A block of statements is parsed as (block stmt1 stmt2 ...).If statement:if a\n    b\nelseif c\n    d\nelse e\n    f\nendparses as:(if a (block (line 2) b)\n    (block (line 3) (if c (block (line 4) d)\n                        (block (line 5) e (line 6) f))))A while loop parses as (while condition body).A for loop parses as (for (= var iter) body). If there is more than one iteration specification, they are parsed as a block: (for (block (= v1 iter1) (= v2 iter2)) body).break and continue are parsed as 0-argument expressions (break) and (continue).let is parsed as (let body (= var1 val1) (= var2 val2) ...).A basic function definition is parsed as (function (call f x) body). A more complex example:function f{T}(x::T; k = 1)\n    return x+1\nendparses as:(function (call (curly f T) (parameters (kw k 1))\n                (:: x T))\n          (block (line 2 file.jl) (return (call + x 1))))Type definition:mutable struct Foo{T<:S}\n    x::T\nendparses as:(type #t (curly Foo (<: T S))\n      (block (line 2 none) (:: x T)))The first argument is a boolean telling whether the type is mutable.try blocks parse as (try try_block var catch_block finally_block). If no variable is present after catch, var is #f. If there is no finally clause, then the last argument is not present."
},

{
    "location": "devdocs/types/#",
    "page": "More about types",
    "title": "More about types",
    "category": "page",
    "text": ""
},

{
    "location": "devdocs/types/#More-about-types-1",
    "page": "More about types",
    "title": "More about types",
    "category": "section",
    "text": "If you\'ve used Julia for a while, you understand the fundamental role that types play.  Here we try to get under the hood, focusing particularly on Parametric Types."
},

{
    "location": "devdocs/types/#Types-and-sets-(and-Any-and-Union{}/Bottom)-1",
    "page": "More about types",
    "title": "Types and sets (and Any and Union{}/Bottom)",
    "category": "section",
    "text": "It\'s perhaps easiest to conceive of Julia\'s type system in terms of sets. While programs manipulate individual values, a type refers to a set of values. This is not the same thing as a collection; for example a Set of values is itself a single Set value. Rather, a type describes a set of possible values, expressing uncertainty about which value we have.A concrete type T describes the set of values whose direct tag, as returned by the typeof function, is T. An abstract type describes some possibly-larger set of values.Any describes the entire universe of possible values. Integer is a subset of Any that includes Int, Int8, and other concrete types. Internally, Julia also makes heavy use of another type known as Bottom, which can also be written as Union{}. This corresponds to the empty set.Julia\'s types support the standard operations of set theory: you can ask whether T1 is a \"subset\" (subtype) of T2 with T1 <: T2. Likewise, you intersect two types using typeintersect, take their union with Union, and compute a type that contains their union with typejoin:julia> typeintersect(Int, Float64)\nUnion{}\n\njulia> Union{Int, Float64}\nUnion{Float64, Int64}\n\njulia> typejoin(Int, Float64)\nReal\n\njulia> typeintersect(Signed, Union{UInt8, Int8})\nInt8\n\njulia> Union{Signed, Union{UInt8, Int8}}\nUnion{Signed, UInt8}\n\njulia> typejoin(Signed, Union{UInt8, Int8})\nInteger\n\njulia> typeintersect(Tuple{Integer,Float64}, Tuple{Int,Real})\nTuple{Int64,Float64}\n\njulia> Union{Tuple{Integer,Float64}, Tuple{Int,Real}}\nUnion{Tuple{Int64,Real}, Tuple{Integer,Float64}}\n\njulia> typejoin(Tuple{Integer,Float64}, Tuple{Int,Real})\nTuple{Integer,Real}While these operations may seem abstract, they lie at the heart of Julia.  For example, method dispatch is implemented by stepping through the items in a method list until reaching one for which the type of the argument tuple is a subtype of the method signature. For this algorithm to work, it\'s important that methods be sorted by their specificity, and that the search begins with the most specific methods. Consequently, Julia also implements a partial order on types; this is achieved by functionality that is similar to <:, but with differences that will be discussed below."
},

{
    "location": "devdocs/types/#UnionAll-types-1",
    "page": "More about types",
    "title": "UnionAll types",
    "category": "section",
    "text": "Julia\'s type system can also express an iterated union of types: a union of types over all values of some variable. This is needed to describe parametric types where the values of some parameters are not known.For example, :obj:Array has two parameters as in Array{Int,2}. If we did not know the element type, we could write Array{T,2} where T, which is the union of Array{T,2} for all values of T: Union{Array{Int8,2}, Array{Int16,2}, ...}.Such a type is represented by a UnionAll object, which contains a variable (T in this example, of type TypeVar), and a wrapped type (Array{T,2} in this example).Consider the following methods:f1(A::Array) = 1\nf2(A::Array{Int}) = 2\nf3(A::Array{T}) where {T<:Any} = 3\nf4(A::Array{Any}) = 4The signature of f3 is a UnionAll type wrapping a tuple type. All but f4 can be called with a = [1,2]; all but f2 can be called with b = Any[1,2].Let\'s look at these types a little more closely:julia> dump(Array)\nUnionAll\n  var: TypeVar\n    name: Symbol T\n    lb: Core.TypeofBottom Union{}\n    ub: Any\n  body: UnionAll\n    var: TypeVar\n      name: Symbol N\n      lb: Core.TypeofBottom Union{}\n      ub: Any\n    body: Array{T,N} <: DenseArray{T,N}This indicates that Array actually names a UnionAll type. There is one UnionAll type for each parameter, nested. The syntax Array{Int,2} is equivalent to Array{Int}{2}; internally each UnionAll is instantiated with a particular variable value, one at a time, outermost-first. This gives a natural meaning to the omission of trailing type parameters; Array{Int} gives a type equivalent to Array{Int,N} where N.A TypeVar is not itself a type, but rather should be considered part of the structure of a UnionAll type. Type variables have lower and upper bounds on their values (in the fields lb and ub). The symbol name is purely cosmetic. Internally, TypeVars are compared by address, so they are defined as mutable types to ensure that \"different\" type variables can be distinguished. However, by convention they should not be mutated.One can construct TypeVars manually:julia> TypeVar(:V, Signed, Real)\nSigned<:V<:RealThere are convenience versions that allow you to omit any of these arguments except the name symbol.The syntax Array{T} where T<:Integer is lowered tolet T = TypeVar(:T,Integer)\n    UnionAll(T, Array{T})\nendso it is seldom necessary to construct a TypeVar manually (indeed, this is to be avoided)."
},

{
    "location": "devdocs/types/#Free-variables-1",
    "page": "More about types",
    "title": "Free variables",
    "category": "section",
    "text": "The concept of a free type variable is extremely important in the type system. We say that a variable V is free in type T if T does not contain the UnionAll that introduces variable V. For example, the type Array{Array{V} where V<:Integer} has no free variables, but the Array{V} part inside of it does have a free variable, V.A type with free variables is, in some sense, not really a type at all. Consider the type Array{Array{T}} where T, which refers to all homogeneous arrays of arrays. The inner type Array{T}, seen by itself, might seem to refer to any kind of array. However, every element of the outer array must have the same array type, so Array{T} cannot refer to just any old array. One could say that Array{T} effectively \"occurs\" multiple times, and T must have the same value each \"time\".For this reason, the function jl_has_free_typevars in the C API is very important. Types for which it returns true will not give meaningful answers in subtyping and other type functions."
},

{
    "location": "devdocs/types/#TypeNames-1",
    "page": "More about types",
    "title": "TypeNames",
    "category": "section",
    "text": "The following two Array types are functionally equivalent, yet print differently:julia> TV, NV = TypeVar(:T), TypeVar(:N)\n(T, N)\n\njulia> Array\nArray\n\njulia> Array{TV,NV}\nArray{T,N}These can be distinguished by examining the name field of the type, which is an object of type TypeName:julia> dump(Array{Int,1}.name)\nTypeName\n  name: Symbol Array\n  module: Module Core\n  names: empty SimpleVector\n  wrapper: UnionAll\n    var: TypeVar\n      name: Symbol T\n      lb: Core.TypeofBottom Union{}\n      ub: Any\n    body: UnionAll\n      var: TypeVar\n        name: Symbol N\n        lb: Core.TypeofBottom Union{}\n        ub: Any\n      body: Array{T,N} <: DenseArray{T,N}\n  cache: SimpleVector\n    ...\n\n  linearcache: SimpleVector\n    ...\n\n  hash: Int64 -7900426068641098781\n  mt: MethodTable\n    name: Symbol Array\n    defs: Void nothing\n    cache: Void nothing\n    max_args: Int64 0\n    kwsorter: #undef\n    module: Module Core\n    : Int64 0\n    : Int64 0In this case, the relevant field is wrapper, which holds a reference to the top-level type used to make new Array types.julia> pointer_from_objref(Array)\nPtr{Void} @0x00007fcc7de64850\n\njulia> pointer_from_objref(Array.body.body.name.wrapper)\nPtr{Void} @0x00007fcc7de64850\n\njulia> pointer_from_objref(Array{TV,NV})\nPtr{Void} @0x00007fcc80c4d930\n\njulia> pointer_from_objref(Array{TV,NV}.name.wrapper)\nPtr{Void} @0x00007fcc7de64850The wrapper field of Array points to itself, but for Array{TV,NV} it points back to the original definition of the type.What about the other fields? hash assigns an integer to each type.  To examine the cache field, it\'s helpful to pick a type that is less heavily used than Array. Let\'s first create our own type:julia> struct MyType{T,N} end\n\njulia> MyType{Int,2}\nMyType{Int64,2}\n\njulia> MyType{Float32, 5}\nMyType{Float32,5}\n\njulia> MyType.body.body.name.cache\nsvec(MyType{Float32,5}, MyType{Int64,2}, #undef, #undef, #undef, #undef, #undef, #undef)(The cache is pre-allocated to have length 8, but only the first two entries are populated.) Consequently, when you instantiate a parametric type, each concrete type gets saved in a type cache.  However, instances containing free type variables are not cached."
},

{
    "location": "devdocs/types/#Tuple-types-1",
    "page": "More about types",
    "title": "Tuple types",
    "category": "section",
    "text": "Tuple types constitute an interesting special case.  For dispatch to work on declarations like x::Tuple, the type has to be able to accommodate any tuple.  Let\'s check the parameters:julia> Tuple\nTuple\n\njulia> Tuple.parameters\nsvec(Vararg{Any,N} where N)Unlike other types, tuple types are covariant in their parameters, so this definition permits Tuple to match any type of tuple:julia> typeintersect(Tuple, Tuple{Int,Float64})\nTuple{Int64,Float64}\n\njulia> typeintersect(Tuple{Vararg{Any}}, Tuple{Int,Float64})\nTuple{Int64,Float64}However, if a variadic (Vararg) tuple type has free variables it can describe different kinds of tuples:julia> typeintersect(Tuple{Vararg{T} where T}, Tuple{Int,Float64})\nTuple{Int64,Float64}\n\njulia> typeintersect(Tuple{Vararg{T}} where T, Tuple{Int,Float64})\nUnion{}Notice that when T is free with respect to the Tuple type (i.e. its binding UnionAll type is outside the Tuple type), only one T value must work over the whole type. Therefore a heterogeneous tuple does not match.Finally, it\'s worth noting that Tuple{} is distinct:julia> Tuple{}\nTuple{}\n\njulia> Tuple{}.parameters\nsvec()\n\njulia> typeintersect(Tuple{}, Tuple{Int})\nUnion{}What is the \"primary\" tuple-type?julia> pointer_from_objref(Tuple)\nPtr{Void} @0x00007f5998a04370\n\njulia> pointer_from_objref(Tuple{})\nPtr{Void} @0x00007f5998a570d0\n\njulia> pointer_from_objref(Tuple.name.wrapper)\nPtr{Void} @0x00007f5998a04370\n\njulia> pointer_from_objref(Tuple{}.name.wrapper)\nPtr{Void} @0x00007f5998a04370so Tuple == Tuple{Vararg{Any}} is indeed the primary type."
},

{
    "location": "devdocs/types/#Diagonal-types-1",
    "page": "More about types",
    "title": "Diagonal types",
    "category": "section",
    "text": "Consider the type Tuple{T,T} where T. A method with this signature would look like:f(x::T, y::T) where {T} = ...According to the usual interpretation of a UnionAll type, this T ranges over all types, including Any, so this type should be equivalent to Tuple{Any,Any}. However, this interpretation causes some practical problems.First, a value of T needs to be available inside the method definition. For a call like f(1, 1.0), it\'s not clear what T should be. It could be Union{Int,Float64}, or perhaps Real. Intuitively, we expect the declaration x::T to mean T === typeof(x). To make sure that invariant holds, we need typeof(x) === typeof(y) === T in this method. That implies the method should only be called for arguments of the exact same type.It turns out that being able to dispatch on whether two values have the same type is very useful (this is used by the promotion system for example), so we have multiple reasons to want a different interpretation of Tuple{T,T} where T. To make this work we add the following rule to subtyping: if a variable occurs more than once in covariant position, it is restricted to ranging over only concrete types. (\"Covariant position\" means that only Tuple and Union types occur between an occurrence of a variable and the UnionAll type that introduces it.) Such variables are called \"diagonal variables\" or \"concrete variables\".So for example, Tuple{T,T} where T can be seen as Union{Tuple{Int8,Int8}, Tuple{Int16,Int16}, ...}, where T ranges over all concrete types. This gives rise to some interesting subtyping results. For example Tuple{Real,Real} is not a subtype of Tuple{T,T} where T, because it includes some types like Tuple{Int8,Int16} where the two elements have different types. Tuple{Real,Real} and Tuple{T,T} where T have the non-trivial intersection Tuple{T,T} where T<:Real. However, Tuple{Real} is a subtype of Tuple{T} where T, because in that case T occurs only once and so is not diagonal.Next consider a signature like the following:f(a::Array{T}, x::T, y::T) where {T} = ...In this case, T occurs in invariant position inside Array{T}. That means whatever type of array is passed unambiguously determines the value of T –- we say T has an equality constraint on it. Therefore in this case the diagonal rule is not really necessary, since the array determines T and we can then allow x and y to be of any subtypes of T. So variables that occur in invariant position are never considered diagonal. This choice of behavior is slightly controversial –- some feel this definition should be written asf(a::Array{T}, x::S, y::S) where {T, S<:T} = ...to clarify whether x and y need to have the same type. In this version of the signature they would, or we could introduce a third variable for the type of y if x and y can have different types.The next complication is the interaction of unions and diagonal variables, e.g.f(x::Union{Void,T}, y::T) where {T} = ...Consider what this declaration means. y has type T. x then can have either the same type T, or else be of type Void. So all of the following calls should match:f(1, 1)\nf(\"\", \"\")\nf(2.0, 2.0)\nf(nothing, 1)\nf(nothing, \"\")\nf(nothing, 2.0)These examples are telling us something: when x is nothing::Void, there are no extra constraints on y. It is as if the method signature had y::Any. This means that whether a variable is diagonal is not a static property based on where it appears in a type. Rather, it depends on where a variable appears when the subtyping algorithm uses it. When x has type Void, we don\'t need to use the T in Union{Void,T}, so T does not \"occur\". Indeed, we have the following type equivalence:(Tuple{Union{Void,T},T} where T) == Union{Tuple{Void,Any}, Tuple{T,T} where T}"
},

{
    "location": "devdocs/types/#Subtyping-diagonal-variables-1",
    "page": "More about types",
    "title": "Subtyping diagonal variables",
    "category": "section",
    "text": "The subtyping algorithm for diagonal variables has two components: (1) identifying variable occurrences, and (2) ensuring that diagonal variables range over concrete types only.The first task is accomplished by keeping counters occurs_inv and occurs_cov (in src/subtype.c) for each variable in the environment, tracking the number of invariant and covariant occurrences, respectively. A variable is diagonal when occurs_inv == 0 && occurs_cov > 1.The second task is accomplished by imposing a condition on a variable\'s lower bound. As the subtyping algorithm runs, it narrows the bounds of each variable (raising lower bounds and lowering upper bounds) to keep track of the range of variable values for which the subtype relation would hold. When we are done evaluating the body of a UnionAll type whose variable is diagonal, we look at the final values of the bounds. Since the variable must be concrete, a contradiction occurs if its lower bound could not be a subtype of a concrete type. For example, an abstract type like AbstractArray cannot be a subtype of a concrete type, but a concrete type like Int can be, and the empty type Bottom can be as well. If a lower bound fails this test the algorithm stops with the answer false.For example, in the problem Tuple{Int,String} <: Tuple{T,T} where T, we derive that this would be true if T were a supertype of Union{Int,String}. However, Union{Int,String} is an abstract type, so the relation does not hold.This concreteness test is done by the function is_leaf_bound. Note that this test is slightly different from jl_is_leaf_type, since it also returns true for Bottom. Currently this function is heuristic, and does not catch all possible concrete types. The difficulty is that whether a lower bound is concrete might depend on the values of other type variable bounds. For example, Vector{T} is equivalent to the concrete type Vector{Int} only if both the upper and lower bounds of T equal Int. We have not yet worked out a complete algorithm for this."
},

{
    "location": "devdocs/types/#Introduction-to-the-internal-machinery-1",
    "page": "More about types",
    "title": "Introduction to the internal machinery",
    "category": "section",
    "text": "Most operations for dealing with types are found in the files jltypes.c and subtype.c. A good way to start is to watch subtyping in action. Build Julia with make debug and fire up Julia within a debugger. gdb debugging tips has some tips which may be useful.Because the subtyping code is used heavily in the REPL itself–and hence breakpoints in this code get triggered often–it will be easiest if you make the following definition:julia> function mysubtype(a,b)\n           ccall(:jl_breakpoint, Void, (Any,), nothing)\n           issubtype(a, b)\n       endand then set a breakpoint in jl_breakpoint.  Once this breakpoint gets triggered, you can set breakpoints in other functions.As a warm-up, try the following:mysubtype(Tuple{Int,Float64}, Tuple{Integer,Real})We can make it more interesting by trying a more complex case:mysubtype(Tuple{Array{Int,2}, Int8}, Tuple{Array{T}, T} where T)"
},

{
    "location": "devdocs/types/#Subtyping-and-method-sorting-1",
    "page": "More about types",
    "title": "Subtyping and method sorting",
    "category": "section",
    "text": "The type_morespecific functions are used for imposing a partial order on functions in method tables (from most-to-least specific). Specificity is strict; if a is more specific than b, then a does not equal b and b is not more specific than a.If a is a strict subtype of b, then it is automatically considered more specific. From there, type_morespecific employs some less formal rules. For example, subtype is sensitive to the number of arguments, but type_morespecific may not be. In particular, Tuple{Int,AbstractFloat} is more specific than Tuple{Integer}, even though it is not a subtype.  (Of Tuple{Int,AbstractFloat} and Tuple{Integer,Float64}, neither is more specific than the other.)  Likewise, Tuple{Int,Vararg{Int}} is not a subtype of Tuple{Integer}, but it is considered more specific. However, morespecific does get a bonus for length: in particular, Tuple{Int,Int} is more specific than Tuple{Int,Vararg{Int}}.If you\'re debugging how methods get sorted, it can be convenient to define the function:type_morespecific(a, b) = ccall(:jl_type_morespecific, Cint, (Any,Any), a, b)which allows you to test whether tuple type a is more specific than tuple type b."
},

{
    "location": "devdocs/object/#",
    "page": "Memory layout of Julia Objects",
    "title": "Memory layout of Julia Objects",
    "category": "page",
    "text": ""
},

{
    "location": "devdocs/object/#Memory-layout-of-Julia-Objects-1",
    "page": "Memory layout of Julia Objects",
    "title": "Memory layout of Julia Objects",
    "category": "section",
    "text": ""
},

{
    "location": "devdocs/object/#Object-layout-(jl_value_t)-1",
    "page": "Memory layout of Julia Objects",
    "title": "Object layout (jl_value_t)",
    "category": "section",
    "text": "The jl_value_t struct is the name for a block of memory owned by the Julia Garbage Collector, representing the data associated with a Julia object in memory. Absent any type information, it is simply an opaque pointer:typedef struct jl_value_t* jl_pvalue_t;Each jl_value_t struct is contained in a jl_typetag_t struct that contains metadata information about the Julia object, such as its type and garbage collector (gc) reachability:typedef struct {\n    opaque metadata;\n    jl_value_t value;\n} jl_typetag_t;The type of any Julia object is an instance of a leaf jl_datatype_t object. The jl_typeof() function can be used to query for it:jl_value_t *jl_typeof(jl_value_t *v);The layout of the object depends on its type. Reflection methods can be used to inspect that layout. A field can be accessed by calling one of the get-field methods:jl_value_t *jl_get_nth_field_checked(jl_value_t *v, size_t i);\njl_value_t *jl_get_field(jl_value_t *o, char *fld);If the field types are known, a priori, to be all pointers, the values can also be extracted directly as an array access:jl_value_t *v = value->fieldptr[n];As an example, a \"boxed\" uint16_t is stored as follows:struct {\n    opaque metadata;\n    struct {\n        uint16_t data;        // -- 2 bytes\n    } jl_value_t;\n};This object is created by jl_box_uint16(). Note that the jl_value_t pointer references the data portion, not the metadata at the top of the struct.A value may be stored \"unboxed\" in many circumstances (just the data, without the metadata, and possibly not even stored but just kept in registers), so it is unsafe to assume that the address of a box is a unique identifier. The \"egal\" test (corresponding to the === function in Julia), should instead be used to compare two unknown objects for equivalence:int jl_egal(jl_value_t *a, jl_value_t *b);This optimization should be relatively transparent to the API, since the object will be \"boxed\" on-demand, whenever a jl_value_t pointer is needed.Note that modification of a jl_value_t pointer in memory is permitted only if the object is mutable. Otherwise, modification of the value may corrupt the program and the result will be undefined. The mutability property of a value can be queried for with:int jl_is_mutable(jl_value_t *v);If the object being stored is a jl_value_t, the Julia garbage collector must be notified also:void jl_gc_wb(jl_value_t *parent, jl_value_t *ptr);However, the Embedding Julia section of the manual is also required reading at this point, for covering other details of boxing and unboxing various types, and understanding the gc interactions.Mirror structs for some of the built-in types are defined in julia.h. The corresponding global jl_datatype_t objects are created by jl_init_types in jltypes.c."
},

{
    "location": "devdocs/object/#Garbage-collector-mark-bits-1",
    "page": "Memory layout of Julia Objects",
    "title": "Garbage collector mark bits",
    "category": "section",
    "text": "The garbage collector uses several bits from the metadata portion of the jl_typetag_t to track each object in the system. Further details about this algorithm can be found in the comments of the garbage collector implementation in gc.c."
},

{
    "location": "devdocs/object/#Object-allocation-1",
    "page": "Memory layout of Julia Objects",
    "title": "Object allocation",
    "category": "section",
    "text": "Most new objects are allocated by jl_new_structv():jl_value_t *jl_new_struct(jl_datatype_t *type, ...);\njl_value_t *jl_new_structv(jl_datatype_t *type, jl_value_t **args, uint32_t na);Although, isbits objects can be also constructed directly from memory:jl_value_t *jl_new_bits(jl_value_t *bt, void *data)And some objects have special constructors that must be used instead of the above functions:Types:jl_datatype_t *jl_apply_type(jl_datatype_t *tc, jl_tuple_t *params);\njl_datatype_t *jl_apply_array_type(jl_datatype_t *type, size_t dim);\njl_uniontype_t *jl_new_uniontype(jl_tuple_t *types);While these are the most commonly used options, there are more low-level constructors too, which you can find declared in julia.h. These are used in jl_init_types() to create the initial types needed to bootstrap the creation of the Julia system image.Tuples:jl_tuple_t *jl_tuple(size_t n, ...);\njl_tuple_t *jl_tuplev(size_t n, jl_value_t **v);\njl_tuple_t *jl_alloc_tuple(size_t n);The representation of tuples is highly unique in the Julia object representation ecosystem. In some cases, a Base.tuple() object may be an array of pointers to the objects contained by the tuple equivalent to:typedef struct {\n    size_t length;\n    jl_value_t *data[length];\n} jl_tuple_t;However, in other cases, the tuple may be converted to an anonymous isbits type and stored unboxed, or it may not stored at all (if it is not being used in a generic context as a jl_value_t*).Symbols:jl_sym_t *jl_symbol(const char *str);Functions and MethodInstance:jl_function_t *jl_new_generic_function(jl_sym_t *name);\njl_method_instance_t *jl_new_method_instance(jl_value_t *ast, jl_tuple_t *sparams);Arrays:jl_array_t *jl_new_array(jl_value_t *atype, jl_tuple_t *dims);\njl_array_t *jl_new_arrayv(jl_value_t *atype, ...);\njl_array_t *jl_alloc_array_1d(jl_value_t *atype, size_t nr);\njl_array_t *jl_alloc_array_2d(jl_value_t *atype, size_t nr, size_t nc);\njl_array_t *jl_alloc_array_3d(jl_value_t *atype, size_t nr, size_t nc, size_t z);\njl_array_t *jl_alloc_vec_any(size_t n);Note that many of these have alternative allocation functions for various special-purposes. The list here reflects the more common usages, but a more complete list can be found by reading the julia.h header file.Internal to Julia, storage is typically allocated by newstruct() (or newobj() for the special types):jl_value_t *newstruct(jl_value_t *type);\njl_value_t *newobj(jl_value_t *type, size_t nfields);And at the lowest level, memory is getting allocated by a call to the garbage collector (in gc.c), then tagged with its type:jl_value_t *jl_gc_allocobj(size_t nbytes);\nvoid jl_set_typeof(jl_value_t *v, jl_datatype_t *type);Note that all objects are allocated in multiples of 4 bytes and aligned to the platform pointer size. Memory is allocated from a pool for smaller objects, or directly with malloc() for large objects.sidebar: Singleton Types\nSingleton types have only one instance and no data fields. Singleton instances have a size of 0 bytes, and consist only of their metadata. e.g. nothing::Void.See Singleton Types and Nothingness and missing values"
},

{
    "location": "devdocs/eval/#",
    "page": "Eval of Julia code",
    "title": "Eval of Julia code",
    "category": "page",
    "text": ""
},

{
    "location": "devdocs/eval/#Eval-of-Julia-code-1",
    "page": "Eval of Julia code",
    "title": "Eval of Julia code",
    "category": "section",
    "text": "One of the hardest parts about learning how the Julia Language runs code is learning how all of the pieces work together to execute a block of code.Each chunk of code typically makes a trip through many steps with potentially unfamiliar names, such as (in no particular order): flisp, AST, C++, LLVM, eval, typeinf, macroexpand, sysimg (or system image), bootstrapping, compile, parse, execute, JIT, interpret, box, unbox, intrinsic function, and primitive function, before turning into the desired result (hopefully).sidebar: Definitions\nREPL\nREPL stands for Read-Eval-Print Loop. It\'s just what we call the command line environment for short.\nAST\nAbstract Syntax Tree The AST is the digital representation of the code structure. In this form the code has been tokenized for meaning so that it is more suitable for manipulation and execution."
},

{
    "location": "devdocs/eval/#Julia-Execution-1",
    "page": "Eval of Julia code",
    "title": "Julia Execution",
    "category": "section",
    "text": "The 10,000 foot view of the whole process is as follows:The user starts julia.\nThe C function main() from ui/repl.c gets called. This function processes the command line arguments, filling in the jl_options struct and setting the variable ARGS. It then initializes Julia (by calling julia_init in task.c, which may load a previously compiled sysimg). Finally, it passes off control to Julia by calling Base._start().\nWhen _start() takes over control, the subsequent sequence of commands depends on the command line arguments given. For example, if a filename was supplied, it will proceed to execute that file. Otherwise, it will start an interactive REPL.\nSkipping the details about how the REPL interacts with the user, let\'s just say the program ends up with a block of code that it wants to run.\nIf the block of code to run is in a file, jl_load(char *filename) gets invoked to load the file and parse it. Each fragment of code is then passed to eval to execute.\nEach fragment of code (or AST), is handed off to eval() to turn into results.\neval() takes each code fragment and tries to run it in jl_toplevel_eval_flex().\njl_toplevel_eval_flex() decides whether the code is a \"toplevel\" action (such as using or module), which would be invalid inside a function. If so, it passes off the code to the toplevel interpreter.\njl_toplevel_eval_flex() then expands the code to eliminate any macros and to \"lower\" the AST to make it simpler to execute.\njl_toplevel_eval_flex() then uses some simple heuristics to decide whether to JIT compiler the  AST or to interpret it directly.\nThe bulk of the work to interpret code is handled by eval in interpreter.c.\nIf instead, the code is compiled, the bulk of the work is handled by codegen.cpp. Whenever a  Julia function is called for the first time with a given set of argument types, type inference  will be run on that function. This information is used by the codegen step to generate  faster code.\nEventually, the user quits the REPL, or the end of the program is reached, and the _start()  method returns.\nJust before exiting, main() calls jl_atexit_hook(exit_code).  This calls Base._atexit() (which calls any functions registered to atexit() inside  Julia). Then it calls jl_gc_run_all_finalizers().  Finally, it gracefully cleans up all libuv handles and waits for them to flush and close."
},

{
    "location": "devdocs/eval/#dev-parsing-1",
    "page": "Eval of Julia code",
    "title": "Parsing",
    "category": "section",
    "text": "The Julia parser is a small lisp program written in femtolisp, the source-code for which is distributed inside Julia in src/flisp.The interface functions for this are primarily defined in jlfrontend.scm. The code in ast.c handles this handoff on the Julia side.The other relevant files at this stage are julia-parser.scm, which handles tokenizing Julia code and turning it into an AST, and julia-syntax.scm, which handles transforming complex AST representations into simpler, \"lowered\" AST representations which are more suitable for analysis and execution."
},

{
    "location": "devdocs/eval/#dev-macro-expansion-1",
    "page": "Eval of Julia code",
    "title": "Macro Expansion",
    "category": "section",
    "text": "When eval() encounters a macro, it expands that AST node before attempting to evaluate the expression. Macro expansion involves a handoff from eval() (in Julia), to the parser function jl_macroexpand() (written in flisp) to the Julia macro itself (written in - what else - Julia) via fl_invoke_julia_macro(), and back.Typically, macro expansion is invoked as a first step during a call to expand()/jl_expand(), although it can also be invoked directly by a call to macroexpand()/jl_macroexpand()."
},

{
    "location": "devdocs/eval/#dev-type-inference-1",
    "page": "Eval of Julia code",
    "title": "Type Inference",
    "category": "section",
    "text": "Type inference is implemented in Julia by typeinf() in inference.jl. Type inference is the process of examining a Julia function and determining bounds for the types of each of its variables, as well as bounds on the type of the return value from the function. This enables many future optimizations, such as unboxing of known immutable values, and compile-time hoisting of various run-time operations such as computing field offsets and function pointers. Type inference may also include other steps such as constant propagation and inlining.sidebar: More Definitions\nJIT\nJust-In-Time Compilation The process of generating native-machine code into memory right when it is needed.\nLLVM\nLow-Level Virtual Machine (a compiler) The Julia JIT compiler is a program/library called libLLVM. Codegen in Julia refers both to the process of taking a Julia AST and turning it into LLVM instructions, and the process of LLVM optimizing that and turning it into native assembly instructions.\nC++\nThe programming language that LLVM is implemented in, which means that codegen is also implemented in this language. The rest of Julia\'s library is implemented in C, in part because its smaller feature set makes it more usable as a cross-language interface layer.\nbox\nThis term is used to describe the process of taking a value and allocating a wrapper around the data that is tracked by the garbage collector (gc) and is tagged with the object\'s type.\nunbox\nThe reverse of boxing a value. This operation enables more efficient manipulation of data when the type of that data is fully known at compile-time (through type inference).\ngeneric function\nA Julia function composed of multiple \"methods\" that are selected for dynamic dispatch based on the argument type-signature\nanonymous function or \"method\"\nA Julia function without a name and without type-dispatch capabilities\nprimitive function\nA function implemented in C but exposed in Julia as a named function \"method\" (albeit without generic function dispatch capabilities, similar to a anonymous function)\nintrinsic function\nA low-level operation exposed as a function in Julia. These pseudo-functions implement operations on raw bits such as add and sign extend that cannot be expressed directly in any other way. Since they operate on bits directly, they must be compiled into a function and surrounded by a call to Core.Intrinsics.box(T, ...) to reassign type information to the value."
},

{
    "location": "devdocs/eval/#dev-codegen-1",
    "page": "Eval of Julia code",
    "title": "JIT Code Generation",
    "category": "section",
    "text": "Codegen is the process of turning a Julia AST into native machine code.The JIT environment is initialized by an early call to jl_init_codegen in codegen.cpp.On demand, a Julia method is converted into a native function by the function emit_function(jl_method_instance_t*). (note, when using the MCJIT (in LLVM v3.4+), each function must be JIT into a new module.) This function recursively calls emit_expr() until the entire function has been emitted.Much of the remaining bulk of this file is devoted to various manual optimizations of specific code patterns. For example, emit_known_call() knows how to inline many of the primitive functions (defined in builtins.c) for various combinations of argument types.Other parts of codegen are handled by various helper files:debuginfo.cpp\nHandles backtraces for JIT functions\nccall.cpp\nHandles the ccall and llvmcall FFI, along with various abi_*.cpp files\nintrinsics.cpp\nHandles the emission of various low-level intrinsic functionssidebar: Bootstrapping\nThe process of creating a new system image is called \"bootstrapping\".The etymology of this word comes from the phrase \"pulling oneself up by the bootstraps\", and refers to the idea of starting from a very limited set of available functions and definitions and ending with the creation of a full-featured environment."
},

{
    "location": "devdocs/eval/#dev-sysimg-1",
    "page": "Eval of Julia code",
    "title": "System Image",
    "category": "section",
    "text": "The system image is a precompiled archive of a set of Julia files. The sys.ji file distributed with Julia is one such system image, generated by executing the file sysimg.jl, and serializing the resulting environment (including Types, Functions, Modules, and all other defined values) into a file. Therefore, it contains a frozen version of the Main, Core, and Base modules (and whatever else was in the environment at the end of bootstrapping). This serializer/deserializer is implemented by jl_save_system_image/jl_restore_system_image in dump.c.If there is no sysimg file (jl_options.image_file == NULL), this also implies that --build was given on the command line, so the final result should be a new sysimg file. During Julia initialization, minimal Core and Main modules are created. Then a file named boot.jl is evaluated from the current directory. Julia then evaluates any file given as a command line argument until it reaches the end. Finally, it saves the resulting environment to a \"sysimg\" file for use as a starting point for a future Julia run."
},

{
    "location": "devdocs/callconv/#",
    "page": "Calling Conventions",
    "title": "Calling Conventions",
    "category": "page",
    "text": ""
},

{
    "location": "devdocs/callconv/#Calling-Conventions-1",
    "page": "Calling Conventions",
    "title": "Calling Conventions",
    "category": "section",
    "text": "Julia uses three calling conventions for four distinct purposes:Name Prefix Purpose\nNative julia_ Speed via specialized signatures\nJL Call jlcall_ Wrapper for generic calls\nJL Call jl_ Builtins\nC ABI jlcapi_ Wrapper callable from C"
},

{
    "location": "devdocs/callconv/#Julia-Native-Calling-Convention-1",
    "page": "Calling Conventions",
    "title": "Julia Native Calling Convention",
    "category": "section",
    "text": "The native calling convention is designed for fast non-generic calls. It usually uses a specialized signature.LLVM ghosts (zero-length types) are omitted.\nLLVM scalars and vectors are passed by value.\nLLVM aggregates (arrays and structs) are passed by reference.A small return values is returned as LLVM return values. A large return values is returned via the \"structure return\" (sret) convention, where the caller provides a pointer to a return slot.An argument or return values thta is a homogeneous tuple is sometimes represented as an LLVM vector instead of an LLVM array."
},

{
    "location": "devdocs/callconv/#JL-Call-Convention-1",
    "page": "Calling Conventions",
    "title": "JL Call Convention",
    "category": "section",
    "text": "The JL Call convention is for builtins and generic dispatch. Hand-written functions using this convention are declared via the macro JL_CALLABLE. The convention uses exactly 3 parameters:F  - Julia representation of function that is being applied\nargs - pointer to array of pointers to boxes\nnargs - length of the arrayThe return value is a pointer to a box."
},

{
    "location": "devdocs/callconv/#C-ABI-1",
    "page": "Calling Conventions",
    "title": "C ABI",
    "category": "section",
    "text": "C ABI wrappers enable calling Julia from C. The wrapper calls a function using the native calling convention.Tuples are always represented as C arrays."
},

{
    "location": "devdocs/compiler/#",
    "page": "High-level Overview of the Native-Code Generation Process",
    "title": "High-level Overview of the Native-Code Generation Process",
    "category": "page",
    "text": ""
},

{
    "location": "devdocs/compiler/#High-level-Overview-of-the-Native-Code-Generation-Process-1",
    "page": "High-level Overview of the Native-Code Generation Process",
    "title": "High-level Overview of the Native-Code Generation Process",
    "category": "section",
    "text": ""
},

{
    "location": "devdocs/compiler/#Representation-of-Pointers-1",
    "page": "High-level Overview of the Native-Code Generation Process",
    "title": "Representation of Pointers",
    "category": "section",
    "text": "When emitting code to an object file, pointers will be emitted as relocations. The deserialization code will ensure any object that pointed to one of these constants gets recreated and contains the right runtime pointer.Otherwise, they will be emitted as literal constants.To emit one of these objects, call literal_pointer_val. It\'ll handle tracking the Julia value and the LLVM global, ensuring they are valid both for the current runtime and after deserialization.When emitted into the object file, these globals are stored as references in a large gvals table. This allows the deserializer to reference them by index, and implement a custom manual mechanism similar to a Global Offset Table (GOT) to restore them.Function pointers are handled similarly. They are stored as values in a large fvals table. Like globals, this allows the deserializer to reference them by index.Note that extern functions are handled separately, with names, via the usual symbol resolution mechanism in the linker.Note too that ccall functions are also handled separately, via a manual GOT and Procedure Linkage Table (PLT)."
},

{
    "location": "devdocs/compiler/#Representation-of-Intermediate-Values-1",
    "page": "High-level Overview of the Native-Code Generation Process",
    "title": "Representation of Intermediate Values",
    "category": "section",
    "text": "Values are passed around in a jl_cgval_t struct. This represents an R-value, and includes enough information to determine how to assign or pass it somewhere.They are created via one of the helper constructors, usually: mark_julia_type (for immediate values) and mark_julia_slot (for pointers to values).The function convert_julia_type can transform between any two types. It returns an R-value with cgval.typ set to typ. It\'ll cast the object to the requested representation, making heap boxes, allocating stack copies, and computing tagged unions as needed to change the representation.By contrast update_julia_type will change cgval.typ to typ, only if it can be done at zero-cost (i.e. without emitting any code)."
},

{
    "location": "devdocs/compiler/#Union-representation-1",
    "page": "High-level Overview of the Native-Code Generation Process",
    "title": "Union representation",
    "category": "section",
    "text": "Inferred union types may be stack allocated via a tagged type representation.The primitive routines that need to be able to handle tagged unions are:mark-type\nload-local\nstore-local\nisa\nis\nemit_typeof\nemit_sizeof\nboxed\nunbox\nspecialized cc-retEverything else should be possible to handle in inference by using these primitives to implement union-splitting.The representation of the tagged-union is as a pair of < void* union, byte selector >. The selector is fixed-size as byte & 0x7f, and will union-tag the first 126 isbits. It records the one-based depth-first count into the type-union of the isbits objects inside. An index of zero indicates that the union* is actually a tagged heap-allocated jl_value_t*, and needs to be treated as normal for a boxed object rather than as a tagged union.The high bit of the selector (byte & 0x80) can be tested to determine if the void* is actually a heap-allocated (jl_value_t*) box, thus avoiding the cost of re-allocating a box, while maintaining the ability to efficiently handle union-splitting based on the low bits.It is guaranteed that byte & 0x7f is an exact test for the type, if the value can be represented by a tag – it will never be marked byte = 0x80. It is not necessary to also test the type-tag when testing isa.The union* memory region may be allocated at any size. The only constraint is that it is big enough to contain the data currently specified by selector. It might not be big enough to contain the union of all types that could be stored there according to the associated Union type field. Use appropriate care when copying."
},

{
    "location": "devdocs/compiler/#Specialized-Calling-Convention-Signature-Representation-1",
    "page": "High-level Overview of the Native-Code Generation Process",
    "title": "Specialized Calling Convention Signature Representation",
    "category": "section",
    "text": "A jl_returninfo_t object describes the calling convention details of any callable.If any of the arguments or return type of a method can be represented unboxed, and the method is not varargs, it\'ll be given an optimized calling convention signature based on its specTypes and rettype fields.The general principles are that:Primitive types get passed in int/float registers.\nTuples of VecElement types get passed in vector registers.\nStructs get passed on the stack.\nReturn values are handle similarly to arguments, with a size-cutoff at which they will instead be returned via a hidden sret argument.The total logic for this is implemented by get_specsig_function and deserves_sret.Additionally, if the return type is a union, it may be returned as a pair of values (a pointer and a tag). If the union values can be stack-allocated, then sufficient space to store them will also be passed as a hidden first argument. It is up to the callee whether the returned pointer will point to this space, a boxed object, or even other constant memory."
},

{
    "location": "devdocs/functions/#",
    "page": "Julia Functions",
    "title": "Julia Functions",
    "category": "page",
    "text": ""
},

{
    "location": "devdocs/functions/#Julia-Functions-1",
    "page": "Julia Functions",
    "title": "Julia Functions",
    "category": "section",
    "text": "This document will explain how functions, method definitions, and method tables work."
},

{
    "location": "devdocs/functions/#Method-Tables-1",
    "page": "Julia Functions",
    "title": "Method Tables",
    "category": "section",
    "text": "Every function in Julia is a generic function. A generic function is conceptually a single function, but consists of many definitions, or methods. The methods of a generic function are stored in a method table. Method tables (type MethodTable) are associated with TypeNames. A TypeName describes a family of parameterized types. For example Complex{Float32} and Complex{Float64} share the same Complex type name object.All objects in Julia are potentially callable, because every object has a type, which in turn has a TypeName."
},

{
    "location": "devdocs/functions/#Function-calls-1",
    "page": "Julia Functions",
    "title": "Function calls",
    "category": "section",
    "text": "Given the call f(x,y), the following steps are performed: first, the method table to use is accessed as typeof(f).name.mt. Second, an argument tuple type is formed, Tuple{typeof(f), typeof(x), typeof(y)}. Note that the type of the function itself is the first element. This is because the type might have parameters, and so needs to take part in dispatch. This tuple type is looked up in the method table.This dispatch process is performed by jl_apply_generic, which takes two arguments: a pointer to an array of the values f, x, and y, and the number of values (in this case 3).Throughout the system, there are two kinds of APIs that handle functions and argument lists: those that accept the function and arguments separately, and those that accept a single argument structure. In the first kind of API, the \"arguments\" part does not contain information about the function, since that is passed separately. In the second kind of API, the function is the first element of the argument structure.For example, the following function for performing a call accepts just an args pointer, so the first element of the args array will be the function to call:jl_value_t *jl_apply(jl_value_t **args, uint32_t nargs)This entry point for the same functionality accepts the function separately, so the args array does not contain the function:jl_value_t *jl_call(jl_function_t *f, jl_value_t **args, int32_t nargs);"
},

{
    "location": "devdocs/functions/#Adding-methods-1",
    "page": "Julia Functions",
    "title": "Adding methods",
    "category": "section",
    "text": "Given the above dispatch process, conceptually all that is needed to add a new method is (1) a tuple type, and (2) code for the body of the method. jl_method_def implements this operation. jl_first_argument_datatype is called to extract the relevant method table from what would be the type of the first argument. This is much more complicated than the corresponding procedure during dispatch, since the argument tuple type might be abstract. For example, we can define:(::Union{Foo{Int},Foo{Int8}})(x) = 0which works since all possible matching methods would belong to the same method table."
},

{
    "location": "devdocs/functions/#Creating-generic-functions-1",
    "page": "Julia Functions",
    "title": "Creating generic functions",
    "category": "section",
    "text": "Since every object is callable, nothing special is needed to create a generic function. Therefore jl_new_generic_function simply creates a new singleton (0 size) subtype of Function and returns its instance. A function can have a mnemonic \"display name\" which is used in debug info and when printing objects. For example the name of Base.sin is sin. By convention, the name of the created type is the same as the function name, with a # prepended. So typeof(sin) is Base.#sin."
},

{
    "location": "devdocs/functions/#Closures-1",
    "page": "Julia Functions",
    "title": "Closures",
    "category": "section",
    "text": "A closure is simply a callable object with field names corresponding to captured variables. For example, the following code:function adder(x)\n    return y->x+y\nendis lowered to (roughly):struct ##1{T}\n    x::T\nend\n\n(_::##1)(y) = _.x + y\n\nfunction adder(x)\n    return ##1(x)\nend"
},

{
    "location": "devdocs/functions/#Constructors-1",
    "page": "Julia Functions",
    "title": "Constructors",
    "category": "section",
    "text": "A constructor call is just a call to a type. The type of most types is DataType, so the method table for DataType contains most constructor definitions. One wrinkle is the fallback definition that makes all types callable via convert:(::Type{T}){T}(args...) = convert(T, args...)::TIn this definition the function type is abstract, which is not normally supported. To make this work, all subtypes of Type (Type, UnionAll, Union, and DataType) currently share a method table via special arrangement."
},

{
    "location": "devdocs/functions/#Builtins-1",
    "page": "Julia Functions",
    "title": "Builtins",
    "category": "section",
    "text": "The \"builtin\" functions, defined in the Core module, are:=== typeof sizeof issubtype isa typeassert throw tuple getfield setfield! fieldtype\nnfields isdefined arrayref arrayset arraysize applicable invoke apply_type _apply\n_expr svecThese are all singleton objects whose types are subtypes of Builtin, which is a subtype of Function. Their purpose is to expose entry points in the run time that use the \"jlcall\" calling convention:jl_value_t *(jl_value_t*, jl_value_t**, uint32_t)The method tables of builtins are empty. Instead, they have a single catch-all method cache entry (Tuple{Vararg{Any}}) whose jlcall fptr points to the correct function. This is kind of a hack but works reasonably well."
},

{
    "location": "devdocs/functions/#Keyword-arguments-1",
    "page": "Julia Functions",
    "title": "Keyword arguments",
    "category": "section",
    "text": "Keyword arguments work by associating a special, hidden function object with each method table that has definitions with keyword arguments. This function is called the \"keyword argument sorter\" or \"keyword sorter\", or \"kwsorter\", and is stored in the kwsorter field of MethodTable objects. Every definition in the kwsorter function has the same arguments as some definition in the normal method table, except with a single Array argument prepended. This array contains alternating symbols and values that represent the passed keyword arguments. The kwsorter\'s job is to move keyword arguments into their canonical positions based on name, plus evaluate and substite any needed default value expressions. The result is a normal positional argument list, which is then passed to yet another function.The easiest way to understand the process is to look at how a keyword argument method definition is lowered. The code:function circle(center, radius; color = black, fill::Bool = true, options...)\n    # draw\nendactually produces three method definitions. The first is a function that accepts all arguments (including keywords) as positional arguments, and includes the code for the method body. It has an auto-generated name:function #circle#1(color, fill::Bool, options, circle, center, radius)\n    # draw\nendThe second method is an ordinary definition for the original circle function, which handles the case where no keyword arguments are passed:function circle(center, radius)\n    #circle#1(black, true, Any[], circle, center, radius)\nendThis simply dispatches to the first method, passing along default values. Finally there is the kwsorter definition:function (::Core.kwftype(typeof(circle)))(kw::Array, circle, center, radius)\n    options = Any[]\n    color = arg associated with :color, or black if not found\n    fill = arg associated with :fill, or true if not found\n    # push remaining elements of kw into options array\n    #circle#1(color, fill, options, circle, center, radius)\nendThe front end generates code to loop over the kw array and pick out arguments in the right order, evaluating default expressions when an argument is not found.The function Core.kwftype(t) fetches (and creates, if necessary) the field t.name.mt.kwsorter.This design has the feature that call sites that don\'t use keyword arguments require no special handling; everything works as if they were not part of the language at all. Call sites that do use keyword arguments are dispatched directly to the called function\'s kwsorter. For example the call:circle((0,0), 1.0, color = red; other...)is lowered to:kwfunc(circle)(Any[:color,red,other...], circle, (0,0), 1.0)The unpacking procedure represented here as other... actually further unpacks each element of other, expecting each one to contain two values (a symbol and a value). kwfunc (also in Core) fetches the kwsorter for the called function. Notice that the original circle function is passed through, to handle closures."
},

{
    "location": "devdocs/functions/#Compiler-efficiency-issues-1",
    "page": "Julia Functions",
    "title": "Compiler efficiency issues",
    "category": "section",
    "text": "Generating a new type for every function has potentially serious consequences for compiler resource use when combined with Julia\'s \"specialize on all arguments by default\" design. Indeed, the initial implementation of this design suffered from much longer build and test times, higher memory use, and a system image nearly 2x larger than the baseline. In a naive implementation, the problem is bad enough to make the system nearly unusable. Several significant optimizations were needed to make the design practical.The first issue is excessive specialization of functions for different values of function-valued arguments. Many functions simply \"pass through\" an argument to somewhere else, e.g. to another function or to a storage location. Such functions do not need to be specialized for every closure that might be passed in. Fortunately this case is easy to distinguish by simply considering whether a function calls one of its arguments (i.e. the argument appears in \"head position\" somewhere). Performance-critical higher-order functions like map certainly call their argument function and so will still be specialized as expected. This optimization is implemented by recording which arguments are called during the analyze-variables pass in the front end. When cache_method sees an argument in the Function type hierarchy passed to a slot declared as Any or Function, it pretends the slot was declared as ANY (the \"don\'t specialize\" hint). This heuristic seems to be extremely effective in practice.The next issue concerns the structure of method cache hash tables. Empirical studies show that the vast majority of dynamically-dispatched calls involve one or two arguments. In turn, many of these cases can be resolved by considering only the first argument. (Aside: proponents of single dispatch would not be surprised by this at all. However, this argument means \"multiple dispatch is easy to optimize in practice\", and that we should therefore use it, not \"we should use single dispatch\"!) So the method cache uses the type of the first argument as its primary key. Note, however, that this corresponds to the second element of the tuple type for a function call (the first element being the type of the function itself). Typically, type variation in head position is extremely low – indeed, the majority of functions belong to singleton types with no parameters. However, this is not the case for constructors, where a single method table holds constructors for every type. Therefore the Type method table is special-cased to use the first tuple type element instead of the second.The front end generates type declarations for all closures. Initially, this was implemented by generating normal type declarations. However, this produced an extremely large number of constructors, all of which were trivial (simply passing all arguments through to new). Since methods are partially ordered, inserting all of these methods is O(n^2), plus there are just too many of them to keep around. This was optimized by generating composite_type expressions directly (bypassing default constructor generation), and using new directly to create closure instances. Not the prettiest thing ever, but you do what you gotta do.The next problem was the @test macro, which generated a 0-argument closure for each test case. This is not really necessary, since each test case is simply run once in place. Therefore I modified @test to expand to a try-catch block that records the test result (true, false, or exception raised) and calls the test suite handler on it.However this caused a new problem. When many tests are grouped together in a single function, e.g. a single top level expression, or some other test grouping function, that function could have a very large number of exception handlers. This triggered a kind of dataflow analysis worst case, where type inference spun around for minutes enumerating possible paths through the forest of handlers. This was fixed by simply bailing out of type inference when it encounters more than some number of handlers (currently 25). Presumably no performance-critical function will have more than 25 exception handlers. If one ever does, I\'m willing to raise the limit to 26.A minor issue occurs during the bootstrap process due to storing all constructors in a single method table. In the second bootstrap step, where inference.ji is compiled using inference0.ji, constructors for inference0\'s types remain in the table, so there are still references to the old inference module and inference.ji is 2x the size it should be. This was fixed in dump.c by filtering definitions from \"replaced modules\" out of method tables and caches before saving a system image. A \"replaced module\" is one that satisfies the condition m != jl_get_global(m->parent, m->name) – in other words, some newer module has taken its name and place.Another type inference worst case was triggered by the following code from the QuadGK.jl package, formerly part of Base:function do_quadgk(f, s, n, ::Type{Tw}, abstol, reltol, maxevals, nrm) where Tw\n    if eltype(s) <: Real # check for infinite or semi-infinite intervals\n        s1 = s[1]; s2 = s[end]; inf1 = isinf(s1); inf2 = isinf(s2)\n        if inf1 || inf2\n            if inf1 && inf2 # x = t/(1-t^2) coordinate transformation\n                return do_quadgk(t -> begin t2 = t*t; den = 1 / (1 - t2);\n                                            f(t*den) * (1+t2)*den*den; end,\n                                 map(x -> isinf(x) ? copysign(one(x), x) : 2x / (1+hypot(1,2x)), s),\n                                 n, Tw, abstol, reltol, maxevals, nrm)\n            end\n            s0,si = inf1 ? (s2,s1) : (s1,s2)\n            if si < 0 # x = s0 - t/(1-t)\n                return do_quadgk(t -> begin den = 1 / (1 - t);\n                                            f(s0 - t*den) * den*den; end,\n                                 reverse!(map(x -> 1 / (1 + 1 / (s0 - x)), s)),\n                                 n, Tw, abstol, reltol, maxevals, nrm)\n            else # x = s0 + t/(1-t)\n                return do_quadgk(t -> begin den = 1 / (1 - t);\n                                            f(s0 + t*den) * den*den; end,\n                                 map(x -> 1 / (1 + 1 / (x - s0)), s),\n                                 n, Tw, abstol, reltol, maxevals, nrm)\n            end\n        end\n    endThis code has a 3-way tail recursion, where each call wraps the current function argument f in a different new closure. Inference must consider 3^n (where n is the call depth) possible signatures. This blows up way too quickly, so logic was added to typeinf_uncached to immediately widen any argument that is a subtype of Function and that grows in depth down the stack."
},

{
    "location": "devdocs/cartesian/#",
    "page": "Base.Cartesian",
    "title": "Base.Cartesian",
    "category": "page",
    "text": ""
},

{
    "location": "devdocs/cartesian/#Base.Cartesian-1",
    "page": "Base.Cartesian",
    "title": "Base.Cartesian",
    "category": "section",
    "text": "The (non-exported) Cartesian module provides macros that facilitate writing multidimensional algorithms. It is hoped that Cartesian will not, in the long term, be necessary; however, at present it is one of the few ways to write compact and performant multidimensional code."
},

{
    "location": "devdocs/cartesian/#Principles-of-usage-1",
    "page": "Base.Cartesian",
    "title": "Principles of usage",
    "category": "section",
    "text": "A simple example of usage is:@nloops 3 i A begin\n    s += @nref 3 A i\nendwhich generates the following code:for i_3 = 1:size(A,3)\n    for i_2 = 1:size(A,2)\n        for i_1 = 1:size(A,1)\n            s += A[i_1,i_2,i_3]\n        end\n    end\nendIn general, Cartesian allows you to write generic code that contains repetitive elements, like the nested loops in this example.  Other applications include repeated expressions (e.g., loop unwinding) or creating function calls with variable numbers of arguments without using the \"splat\" construct (i...)."
},

{
    "location": "devdocs/cartesian/#Basic-syntax-1",
    "page": "Base.Cartesian",
    "title": "Basic syntax",
    "category": "section",
    "text": "The (basic) syntax of @nloops is as follows:The first argument must be an integer (not a variable) specifying the number of loops.\nThe second argument is the symbol-prefix used for the iterator variable. Here we used i, and variables i_1, i_2, i_3 were generated.\nThe third argument specifies the range for each iterator variable. If you use a variable (symbol) here, it\'s taken as 1:size(A,dim). More flexibly, you can use the anonymous-function expression syntax described below.\nThe last argument is the body of the loop. Here, that\'s what appears between the begin...end.There are some additional features of @nloops described in the reference section.@nref follows a similar pattern, generating A[i_1,i_2,i_3] from @nref 3 A i. The general practice is to read from left to right, which is why @nloops is @nloops 3 i A expr (as in for i_2 = 1:size(A,2), where i_2 is to the left and the range is to the right) whereas @nref is @nref 3 A i (as in A[i_1,i_2,i_3], where the array comes first).If you\'re developing code with Cartesian, you may find that debugging is easier when you examine the generated code, using macroexpand:DocTestSetup = quote\n    import Base.Cartesian: @nref\nendjulia> macroexpand(:(@nref 2 A i))\n:(A[i_1, i_2])DocTestSetup = nothing"
},

{
    "location": "devdocs/cartesian/#Supplying-the-number-of-expressions-1",
    "page": "Base.Cartesian",
    "title": "Supplying the number of expressions",
    "category": "section",
    "text": "The first argument to both of these macros is the number of expressions, which must be an integer. When you\'re writing a function that you intend to work in multiple dimensions, this may not be something you want to hard-code. If you\'re writing code that you need to work with older Julia versions, currently you should use the @ngenerate macro described in an older version of this documentation.Starting in Julia 0.4-pre, the recommended approach is to use a @generated function.  Here\'s an example:@generated function mysum(A::Array{T,N}) where {T,N}\n    quote\n        s = zero(T)\n        @nloops $N i A begin\n            s += @nref $N A i\n        end\n        s\n    end\nendNaturally, you can also prepare expressions or perform calculations before the quote block."
},

{
    "location": "devdocs/cartesian/#Anonymous-function-expressions-as-macro-arguments-1",
    "page": "Base.Cartesian",
    "title": "Anonymous-function expressions as macro arguments",
    "category": "section",
    "text": "Perhaps the single most powerful feature in Cartesian is the ability to supply anonymous-function expressions that get evaluated at parsing time.  Let\'s consider a simple example:@nexprs 2 j->(i_j = 1)@nexprs generates n expressions that follow a pattern. This code would generate the following statements:i_1 = 1\ni_2 = 1In each generated statement, an \"isolated\" j (the variable of the anonymous function) gets replaced by values in the range 1:2. Generally speaking, Cartesian employs a LaTeX-like syntax.  This allows you to do math on the index j.  Here\'s an example computing the strides of an array:s_1 = 1\n@nexprs 3 j->(s_{j+1} = s_j * size(A, j))would generate expressionss_1 = 1\ns_2 = s_1 * size(A, 1)\ns_3 = s_2 * size(A, 2)\ns_4 = s_3 * size(A, 3)Anonymous-function expressions have many uses in practice."
},

{
    "location": "devdocs/cartesian/#Base.Cartesian.@nloops",
    "page": "Base.Cartesian",
    "title": "Base.Cartesian.@nloops",
    "category": "macro",
    "text": "@nloops N itersym rangeexpr bodyexpr\n@nloops N itersym rangeexpr preexpr bodyexpr\n@nloops N itersym rangeexpr preexpr postexpr bodyexpr\n\nGenerate N nested loops, using itersym as the prefix for the iteration variables. rangeexpr may be an anonymous-function expression, or a simple symbol var in which case the range is indices(var, d) for dimension d.\n\nOptionally, you can provide \"pre\" and \"post\" expressions. These get executed first and last, respectively, in the body of each loop. For example:\n\n@nloops 2 i A d -> j_d = min(i_d, 5) begin\n    s += @nref 2 A j\nend\n\nwould generate:\n\nfor i_2 = indices(A, 2)\n    j_2 = min(i_2, 5)\n    for i_1 = indices(A, 1)\n        j_1 = min(i_1, 5)\n        s += A[j_1, j_2]\n    end\nend\n\nIf you want just a post-expression, supply nothing for the pre-expression. Using parentheses and semicolons, you can supply multi-statement expressions.\n\n\n\n"
},

{
    "location": "devdocs/cartesian/#Base.Cartesian.@nref",
    "page": "Base.Cartesian",
    "title": "Base.Cartesian.@nref",
    "category": "macro",
    "text": "@nref N A indexexpr\n\nGenerate expressions like A[i_1, i_2, ...]. indexexpr can either be an iteration-symbol prefix, or an anonymous-function expression.\n\njulia> @macroexpand Base.Cartesian.@nref 3 A i\n:(A[i_1, i_2, i_3])\n\n\n\n"
},

{
    "location": "devdocs/cartesian/#Base.Cartesian.@nextract",
    "page": "Base.Cartesian",
    "title": "Base.Cartesian.@nextract",
    "category": "macro",
    "text": "@nextract N esym isym\n\nGenerate N variables esym_1, esym_2, ..., esym_N to extract values from isym. isym can be either a Symbol or anonymous-function expression.\n\n@nextract 2 x y would generate\n\nx_1 = y[1]\nx_2 = y[2]\n\nwhile @nextract 3 x d->y[2d-1] yields\n\nx_1 = y[1]\nx_2 = y[3]\nx_3 = y[5]\n\n\n\n"
},

{
    "location": "devdocs/cartesian/#Base.Cartesian.@nexprs",
    "page": "Base.Cartesian",
    "title": "Base.Cartesian.@nexprs",
    "category": "macro",
    "text": "@nexprs N expr\n\nGenerate N expressions. expr should be an anonymous-function expression.\n\njulia> @macroexpand Base.Cartesian.@nexprs 4 i -> y[i] = A[i+j]\nquote\n    y[1] = A[1 + j]\n    y[2] = A[2 + j]\n    y[3] = A[3 + j]\n    y[4] = A[4 + j]\nend\n\n\n\n"
},

{
    "location": "devdocs/cartesian/#Base.Cartesian.@ncall",
    "page": "Base.Cartesian",
    "title": "Base.Cartesian.@ncall",
    "category": "macro",
    "text": "@ncall N f sym...\n\nGenerate a function call expression. sym represents any number of function arguments, the last of which may be an anonymous-function expression and is expanded into N arguments.\n\nFor example @ncall 3 func a generates\n\nfunc(a_1, a_2, a_3)\n\nwhile @ncall 2 func a b i->c[i] yields\n\nfunc(a, b, c[1], c[2])\n\n\n\n"
},

{
    "location": "devdocs/cartesian/#Base.Cartesian.@ntuple",
    "page": "Base.Cartesian",
    "title": "Base.Cartesian.@ntuple",
    "category": "macro",
    "text": "@ntuple N expr\n\nGenerates an N-tuple. @ntuple 2 i would generate (i_1, i_2), and @ntuple 2 k->k+1 would generate (2,3).\n\n\n\n"
},

{
    "location": "devdocs/cartesian/#Base.Cartesian.@nall",
    "page": "Base.Cartesian",
    "title": "Base.Cartesian.@nall",
    "category": "macro",
    "text": "@nall N expr\n\nCheck whether all of the expressions generated by the anonymous-function expression expr evaluate to true.\n\n@nall 3 d->(i_d > 1) would generate the expression (i_1 > 1 && i_2 > 1 && i_3 > 1). This can be convenient for bounds-checking.\n\n\n\n"
},

{
    "location": "devdocs/cartesian/#Base.Cartesian.@nany",
    "page": "Base.Cartesian",
    "title": "Base.Cartesian.@nany",
    "category": "macro",
    "text": "@nany N expr\n\nCheck whether any of the expressions generated by the anonymous-function expression expr evaluate to true.\n\n@nany 3 d->(i_d > 1) would generate the expression (i_1 > 1 || i_2 > 1 || i_3 > 1).\n\n\n\n"
},

{
    "location": "devdocs/cartesian/#Base.Cartesian.@nif",
    "page": "Base.Cartesian",
    "title": "Base.Cartesian.@nif",
    "category": "macro",
    "text": "@nif N conditionexpr expr\n@nif N conditionexpr expr elseexpr\n\nGenerates a sequence of if ... elseif ... else ... end statements. For example:\n\n@nif 3 d->(i_d >= size(A,d)) d->(error(\"Dimension \", d, \" too big\")) d->println(\"All OK\")\n\nwould generate:\n\nif i_1 > size(A, 1)\n    error(\"Dimension \", 1, \" too big\")\nelseif i_2 > size(A, 2)\n    error(\"Dimension \", 2, \" too big\")\nelse\n    println(\"All OK\")\nend\n\n\n\n"
},

{
    "location": "devdocs/cartesian/#dev-cartesian-reference-1",
    "page": "Base.Cartesian",
    "title": "Macro reference",
    "category": "section",
    "text": "Base.Cartesian.@nloops\nBase.Cartesian.@nref\nBase.Cartesian.@nextract\nBase.Cartesian.@nexprs\nBase.Cartesian.@ncall\nBase.Cartesian.@ntuple\nBase.Cartesian.@nall\nBase.Cartesian.@nany\nBase.Cartesian.@nif"
},

{
    "location": "devdocs/meta/#",
    "page": "Talking to the compiler (the :meta mechanism)",
    "title": "Talking to the compiler (the :meta mechanism)",
    "category": "page",
    "text": ""
},

{
    "location": "devdocs/meta/#Talking-to-the-compiler-(the-:meta-mechanism)-1",
    "page": "Talking to the compiler (the :meta mechanism)",
    "title": "Talking to the compiler (the :meta mechanism)",
    "category": "section",
    "text": "In some circumstances, one might wish to provide hints or instructions that a given block of code has special properties: you might always want to inline it, or you might want to turn on special compiler optimization passes.  Starting with version 0.4, Julia has a convention that these instructions can be placed inside a :meta expression, which is typically (but not necessarily) the first expression in the body of a function.:meta expressions are created with macros. As an example, consider the implementation of the @inline macro:macro inline(ex)\n    esc(isa(ex, Expr) ? pushmeta!(ex, :inline) : ex)\nendHere, ex is expected to be an expression defining a function. A statement like this:@inline function myfunction(x)\n    x*(x+3)\nendgets turned into an expression like this:quote\n    function myfunction(x)\n        Expr(:meta, :inline)\n        x*(x+3)\n    end\nendBase.pushmeta!(ex, :symbol, args...) appends :symbol to the end of the :meta expression, creating a new :meta expression if necessary. If args is specified, a nested expression containing :symbol and these arguments is appended instead, which can be used to specify additional information.To use the metadata, you have to parse these :meta expressions. If your implementation can be performed within Julia, Base.popmeta! is very handy: Base.popmeta!(body, :symbol) will scan a function body expression (one without the function signature) for the first :meta expression containing :symbol, extract any arguments, and return a tuple (found::Bool, args::Array{Any}). If the metadata did not have any arguments, or :symbol was not found, the args array will be empty.Not yet provided is a convenient infrastructure for parsing :meta expressions from C++."
},

{
    "location": "devdocs/subarrays/#",
    "page": "SubArrays",
    "title": "SubArrays",
    "category": "page",
    "text": ""
},

{
    "location": "devdocs/subarrays/#SubArrays-1",
    "page": "SubArrays",
    "title": "SubArrays",
    "category": "section",
    "text": "Julia\'s SubArray type is a container encoding a \"view\" of a parent AbstractArray.  This page documents some of the design principles and implementation of SubArrays."
},

{
    "location": "devdocs/subarrays/#Indexing:-cartesian-vs.-linear-indexing-1",
    "page": "SubArrays",
    "title": "Indexing: cartesian vs. linear indexing",
    "category": "section",
    "text": "Broadly speaking, there are two main ways to access data in an array. The first, often called cartesian indexing, uses N indexes for an N -dimensional AbstractArray.  For example, a matrix A (2-dimensional) can be indexed in cartesian style as A[i,j].  The second indexing method, referred to as linear indexing, uses a single index even for higher-dimensional objects.  For example, if A = reshape(1:12, 3, 4), then the expression A[5] returns the value 5.  Julia allows you to combine these styles of indexing: for example, a 3d array A3 can be indexed as A3[i,j], in which case i is interpreted as a cartesian index for the first dimension, and j is a linear index over dimensions 2 and 3.For Arrays, linear indexing appeals to the underlying storage format: an array is laid out as a contiguous block of memory, and hence the linear index is just the offset (+1) of the corresponding entry relative to the beginning of the array.  However, this is not true for many other AbstractArray types: examples include SparseMatrixCSC, arrays that require some kind of computation (such as interpolation), and the type under discussion here, SubArray. For these types, the underlying information is more naturally described in terms of cartesian indexes.You can manually convert from a cartesian index to a linear index with sub2ind, and vice versa using ind2sub.  getindex and setindex! functions for AbstractArray types may include similar operations.While converting from a cartesian index to a linear index is fast (it\'s just multiplication and addition), converting from a linear index to a cartesian index is very slow: it relies on the div operation, which is one of the slowest low-level operations you can perform with a CPU.  For this reason, any code that deals with AbstractArray types is best designed in terms of cartesian, rather than linear, indexing."
},

{
    "location": "devdocs/subarrays/#Index-replacement-1",
    "page": "SubArrays",
    "title": "Index replacement",
    "category": "section",
    "text": "Consider making 2d slices of a 3d array:S1 = view(A, :, 5, 2:6)\nS2 = view(A, 5, :, 2:6)view drops \"singleton\" dimensions (ones that are specified by an Int), so both S1 and S2 are two-dimensional SubArrays. Consequently, the natural way to index these is with S1[i,j].  To extract the value from the parent array A, the natural approach is to replace S1[i,j] with A[i,5,(2:6)[j]] and S2[i,j] with A[5,i,(2:6)[j]].The key feature of the design of SubArrays is that this index replacement can be performed without any runtime overhead."
},

{
    "location": "devdocs/subarrays/#SubArray-design-1",
    "page": "SubArrays",
    "title": "SubArray design",
    "category": "section",
    "text": ""
},

{
    "location": "devdocs/subarrays/#Type-parameters-and-fields-1",
    "page": "SubArrays",
    "title": "Type parameters and fields",
    "category": "section",
    "text": "The strategy adopted is first and foremost expressed in the definition of the type:struct SubArray{T,N,P,I,L} <: AbstractArray{T,N}\n    parent::P\n    indexes::I\n    offset1::Int       # for linear indexing and pointer, only valid when L==true\n    stride1::Int       # used only for linear indexing\n    ...\nendSubArray has 5 type parameters.  The first two are the standard element type and dimensionality.  The next is the type of the parent AbstractArray.  The most heavily-used is the fourth parameter, a Tuple of the types of the indices for each dimension. The final one, L, is only provided as a convenience for dispatch; it\'s a boolean that represents whether the index types support fast linear indexing. More on that later.If in our example above A is a Array{Float64, 3}, our S1 case above would be a SubArray{Int64,2,Array{Int64,3},Tuple{Colon,Int64,UnitRange{Int64}},false}. Note in particular the tuple parameter, which stores the types of the indices used to create S1.  Likewise,julia> S1.indexes\n(Colon(),5,2:6)Storing these values allows index replacement, and having the types encoded as parameters allows one to dispatch to efficient algorithms."
},

{
    "location": "devdocs/subarrays/#Index-translation-1",
    "page": "SubArrays",
    "title": "Index translation",
    "category": "section",
    "text": "Performing index translation requires that you do different things for different concrete SubArray types.  For example, for S1, one needs to apply the i,j indices to the first and third dimensions of the parent array, whereas for S2 one needs to apply them to the second and third.  The simplest approach to indexing would be to do the type-analysis at runtime:parentindexes = Array{Any}(0)\nfor thisindex in S.indexes\n    ...\n    if isa(thisindex, Int)\n        # Don\'t consume one of the input indexes\n        push!(parentindexes, thisindex)\n    elseif isa(thisindex, AbstractVector)\n        # Consume an input index\n        push!(parentindexes, thisindex[inputindex[j]])\n        j += 1\n    elseif isa(thisindex, AbstractMatrix)\n        # Consume two input indices\n        push!(parentindexes, thisindex[inputindex[j], inputindex[j+1]])\n        j += 2\n    elseif ...\nend\nS.parent[parentindexes...]Unfortunately, this would be disastrous in terms of performance: each element access would allocate memory, and involves the running of a lot of poorly-typed code.The better approach is to dispatch to specific methods to handle each type of stored index. That\'s what reindex does: it dispatches on the type of the first stored index and consumes the appropriate number of input indices, and then it recurses on the remaining indices. In the case of S1, this expands toBase.reindex(S1, S1.indexes, (i, j)) == (i, S1.indexes[2], S1.indexes[3][j])for any pair of indices (i,j) (except CartesianIndexs and arrays thereof, see below).This is the core of a SubArray; indexing methods depend upon reindex to do this index translation. Sometimes, though, we can avoid the indirection and make it even faster."
},

{
    "location": "devdocs/subarrays/#Linear-indexing-1",
    "page": "SubArrays",
    "title": "Linear indexing",
    "category": "section",
    "text": "Linear indexing can be implemented efficiently when the entire array has a single stride that separates successive elements, starting from some offset. This means that we can pre-compute these values and represent linear indexing simply as an addition and multiplication, avoiding the indirection of reindex and (more importantly) the slow computation of the cartesian coordinates entirely.For SubArray types, the availability of efficient linear indexing is based purely on the types of the indices, and does not depend on values like the size of the parent array. You can ask whether a given set of indices supports fast linear indexing with the internal Base.viewindexing function:julia> Base.viewindexing(S1.indexes)\nIndexCartesian()\n\njulia> Base.viewindexing(S2.indexes)\nIndexLinear()This is computed during construction of the SubArray and stored in the L type parameter as a boolean that encodes fast linear indexing support. While not strictly necessary, it means that we can define dispatch directly on SubArray{T,N,A,I,true} without any intermediaries.Since this computation doesn\'t depend on runtime values, it can miss some cases in which the stride happens to be uniform:julia> A = reshape(1:4*2, 4, 2)\n4×2 Base.ReshapedArray{Int64,2,UnitRange{Int64},Tuple{}}:\n 1  5\n 2  6\n 3  7\n 4  8\n\njulia> diff(A[2:2:4,:][:])\n3-element Array{Int64,1}:\n 2\n 2\n 2A view constructed as view(A, 2:2:4, :) happens to have uniform stride, and therefore linear indexing indeed could be performed efficiently.  However, success in this case depends on the size of the array: if the first dimension instead were odd,julia> A = reshape(1:5*2, 5, 2)\n5×2 Base.ReshapedArray{Int64,2,UnitRange{Int64},Tuple{}}:\n 1   6\n 2   7\n 3   8\n 4   9\n 5  10\n\njulia> diff(A[2:2:4,:][:])\n3-element Array{Int64,1}:\n 2\n 3\n 2then A[2:2:4,:] does not have uniform stride, so we cannot guarantee efficient linear indexing.  Since we have to base this decision based purely on types encoded in the parameters of the SubArray, S = view(A, 2:2:4, :) cannot implement efficient linear indexing."
},

{
    "location": "devdocs/subarrays/#A-few-details-1",
    "page": "SubArrays",
    "title": "A few details",
    "category": "section",
    "text": "Note that the Base.reindex function is agnostic to the types of the input indices; it simply determines how and where the stored indices should be reindexed. It not only supports integer indices, but it supports non-scalar indexing, too. This means that views of views don\'t need two levels of indirection; they can simply re-compute the indices into the original parent array!\nHopefully by now it\'s fairly clear that supporting slices means that the dimensionality, given by the parameter N, is not necessarily equal to the dimensionality of the parent array or the length of the indexes tuple.  Neither do user-supplied indices necessarily line up with entries in the indexes tuple (e.g., the second user-supplied index might correspond to the third dimension of the parent array, and the third element in the indexes tuple).\nWhat might be less obvious is that the dimensionality of the stored parent array must be equal to the number of effective indices in the indexes tuple. Some examples:\nA = reshape(1:35, 5, 7) # A 2d parent Array\nS = view(A, 2:7)         # A 1d view created by linear indexing\nS = view(A, :, :, 1:1)   # Appending extra indices is supported\nNaively, you\'d think you could just set S.parent = A and S.indexes = (:,:,1:1), but supporting this dramatically complicates the reindexing process, especially for views of views. Not only do you need to dispatch on the types of the stored indices, but you need to examine whether a given index is the final one and \"merge\" any remaining stored indices together. This is not an easy task, and even worse: it\'s slow since it implicitly depends upon linear indexing.\nFortunately, this is precisely the computation that ReshapedArray performs, and it does so linearly if possible. Consequently, view ensures that the parent array is the appropriate dimensionality for the given indices by reshaping it if needed. The inner SubArray constructor ensures that this invariant is satisfied.\nCartesianIndex and arrays thereof throw a nasty wrench into the reindex scheme. Recall that reindex simply dispatches on the type of the stored indices in order to determine how many passed indices should be used and where they should go. But with CartesianIndex, there\'s no longer a one-to-one correspondence between the number of passed arguments and the number of dimensions that they index into. If we return to the above example of Base.reindex(S1, S1.indexes, (i, j)), you can see that the expansion is incorrect for i, j = CartesianIndex(), CartesianIndex(2,1). It should skip the CartesianIndex() entirely and return:\n(CartesianIndex(2,1)[1], S1.indexes[2], S1.indexes[3][CartesianIndex(2,1)[2]])\nInstead, though, we get:\n(CartesianIndex(), S1.indexes[2], S1.indexes[3][CartesianIndex(2,1)])\nDoing this correctly would require combined dispatch on both the stored and passed indices across all combinations of dimensionalities in an intractable manner. As such, reindex must never be called with CartesianIndex indices. Fortunately, the scalar case is easily handled by first flattening the CartesianIndex arguments to plain integers. Arrays of CartesianIndex, however, cannot be split apart into orthogonal pieces so easily. Before attempting to use reindex, view must ensure that there are no arrays of CartesianIndex in the argument list. If there are, it can simply \"punt\" by avoiding the reindex calculation entirely, constructing a nested SubArray with two levels of indirection instead."
},

{
    "location": "devdocs/sysimg/#",
    "page": "System Image Building",
    "title": "System Image Building",
    "category": "page",
    "text": ""
},

{
    "location": "devdocs/sysimg/#System-Image-Building-1",
    "page": "System Image Building",
    "title": "System Image Building",
    "category": "section",
    "text": ""
},

{
    "location": "devdocs/sysimg/#BuildSysImg.build_sysimg",
    "page": "System Image Building",
    "title": "BuildSysImg.build_sysimg",
    "category": "function",
    "text": "build_sysimg(sysimg_path=default_sysimg_path(), cpu_target=\"native\", userimg_path=nothing; force=false)\n\nRebuild the system image. Store it in sysimg_path, which defaults to a file named sys.ji that sits in the same folder as libjulia.{so,dylib}, except on Windows where it defaults to JULIA_HOME/../lib/julia/sys.ji.  Use the cpu instruction set given by cpu_target. Valid CPU targets are the same as for the -C option to julia, or the -march option to gcc.  Defaults to native, which means to use all CPU instructions available on the current processor. Include the user image file given by userimg_path, which should contain directives such as using MyPackage to include that package in the new system image. New system image will not replace an older image unless force is set to true.\n\n\n\n"
},

{
    "location": "devdocs/sysimg/#Building-the-Julia-system-image-1",
    "page": "System Image Building",
    "title": "Building the Julia system image",
    "category": "section",
    "text": "Julia ships with a preparsed system image containing the contents of the Base module, named sys.ji.  This file is also precompiled into a shared library called sys.{so,dll,dylib} on as many platforms as possible, so as to give vastly improved startup times.  On systems that do not ship with a precompiled system image file, one can be generated from the source files shipped in Julia\'s DATAROOTDIR/julia/base folder.This operation is useful for multiple reasons.  A user may:Build a precompiled shared library system image on a platform that did not ship with one, thereby improving startup times.\nModify Base, rebuild the system image and use the new Base next time Julia is started.\nInclude a userimg.jl file that includes packages into the system image, thereby creating a system image that has packages embedded into the startup environment.Julia now ships with a script that automates the tasks of building the system image, wittingly named build_sysimg.jl that lives in DATAROOTDIR/julia/.  That is, to include it into a current Julia session, type:include(joinpath(JULIA_HOME, Base.DATAROOTDIR, \"julia\", \"build_sysimg.jl\"))This will include a build_sysimg() function:BuildSysImg.build_sysimgNote that this file can also be run as a script itself, with command line arguments taking the place of arguments passed to the build_sysimg function.  For example, to build a system image in /tmp/sys.{so,dll,dylib}, with the core2 CPU instruction set, a user image of ~/userimg.jl and force set to true, one would execute:julia build_sysimg.jl /tmp/sys core2 ~/userimg.jl --force"
},

{
    "location": "devdocs/llvm/#",
    "page": "Working with LLVM",
    "title": "Working with LLVM",
    "category": "page",
    "text": ""
},

{
    "location": "devdocs/llvm/#Working-with-LLVM-1",
    "page": "Working with LLVM",
    "title": "Working with LLVM",
    "category": "section",
    "text": "This is not a replacement for the LLVM documentation, but a collection of tips for working on LLVM for Julia."
},

{
    "location": "devdocs/llvm/#Overview-of-Julia-to-LLVM-Interface-1",
    "page": "Working with LLVM",
    "title": "Overview of Julia to LLVM Interface",
    "category": "section",
    "text": "Julia statically links in LLVM by default. Build with USE_LLVM_SHLIB=1 to link dynamically.The code for lowering Julia AST to LLVM IR or interpreting it directly is in directory src/.File Description\nbuiltins.c Builtin functions\nccall.cpp Lowering ccall\ncgutils.cpp Lowering utilities, notably for array and tuple accesses\ncodegen.cpp Top-level of code generation, pass list, lowering builtins\ndebuginfo.cpp Tracks debug information for JIT code\ndisasm.cpp Handles native object file and JIT code diassembly\ngf.c Generic functions\nintrinsics.cpp Lowering intrinsics\nllvm-simdloop.cpp Custom LLVM pass for @simd\nsys.c I/O and operating system utility functionsSome of the .cpp files form a group that compile to a single object.The difference between an intrinsic and a builtin is that a builtin is a first class function that can be used like any other Julia function.  An intrinsic can operate only on unboxed data, and therefore its arguments must be statically typed."
},

{
    "location": "devdocs/llvm/#Alias-Analysis-1",
    "page": "Working with LLVM",
    "title": "Alias Analysis",
    "category": "section",
    "text": "Julia currently uses LLVM\'s Type Based Alias Analysis. To find the comments that document the inclusion relationships, look for static MDNode* in src/codegen.cpp.The -O option enables LLVM\'s Basic Alias Analysis."
},

{
    "location": "devdocs/llvm/#Building-Julia-with-a-different-version-of-LLVM-1",
    "page": "Working with LLVM",
    "title": "Building Julia with a different version of LLVM",
    "category": "section",
    "text": "The default version of LLVM is specified in deps/Versions.make. You can override it by creating a file called Make.user in the top-level directory and adding a line to it such as:LLVM_VER = 3.5.0Besides the LLVM release numerals, you can also use LLVM_VER = svn to bulid against the latest development version of LLVM."
},

{
    "location": "devdocs/llvm/#Passing-options-to-LLVM-1",
    "page": "Working with LLVM",
    "title": "Passing options to LLVM",
    "category": "section",
    "text": "You can pass options to LLVM using debug builds of Julia.  To create a debug build, run make debug.  The resulting executable is usr/bin/julia-debug. You can pass LLVM options to this executable via the environment variable JULIA_LLVM_ARGS. Here are example settings using bash syntax:export JULIA_LLVM_ARGS = -print-after-all dumps IR after each pass.\nexport JULIA_LLVM_ARGS = -debug-only=loop-vectorize dumps LLVM DEBUG(...) diagnostics for loop vectorizer if you built Julia with LLVM_ASSERTIONS=1. Otherwise you will get warnings about \"Unknown command line argument\". Counter-intuitively, building Julia with LLVM_DEBUG=1 is not enough to dump DEBUG diagnostics from a pass."
},

{
    "location": "devdocs/llvm/#Improving-LLVM-optimizations-for-Julia-1",
    "page": "Working with LLVM",
    "title": "Improving LLVM optimizations for Julia",
    "category": "section",
    "text": "Improving LLVM code generation usually involves either changing Julia lowering to be more friendly to LLVM\'s passes, or improving a pass.If you are planning to improve a pass, be sure to read the LLVM developer policy. The best strategy is to create a code example in a form where you can use LLVM\'s opt tool to study it and the pass of interest in isolation.Create an example Julia code of interest.\nUse JULIA_LLVM_ARGS = -print-after-all to dump the IR.\nPick out the IR at the point just before the pass of interest runs.\nStrip the debug metadata and fix up the TBAA metadata by hand.The last step is labor intensive.  Suggestions on a better way would be appreciated."
},

{
    "location": "devdocs/stdio/#",
    "page": "printf() and stdio in the Julia runtime",
    "title": "printf() and stdio in the Julia runtime",
    "category": "page",
    "text": ""
},

{
    "location": "devdocs/stdio/#printf()-and-stdio-in-the-Julia-runtime-1",
    "page": "printf() and stdio in the Julia runtime",
    "title": "printf() and stdio in the Julia runtime",
    "category": "section",
    "text": ""
},

{
    "location": "devdocs/stdio/#Libuv-wrappers-for-stdio-1",
    "page": "printf() and stdio in the Julia runtime",
    "title": "Libuv wrappers for stdio",
    "category": "section",
    "text": "julia.h defines libuv wrappers for the stdio.h streams:uv_stream_t *JL_STDIN;\nuv_stream_t *JL_STDOUT;\nuv_stream_t *JL_STDERR;... and corresponding output functions:int jl_printf(uv_stream_t *s, const char *format, ...);\nint jl_vprintf(uv_stream_t *s, const char *format, va_list args);These printf functions are used by the .c files in the src/ and ui/ directories wherever stdio is needed to ensure that output buffering is handled in a unified way.In special cases, like signal handlers, where the full libuv infrastructure is too heavy, jl_safe_printf() can be used to write(2) directly to STDERR_FILENO:void jl_safe_printf(const char *str, ...);"
},

{
    "location": "devdocs/stdio/#Interface-between-JL_STD*-and-Julia-code-1",
    "page": "printf() and stdio in the Julia runtime",
    "title": "Interface between JL_STD* and Julia code",
    "category": "section",
    "text": "Base.STDIN, Base.STDOUT and Base.STDERR are bound to the JL_STD* libuv streams defined in the runtime.Julia\'s __init__() function (in base/sysimg.jl) calls reinit_stdio() (in base/stream.jl) to create Julia objects for Base.STDIN, Base.STDOUT and Base.STDERR.reinit_stdio() uses ccall to retrieve pointers to JL_STD* and calls jl_uv_handle_type() to inspect the type of each stream.  It then creates a Julia Base.IOStream, Base.TTY or Base.PipeEndpoint object to represent each stream, e.g.:$ julia -e \'println(typeof((STDIN, STDOUT, STDERR)))\'\nTuple{Base.TTY,Base.TTY,Base.TTY}\n\n$ julia -e \'println(typeof((STDIN, STDOUT, STDERR)))\' < /dev/null 2>/dev/null\nTuple{IOStream,Base.TTY,IOStream}\n\n$ echo hello | julia -e \'println(typeof((STDIN, STDOUT, STDERR)))\' | cat\nTuple{Base.PipeEndpoint,Base.PipeEndpoint,Base.TTY}The Base.read() and Base.write() methods for these streams use ccall to call libuv wrappers in src/jl_uv.c, e.g.:stream.jl: function write(s::IO, p::Ptr, nb::Integer)\n               -> ccall(:jl_uv_write, ...)\n  jl_uv.c:          -> int jl_uv_write(uv_stream_t *stream, ...)\n                        -> uv_write(uvw, stream, buf, ...)"
},

{
    "location": "devdocs/stdio/#printf()-during-initialization-1",
    "page": "printf() and stdio in the Julia runtime",
    "title": "printf() during initialization",
    "category": "section",
    "text": "The libuv streams relied upon by jl_printf() etc., are not available until midway through initialization of the runtime (see init.c, init_stdio()).  Error messages or warnings that need to be printed before this are routed to the standard C library fwrite() function by the following mechanism:In sys.c, the JL_STD* stream pointers are statically initialized to integer constants: STD*_FILENO (0, 1 and 2). In jl_uv.c the jl_uv_puts() function checks its uv_stream_t* stream argument and calls fwrite() if stream is set to STDOUT_FILENO or STDERR_FILENO.This allows for uniform use of jl_printf() throughout the runtime regardless of whether or not any particular piece of code is reachable before initialization is complete."
},

{
    "location": "devdocs/stdio/#Legacy-ios.c-library-1",
    "page": "printf() and stdio in the Julia runtime",
    "title": "Legacy ios.c library",
    "category": "section",
    "text": "The src/support/ios.c library is inherited from femtolisp. It provides cross-platform buffered file IO and in-memory temporary buffers.ios.c is still used by:src/flisp/*.c\nsrc/dump.c – for serialization file IO and for memory buffers.\nbase/iostream.jl – for file IO (see base/fs.jl for libuv equivalent).Use of ios.c in these modules is mostly self-contained and separated from the libuv I/O system. However, there is one place where femtolisp calls through to jl_printf() with a legacy ios_t stream.There is a hack in ios.h that makes the ios_t.bm field line up with the uv_stream_t.type and ensures that the values used for ios_t.bm to not overlap with valid UV_HANDLE_TYPE values.  This allows uv_stream_t pointers to point to ios_t streams.This is needed because jl_printf() caller jl_static_show() is passed an ios_t stream by femtolisp\'s fl_print() function. Julia\'s jl_uv_puts() function has special handling for this:if (stream->type > UV_HANDLE_TYPE_MAX) {\n    return ios_write((ios_t*)stream, str, n);\n}"
},

{
    "location": "devdocs/boundscheck/#",
    "page": "Bounds checking",
    "title": "Bounds checking",
    "category": "page",
    "text": ""
},

{
    "location": "devdocs/boundscheck/#Bounds-checking-1",
    "page": "Bounds checking",
    "title": "Bounds checking",
    "category": "section",
    "text": "Like many modern programming languages, Julia uses bounds checking to ensure program safety when accessing arrays. In tight inner loops or other performance critical situations, you may wish to skip these bounds checks to improve runtime performance. For instance, in order to emit vectorized (SIMD) instructions, your loop body cannot contain branches, and thus cannot contain bounds checks. Consequently, Julia includes an @inbounds(...) macro to tell the compiler to skip such bounds checks within the given block. For the built-in Array type, the magic happens inside the arrayref and arrayset intrinsics. User-defined array types instead use the @boundscheck(...) macro to achieve context-sensitive code selection."
},

{
    "location": "devdocs/boundscheck/#Eliding-bounds-checks-1",
    "page": "Bounds checking",
    "title": "Eliding bounds checks",
    "category": "section",
    "text": "The @boundscheck(...) macro marks blocks of code that perform bounds checking. When such blocks appear inside of an @inbounds(...) block, the compiler removes these blocks. When the @boundscheck(...) is nested inside of a calling function containing an @inbounds(...), the compiler will remove the @boundscheck block only if it is inlined into the calling function. For example, you might write the method sum as:function sum(A::AbstractArray)\n    r = zero(eltype(A))\n    for i = 1:length(A)\n        @inbounds r += A[i]\n    end\n    return r\nendWith a custom array-like type MyArray having:@inline getindex(A::MyArray, i::Real) = (@boundscheck checkbounds(A,i); A.data[to_index(i)])Then when getindex is inlined into sum, the call to checkbounds(A,i) will be elided. If your function contains multiple layers of inlining, only @boundscheck blocks at most one level of inlining deeper are eliminated. The rule prevents unintended changes in program behavior from code further up the stack."
},

{
    "location": "devdocs/boundscheck/#Propagating-inbounds-1",
    "page": "Bounds checking",
    "title": "Propagating inbounds",
    "category": "section",
    "text": "There may be certain scenarios where for code-organization reasons you want more than one layer between the @inbounds and @boundscheck declarations. For instance, the default getindex methods have the chain getindex(A::AbstractArray, i::Real) calls getindex(IndexStyle(A), A, i) calls _getindex(::IndexLinear, A, i).To override the \"one layer of inlining\" rule, a function may be marked with @propagate_inbounds to propagate an inbounds context (or out of bounds context) through one additional layer of inlining."
},

{
    "location": "devdocs/boundscheck/#The-bounds-checking-call-hierarchy-1",
    "page": "Bounds checking",
    "title": "The bounds checking call hierarchy",
    "category": "section",
    "text": "The overall hierarchy is:checkbounds(A, I...) which calls\ncheckbounds(Bool, A, I...) which calls\ncheckbounds_indices(Bool, indices(A), I) which recursively calls\ncheckindex for each dimensionHere A is the array, and I contains the \"requested\" indices. indices(A) returns a tuple of \"permitted\" indices of A.checkbounds(A, I...) throws an error if the indices are invalid, whereas checkbounds(Bool, A, I...) returns false in that circumstance.  checkbounds_indices discards any information about the array other than its indices tuple, and performs a pure indices-vs-indices comparison: this allows relatively few compiled methods to serve a huge variety of array types. Indices are specified as tuples, and are usually compared in a 1-1 fashion with individual dimensions handled by calling another important function, checkindex: typically,checkbounds_indices(Bool, (IA1, IA...), (I1, I...)) = checkindex(Bool, IA1, I1) &\n                                                      checkbounds_indices(Bool, IA, I)so checkindex checks a single dimension.  All of these functions, including the unexported checkbounds_indices have docstrings accessible with ? .If you have to customize bounds checking for a specific array type, you should specialize checkbounds(Bool, A, I...). However, in most cases you should be able to rely on checkbounds_indices as long as you supply useful indices for your array type.If you have novel index types, first consider specializing checkindex, which handles a single index for a particular dimension of an array.  If you have a custom multidimensional index type (similar to CartesianIndex), then you may have to consider specializing checkbounds_indices.Note this hierarchy has been designed to reduce the likelihood of method ambiguities.  We try to make checkbounds the place to specialize on array type, and try to avoid specializations on index types; conversely, checkindex is intended to be specialized only on index type (especially, the last argument)."
},

{
    "location": "devdocs/locks/#",
    "page": "Proper maintenance and care of multi-threading locks",
    "title": "Proper maintenance and care of multi-threading locks",
    "category": "page",
    "text": ""
},

{
    "location": "devdocs/locks/#Proper-maintenance-and-care-of-multi-threading-locks-1",
    "page": "Proper maintenance and care of multi-threading locks",
    "title": "Proper maintenance and care of multi-threading locks",
    "category": "section",
    "text": "The following strategies are used to ensure that the code is dead-lock free (generally by addressing the 4th Coffman condition: circular wait).structure code such that only one lock will need to be acquired at a time\nalways acquire shared locks in the same order, as given by the table below\navoid constructs that expect to need unrestricted recursion"
},

{
    "location": "devdocs/locks/#Locks-1",
    "page": "Proper maintenance and care of multi-threading locks",
    "title": "Locks",
    "category": "section",
    "text": "Below are all of the locks that exist in the system and the mechanisms for using them that avoid the potential for deadlocks (no Ostrich algorithm allowed here):The following are definitely leaf locks (level 1), and must not try to acquire any other lock:safepoint\nNote that this lock is acquired implicitly by JL_LOCK and JL_UNLOCK. use the _NOGC variants to avoid that for level 1 locks.While holding this lock, the code must not do any allocation or hit any safepoints. Note that there are safepoints when doing allocation, enabling / disabling GC, entering / restoring exception frames, and taking / releasing locks.\nshared_map\nfinalizers\npagealloc\ngc_perm_lock\nflisp\nflisp itself is already threadsafe, this lock only protects the jl_ast_context_list_t poolThe following is a leaf lock (level 2), and only acquires level 1 locks (safepoint) internally:typecacheThe following is a level 3 lock, which can only acquire level 1 or level 2 locks internally:Method->writelockThe following is a level 4 lock, which can only recurse to acquire level 1, 2, or 3 locks:MethodTable->writelockNo Julia code may be called while holding a lock above this point.The following is a level 6 lock, which can only recurse to acquire locks at lower levels:codegenThe following is an almost root lock (level end-1), meaning only the root look may be held when trying to acquire it:typeinf\nthis one is perhaps one of the most tricky ones, since type-inference can be invoked from many pointscurrently the lock is merged with the codegen lock, since they call each other recursivelyThe following is the root lock, meaning no other lock shall be held when trying to acquire it:toplevel\nthis should be held while attempting a top-level action (such as making a new type or defining a new method): trying to obtain this lock inside a staged function will cause a deadlock condition!additionally, it\'s unclear if any code can safely run in parallel with an arbitrary toplevel expression, so it may require all threads to get to a safepoint first"
},

{
    "location": "devdocs/locks/#Broken-Locks-1",
    "page": "Proper maintenance and care of multi-threading locks",
    "title": "Broken Locks",
    "category": "section",
    "text": "The following locks are broken:toplevel\ndoesn\'t exist right nowfix: create it"
},

{
    "location": "devdocs/locks/#Shared-Global-Data-Structures-1",
    "page": "Proper maintenance and care of multi-threading locks",
    "title": "Shared Global Data Structures",
    "category": "section",
    "text": "These data structures each need locks due to being shared mutable global state. It is the inverse list for the above lock priority list. This list does not include level 1 leaf resources due to their simplicity.MethodTable modifications (def, cache, kwsorter type) : MethodTable->writelockType declarations : toplevel lockType application : typecache lockModule serializer : toplevel lockJIT & type-inference : codegen lockMethodInstance updates : codegen lockThese fields are generally lazy initialized, using the test-and-test-and-set pattern.\nThese are set at construction and immutable:\nspecTypes\nsparam_vals\ndef\nThese are set by jl_type_infer (while holding codegen lock):\nrettype\ninferred\nthese can also be reset, see jl_set_lambda_rettype for that logic as it needs to keep functionObjectsDecls in sync\ninInference flag:\noptimization to quickly avoid recurring into jl_type_infer while it is already running\nactual state (of setting inferred, then fptr) is protected by codegen lock\nFunction pointers (jlcall_api and fptr, unspecialized_ducttape):\nthese transition once, from NULL to a value, while the codegen lock is held\nCode-generator cache (the contents of functionObjectsDecls):\nthese can transition multiple times, but only while the codegen lock is held\nit is valid to use old version of this, or block for new versions of this, so races are benign, as long as the code is careful not to reference other data in the method instance (such as rettype) and assume it is coordinated, unless also holding the codegen lock\ncompile_traced flag:\nunknownLLVMContext : codegen lockMethod : Method->writelockroots array (serializer and codegen)\ninvoke / specializations / tfunc modifications"
},

{
    "location": "devdocs/offset-arrays/#",
    "page": "Arrays with custom indices",
    "title": "Arrays with custom indices",
    "category": "page",
    "text": ""
},

{
    "location": "devdocs/offset-arrays/#Arrays-with-custom-indices-1",
    "page": "Arrays with custom indices",
    "title": "Arrays with custom indices",
    "category": "section",
    "text": "Julia 0.5 adds experimental support for arrays with arbitrary indices. Conventionally, Julia\'s arrays are indexed starting at 1, whereas some other languages start numbering at 0, and yet others (e.g., Fortran) allow you to specify arbitrary starting indices.  While there is much merit in picking a standard (i.e., 1 for Julia), there are some algorithms which simplify considerably if you can index outside the range 1:size(A,d) (and not just 0:size(A,d)-1, either). Such array types are expected to be supplied through packages.The purpose of this page is to address the question, \"what do I have to do to support such arrays in my own code?\"  First, let\'s address the simplest case: if you know that your code will never need to handle arrays with unconventional indexing, hopefully the answer is \"nothing.\" Old code, on conventional arrays, should function essentially without alteration as long as it was using the exported interfaces of Julia."
},

{
    "location": "devdocs/offset-arrays/#Generalizing-existing-code-1",
    "page": "Arrays with custom indices",
    "title": "Generalizing existing code",
    "category": "section",
    "text": "As an overview, the steps are:replace many uses of size with indices\nreplace 1:length(A) with linearindices(A), and length(A) with length(linearindices(A))\nreplace explicit allocations like Array{Int}(size(B)) with similar(Array{Int}, indices(B))These are described in more detail below."
},

{
    "location": "devdocs/offset-arrays/#Background-1",
    "page": "Arrays with custom indices",
    "title": "Background",
    "category": "section",
    "text": "Because unconventional indexing breaks deeply-held assumptions throughout the Julia ecosystem, early adopters running code that has not been updated are likely to experience errors.  The most frustrating bugs would be incorrect results or segfaults (total crashes of Julia).  For example, consider the following function:function mycopy!(dest::AbstractVector, src::AbstractVector)\n    length(dest) == length(src) || throw(DimensionMismatch(\"vectors must match\"))\n    # OK, now we\'re safe to use @inbounds, right? (not anymore!)\n    for i = 1:length(src)\n        @inbounds dest[i] = src[i]\n    end\n    dest\nendThis code implicitly assumes that vectors are indexed from 1. Previously that was a safe assumption, so this code was fine, but (depending on what types the user passes to this function) it may no longer be safe.  If this code continued to work when passed a vector with non-1 indices, it would either produce an incorrect answer or it would segfault.  (If you do get segfaults, to help locate the cause try running julia with the option --check-bounds=yes.)To ensure that such errors are caught, in Julia 0.5 both length and sizeshould throw an error when passed an array with non-1 indexing.  This is designed to force users of such arrays to check the code, and inspect it for whether it needs to be generalized."
},

{
    "location": "devdocs/offset-arrays/#Using-indices-for-bounds-checks-and-loop-iteration-1",
    "page": "Arrays with custom indices",
    "title": "Using indices for bounds checks and loop iteration",
    "category": "section",
    "text": "indices(A) (reminiscent of size(A)) returns a tuple of AbstractUnitRange objects, specifying the range of valid indices along each dimension of A.  When A has unconventional indexing, the ranges may not start at 1.  If you just want the range for a particular dimension d, there is indices(A, d).Base implements a custom range type, OneTo, where OneTo(n) means the same thing as 1:n but in a form that guarantees (via the type system) that the lower index is 1. For any new AbstractArray type, this is the default returned by indices, and it indicates that this array type uses \"conventional\" 1-based indexing.  Note that if you don\'t want to be bothered supporting arrays with non-1 indexing, you can add the following line:@assert all(x->isa(x, Base.OneTo), indices(A))at the top of any function.For bounds checking, note that there are dedicated functions checkbounds and checkindex which can sometimes simplify such tests."
},

{
    "location": "devdocs/offset-arrays/#Linear-indexing-(linearindices)-1",
    "page": "Arrays with custom indices",
    "title": "Linear indexing (linearindices)",
    "category": "section",
    "text": "Some algorithms are most conveniently (or efficiently) written in terms of a single linear index, A[i] even if A is multi-dimensional.  In \"true\" linear indexing, the indices always range from 1:length(A). However, this raises an ambiguity for one-dimensional arrays (a.k.a., AbstractVector): does v[i] mean linear indexing, or Cartesian indexing with the array\'s native indices?For this reason, if you want to use linear indexing in an algorithm, your best option is to get the index range by calling linearindices(A).  This will return indices(A, 1) if A is an AbstractVector, and the equivalent of 1:length(A) otherwise.In a sense, one can say that 1-dimensional arrays always use Cartesian indexing. To help enforce this, it\'s worth noting that sub2ind(shape, i...) and ind2sub(shape, ind) will throw an error if shape indicates a 1-dimensional array with unconventional indexing (i.e., is a Tuple{UnitRange} rather than a tuple of OneTo).  For arrays with conventional indexing, these functions continue to work the same as always.Using indices and linearindices, here is one way you could rewrite mycopy!:function mycopy!(dest::AbstractVector, src::AbstractVector)\n    indices(dest) == indices(src) || throw(DimensionMismatch(\"vectors must match\"))\n    for i in linearindices(src)\n        @inbounds dest[i] = src[i]\n    end\n    dest\nend"
},

{
    "location": "devdocs/offset-arrays/#Allocating-storage-using-generalizations-of-similar-1",
    "page": "Arrays with custom indices",
    "title": "Allocating storage using generalizations of similar",
    "category": "section",
    "text": "Storage is often allocated with Array{Int}(dims) or similar(A, args...). When the result needs to match the indices of some other array, this may not always suffice. The generic replacement for such patterns is to use similar(storagetype, shape).  storagetype indicates the kind of underlying \"conventional\" behavior you\'d like, e.g., Array{Int} or BitArray or even dims->zeros(Float32, dims) (which would allocate an all-zeros array). shape is a tuple of Integer or AbstractUnitRange values, specifying the indices that you want the result to use.Let\'s walk through a couple of explicit examples. First, if A has conventional indices, then similar(Array{Int}, indices(A)) would end up calling Array{Int}(size(A)), and thus return an array.  If A is an AbstractArray type with unconventional indexing, then similar(Array{Int}, indices(A)) should return something that \"behaves like\" an Array{Int} but with a shape (including indices) that matches A.  (The most obvious implementation is to allocate an Array{Int}(size(A)) and then \"wrap\" it in a type that shifts the indices.)Note also that similar(Array{Int}, (indices(A, 2),)) would allocate an AbstractVector{Int} (i.e., 1-dimensional array) that matches the indices of the columns of A."
},

{
    "location": "devdocs/offset-arrays/#Deprecations-1",
    "page": "Arrays with custom indices",
    "title": "Deprecations",
    "category": "section",
    "text": "In generalizing Julia\'s code base, at least one deprecation was unavoidable: earlier versions of Julia defined first(::Colon) = 1, meaning that the first index along a dimension indexed by : is 1. This definition can no longer be justified, so it was deprecated. There is no provided replacement, because the proper replacement depends on what you are doing and might need to know more about the array. However, it appears that many uses of first(::Colon) are really about computing an index offset; when that is the case, a candidate replacement is:indexoffset(r::AbstractVector) = first(r) - 1\nindexoffset(::Colon) = 0In other words, while first(:) does not itself make sense, in general you can say that the offset associated with a colon-index is zero."
},

{
    "location": "devdocs/offset-arrays/#Writing-custom-array-types-with-non-1-indexing-1",
    "page": "Arrays with custom indices",
    "title": "Writing custom array types with non-1 indexing",
    "category": "section",
    "text": "Most of the methods you\'ll need to define are standard for any AbstractArray type, see Abstract Arrays. This page focuses on the steps needed to define unconventional indexing."
},

{
    "location": "devdocs/offset-arrays/#Do-**not**-implement-size-or-length-1",
    "page": "Arrays with custom indices",
    "title": "Do not implement size or length",
    "category": "section",
    "text": "Perhaps the majority of pre-existing code that uses size will not work properly for arrays with non-1 indices.  For that reason, it is much better to avoid implementing these methods, and use the resulting MethodError to identify code that needs to be audited and perhaps generalized."
},

{
    "location": "devdocs/offset-arrays/#Do-**not**-annotate-bounds-checks-1",
    "page": "Arrays with custom indices",
    "title": "Do not annotate bounds checks",
    "category": "section",
    "text": "Julia 0.5 includes @boundscheck to annotate code that can be removed for callers that exploit @inbounds. Initially, it seems far preferable to run with bounds checking always enabled (i.e., omit the @boundscheck annotation so the check always runs)."
},

{
    "location": "devdocs/offset-arrays/#Custom-AbstractUnitRange-types-1",
    "page": "Arrays with custom indices",
    "title": "Custom AbstractUnitRange types",
    "category": "section",
    "text": "If you\'re writing a non-1 indexed array type, you will want to specialize indices so it returns a UnitRange, or (perhaps better) a custom AbstractUnitRange.  The advantage of a custom type is that it \"signals\" the allocation type for functions like similar. If we\'re writing an array type for which indexing will start at 0, we likely want to begin by creating a new AbstractUnitRange, ZeroRange, where ZeroRange(n) is equivalent to 0:n-1.In general, you should probably not export ZeroRange from your package: there may be other packages that implement their own ZeroRange, and having multiple distinct ZeroRange types is (perhaps counterintuitively) an advantage: ModuleA.ZeroRange indicates that similar should create a ModuleA.ZeroArray, whereas ModuleB.ZeroRange indicates a ModuleB.ZeroArray type.  This design allows peaceful coexistence among many different custom array types.Note that the Julia package CustomUnitRanges.jl can sometimes be used to avoid the need to write your own ZeroRange type."
},

{
    "location": "devdocs/offset-arrays/#Specializing-indices-1",
    "page": "Arrays with custom indices",
    "title": "Specializing indices",
    "category": "section",
    "text": "Once you have your AbstractUnitRange type, then specialize indices:Base.indices(A::ZeroArray) = map(n->ZeroRange(n), A.size)where here we imagine that ZeroArray has a field called size (there would be other ways to implement this).In some cases, the fallback definition for indices(A, d):indices(A::AbstractArray{T,N}, d) where {T,N} = d <= N ? indices(A)[d] : OneTo(1)may not be what you want: you may need to specialize it to return something other than OneTo(1) when d > ndims(A).  Likewise, in Base there is a dedicated function indices1 which is equivalent to indices(A, 1) but which avoids checking (at runtime) whether ndims(A) > 0. (This is purely a performance optimization.)  It is defined as:indices1(A::AbstractArray{T,0}) where {T} = OneTo(1)\nindices1(A::AbstractArray) = indices(A)[1]If the first of these (the zero-dimensional case) is problematic for your custom array type, be sure to specialize it appropriately."
},

{
    "location": "devdocs/offset-arrays/#Specializing-similar-1",
    "page": "Arrays with custom indices",
    "title": "Specializing similar",
    "category": "section",
    "text": "Given your custom ZeroRange type, then you should also add the following two specializations for similar:function Base.similar(A::AbstractArray, T::Type, shape::Tuple{ZeroRange,Vararg{ZeroRange}})\n    # body\nend\n\nfunction Base.similar(f::Union{Function,DataType}, shape::Tuple{ZeroRange,Vararg{ZeroRange}})\n    # body\nendBoth of these should allocate your custom array type."
},

{
    "location": "devdocs/offset-arrays/#Specializing-reshape-1",
    "page": "Arrays with custom indices",
    "title": "Specializing reshape",
    "category": "section",
    "text": "Optionally, define a methodBase.reshape(A::AbstractArray, shape::Tuple{ZeroRange,Vararg{ZeroRange}}) = ...and you can reshape an array so that the result has custom indices."
},

{
    "location": "devdocs/offset-arrays/#Summary-1",
    "page": "Arrays with custom indices",
    "title": "Summary",
    "category": "section",
    "text": "Writing code that doesn\'t make assumptions about indexing requires a few extra abstractions, but hopefully the necessary changes are relatively straightforward.As a reminder, this support is still experimental. While much of Julia\'s base code has been updated to support unconventional indexing, without a doubt there are many omissions that will be discovered only through usage.  Moreover, at the time of this writing, most packages do not support unconventional indexing.  As a consequence, early adopters should be prepared to identify and/or fix bugs.  On the other hand, only through practical usage will it become clear whether this experimental feature should be retained in future versions of Julia; consequently, interested parties are encouraged to accept some ownership for putting it through its paces."
},

{
    "location": "devdocs/libgit2/#",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2",
    "category": "page",
    "text": ""
},

{
    "location": "devdocs/libgit2/#Base.LibGit2-1",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2",
    "category": "section",
    "text": "The LibGit2 module provides bindings to libgit2, a portable C library that implements core functionality for the Git version control system. These bindings are currently used to power Julia\'s package manager. It is expected that this module will eventually be moved into a separate package."
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.AbstractCredentials",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.AbstractCredentials",
    "category": "type",
    "text": "Abstract credentials payload\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.Buffer",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.Buffer",
    "category": "type",
    "text": "LibGit2.Buffer\n\nA data buffer for exporting data from libgit2. Matches the git_buf struct.\n\nWhen fetching data from LibGit2, a typical usage would look like:\n\nbuf_ref = Ref(Buffer())\n@check ccall(..., (Ptr{Buffer},), buf_ref)\n# operation on buf_ref\nfree(buf_ref)\n\nIn particular, note that LibGit2.free should be called afterward on the Ref object.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.CachedCredentials",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.CachedCredentials",
    "category": "type",
    "text": "Credentials that support caching\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.CheckoutOptions",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.CheckoutOptions",
    "category": "type",
    "text": "LibGit2.CheckoutOptions\n\nMatches the git_checkout_options struct.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.CloneOptions",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.CloneOptions",
    "category": "type",
    "text": "LibGit2.CloneOptions\n\nMatches the git_clone_options struct.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.DiffDelta",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.DiffDelta",
    "category": "type",
    "text": "LibGit2.DiffDelta\n\nDescription of changes to one entry. Matches the git_diff_delta struct.\n\nThe fields represent:\n\nstatus: One of Consts.DELTA_STATUS, indicating whether the file has been added/modified/deleted.\nflags: Flags for the delta and the objects on each side. Determines whether to treat the file(s)  as binary/text, whether they exist on each side of the diff, and whether the object ids are known  to be correct.\nsimilarity: Used to indicate if a file has been renamed or copied.\nnfiles: The number of files in the delta (for instance, if the delta  was run on a submodule commit id, it may contain more than one file).\nold_file: A DiffFile containing information about the file(s) before the changes.\nnew_file: A DiffFile containing information about the file(s) after the changes.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.DiffFile",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.DiffFile",
    "category": "type",
    "text": "LibGit2.DiffFile\n\nDescription of one side of a delta. Matches the git_diff_file struct.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.DiffOptionsStruct",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.DiffOptionsStruct",
    "category": "type",
    "text": "LibGit2.DiffOptionsStruct\n\nMatches the git_diff_options struct.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.FetchHead",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.FetchHead",
    "category": "type",
    "text": "LibGit2.FetchHead\n\nContains the information about HEAD during a fetch, including the name and URL of the branch fetched from, the oid of the HEAD, and whether the fetched HEAD has been merged locally.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.FetchOptions",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.FetchOptions",
    "category": "type",
    "text": "LibGit2.FetchOptions\n\nMatches the git_fetch_options struct.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.GitBlob",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.GitBlob",
    "category": "type",
    "text": "GitBlob(repo::GitRepo, hash::AbstractGitHash)\nGitBlob(repo::GitRepo, spec::AbstractString)\n\nReturn a GitBlob object from repo specified by hash/spec.\n\nhash is a full (GitHash) or partial (GitShortHash) hash.\nspec is a textual specification: see the git docs for a full list.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.GitCommit",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.GitCommit",
    "category": "type",
    "text": "GitCommit(repo::GitRepo, hash::AbstractGitHash)\nGitCommit(repo::GitRepo, spec::AbstractString)\n\nReturn a GitCommit object from repo specified by hash/spec.\n\nhash is a full (GitHash) or partial (GitShortHash) hash.\nspec is a textual specification: see the git docs for a full list.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.GitHash",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.GitHash",
    "category": "type",
    "text": "GitHash\n\nA git object identifier, based on the sha-1 hash. It is a 20 byte string (40 hex digits) used to identify a GitObject in a repository.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.GitObject",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.GitObject",
    "category": "type",
    "text": "GitObject(repo::GitRepo, hash::AbstractGitHash)\nGitObject(repo::GitRepo, spec::AbstractString)\n\nReturn the specified object (GitCommit, GitBlob, GitTree or GitTag) from repo specified by hash/spec.\n\nhash is a full (GitHash) or partial (GitShortHash) hash.\nspec is a textual specification: see the git docs for a full list.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.GitRemote",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.GitRemote",
    "category": "type",
    "text": "GitRemote(repo::GitRepo, rmt_name::AbstractString, rmt_url::AbstractString) -> GitRemote\n\nLook up a remote git repository using its name and URL. Uses the default fetch refspec.\n\nExample\n\nrepo = LibGit2.init(repo_path)\nremote = LibGit2.GitRemote(repo, \"upstream\", repo_url)\n\n\n\nGitRemote(repo::GitRepo, rmt_name::AbstractString, rmt_url::AbstractString, fetch_spec::AbstractString) -> GitRemote\n\nLook up a remote git repository using the repository\'s name and URL, as well as specifications for how to fetch from the remote (e.g. which remote branch to fetch from).\n\nExample\n\nrepo = LibGit2.init(repo_path)\nrefspec = \"+refs/heads/mybranch:refs/remotes/origin/mybranch\"\nremote = LibGit2.GitRemote(repo, \"upstream\", repo_url, refspec)\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.GitRemoteAnon",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.GitRemoteAnon",
    "category": "function",
    "text": "GitRemoteAnon(repo::GitRepo, url::AbstractString) -> GitRemote\n\nLook up a remote git repository using only its URL, not its name.\n\nExample\n\nrepo = LibGit2.init(repo_path)\nremote = LibGit2.GitRemoteAnon(repo, repo_url)\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.GitRepo",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.GitRepo",
    "category": "type",
    "text": "LibGit2.GitRepo(path::AbstractString)\n\nOpens a git repository at path.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.GitRepoExt",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.GitRepoExt",
    "category": "function",
    "text": "LibGit2.GitRepoExt(path::AbstractString, flags::Cuint = Cuint(Consts.REPOSITORY_OPEN_DEFAULT))\n\nOpens a git repository at path with extended controls (for instance, if the current user must be a member of a special access group to read path).\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.GitShortHash",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.GitShortHash",
    "category": "type",
    "text": "GitShortHash\n\nThis is a shortened form of GitHash, which can be used to identify a git object when it is unique.\n\nInternally it is stored as two fields: a full-size GitHash (hash) and a length (len). Only the initial len hex digits of hash are used.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.GitSignature",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.GitSignature",
    "category": "type",
    "text": "LibGit2.GitSignature\n\nThis is a Julia wrapper around a pointer to a git_signature object.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.GitStatus",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.GitStatus",
    "category": "type",
    "text": "LibGit2.GitStatus(repo::GitRepo; status_opts=StatusOptions())\n\nCollect information about the status of each file in the git repository repo (e.g. is the file modified, staged, etc.). status_opts can be used to set various options, for instance whether or not to look at untracked files or whether to include submodules or not.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.GitTag",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.GitTag",
    "category": "type",
    "text": "GitTag(repo::GitRepo, hash::AbstractGitHash)\nGitTag(repo::GitRepo, spec::AbstractString)\n\nReturn a GitTag object from repo specified by hash/spec.\n\nhash is a full (GitHash) or partial (GitShortHash) hash.\nspec is a textual specification: see the git docs for a full list.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.GitTree",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.GitTree",
    "category": "type",
    "text": "GitTree(repo::GitRepo, hash::AbstractGitHash)\nGitTree(repo::GitRepo, spec::AbstractString)\n\nReturn a GitTree object from repo specified by hash/spec.\n\nhash is a full (GitHash) or partial (GitShortHash) hash.\nspec is a textual specification: see the git docs for a full list.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.IndexEntry",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.IndexEntry",
    "category": "type",
    "text": "LibGit2.IndexEntry\n\nIn-memory representation of a file entry in the index. Matches the git_index_entry struct.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.IndexTime",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.IndexTime",
    "category": "type",
    "text": "LibGit2.IndexTime\n\nMatches the git_index_time struct.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.MergeOptions",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.MergeOptions",
    "category": "type",
    "text": "LibGit2.MergeOptions\n\nMatches the git_merge_options struct.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.ProxyOptions",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.ProxyOptions",
    "category": "type",
    "text": "LibGit2.ProxyOptions\n\nOptions for connecting through a proxy.\n\nMatches the git_proxy_options struct.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.PushOptions",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.PushOptions",
    "category": "type",
    "text": "LibGit2.PushOptions\n\nMatches the git_push_options struct.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.RebaseOperation",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.RebaseOperation",
    "category": "type",
    "text": "LibGit2.RebaseOperation\n\nDescribes a single instruction/operation to be performed during the rebase. Matches the git_rebase_operation struct.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.RebaseOptions",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.RebaseOptions",
    "category": "type",
    "text": "LibGit2.RebaseOptions\n\nMatches the git_rebase_options struct.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.RemoteCallbacks",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.RemoteCallbacks",
    "category": "type",
    "text": "LibGit2.RemoteCallbacks\n\nCallback settings. Matches the git_remote_callbacks struct.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.SSHCredentials",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.SSHCredentials",
    "category": "type",
    "text": "SSH credentials type\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.SignatureStruct",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.SignatureStruct",
    "category": "type",
    "text": "LibGit2.SignatureStruct\n\nAn action signature (e.g. for committers, taggers, etc). Matches the git_signature struct.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.StatusEntry",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.StatusEntry",
    "category": "type",
    "text": "LibGit2.StatusEntry\n\nProviding the differences between the file as it exists in HEAD and the index, and providing the differences between the index and the working directory. Matches the git_status_entry struct.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.StatusOptions",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.StatusOptions",
    "category": "type",
    "text": "LibGit2.StatusOptions\n\nOptions to control how git_status_foreach_ext() will issue callbacks. Matches the git_status_opt_t struct.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.StrArrayStruct",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.StrArrayStruct",
    "category": "type",
    "text": "LibGit2.StrArrayStruct\n\nA LibGit2 representation of an array of strings. Matches the git_strarray struct.\n\nWhen fetching data from LibGit2, a typical usage would look like:\n\nsa_ref = Ref(StrArrayStruct())\n@check ccall(..., (Ptr{StrArrayStruct},), sa_ref)\nres = convert(Vector{String}, sa_ref[])\nfree(sa_ref)\n\nIn particular, note that LibGit2.free should be called afterward on the Ref object.\n\nConversely, when passing a vector of strings to LibGit2, it is generally simplest to rely on implicit conversion:\n\nstrs = String[...]\n@check ccall(..., (Ptr{StrArrayStruct},), strs)\n\nNote that no call to free is required as the data is allocated by Julia.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.TimeStruct",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.TimeStruct",
    "category": "type",
    "text": "LibGit2.TimeStruct\n\nTime in a signature. Matches the git_time struct.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.UserPasswordCredentials",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.UserPasswordCredentials",
    "category": "type",
    "text": "Credentials that support only user and password parameters\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.add_fetch!",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.add_fetch!",
    "category": "function",
    "text": "add_fetch!(repo::GitRepo, rmt::GitRemote, fetch_spec::String)\n\nAdd a fetch refspec for the specified rmt. This refspec will contain information about which branch(es) to fetch from.\n\nExample\n\njulia> LibGit2.add_fetch!(repo, remote, \"upstream\");\n\njulia> LibGit2.fetch_refspecs(remote)\nString[\"+refs/heads/*:refs/remotes/upstream/*\"]\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.add_push!",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.add_push!",
    "category": "function",
    "text": "add_push!(repo::GitRepo, rmt::GitRemote, push_spec::String)\n\nAdd a push refspec for the specified rmt. This refspec will contain information about which branch(es) to push to.\n\nExample\n\njulia> LibGit2.add_push!(repo, remote, \"refs/heads/master\");\n\njulia> remote = LibGit2.get(LibGit2.GitRemote, repo, branch);\n\njulia> LibGit2.push_refspecs(remote)\nString[\"refs/heads/master\"]\n\nnote: Note\nYou may need to close and reopen the GitRemote in question after updating its push refspecs in order for the change to take effect and for calls to push to work.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.addblob!",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.addblob!",
    "category": "function",
    "text": "LibGit2.addblob!(repo::GitRepo, path::AbstractString)\n\nReads the file at path and adds it to the object database of repo as a loose blob. Returns the GitHash of the resulting blob.\n\nExample\n\nhash_str = hex(commit_oid)\nblob_file = joinpath(repo_path, \".git\", \"objects\", hash_str[1:2], hash_str[3:end])\nid = LibGit2.addblob!(repo, blob_file)\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.authors",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.authors",
    "category": "function",
    "text": "authors(repo::GitRepo) -> Vector{Signature}\n\nReturns all authors of commits to the repo repository.\n\nExample\n\nrepo = LibGit2.GitRepo(repo_path)\nrepo_file = open(joinpath(repo_path, test_file), \"a\")\n\nprintln(repo_file, commit_msg)\nflush(repo_file)\nLibGit2.add!(repo, test_file)\nsig = LibGit2.Signature(\"TEST\", \"TEST@TEST.COM\", round(time(), 0), 0)\ncommit_oid1 = LibGit2.commit(repo, \"commit1\"; author=sig, committer=sig)\nprintln(repo_file, randstring(10))\nflush(repo_file)\nLibGit2.add!(repo, test_file)\ncommit_oid2 = LibGit2.commit(repo, \"commit2\"; author=sig, committer=sig)\n\n# will be a Vector of [sig, sig]\nauths = LibGit2.authors(repo)\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.branch",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.branch",
    "category": "function",
    "text": "branch(repo::GitRepo)\n\nEquivalent to git branch. Create a new branch from the current HEAD.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.branch!",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.branch!",
    "category": "function",
    "text": "branch!(repo::GitRepo, branch_name::AbstractString, commit::AbstractString=\"\"; kwargs...)\n\nCheckout a new git branch in the repo repository. commit is the GitHash, in string form, which will be the start of the new branch. If commit is an empty string, the current HEAD will be used.\n\nThe keyword arguments are:\n\ntrack::AbstractString=\"\": the name of the remote branch this new branch should track, if any. If empty (the default), no remote branch will be tracked.\nforce::Bool=false: if true, branch creation will be forced.\nset_head::Bool=true: if true, after the branch creation finishes the branch head will be set as the HEAD of repo.\n\nEquivalent to git checkout [-b|-B] <branch_name> [<commit>] [--track <track>].\n\nExample\n\nrepo = LibGit2.GitRepo(repo_path)\nLibGit2.branch!(repo, \"new_branch\", set_head=false)\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.checkout!",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.checkout!",
    "category": "function",
    "text": "checkout!(repo::GitRepo, commit::AbstractString=\"\"; force::Bool=true)\n\nEquivalent to git checkout [-f] --detach <commit>. Checkout the git commit commit (a GitHash in string form) in repo. If force is true, force the checkout and discard any current changes. Note that this detaches the current HEAD.\n\nExample\n\nrepo = LibGit2.init(repo_path)\nopen(joinpath(LibGit2.path(repo), \"file1\"), \"w\") do f\n    write(f, \"111\n\")\nend\nLibGit2.add!(repo, \"file1\")\ncommit_oid = LibGit2.commit(repo, \"add file1\")\nopen(joinpath(LibGit2.path(repo), \"file1\"), \"w\") do f\n    write(f, \"112\n\")\nend\n# would fail without the force=true\n# since there are modifications to the file\nLibGit2.checkout!(repo, string(commit_oid), force=true)\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.checkused!",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.checkused!",
    "category": "function",
    "text": "Checks if credentials were used\n\n\n\nChecks if credentials were used or failed authentication, see LibGit2.credentials_callback\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.clone",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.clone",
    "category": "function",
    "text": "clone(repo_url::AbstractString, repo_path::AbstractString; kwargs...)\n\nClone a remote repository located at repo_url to the local filesystem location repo_path.\n\nThe keyword arguments are:\n\nbranch::AbstractString=\"\": which branch of the remote to clone, if not the default repository branch (usually master).\nisbare::Bool=false: if true, clone the remote as a bare repository, which will make repo_path itself the git directory instead of repo_path/.git. This means that a working tree cannot be checked out. Plays the role of the git CLI argument --bare.\nremote_cb::Ptr{Void}=C_NULL: a callback which will be used to create the remote before it is cloned. If C_NULL (the default), no attempt will be made to create the remote - it will be assumed to already exist.\npayload::Nullable{P<:AbstractCredentials}=Nullable{AbstractCredentials}(): provides credentials if necessary, for instance if the remote is a private repository.\n\nEquivalent to git clone [-b <branch>] [--bare] <repo_url> <repo_path>.\n\nExamples\n\nrepo_url = \"https://github.com/JuliaLang/Example.jl\"\nrepo1 = LibGit2.clone(repo_url, \"test_path\")\nrepo2 = LibGit2.clone(repo_url, \"test_path\", isbare=true)\njulia_url = \"https://github.com/JuliaLang/julia\"\njulia_repo = LibGit2.clone(julia_url, \"julia_path\", branch=\"release-0.6\")\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.commit",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.commit",
    "category": "function",
    "text": "Wrapper around git_commit_create \n\n\n\nCommit changes to repository\n\n\n\nLibGit2.commit(rb::GitRebase, sig::GitSignature)\n\nCommits the current patch to the rebase rb, using sig as the committer. Is silent if the commit has already been applied.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.create_branch",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.create_branch",
    "category": "function",
    "text": "LibGit2.create_branch(repo::GitRepo, bname::AbstractString, commit_obj::GitCommit; force::Bool=false)\n\nCreate a new branch in the repository repo with name bname, which points to commit commit_obj (which has to be part of repo). If force is true, overwrite an existing branch named bname if it exists. If force is false and a branch already exists named bname, this function will throw an error.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.credentials_callback",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.credentials_callback",
    "category": "function",
    "text": "Credentials callback function\n\nFunction provides different credential acquisition functionality w.r.t. a connection protocol. If a payload is provided then payload_ptr should contain a LibGit2.AbstractCredentials object.\n\nFor LibGit2.Consts.CREDTYPE_USERPASS_PLAINTEXT type, if the payload contains fields: user & pass, they are used to create authentication credentials. Empty user name and password trigger an authentication error.\n\nFor LibGit2.Consts.CREDTYPE_SSH_KEY type, if the payload contains fields: user, prvkey, pubkey & pass, they are used to create authentication credentials. Empty user name triggers an authentication error.\n\nCredentials are checked in the following order (if supported):\n\nssh key pair (ssh-agent if specified in payload\'s usesshagent field)\nplain text\n\nNote: Due to the specifics of the libgit2 authentication procedure, when authentication fails, this function is called again without any indication whether authentication was successful or not. To avoid an infinite loop from repeatedly using the same faulty credentials, the checkused! function can be called. This function returns true if the credentials were used. Using credentials triggers a user prompt for (re)entering required information. UserPasswordCredentials and CachedCredentials are implemented using a call counting strategy that prevents repeated usage of faulty credentials.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.credentials_cb",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.credentials_cb",
    "category": "function",
    "text": "C function pointer for credentials_callback\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.default_signature",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.default_signature",
    "category": "function",
    "text": "Return signature object. Free it after use.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.delete_branch",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.delete_branch",
    "category": "function",
    "text": "LibGit2.delete_branch(branch::GitReference)\n\nDelete the branch pointed to by branch.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.diff_files",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.diff_files",
    "category": "function",
    "text": "diff_files(repo::GitRepo, branch1::AbstractString, branch2::AbstractString; kwarg...) -> Vector{AbstractString}\n\nShow which files have changed in the git repository repo between branches branch1 and branch2.\n\nThe keyword argument is:\n\nfilter::Set{Consts.DELTA_STATUS}=Set([Consts.DELTA_ADDED, Consts.DELTA_MODIFIED, Consts.DELTA_DELETED])), and it sets options for the diff. The default is to show files added, modified, or deleted.\n\nReturns only the names of the files which have changed, not their contents.\n\nExample\n\nLibGit2.branch!(repo, \"branch/a\")\nLibGit2.branch!(repo, \"branch/b\")\n# add a file to repo\nopen(joinpath(LibGit2.path(repo),\"file\"),\"w\") do f\n    write(f, \"hello repo\n\")\nend\nLibGit2.add!(repo, \"file\")\nLibGit2.commit(repo, \"add file\")\n# returns [\"file\"]\nfilt = Set([LibGit2.Consts.DELTA_ADDED])\nfiles = LibGit2.diff_files(repo, \"branch/a\", \"branch/b\", filter=filt)\n# returns [] because existing files weren\'t modified\nfilt = Set([LibGit2.Consts.DELTA_MODIFIED])\nfiles = LibGit2.diff_files(repo, \"branch/a\", \"branch/b\", filter=filt)\n\nEquivalent to git diff --name-only --diff-filter=<filter> <branch1> <branch2>.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.fetch",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.fetch",
    "category": "function",
    "text": "fetch(rmt::GitRemote, refspecs; options::FetchOptions=FetchOptions(), msg=\"\")\n\nFetch from the specified rmt remote git repository, using refspecs to determine which remote branch(es) to fetch. The keyword arguments are:\n\noptions: determines the options for the fetch, e.g. whether to prune afterwards.\nmsg: a message to insert into the reflogs.\n\n\n\nfetch(repo::GitRepo; kwargs...)\n\nFetches updates from an upstream of the repository repo.\n\nThe keyword arguments are:\n\nremote::AbstractString=\"origin\": which remote, specified by name, of repo to fetch from. If this is empty, the URL will be used to construct an anonymous remote.\nremoteurl::AbstractString=\"\": the URL of remote. If not specified, will be assumed based on the given name of remote.\nrefspecs=AbstractString[]: determines properties of the fetch.\npayload=Nullable{AbstractCredentials}(): provides credentials, if necessary, for instance if remote is a private repository.\n\nEquivalent to git fetch [<remoteurl>|<repo>] [<refspecs>].\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.fetch_refspecs",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.fetch_refspecs",
    "category": "function",
    "text": "fetch_refspecs(rmt::GitRemote) -> Vector{String}\n\nGet the fetch refspecs for the specified rmt. These refspecs contain information about which branch(es) to fetch from.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.fetchhead_foreach_cb",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.fetchhead_foreach_cb",
    "category": "function",
    "text": "C function pointer for fetchhead_foreach_callback\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.ffmerge!",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.ffmerge!",
    "category": "function",
    "text": "Fastforward merge changes into current head \n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.fullname",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.fullname",
    "category": "function",
    "text": "LibGit2.fullname(ref::GitReference)\n\nReturn the name of the reference pointed to by the symbolic reference ref. If ref is not a symbolic reference, returns an empty string.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.get_creds!",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.get_creds!",
    "category": "function",
    "text": "Obtain the cached credentials for the given host+protocol (credid), or return and store the default if not found\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.gitdir",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.gitdir",
    "category": "function",
    "text": "LibGit2.gitdir(repo::GitRepo)\n\nReturns the location of the \"git\" files of repo:\n\nfor normal repositories, this is the location of the .git folder.\nfor bare repositories, this is the location of the repository itself.\n\nSee also workdir, path.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.head",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.head",
    "category": "function",
    "text": "LibGit2.head(repo::GitRepo) -> GitReference\n\nReturns a GitReference to the current HEAD of repo.\n\n\n\nhead(pkg::AbstractString) -> String\n\nReturn current HEAD GitHash of the pkg repo as a string.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.head!",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.head!",
    "category": "function",
    "text": "LibGit2.head!(repo::GitRepo, ref::GitReference) -> GitReference\n\nSet the HEAD of repo to the object pointed to by ref.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.head_oid",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.head_oid",
    "category": "function",
    "text": "LibGit2.head_oid(repo::GitRepo) -> GitHash\n\nLookup the object id of the current HEAD of git repository repo.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.headname",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.headname",
    "category": "function",
    "text": "LibGit2.headname(repo::GitRepo)\n\nLookup the name of the current HEAD of git repository repo. If repo is currently detached, returns the name of the HEAD it\'s detached from.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.init",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.init",
    "category": "function",
    "text": "LibGit2.init(path::AbstractString, bare::Bool=false) -> GitRepo\n\nOpens a new git repository at path. If bare is false, the working tree will be created in path/.git. If bare is true, no working directory will be created.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.is_ancestor_of",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.is_ancestor_of",
    "category": "function",
    "text": "is_ancestor_of(a::AbstractString, b::AbstractString, repo::GitRepo) -> Bool\n\nReturns true if a, a GitHash in string form, is an ancestor of b, a GitHash in string form.\n\nExample\n\njulia> repo = LibGit2.GitRepo(repo_path);\n\njulia> LibGit2.add!(repo, test_file1);\n\njulia> commit_oid1 = LibGit2.commit(repo, \"commit1\");\n\njulia> LibGit2.add!(repo, test_file2);\n\njulia> commit_oid2 = LibGit2.commit(repo, \"commit2\");\n\njulia> LibGit2.is_ancestor_of(string(commit_oid1), string(commit_oid2), repo)\ntrue\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.isbinary",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.isbinary",
    "category": "function",
    "text": "Use a heuristic to guess if a file is binary: searching for NULL bytes and looking for a reasonable ratio of printable to non-printable characters among the first 8000 bytes.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.iscommit",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.iscommit",
    "category": "function",
    "text": "iscommit(id::AbstractString, repo::GitRepo) -> Bool\n\nChecks if commit id (which is a GitHash in string form) is in the repository.\n\nExample\n\njulia> repo = LibGit2.GitRepo(repo_path);\n\njulia> LibGit2.add!(repo, test_file);\n\njulia> commit_oid = LibGit2.commit(repo, \"add test_file\");\n\njulia> LibGit2.iscommit(string(commit_oid), repo)\ntrue\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.isdiff",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.isdiff",
    "category": "function",
    "text": "LibGit2.isdiff(repo::GitRepo, treeish::AbstractString, pathspecs::AbstractString=\"\"; cached::Bool=false)\n\nChecks if there are any differences between the tree specified by treeish and the tracked files in the working tree (if cached=false) or the index (if cached=true). pathspecs are the specifications for options for the diff.\n\nExample\n\nrepo = LibGit2.GitRepo(repo_path)\nLibGit2.isdiff(repo, \"HEAD\") # should be false\nopen(joinpath(repo_path, new_file), \"a\") do f\n    println(f, \"here\'s my cool new file\")\nend\nLibGit2.isdiff(repo, \"HEAD\") # now true\n\nEquivalent to git diff-index <treeish> [-- <pathspecs>].\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.isdirty",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.isdirty",
    "category": "function",
    "text": "LibGit2.isdirty(repo::GitRepo, pathspecs::AbstractString=\"\"; cached::Bool=false) -> Bool\n\nChecks if there have been any changes to tracked files in the working tree (if cached=false) or the index (if cached=true). pathspecs are the specifications for options for the diff.\n\nExample\n\nrepo = LibGit2.GitRepo(repo_path)\nLibGit2.isdirty(repo) # should be false\nopen(joinpath(repo_path, new_file), \"a\") do f\n    println(f, \"here\'s my cool new file\")\nend\nLibGit2.isdirty(repo) # now true\nLibGit2.isdirty(repo, new_file) # now true\n\nEquivalent to git diff-index HEAD [-- <pathspecs>].\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.isorphan",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.isorphan",
    "category": "function",
    "text": "LibGit2.isorphan(repo::GitRepo)\n\nChecks if the current branch is an \"orphan\" branch, i.e. has no commits. The first commit to this branch will have no parents.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.lookup_branch",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.lookup_branch",
    "category": "function",
    "text": "lookup_branch(repo::GitRepo, branch_name::AbstractString, remote::Bool=false) -> Nullable{GitReference}\n\nDetermine if the branch specified by branch_name exists in the repository repo. If remote is true, repo is assumed to be a remote git repository. Otherwise, it is part of the local filesystem.\n\nlookup_branch returns a Nullable, which will be null if the requested branch does not exist yet. If the branch does exist, the Nullable contains a GitReference to the branch.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.mirror_callback",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.mirror_callback",
    "category": "function",
    "text": "Mirror callback function\n\nFunction sets +refs/*:refs/* refspecs and mirror flag for remote reference.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.mirror_cb",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.mirror_cb",
    "category": "function",
    "text": "C function pointer for mirror_callback\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.name",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.name",
    "category": "function",
    "text": "LibGit2.name(ref::GitReference)\n\nReturn the full name of ref.\n\n\n\nname(rmt::GitRemote)\n\nGet the name of a remote repository, for instance \"origin\". If the remote is anonymous (see GitRemoteAnon) the name will be an empty string \"\".\n\nExample\n\njulia> repo_url = \"https://github.com/JuliaLang/Example.jl\";\n\njulia> repo = LibGit2.clone(cache_repo, \"test_directory\");\n\njulia> remote = LibGit2.GitRemote(repo, \"origin\", repo_url);\n\njulia> name(remote)\n\"origin\"\n\n\n\nLibGit2.name(tag::GitTag)\n\nThe name of tag (e.g. \"v0.5\").\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.need_update",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.need_update",
    "category": "function",
    "text": "need_update(repo::GitRepo)\n\nEquivalent to git update-index. Returns true if repo needs updating.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.objtype",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.objtype",
    "category": "function",
    "text": "objtype(obj_type::Consts.OBJECT)\n\nReturns the type corresponding to the enum value.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.path",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.path",
    "category": "function",
    "text": "LibGit2.path(repo::GitRepo)\n\nThe base file path of the repository repo.\n\nfor normal repositories, this will typically be the parent directory of the \".git\" directory (note: this may be different than the working directory, see workdir for more details).\nfor bare repositories, this is the location of the \"git\" files.\n\nSee also gitdir, workdir.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.peel",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.peel",
    "category": "function",
    "text": "peel([T,] ref::GitReference)\n\nRecursively peel ref until an object of type T is obtained. If no T is provided, then ref will be peeled until an object other than a GitTag is obtained.\n\nA GitTag will be peeled to the object it references.\nA GitCommit will be peeled to a GitTree.\n\nnote: Note\nOnly annotated tags can be peeled to GitTag objects. Lightweight tags (the default) are references under refs/tags/ which point directly to GitCommit objects.\n\n\n\npeel([T,] obj::GitObject)\n\nRecursively peel obj until an object of type T is obtained. If no T is provided, then obj will be peeled until the type changes.\n\nA GitTag will be peeled to the object it references.\nA GitCommit will be peeled to a GitTree.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.posixpath",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.posixpath",
    "category": "function",
    "text": "LibGit2.posixpath(path)\n\nStandardise the path string path to use POSIX separators.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.push",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.push",
    "category": "function",
    "text": "push(rmt::GitRemote, refspecs; force::Bool=false, options::PushOptions=PushOptions())\n\nPush to the specified rmt remote git repository, using refspecs to determine which remote branch(es) to push to. The keyword arguments are:\n\nforce: if true, a force-push will occur, disregarding conflicts.\noptions: determines the options for the push, e.g. which proxy headers to use.\n\nnote: Note\nYou can add information about the push refspecs in two other ways: by setting an option in the repository\'s GitConfig (with push.default as the key) or by calling add_push!. Otherwise you will need to explicitly specify a push refspec in the call to push for it to have any effect, like so: LibGit2.push(repo, refspecs=[\"refs/heads/master\"]).\n\n\n\npush(repo::GitRepo; kwargs...)\n\nPushes updates to an upstream of repo.\n\nThe keyword arguments are:\n\nremote::AbstractString=\"origin\": the name of the upstream remote to push to.\nremoteurl::AbstractString=\"\": the URL of remote.\nrefspecs=AbstractString[]: determines properties of the push.\nforce::Bool=false: determines if the push will be a force push,  overwriting the remote branch.\npayload=Nullable{AbstractCredentials}(): provides credentials, if necessary, for instance if remote is a private repository.\n\nEquivalent to git push [<remoteurl>|<repo>] [<refspecs>].\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.push_refspecs",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.push_refspecs",
    "category": "function",
    "text": "push_refspecs(rmt::GitRemote) -> Vector{String}\n\nGet the push refspecs for the specified rmt. These refspecs contain information about which branch(es) to push to.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.read_tree!",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.read_tree!",
    "category": "function",
    "text": "LibGit2.read_tree!(idx::GitIndex, tree::GitTree)\nLibGit2.read_tree!(idx::GitIndex, treehash::AbstractGitHash)\n\nRead the tree tree (or the tree pointed to by treehash in the repository owned by idx) into the index idx. The current index contents will be replaced.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.rebase!",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.rebase!",
    "category": "function",
    "text": "LibGit2.rebase!(repo::GitRepo, upstream::AbstractString=\"\", newbase::AbstractString=\"\")\n\nAttempt an automatic merge rebase of the current branch, from upstream if provided, or otherwise from the upstream tracking branch. newbase is the branch to rebase onto. By default this is upstream.\n\nIf any conflicts arise which cannot be automatically resolved, the rebase will abort, leaving the repository and working tree in its original state, and the function will throw a GitError. This is roughly equivalent to the following command line statement:\n\ngit rebase --merge [<upstream>]\nif [ -d \".git/rebase-merge\" ]; then\n    git rebase --abort\nfi\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.ref_list",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.ref_list",
    "category": "function",
    "text": "LibGit2.ref_list(repo::GitRepo) -> Vector{String}\n\nGet a list of all reference names in the repo repository.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.reftype",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.reftype",
    "category": "function",
    "text": "LibGit2.reftype(ref::GitReference) -> Cint\n\nReturns a Cint corresponding to the type of ref:\n\n0 if the reference is invalid\n1 if the reference is an object id\n2 if the reference is symbolic\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.remotes",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.remotes",
    "category": "function",
    "text": "LibGit2.remotes(repo::GitRepo)\n\nReturns a vector of the names of the remotes of repo.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.reset!",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.reset!",
    "category": "function",
    "text": "Resets credentials for another use\n\n\n\nUpdates some entries, determined by the pathspecs, in the index from the target commit tree.\n\n\n\nSets the current head to the specified commit oid and optionally resets the index and working tree to match.\n\n\n\ngit reset [<committish>] [–] <pathspecs>... \n\n\n\nreset!(repo::GitRepo, id::GitHash, mode::Cint = Consts.RESET_MIXED)\n\nReset the repository repo to its state at id, using one of three modes set by mode:\n\nConsts.RESET_SOFT - move HEAD to id.\nConsts.RESET_MIXED - default, move HEAD to id and reset the index to id.\nConsts.RESET_HARD - move HEAD to id, reset the index to id, and discard all working changes.\n\nEquivalent to git reset [--soft | --mixed | --hard] <id>.\n\nExample\n\nrepo = LibGit2.GitRepo(repo_path)\nhead_oid = LibGit2.head_oid(repo)\nopen(joinpath(repo_path, \"file1\"), \"w\") do f\n    write(f, \"111\n\")\nend\nLibGit2.add!(repo, \"file1\")\nmode = LibGit2.Consts.RESET_HARD\n# will discard the changes to file1\n# and unstage it\nnew_head = LibGit2.reset!(repo, head_oid, mode)\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.restore",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.restore",
    "category": "function",
    "text": "restore(s::State, repo::GitRepo)\n\nReturn a repository repo to a previous State s, for example the HEAD of a branch before a merge attempt. s can be generated using the snapshot function.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.revcount",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.revcount",
    "category": "function",
    "text": "LibGit2.revcount(repo::GitRepo, commit1::AbstractString, commit2::AbstractString)\n\nList the number of revisions between commit1 and commit2 (committish OIDs in string form). Since commit1 and commit2 may be on different branches, revcount performs a \"left-right\" revision list (and count), returning a tuple of Ints - the number of left and right commits, respectively. A left (or right) commit refers to which side of a symmetric difference in a tree the commit is reachable from.\n\nEquivalent to git rev-list --left-right --count <commit1> <commit2>.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.set_remote_url",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.set_remote_url",
    "category": "function",
    "text": "set_remote_url(repo::GitRepo, url::AbstractString; remote::AbstractString=\"origin\")\n\nSet the url for remote for the git repository repo. The default name of the remote is \"origin\".\n\nExamples\n\nrepo_path = joinpath(\"test_directory\", \"Example\")\nrepo = LibGit2.init(repo_path)\nurl1 = \"https://github.com/JuliaLang/Example.jl\"\nLibGit2.set_remote_url(repo, url1, remote=\"upstream\")\nurl2 = \"https://github.com/JuliaLang/Example2.jl\"\nLibGit2.set_remote_url(repo_path, url2, remote=\"upstream2\")\n\n\n\nset_remote_url(path::AbstractString, url::AbstractString; remote::AbstractString=\"origin\")\n\nSet the url for remote for the git repository located at path. The default name of the remote is \"origin\".\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.shortname",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.shortname",
    "category": "function",
    "text": "LibGit2.shortname(ref::GitReference)\n\nReturns a shortened version of the name of ref that\'s \"human-readable\".\n\njulia> repo = LibGit2.GitRepo(path_to_repo);\n\njulia> branch_ref = LibGit2.head(repo);\n\njulia> LibGit2.name(branch_ref)\n\"refs/heads/master\"\n\njulia> LibGit2.shortname(branch_ref)\n\"master\"\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.snapshot",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.snapshot",
    "category": "function",
    "text": "snapshot(repo::GitRepo) -> State\n\nTake a snapshot of the current state of the repository repo, storing the current HEAD, index, and any uncommitted work. The output State can be used later during a call to restore to return the repository to the snapshotted state.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.status",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.status",
    "category": "function",
    "text": "LibGit2.status(repo::GitRepo, path::String)\n\nLookup the status of the file at path in the git repository repo. For instance, this can be used to check if the file at path has been modified and needs to be staged and committed.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.tag_create",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.tag_create",
    "category": "function",
    "text": "LibGit2.tag_create(repo::GitRepo, tag::AbstractString, commit; kwargs...)\n\nCreate a new git tag tag (e.g. \"v0.5\") in the repository repo, at the commit commit.\n\nThe keyword arguments are:\n\nmsg::AbstractString=\"\": the message for the tag.\nforce::Bool=false: if true, existing references will be overwritten.\nsig::Signature=Signature(repo): the tagger\'s signature.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.tag_delete",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.tag_delete",
    "category": "function",
    "text": "LibGit2.tag_delete(repo::GitRepo, tag::AbstractString)\n\nRemove the git tag tag from the repository repo.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.tag_list",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.tag_list",
    "category": "function",
    "text": "LibGit2.tag_list(repo::GitRepo) -> Vector{String}\n\nGet a list of all tags in the git repository repo.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.target",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.target",
    "category": "function",
    "text": "LibGit2.target(tag::GitTag)\n\nThe GitHash of the target object of tag.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.treewalk",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.treewalk",
    "category": "function",
    "text": "Traverse the entries in a tree and its subtrees in post or pre order.\n\nFunction parameter should have following signature:\n\n(Cstring, Ptr{Void}, Ptr{Void}) -> Cint\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.upstream",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.upstream",
    "category": "function",
    "text": "upstream(ref::GitReference) -> Nullable{GitReference}\n\nDetermine if the branch containing ref has a specified upstream branch.\n\nupstream returns a Nullable, which will be null if the requested branch does not have an upstream counterpart. If the upstream branch does exist, the Nullable contains a GitReference to the upstream branch.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.url",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.url",
    "category": "function",
    "text": "url(rmt::GitRemote)\n\nGet the fetch URL of a remote git repository.\n\nExample\n\njulia> repo_url = \"https://github.com/JuliaLang/Example.jl\";\n\njulia> repo = LibGit2.init(mktempdir());\n\njulia> remote = LibGit2.GitRemote(repo, \"origin\", repo_url);\n\njulia> LibGit2.url(remote)\n\"https://github.com/JuliaLang/Example.jl\"\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.with",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.with",
    "category": "function",
    "text": "Resource management helper function\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Base.LibGit2.workdir",
    "page": "Base.LibGit2",
    "title": "Base.LibGit2.workdir",
    "category": "function",
    "text": "LibGit2.workdir(repo::GitRepo)\n\nThe location of the working directory of repo. This will throw an error for bare repositories.\n\nnote: Note\nThis will typically be the parent directory of gitdir(repo), but can be different in some cases: e.g. if either the core.worktree configuration variable or the GIT_WORK_TREE environment variable is set.\n\nSee also gitdir, path.\n\n\n\n"
},

{
    "location": "devdocs/libgit2/#Functionality-1",
    "page": "Base.LibGit2",
    "title": "Functionality",
    "category": "section",
    "text": "Some of this documentation assumes some prior knowledge of the libgit2 API. For more information on some of the objects and methods referenced here, consult the upstream libgit2 API reference.Base.LibGit2.AbstractCredentials\nBase.LibGit2.Buffer\nBase.LibGit2.CachedCredentials\nBase.LibGit2.CheckoutOptions\nBase.LibGit2.CloneOptions\nBase.LibGit2.DiffDelta\nBase.LibGit2.DiffFile\nBase.LibGit2.DiffOptionsStruct\nBase.LibGit2.FetchHead\nBase.LibGit2.FetchOptions\nBase.LibGit2.GitBlob\nBase.LibGit2.GitCommit\nBase.LibGit2.GitHash\nBase.LibGit2.GitObject\nBase.LibGit2.GitRemote\nBase.LibGit2.GitRemoteAnon\nBase.LibGit2.GitRepo\nBase.LibGit2.GitRepoExt\nBase.LibGit2.GitShortHash\nBase.LibGit2.GitSignature\nBase.LibGit2.GitStatus\nBase.LibGit2.GitTag\nBase.LibGit2.GitTree\nBase.LibGit2.IndexEntry\nBase.LibGit2.IndexTime\nBase.LibGit2.MergeOptions\nBase.LibGit2.ProxyOptions\nBase.LibGit2.PushOptions\nBase.LibGit2.RebaseOperation\nBase.LibGit2.RebaseOptions\nBase.LibGit2.RemoteCallbacks\nBase.LibGit2.SSHCredentials\nBase.LibGit2.SignatureStruct\nBase.LibGit2.StatusEntry\nBase.LibGit2.StatusOptions\nBase.LibGit2.StrArrayStruct\nBase.LibGit2.TimeStruct\nBase.LibGit2.UserPasswordCredentials\nBase.LibGit2.add_fetch!\nBase.LibGit2.add_push!\nBase.LibGit2.addblob!\nBase.LibGit2.authors\nBase.LibGit2.branch\nBase.LibGit2.branch!\nBase.LibGit2.checkout!\nBase.LibGit2.checkused!\nBase.LibGit2.clone\nBase.LibGit2.commit\nBase.LibGit2.create_branch\nBase.LibGit2.credentials_callback\nBase.LibGit2.credentials_cb\nBase.LibGit2.default_signature\nBase.LibGit2.delete_branch\nBase.LibGit2.diff_files\nBase.LibGit2.fetch\nBase.LibGit2.fetch_refspecs\nBase.LibGit2.fetchhead_foreach_cb\nBase.LibGit2.ffmerge!\nBase.LibGit2.fullname\nBase.LibGit2.get_creds!\nBase.LibGit2.gitdir\nBase.LibGit2.head\nBase.LibGit2.head!\nBase.LibGit2.head_oid\nBase.LibGit2.headname\nBase.LibGit2.init\nBase.LibGit2.is_ancestor_of\nBase.LibGit2.isbinary\nBase.LibGit2.iscommit\nBase.LibGit2.isdiff\nBase.LibGit2.isdirty\nBase.LibGit2.isorphan\nBase.LibGit2.lookup_branch\nBase.LibGit2.mirror_callback\nBase.LibGit2.mirror_cb\nBase.LibGit2.name\nBase.LibGit2.need_update\nBase.LibGit2.objtype\nBase.LibGit2.path\nBase.LibGit2.peel\nBase.LibGit2.posixpath\nBase.LibGit2.push\nBase.LibGit2.push_refspecs\nBase.LibGit2.read_tree!\nBase.LibGit2.rebase!\nBase.LibGit2.ref_list\nBase.LibGit2.reftype\nBase.LibGit2.remotes\nBase.LibGit2.reset!\nBase.LibGit2.restore\nBase.LibGit2.revcount\nBase.LibGit2.set_remote_url\nBase.LibGit2.shortname\nBase.LibGit2.snapshot\nBase.LibGit2.status\nBase.LibGit2.tag_create\nBase.LibGit2.tag_delete\nBase.LibGit2.tag_list\nBase.LibGit2.target\nBase.LibGit2.treewalk\nBase.LibGit2.upstream\nBase.LibGit2.url\nBase.LibGit2.with\nBase.LibGit2.workdir"
},

{
    "location": "devdocs/require/#",
    "page": "Module loading",
    "title": "Module loading",
    "category": "page",
    "text": ""
},

{
    "location": "devdocs/require/#Module-loading-1",
    "page": "Module loading",
    "title": "Module loading",
    "category": "section",
    "text": "Base.require[@ref] is responsible for loading modules and it also manages the precompilation cache. It is the implementation of the import statement."
},

{
    "location": "devdocs/require/#Experimental-features-1",
    "page": "Module loading",
    "title": "Experimental features",
    "category": "section",
    "text": "The features below are experimental and not part of the stable Julia API. Before building upon them inform yourself about the current thinking and whether they might change soon."
},

{
    "location": "devdocs/require/#Module-loading-callbacks-1",
    "page": "Module loading",
    "title": "Module loading callbacks",
    "category": "section",
    "text": "It is possible to listen to the modules loaded by Base.require, by registering a callback.loaded_packages = Channel{Symbol}()\ncallback = (mod::Symbol) -> put!(loaded_packages, mod)\npush!(Base.package_callbacks, callback)Please note that the symbol given to the callback is a non-unique identifier and it is the responsibility of the callback provider to walk the module chain to determine the fully qualified name of the loaded binding.The callback below is an example of how to do that:# Get the fully-qualified name of a module.\nfunction module_fqn(name::Symbol)\n    fqn = Symbol[name]\n    mod = getfield(Main, name)\n    parent = Base.module_parent(mod)\n    while parent !== Main\n        push!(fqn, Base.module_name(parent))\n        parent = Base.module_parent(parent)\n    end\n    fqn = reverse!(fqn)\n    return join(fqn, \'.\')\nend"
},

{
    "location": "devdocs/backtraces/#",
    "page": "Reporting and analyzing crashes (segfaults)",
    "title": "Reporting and analyzing crashes (segfaults)",
    "category": "page",
    "text": ""
},

{
    "location": "devdocs/backtraces/#Reporting-and-analyzing-crashes-(segfaults)-1",
    "page": "Reporting and analyzing crashes (segfaults)",
    "title": "Reporting and analyzing crashes (segfaults)",
    "category": "section",
    "text": "So you managed to break Julia.  Congratulations!  Collected here are some general procedures you can undergo for common symptoms encountered when something goes awry.  Including the information from these debugging steps can greatly help the maintainers when tracking down a segfault or trying to figure out why your script is running slower than expected.If you\'ve been directed to this page, find the symptom that best matches what you\'re experiencing and follow the instructions to generate the debugging information requested.  Table of symptoms:Segfaults during bootstrap (sysimg.jl)\nSegfaults when running a script\nErrors during Julia startup"
},

{
    "location": "devdocs/backtraces/#dev-version-info-1",
    "page": "Reporting and analyzing crashes (segfaults)",
    "title": "Version/Environment info",
    "category": "section",
    "text": "No matter the error, we will always need to know what version of Julia you are running. When Julia first starts up, a header is printed out with a version number and date.  If your version is 0.2.0 or higher, please include the output of versioninfo() in any report you create:versioninfo()"
},

{
    "location": "devdocs/backtraces/#Segfaults-during-bootstrap-(sysimg.jl)-1",
    "page": "Reporting and analyzing crashes (segfaults)",
    "title": "Segfaults during bootstrap (sysimg.jl)",
    "category": "section",
    "text": "Segfaults toward the end of the make process of building Julia are a common symptom of something going wrong while Julia is preparsing the corpus of code in the base/ folder.  Many factors can contribute toward this process dying unexpectedly, however it is as often as not due to an error in the C-code portion of Julia, and as such must typically be debugged with a debug build inside of gdb.  Explicitly:Create a debug build of Julia:$ cd <julia_root>\n$ make debugNote that this process will likely fail with the same error as a normal make incantation, however this will create a debug executable that will offer gdb the debugging symbols needed to get accurate backtraces.  Next, manually run the bootstrap process inside of gdb:$ cd base/\n$ gdb -x ../contrib/debug_bootstrap.gdbThis will start gdb, attempt to run the bootstrap process using the debug build of Julia, and print out a backtrace if (when) it segfaults.  You may need to hit <enter> a few times to get the full backtrace.  Create a gist with the backtrace, the version info, and any other pertinent information you can think of and open a new issue on Github with a link to the gist."
},

{
    "location": "devdocs/backtraces/#Segfaults-when-running-a-script-1",
    "page": "Reporting and analyzing crashes (segfaults)",
    "title": "Segfaults when running a script",
    "category": "section",
    "text": "The procedure is very similar to Segfaults during bootstrap (sysimg.jl).  Create a debug build of Julia, and run your script inside of a debugged Julia process:$ cd <julia_root>\n$ make debug\n$ gdb --args usr/bin/julia-debug <path_to_your_script>Note that gdb will sit there, waiting for instructions.  Type r to run the process, and bt to generate a backtrace once it segfaults:(gdb) r\nStarting program: /home/sabae/src/julia/usr/bin/julia-debug ./test.jl\n...\n(gdb) btCreate a gist with the backtrace, the version info, and any other pertinent information you can think of and open a new issue on Github with a link to the gist."
},

{
    "location": "devdocs/backtraces/#Errors-during-Julia-startup-1",
    "page": "Reporting and analyzing crashes (segfaults)",
    "title": "Errors during Julia startup",
    "category": "section",
    "text": "Occasionally errors occur during Julia\'s startup process (especially when using binary distributions, as opposed to compiling from source) such as the following:$ julia\nexec: error -5These errors typically indicate something is not getting loaded properly very early on in the bootup phase, and our best bet in determining what\'s going wrong is to use external tools to audit the disk activity of the julia process:On Linux, use strace:\n$ strace julia\nOn OSX, use dtruss:\n$ dtruss -f juliaCreate a gist with the strace/ dtruss ouput, the version info, and any other pertinent information and open a new issue on Github with a link to the gist."
},

{
    "location": "devdocs/backtraces/#Glossary-1",
    "page": "Reporting and analyzing crashes (segfaults)",
    "title": "Glossary",
    "category": "section",
    "text": "A few terms have been used as shorthand in this guide:<julia_root> refers to the root directory of the Julia source tree; e.g. it should contain folders such as base, deps, src, test, etc....."
},

{
    "location": "devdocs/debuggingtips/#",
    "page": "gdb debugging tips",
    "title": "gdb debugging tips",
    "category": "page",
    "text": ""
},

{
    "location": "devdocs/debuggingtips/#gdb-debugging-tips-1",
    "page": "gdb debugging tips",
    "title": "gdb debugging tips",
    "category": "section",
    "text": ""
},

{
    "location": "devdocs/debuggingtips/#Displaying-Julia-variables-1",
    "page": "gdb debugging tips",
    "title": "Displaying Julia variables",
    "category": "section",
    "text": "Within gdb, any jl_value_t* object obj can be displayed using(gdb) call jl_(obj)The object will be displayed in the julia session, not in the gdb session. This is a useful way to discover the types and values of objects being manipulated by Julia\'s C code.Similarly, if you\'re debugging some of Julia\'s internals (e.g., inference.jl), you can print obj usingccall(:jl_, Void, (Any,), obj)This is a good way to circumvent problems that arise from the order in which julia\'s output streams are initialized.Julia\'s flisp interpreter uses value_t objects; these can be displayed with call fl_print(fl_ctx, ios_stdout, obj)."
},

{
    "location": "devdocs/debuggingtips/#Useful-Julia-variables-for-Inspecting-1",
    "page": "gdb debugging tips",
    "title": "Useful Julia variables for Inspecting",
    "category": "section",
    "text": "While the addresses of many variables, like singletons, can be be useful to print for many failures, there are a number of additional variables (see julia.h for a complete list) that are even more useful.(when in jl_apply_generic) mfunc and jl_uncompress_ast(mfunc->def, mfunc->code) :: for figuring out a bit about the call-stack\njl_lineno and jl_filename :: for figuring out what line in a test to go start debugging from (or figure out how far into a file has been parsed)\n$1 :: not really a variable, but still a useful shorthand for referring to the result of the last gdb command (such as print)\njl_options :: sometimes useful, since it lists all of the command line options that were successfully parsed\njl_uv_stderr :: because who doesn\'t like to be able to interact with stdio"
},

{
    "location": "devdocs/debuggingtips/#Useful-Julia-functions-for-Inspecting-those-variables-1",
    "page": "gdb debugging tips",
    "title": "Useful Julia functions for Inspecting those variables",
    "category": "section",
    "text": "jl_gdblookup($rip) :: For looking up the current function and line. (use $eip on i686 platforms)\njlbacktrace() :: For dumping the current Julia backtrace stack to stderr. Only usable after record_backtrace() has been called.\njl_dump_llvm_value(Value*) :: For invoking Value->dump() in gdb, where it doesn\'t work natively. For example, f->linfo->functionObject, f->linfo->specFunctionObject, and to_function(f->linfo).\nType->dump() :: only works in lldb. Note: add something like ;1 to prevent lldb from printing its prompt over the output\njl_eval_string(\"expr\") :: for invoking side-effects to modify the current state or to lookup symbols\njl_typeof(jl_value_t*) :: for extracting the type tag of a Julia value (in gdb, call macro define jl_typeof jl_typeof first, or pick something short like ty for the first arg to define a shorthand)"
},

{
    "location": "devdocs/debuggingtips/#Inserting-breakpoints-for-inspection-from-gdb-1",
    "page": "gdb debugging tips",
    "title": "Inserting breakpoints for inspection from gdb",
    "category": "section",
    "text": "In your gdb session, set a breakpoint in jl_breakpoint like so:(gdb) break jl_breakpointThen within your Julia code, insert a call to jl_breakpoint by addingccall(:jl_breakpoint, Void, (Any,), obj)where obj can be any variable or tuple you want to be accessible in the breakpoint.It\'s particularly helpful to back up to the jl_apply frame, from which you can display the arguments to a function using, e.g.,(gdb) call jl_(args[0])Another useful frame is to_function(jl_method_instance_t *li, bool cstyle). The jl_method_instance_t* argument is a struct with a reference to the final AST sent into the compiler. However, the AST at this point will usually be compressed; to view the AST, call jl_uncompress_ast and then pass the result to jl_:#2  0x00007ffff7928bf7 in to_function (li=0x2812060, cstyle=false) at codegen.cpp:584\n584          abort();\n(gdb) p jl_(jl_uncompress_ast(li, li->ast))"
},

{
    "location": "devdocs/debuggingtips/#Inserting-breakpoints-upon-certain-conditions-1",
    "page": "gdb debugging tips",
    "title": "Inserting breakpoints upon certain conditions",
    "category": "section",
    "text": ""
},

{
    "location": "devdocs/debuggingtips/#Loading-a-particular-file-1",
    "page": "gdb debugging tips",
    "title": "Loading a particular file",
    "category": "section",
    "text": "Let\'s say the file is sysimg.jl:(gdb) break jl_load if strcmp(fname, \"sysimg.jl\")==0"
},

{
    "location": "devdocs/debuggingtips/#Calling-a-particular-method-1",
    "page": "gdb debugging tips",
    "title": "Calling a particular method",
    "category": "section",
    "text": "(gdb) break jl_apply_generic if strcmp((char*)(jl_symbol_name)(jl_gf_mtable(F)->name), \"method_to_break\")==0Since this function is used for every call, you will make everything 1000x slower if you do this."
},

{
    "location": "devdocs/debuggingtips/#Dealing-with-signals-1",
    "page": "gdb debugging tips",
    "title": "Dealing with signals",
    "category": "section",
    "text": "Julia requires a few signal to function property. The profiler uses SIGUSR2 for sampling and the garbage collector uses SIGSEGV for threads synchronization. If you are debugging some code that uses the profiler or multiple threads, you may want to let the debugger ignore these signals since they can be triggered very often during normal operations. The command to do this in GDB is (replace SIGSEGV with SIGUSRS or other signals you want to ignore):(gdb) handle SIGSEGV noprint nostop passThe corresponding LLDB command is (after the process is started):(lldb) pro hand -p true -s false -n false SIGSEGVIf you are debugging a segfault with threaded code, you can set a breakpoint on jl_critical_error (sigdie_handler should also work on Linux and BSD) in order to only catch the actual segfault rather than the GC synchronization points."
},

{
    "location": "devdocs/debuggingtips/#Debugging-during-Julia\'s-build-process-(bootstrap)-1",
    "page": "gdb debugging tips",
    "title": "Debugging during Julia\'s build process (bootstrap)",
    "category": "section",
    "text": "Errors that occur during make need special handling. Julia is built in two stages, constructing sys0 and sys.ji. To see what commands are running at the time of failure, use make VERBOSE=1.At the time of this writing, you can debug build errors during the sys0 phase from the base directory using:julia/base$ gdb --args ../usr/bin/julia-debug -C native --build ../usr/lib/julia/sys0 sysimg.jlYou might need to delete all the files in usr/lib/julia/ to get this to work.You can debug the sys.ji phase using:julia/base$ gdb --args ../usr/bin/julia-debug -C native --build ../usr/lib/julia/sys -J ../usr/lib/julia/sys0.ji sysimg.jlBy default, any errors will cause Julia to exit, even under gdb. To catch an error \"in the act\", set a breakpoint in jl_error (there are several other useful spots, for specific kinds of failures, including: jl_too_few_args, jl_too_many_args, and jl_throw).Once an error is caught, a useful technique is to walk up the stack and examine the function by inspecting the related call to jl_apply. To take a real-world example:Breakpoint 1, jl_throw (e=0x7ffdf42de400) at task.c:802\n802 {\n(gdb) p jl_(e)\nErrorException(\"auto_unbox: unable to determine argument type\")\n$2 = void\n(gdb) bt 10\n#0  jl_throw (e=0x7ffdf42de400) at task.c:802\n#1  0x00007ffff65412fe in jl_error (str=0x7ffde56be000 <_j_str267> \"auto_unbox:\n   unable to determine argument type\")\n   at builtins.c:39\n#2  0x00007ffde56bd01a in julia_convert_16886 ()\n#3  0x00007ffff6541154 in jl_apply (f=0x7ffdf367f630, args=0x7fffffffc2b0, nargs=2) at julia.h:1281\n...The most recent jl_apply is at frame #3, so we can go back there and look at the AST for the function julia_convert_16886. This is the uniqued name for some method of convert. f in this frame is a jl_function_t*, so we can look at the type signature, if any, from the specTypes field:(gdb) f 3\n#3  0x00007ffff6541154 in jl_apply (f=0x7ffdf367f630, args=0x7fffffffc2b0, nargs=2) at julia.h:1281\n1281            return f->fptr((jl_value_t*)f, args, nargs);\n(gdb) p f->linfo->specTypes\n$4 = (jl_tupletype_t *) 0x7ffdf39b1030\n(gdb) p jl_( f->linfo->specTypes )\nTuple{Type{Float32}, Float64}           # <-- type signature for julia_convert_16886Then, we can look at the AST for this function:(gdb) p jl_( jl_uncompress_ast(f->linfo, f->linfo->ast) )\nExpr(:lambda, Array{Any, 1}[:#s29, :x], Array{Any, 1}[Array{Any, 1}[], Array{Any, 1}[Array{Any, 1}[:#s29, :Any, 0], Array{Any, 1}[:x, :Any, 0]], Array{Any, 1}[], 0], Expr(:body,\nExpr(:line, 90, :float.jl)::Any,\nExpr(:return, Expr(:call, :box, :Float32, Expr(:call, :fptrunc, :Float32, :x)::Any)::Any)::Any)::Any)::AnyFinally, and perhaps most usefully, we can force the function to be recompiled in order to step through the codegen process. To do this, clear the cached functionObject from the jl_lamdbda_info_t*:(gdb) p f->linfo->functionObject\n$8 = (void *) 0x1289d070\n(gdb) set f->linfo->functionObject = NULLThen, set a breakpoint somewhere useful (e.g. emit_function, emit_expr, emit_call, etc.), and run codegen:(gdb) p jl_compile(f)\n... # your breakpoint here"
},

{
    "location": "devdocs/debuggingtips/#Debugging-precompilation-errors-1",
    "page": "gdb debugging tips",
    "title": "Debugging precompilation errors",
    "category": "section",
    "text": "Module precompilation spawns a separate Julia process to precompile each module. Setting a breakpoint or catching failures in a precompile worker requires attaching a debugger to the worker. The easiest approach is to set the debugger watch for new process launches matching a given name. For example:(gdb) attach -w -n julia-debugor:(lldb) process attach -w -n julia-debugThen run a script/command to start precompilation. As described earlier, use conditional breakpoints in the parent process to catch specific file-loading events and narrow the debugging window. (some operating systems may require alternative approaches, such as following each fork from the parent process)"
},

{
    "location": "devdocs/debuggingtips/#Mozilla\'s-Record-and-Replay-Framework-(rr)-1",
    "page": "gdb debugging tips",
    "title": "Mozilla\'s Record and Replay Framework (rr)",
    "category": "section",
    "text": "Julia now works out of the box with rr, the lightweight recording and deterministic debugging framework from Mozilla. This allows you to replay the trace of an execution deterministically.  The replayed execution\'s address spaces, register contents, syscall data etc are exactly the same in every run.A recent version of rr (3.1.0 or higher) is required."
},

{
    "location": "devdocs/valgrind/#",
    "page": "Using Valgrind with Julia",
    "title": "Using Valgrind with Julia",
    "category": "page",
    "text": ""
},

{
    "location": "devdocs/valgrind/#Using-Valgrind-with-Julia-1",
    "page": "Using Valgrind with Julia",
    "title": "Using Valgrind with Julia",
    "category": "section",
    "text": "Valgrind is a tool for memory debugging, memory leak detection, and profiling.  This section describes things to keep in mind when using Valgrind to debug memory issues with Julia."
},

{
    "location": "devdocs/valgrind/#General-considerations-1",
    "page": "Using Valgrind with Julia",
    "title": "General considerations",
    "category": "section",
    "text": "By default, Valgrind assumes that there is no self modifying code in the programs it runs.  This assumption works fine in most instances but fails miserably for a just-in-time compiler like julia.  For this reason it is crucial to pass --smc-check=all-non-file to valgrind, else code may crash or behave unexpectedly (often in subtle ways).In some cases, to better detect memory errors using Valgrind it can help to compile julia with memory pools disabled.  The compile-time flag MEMDEBUG disables memory pools in Julia, and MEMDEBUG2 disables memory pools in FemtoLisp.  To build julia with both flags, add the following line to Make.user:CFLAGS = -DMEMDEBUG -DMEMDEBUG2Another thing to note: if your program uses multiple workers processes, it is likely that you want all such worker processes to run under Valgrind, not just the parent process.  To do this, pass --trace-children=yes to valgrind."
},

{
    "location": "devdocs/valgrind/#Suppressions-1",
    "page": "Using Valgrind with Julia",
    "title": "Suppressions",
    "category": "section",
    "text": "Valgrind will typically display spurious warnings as it runs.  To reduce the number of such warnings, it helps to provide a suppressions file to Valgrind.  A sample suppressions file is included in the Julia source distribution at contrib/valgrind-julia.supp.The suppressions file can be used from the julia/ source directory as follows:$ valgrind --smc-check=all-non-file --suppressions=contrib/valgrind-julia.supp ./julia progname.jlAny memory errors that are displayed should either be reported as bugs or contributed as additional suppressions.  Note that some versions of Valgrind are shipped with insufficient default suppressions, so that may be one thing to consider before submitting any bugs."
},

{
    "location": "devdocs/valgrind/#Running-the-Julia-test-suite-under-Valgrind-1",
    "page": "Using Valgrind with Julia",
    "title": "Running the Julia test suite under Valgrind",
    "category": "section",
    "text": "It is possible to run the entire Julia test suite under Valgrind, but it does take quite some time (typically several hours).  To do so, run the following command from the julia/test/ directory:valgrind --smc-check=all-non-file --trace-children=yes --suppressions=$PWD/../contrib/valgrind-julia.supp ../julia runtests.jl allIf you would like to see a report of \"definite\" memory leaks, pass the flags --leak-check=full --show-leak-kinds=definite to valgrind as well."
},

{
    "location": "devdocs/valgrind/#Caveats-1",
    "page": "Using Valgrind with Julia",
    "title": "Caveats",
    "category": "section",
    "text": "Valgrind currently does not support multiple rounding modes, so code that adjusts the rounding mode will behave differently when run under Valgrind.In general, if after setting --smc-check=all-non-file you find that your program behaves differently when run under Valgrind, it may help to pass --tool=none to valgrind as you investigate further.  This will enable the minimal Valgrind machinery but will also run much faster than when the full memory checker is enabled."
},

{
    "location": "devdocs/sanitizers/#",
    "page": "Sanitizer support",
    "title": "Sanitizer support",
    "category": "page",
    "text": ""
},

{
    "location": "devdocs/sanitizers/#Sanitizer-support-1",
    "page": "Sanitizer support",
    "title": "Sanitizer support",
    "category": "section",
    "text": ""
},

{
    "location": "devdocs/sanitizers/#General-considerations-1",
    "page": "Sanitizer support",
    "title": "General considerations",
    "category": "section",
    "text": "Using Clang\'s sanitizers obviously require you to use Clang (USECLANG=1), but there\'s another catch: most sanitizers require a run-time library, provided by the host compiler, while the instrumented code generated by Julia\'s JIT relies on functionality from that library. This implies that the LLVM version of your host compiler matches that of the LLVM library used within Julia.An easy solution is to have an dedicated build folder for providing a matching toolchain, by building with BUILD_LLVM_CLANG=1 and overriding LLVM_USE_CMAKE=1 (Autotool-based builds are incompatible with ASAN). You can then refer to this toolchain from another build folder by specifying USECLANG=1 while overriding the CC and CXX variables."
},

{
    "location": "devdocs/sanitizers/#Address-Sanitizer-(ASAN)-1",
    "page": "Sanitizer support",
    "title": "Address Sanitizer (ASAN)",
    "category": "section",
    "text": "For detecting or debugging memory bugs, you can use Clang\'s address sanitizer (ASAN). By compiling with SANITIZE=1 you enable ASAN for the Julia compiler and its generated code. In addition, you can specify LLVM_SANITIZE=1 to sanitize the LLVM library as well. Note that these options incur a high performance and memory cost. For example, using ASAN for Julia and LLVM makes testall1 takes 8-10 times as long while using 20 times as much memory (this can be reduced to respectively a factor of 3 and 4 by using the options described below).By default, Julia sets the allow_user_segv_handler=1 ASAN flag, which is required for signal delivery to work properly. You can define other options using the ASAN_OPTIONS environment flag, in which case you\'ll need to repeat the default option mentioned before. For example, memory usage can be reduced by specifying fast_unwind_on_malloc=0 and malloc_context_size=2, at the cost of backtrace accuracy. For now, Julia also sets detect_leaks=0, but this should be removed in the future."
},

{
    "location": "devdocs/sanitizers/#Memory-Sanitizer-(MSAN)-1",
    "page": "Sanitizer support",
    "title": "Memory Sanitizer (MSAN)",
    "category": "section",
    "text": "For detecting use of uninitialized memory, you can use Clang\'s memory sanitizer (MSAN) by compiling with SANITIZE_MEMORY=1."
},

]}
